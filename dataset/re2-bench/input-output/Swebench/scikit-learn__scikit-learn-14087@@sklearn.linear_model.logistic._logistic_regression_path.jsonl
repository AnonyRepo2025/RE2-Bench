{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.63251292 0.458337   0.46550902]]", "[1.]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]", "data": "[-1.  1.  1.  1.]"}, "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.63251292 0.458337   0.46550902]]", "[1.]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.59106196 0.59106196]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]", "data": "[-1.  1.  1.  1.]"}, "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.59106196 0.59106196]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 int"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[1. 1.]]", "y": "[1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]\n [3.30222655e-11 3.30222655e-11 9.76234039e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[15  0  0  0  0  0  0  0  0  0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 int"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[1. 1.]]", "y": "[1]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[5.76191416e-05 5.76191416e-05 1.03158958e+01]\n [5.76191416e-05 5.76191416e-05 1.03158958e+01]\n [5.76191416e-05 5.76191416e-05 1.03158958e+01]\n [5.76191416e-05 5.76191416e-05 1.03158958e+01]]", "[1 2 3 4]", "[16  0  0  0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]]", "y": "[0 1]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.40104279 0.40104279 0.        ]\n [0.67470291 0.67470291 0.        ]\n [0.87956271 0.87956271 0.        ]\n [1.0425282  1.0425282  0.        ]]", "[1 2 3 4]", "[3 1 1 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[0.43981016 0.43981016 5.15794789]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[1.16123019 0.91439449 0.33652   ]]", "[3]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]]", "y": "[0 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[4.99987264e-05 4.99987264e-05 0.00000000e+00]\n [3.87055691e-04 3.87055691e-04 0.00000000e+00]\n [2.99286296e-03 2.99286296e-03 0.00000000e+00]\n [2.29377994e-02 2.29377994e-02 0.00000000e+00]\n [1.64907923e-01 1.64907923e-01 0.00000000e+00]\n [8.39390746e-01 8.39390746e-01 0.00000000e+00]\n [2.18271217e+00 2.18271217e+00 0.00000000e+00]\n [3.76681352e+00 3.76681352e+00 0.00000000e+00]\n [5.45876181e+00 5.45876181e+00 0.00000000e+00]\n [7.17690880e+00 7.17690880e+00 0.00000000e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[1 1 1 1 2 3 5 5 5 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[2.49993797e-05 2.49993797e-05 4.88117019e+00]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[9.99942156e-05 6.66634311e-05 6.93103322e-01]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[2 1 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 2.10694488  0.08342043 -0.35381187]\n  [-0.5916486   1.29532673 -0.30889927]\n  [-1.51529628 -1.37874717  0.66271115]]]", "[10]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]", "data": "[-1.  1.  1.  1.]"}, "y": "[2 1 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 2.10694488  0.08342043 -0.35381187]\n  [-0.5916486   1.29532673 -0.30889927]\n  [-1.51529628 -1.37874717  0.66271115]]]", "[10]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[  2.26258364   4.22943943  -6.7635422   -3.83354544   5.59902217]\n  [  0.08692762   0.30074645  -0.42307949  -4.62215934  12.36469379]\n  [ -2.34951126  -4.53018588   7.18662169   8.45570478 -17.96371596]]]", "[150]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.41096929   3.67010491  -6.79506449  -3.79547263  21.06358824]\n  [  1.39016498   0.53367881  -0.5007139   -4.80742549   5.7131182 ]\n  [ -0.9791957   -4.20378372   7.29577839   8.60289812 -26.77670644]]]", "[150]", "[22]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": "setosa", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.53887276  1.8474007  -2.8819417  -1.34941566  0.35898982]]", "[150]", "[16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": "versicolor", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.66717593 -2.10759858  0.68917861 -2.01242878  1.45676814]]", "[150]", "[36]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": "virginica", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-2.70664572 -2.49709553  3.95484691  3.92034825 -1.78151657]]", "[150]", "[39]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": "setosa", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.47285228  1.60348206 -2.51419828 -1.15854006  0.30922301]]", "[150]", "[24]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": "versicolor", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.63895699 -1.87387925  0.56329751 -1.62067165  0.94528182]]", "[150]", "[46]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": "virginica", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-2.17240596 -1.921588    3.1546758   2.98150795 -1.27492648]]", "[150]", "[44]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.23190559  0.54969466 -1.33579098 -0.57072713  3.60068632]]]", "[1.]", "[31]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.25832855  0.86084736 -1.30339903 -0.59645662]]]", "[1.]", "[26]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.23172983  0.54979429 -1.33576548 -0.57073036  3.59939353]]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.25833116  0.86084374 -1.30340026 -0.59645755]]]", "[1.]", "[12]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.12602646  0.61494557 -1.32106301 -0.57297639  2.80888902]]]", "[1.]", "[1121]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.25994365  0.85851998 -1.30300641 -0.60006133]]]", "[1.]", "[55]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.02058678  0.68080745 -1.31089939 -0.57716539  2.02964006]]]", "[1.]", "[1218]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa' 'not-setosa'\n 'not-setosa']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.26057675  0.85666158 -1.30240745 -0.59933164]]]", "[1.]", "[70]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.41796398   0.96618786  -2.52148566  -1.08399394   9.83857507]\n  [  0.53085183  -0.31438328  -0.19906402  -0.94910998   2.2145103 ]\n  [ -0.11288784  -0.65180458   2.72054969   2.03310393 -12.05308537]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "float", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411\n  0.43758721 0.891773   0.96366276 0.38344152]\n [0.79172504 0.52889492 0.56804456 0.92559664 0.07103606 0.0871293\n  0.0202184  0.83261985 0.77815675 0.87001215]\n [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443 0.63992102\n  0.14335329 0.94466892 0.52184832 0.41466194]\n [0.26455561 0.77423369 0.45615033 0.56843395 0.0187898  0.6176355\n  0.61209572 0.616934   0.94374808 0.6818203 ]\n [0.3595079  0.43703195 0.6976312  0.06022547 0.66676672 0.67063787\n  0.21038256 0.1289263  0.31542835 0.36371077]]", "y": "[0. 1. 1. 1. 1.]"}, "kwargs": {"pos_class": 1.0, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.03348603 -0.05599505 -0.04680467  0.02921864 -0.16188306 -0.10207728\n  -0.1379556  -0.19859974 -0.2439729   0.15122523  1.77751897]]", "[1.]", "[11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "np.ndarray[float64]", "fit_intercept": "bool", "tol": "float", "solver": "str", "max_iter": "int", "multi_class": "str", "random_state": "int"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": "[1.00000000e+00 2.78255940e+00 7.74263683e+00 2.15443469e+01\n 5.99484250e+01 1.66810054e+02 4.64158883e+02 1.29154967e+03\n 3.59381366e+03 1.00000000e+04]", "fit_intercept": false, "tol": 1e-05, "solver": "sag", "max_iter": 1000, "multi_class": "ovr", "random_state": 0}}, "return": ["[[0.85609544 0.90212178]\n [0.87501852 0.92049059]\n [0.88219598 0.92741875]\n [0.88481997 0.92993913]\n [0.88577044 0.93087473]\n [0.88610629 0.93120839]\n [0.88623193 0.93132931]\n [0.8862759  0.93136633]\n [0.88629438 0.93138443]\n [0.88629703 0.93138775]]", "[1.00000000e+00 2.78255940e+00 7.74263683e+00 2.15443469e+01\n 5.99484250e+01 1.66810054e+02 4.64158883e+02 1.29154967e+03\n 3.59381366e+03 1.00000000e+04]", "[28 21 18 18 15 12 12  9  6  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-05, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1000, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[0.85609544 0.90212178]]", "[1.]", "[28]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "np.ndarray[float64]", "fit_intercept": "bool", "tol": "float", "solver": "str", "max_iter": "int", "multi_class": "str", "random_state": "int"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": "[1.00000000e+00 2.78255940e+00 7.74263683e+00 2.15443469e+01\n 5.99484250e+01 1.66810054e+02 4.64158883e+02 1.29154967e+03\n 3.59381366e+03 1.00000000e+04]", "fit_intercept": false, "tol": 1e-05, "solver": "saga", "max_iter": 1000, "multi_class": "ovr", "random_state": 0}}, "return": ["[[0.85609407 0.9021207 ]\n [0.87502211 0.92049303]\n [0.88218937 0.92742221]\n [0.8848185  0.92995951]\n [0.88576864 0.9308916 ]\n [0.8861027  0.93120634]\n [0.8862359  0.93132555]\n [0.8862821  0.93137091]\n [0.88629075 0.93138591]\n [0.88629807 0.93138876]]", "[1.00000000e+00 2.78255940e+00 7.74263683e+00 2.15443469e+01\n 5.99484250e+01 1.66810054e+02 4.64158883e+02 1.29154967e+03\n 3.59381366e+03 1.00000000e+04]", "[18 11 11  8  7  5  4  2  2  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-05, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1000, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[0.85609407 0.9021207 ]]", "[1.]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "solver": "str", "intercept_scaling": "float", "random_state": "int", "multi_class": "str"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": null, "fit_intercept": true, "tol": 1e-06, "solver": "lbfgs", "intercept_scaling": 10000.0, "random_state": 0, "multi_class": "ovr"}}, "return": ["[[ 1.28113485  1.43600576 -1.24540106]]", "[1000.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.28113485  1.43600576 -1.24540106]]", "[1000.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "solver": "str", "intercept_scaling": "float", "random_state": "int", "multi_class": "str"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": null, "fit_intercept": true, "tol": 1e-06, "solver": "newton-cg", "intercept_scaling": 10000.0, "random_state": 0, "multi_class": "ovr"}}, "return": ["[[ 1.28113635  1.43600308 -1.24540022]]", "[1000.]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.28113423  1.43599955 -1.24539658]]", "[1000.]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "solver": "str", "intercept_scaling": "float", "random_state": "int", "multi_class": "str"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": null, "fit_intercept": true, "tol": 1e-06, "solver": "liblinear", "intercept_scaling": 10000.0, "random_state": 0, "multi_class": "ovr"}}, "return": ["[[ 1.2811356   1.43600257 -1.24539967]]", "[1000.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "solver": "str", "intercept_scaling": "float", "random_state": "int", "multi_class": "str"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": null, "fit_intercept": true, "tol": 1e-06, "solver": "sag", "intercept_scaling": 10000.0, "random_state": 0, "multi_class": "ovr"}}, "return": ["[[ 1.28113694  1.43600247 -1.24539899]]", "[1000.]", "[32]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[ 1.28117888  1.43605376 -1.24541095]]", "[1000.]", "[21]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "solver": "str", "intercept_scaling": "float", "random_state": "int", "multi_class": "str"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": null, "fit_intercept": true, "tol": 1e-06, "solver": "saga", "intercept_scaling": 10000.0, "random_state": 0, "multi_class": "ovr"}}, "return": ["[[ 1.28113691  1.43600388 -1.24539948]]", "[1000.]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[ 1.28121976  1.4361309  -1.24535938]]", "[1000.]", "[13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "null value in the ground truth"}, "kwargs": {"Cs": "null value in the ground truth", "tol": "float", "max_iter": "int", "random_state": "int", "verbose": "int"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": null}, "kwargs": {"Cs": null, "tol": 0.0, "max_iter": 1, "random_state": 0, "verbose": 1}}, "return": ["[[0.67284971 0.7397792  0.        ]]", "[1000.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-7.19396057e-01 -9.06111206e-01 -6.13020823e-01 -3.44677291e-01\n   2.44801040e-02]\n [-1.20161621e+00  8.72447879e-01  4.35580277e-01 -1.57416279e+00\n   1.46217321e+00]\n [ 1.87140598e+00  1.15148908e+00 -2.12534306e-01 -1.10684945e+00\n   1.02667452e+00]\n [ 6.77434109e-01 -2.13639855e-02  1.76095660e+00  9.55038097e-02\n   3.71657937e-01]\n [ 1.85861763e+00 -1.38494030e+00 -1.30736373e+00  9.41286535e-01\n  -1.20962099e+00]\n [ 1.91932485e+00 -4.47143303e-01 -7.82286015e-01  1.89856474e+00\n   1.45440551e+00]\n [ 7.73692694e-01  9.19055103e-01 -1.87522029e-01  5.84578221e-01\n   8.93911761e-01]\n [ 3.45994029e-01 -1.13560977e+00  2.67500589e-01  1.29967324e+00\n  -7.29192025e-01]\n [-1.82125432e-01 -4.68762177e-01  1.82459801e+00  6.43021506e-01\n   3.77151833e-01]\n [-8.04835208e-01  5.09455102e-01 -7.08877610e-01  5.00556011e-05\n  -6.70240363e-01]\n [ 6.47176246e-01  5.46942910e-01 -2.41019302e-01  3.65651866e-01\n  -1.12924567e+00]\n [-1.52900059e+00  4.09206695e-01  1.35420868e-01  6.05612310e-01\n   2.36056906e+00]\n [ 9.16271769e-01 -9.48300800e-01  1.08948401e+00 -1.35296396e+00\n  -4.95296700e-01]\n [-1.00413865e-01  1.68814490e+00 -7.79575456e-01 -8.61578943e-01\n  -1.30743052e-01]\n [-6.97980744e-01  1.09914130e+00 -1.11606427e+00 -1.18386581e+00\n  -4.71439108e-01]\n [-5.31887230e-01  1.90518056e+00  9.21232433e-01  5.59888708e-02\n  -1.26213789e+00]\n [ 8.15763328e-01 -1.03603604e+00 -1.58272359e+00  1.16077551e+00\n   2.86278249e-01]\n [ 8.92558637e-01  2.88070278e-01  8.28279771e-01 -6.85479301e-01\n  -1.07019675e+00]\n [ 6.52357674e-01 -8.38459917e-01 -7.24154298e-01 -4.89220907e-01\n  -1.43575257e-02]\n [-3.87284817e-01 -1.41223898e+00 -6.78043114e-01 -2.26401231e+00\n   5.95773960e-01]\n [-1.64023441e+00 -1.14061183e+00  2.04641810e-02 -7.74363306e-01\n   1.51714999e+00]\n [-1.32982322e+00  2.36191193e-01 -7.13417114e-02 -1.20457139e+00\n   4.93420042e-01]\n [-2.04123002e-01  7.42906801e-01  7.94822849e-01  2.13979935e+00\n   1.30985500e+00]\n [-4.02532201e-01 -2.72221396e-01  1.07205937e+00  6.25923808e-01\n   6.10732365e-01]\n [-1.65519112e+00 -5.63264660e-02 -7.72825221e-01  2.49115320e-01\n  -1.30439734e-01]\n [ 8.81836912e-01  2.86554931e-01  7.57501122e-01 -5.00150118e-01\n  -9.80048630e-01]\n [-4.43560043e-01 -4.89921555e-02  3.48730906e-01  2.23624845e+00\n  -7.43276886e-02]\n [-9.91592389e-01 -3.79241316e-01 -4.97315944e-01  4.51461238e-01\n  -1.57873395e+00]\n [ 3.16045375e-02  1.25214110e-01  2.01184854e-01 -6.31559518e-01\n  -2.70758243e-01]\n [-1.46154085e+00 -5.27156214e-01 -5.76891750e-01  3.85773664e-01\n  -1.19261370e+00]\n [ 7.52351179e-01  1.46842995e+00 -2.10999359e+00  3.96022313e-01\n   6.47652844e-01]\n [-6.71837538e-01 -4.30732142e-01 -1.65305882e-01 -3.30861765e-01\n  -3.42127786e-01]\n [-1.71447004e+00  1.12493753e+00  1.05193991e+00 -8.48453481e-01\n  -1.50407011e+00]]", "y": "[1 1 1 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.94159875 -1.3425706   0.23200647 -0.64110515  1.63808649]]", "[1.]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.73905304  0.36981861  0.95066438  2.21776061  1.84296389]\n [-1.01300878  0.92190266 -0.18385484 -0.13552804  0.38030078]\n [ 0.11270235  1.4280615   0.73211188  0.09024623  0.41369573]\n [ 0.30307547  1.4680229  -0.23786652  0.28238817 -0.88934441]\n [-2.59488922  0.62427223  0.83591513 -0.77697552  2.24673502]\n [-1.49196425  0.01403254 -0.21982174  1.50687454  1.44320582]\n [ 0.12364889  0.34773782 -0.92316631 -2.02045589 -0.38117925]\n [ 0.12505592  1.20320184  1.17518174 -0.42074821 -0.3353913 ]\n [-1.08456289 -1.45748205 -1.74485491  1.92650707 -0.54355245]\n [-0.47169436 -1.28960484  0.74862892 -1.65212095 -0.24547821]\n [-0.93087719  0.35651201 -0.54470992 -1.21715917 -0.06019767]\n [ 0.39810357  0.03487251  0.27175089 -0.66871041 -0.39606632]\n [-0.70699807 -0.39286583 -0.84823465 -1.76494566  0.14621561]\n [-0.43525892 -1.66848526  0.43268882 -0.94275531  0.02024364]\n [ 0.70003965  0.09758273  1.11195603 -1.27156496  0.37201159]\n [-0.43666039  1.19532552  0.17718521  0.94855721  0.32585637]\n [ 1.84296486  0.87768648 -0.89650227  1.88563725 -0.30095765]\n [-1.52900059  0.4092067   0.13542087  0.60561231  2.36056906]\n [ 0.91627177 -0.9483008   1.08948401 -1.35296396 -0.4952967 ]\n [ 0.81576333 -1.03603604 -1.58272359  1.16077551  0.28627825]\n [ 0.65235767 -0.83845992 -0.7241543  -0.48922091 -0.01435753]\n [-0.38728482 -1.41223898 -0.67804311 -2.26401231  0.59577396]\n [-1.64023441 -1.14061183  0.02046418 -0.77436331  1.51714999]\n [-0.4025322  -0.2722214   1.07205937  0.62592381  0.61073236]\n [-1.65519112 -0.05632647 -0.77282522  0.24911532 -0.13043973]\n [ 0.88183691  0.28655493  0.75750112 -0.50015012 -0.98004863]\n [-0.44356004 -0.04899216  0.34873091  2.23624845 -0.07432769]\n [-0.99159239 -0.37924132 -0.49731594  0.45146124 -1.57873395]\n [ 0.03160454  0.12521411  0.20118485 -0.63155952 -0.27075824]\n [-1.46154085 -0.52715621 -0.57689175  0.38577366 -1.1926137 ]\n [ 0.75235118  1.46842995 -2.10999359  0.39602231  0.64765284]\n [-0.67183754 -0.43073214 -0.16530588 -0.33086176 -0.34212779]\n [-1.71447004  1.12493753  1.05193991 -0.84845348 -1.50407011]]", "y": "[1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.82837511 -1.42955393  0.36573247 -1.04208688  1.48552547]]", "[1.]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.73905304e+00  3.69818609e-01  9.50664379e-01  2.21776061e+00\n   1.84296389e+00]\n [-1.01300878e+00  9.21902657e-01 -1.83854844e-01 -1.35528038e-01\n   3.80300778e-01]\n [ 1.12702353e-01  1.42806150e+00  7.32111880e-01  9.02462317e-02\n   4.13695732e-01]\n [ 3.03075465e-01  1.46802290e+00 -2.37866516e-01  2.82388170e-01\n  -8.89344415e-01]\n [-2.59488922e+00  6.24272232e-01  8.35915132e-01 -7.76975516e-01\n   2.24673502e+00]\n [-1.49196425e+00  1.40325390e-02 -2.19821738e-01  1.50687454e+00\n   1.44320582e+00]\n [ 1.23648894e-01  3.47737817e-01 -9.23166311e-01 -2.02045589e+00\n  -3.81179247e-01]\n [ 1.25055924e-01  1.20320184e+00  1.17518174e+00 -4.20748213e-01\n  -3.35391299e-01]\n [-1.08456289e+00 -1.45748205e+00 -1.74485491e+00  1.92650707e+00\n  -5.43552450e-01]\n [-4.71694360e-01 -1.28960484e+00  7.48628919e-01 -1.65212095e+00\n  -2.45478215e-01]\n [-9.30877193e-01  3.56512010e-01 -5.44709919e-01 -1.21715917e+00\n  -6.01976656e-02]\n [ 3.98103568e-01  3.48725090e-02  2.71750886e-01 -6.68710412e-01\n  -3.96066315e-01]\n [-7.06998068e-01 -3.92865830e-01 -8.48234651e-01 -1.76494566e+00\n   1.46215609e-01]\n [-4.35258916e-01 -1.66848526e+00  4.32688817e-01 -9.42755314e-01\n   2.02436375e-02]\n [ 7.00039652e-01  9.75827345e-02  1.11195603e+00 -1.27156496e+00\n   3.72011594e-01]\n [-7.19396057e-01 -9.06111206e-01 -6.13020823e-01 -3.44677291e-01\n   2.44801040e-02]\n [-1.20161621e+00  8.72447879e-01  4.35580277e-01 -1.57416279e+00\n   1.46217321e+00]\n [ 1.87140598e+00  1.15148908e+00 -2.12534306e-01 -1.10684945e+00\n   1.02667452e+00]\n [-4.36660392e-01  1.19532552e+00  1.77185210e-01  9.48557215e-01\n   3.25856368e-01]\n [ 6.77434109e-01 -2.13639855e-02  1.76095660e+00  9.55038097e-02\n   3.71657937e-01]\n [ 1.85861763e+00 -1.38494030e+00 -1.30736373e+00  9.41286535e-01\n  -1.20962099e+00]\n [ 1.91932485e+00 -4.47143303e-01 -7.82286015e-01  1.89856474e+00\n   1.45440551e+00]\n [ 1.84296486e+00  8.77686478e-01 -8.96502272e-01  1.88563725e+00\n  -3.00957646e-01]\n [ 7.73692694e-01  9.19055103e-01 -1.87522029e-01  5.84578221e-01\n   8.93911761e-01]\n [ 3.45994029e-01 -1.13560977e+00  2.67500589e-01  1.29967324e+00\n  -7.29192025e-01]\n [-1.82125432e-01 -4.68762177e-01  1.82459801e+00  6.43021506e-01\n   3.77151833e-01]\n [-8.04835208e-01  5.09455102e-01 -7.08877610e-01  5.00556011e-05\n  -6.70240363e-01]\n [ 6.47176246e-01  5.46942910e-01 -2.41019302e-01  3.65651866e-01\n  -1.12924567e+00]\n [-1.00413865e-01  1.68814490e+00 -7.79575456e-01 -8.61578943e-01\n  -1.30743052e-01]\n [-6.97980744e-01  1.09914130e+00 -1.11606427e+00 -1.18386581e+00\n  -4.71439108e-01]\n [-5.31887230e-01  1.90518056e+00  9.21232433e-01  5.59888708e-02\n  -1.26213789e+00]\n [ 8.92558637e-01  2.88070278e-01  8.28279771e-01 -6.85479301e-01\n  -1.07019675e+00]\n [-1.32982322e+00  2.36191193e-01 -7.13417114e-02 -1.20457139e+00\n   4.93420042e-01]\n [-2.04123002e-01  7.42906801e-01  7.94822849e-01  2.13979935e+00\n   1.30985500e+00]]", "y": "[1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.08405575 -1.42668038  0.23874378 -1.03895024  1.51208872]]", "[1.]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.73905304e+00  3.69818609e-01  9.50664379e-01  2.21776061e+00\n   1.84296389e+00]\n [-1.01300878e+00  9.21902657e-01 -1.83854844e-01 -1.35528038e-01\n   3.80300778e-01]\n [ 1.12702353e-01  1.42806150e+00  7.32111880e-01  9.02462317e-02\n   4.13695732e-01]\n [ 3.03075465e-01  1.46802290e+00 -2.37866516e-01  2.82388170e-01\n  -8.89344415e-01]\n [-2.59488922e+00  6.24272232e-01  8.35915132e-01 -7.76975516e-01\n   2.24673502e+00]\n [-1.49196425e+00  1.40325390e-02 -2.19821738e-01  1.50687454e+00\n   1.44320582e+00]\n [ 1.23648894e-01  3.47737817e-01 -9.23166311e-01 -2.02045589e+00\n  -3.81179247e-01]\n [ 1.25055924e-01  1.20320184e+00  1.17518174e+00 -4.20748213e-01\n  -3.35391299e-01]\n [-1.08456289e+00 -1.45748205e+00 -1.74485491e+00  1.92650707e+00\n  -5.43552450e-01]\n [-4.71694360e-01 -1.28960484e+00  7.48628919e-01 -1.65212095e+00\n  -2.45478215e-01]\n [-9.30877193e-01  3.56512010e-01 -5.44709919e-01 -1.21715917e+00\n  -6.01976656e-02]\n [ 3.98103568e-01  3.48725090e-02  2.71750886e-01 -6.68710412e-01\n  -3.96066315e-01]\n [-7.06998068e-01 -3.92865830e-01 -8.48234651e-01 -1.76494566e+00\n   1.46215609e-01]\n [-4.35258916e-01 -1.66848526e+00  4.32688817e-01 -9.42755314e-01\n   2.02436375e-02]\n [ 7.00039652e-01  9.75827345e-02  1.11195603e+00 -1.27156496e+00\n   3.72011594e-01]\n [-7.19396057e-01 -9.06111206e-01 -6.13020823e-01 -3.44677291e-01\n   2.44801040e-02]\n [-1.20161621e+00  8.72447879e-01  4.35580277e-01 -1.57416279e+00\n   1.46217321e+00]\n [ 1.87140598e+00  1.15148908e+00 -2.12534306e-01 -1.10684945e+00\n   1.02667452e+00]\n [-4.36660392e-01  1.19532552e+00  1.77185210e-01  9.48557215e-01\n   3.25856368e-01]\n [ 6.77434109e-01 -2.13639855e-02  1.76095660e+00  9.55038097e-02\n   3.71657937e-01]\n [ 1.85861763e+00 -1.38494030e+00 -1.30736373e+00  9.41286535e-01\n  -1.20962099e+00]\n [ 1.91932485e+00 -4.47143303e-01 -7.82286015e-01  1.89856474e+00\n   1.45440551e+00]\n [ 1.84296486e+00  8.77686478e-01 -8.96502272e-01  1.88563725e+00\n  -3.00957646e-01]\n [ 7.73692694e-01  9.19055103e-01 -1.87522029e-01  5.84578221e-01\n   8.93911761e-01]\n [ 3.45994029e-01 -1.13560977e+00  2.67500589e-01  1.29967324e+00\n  -7.29192025e-01]\n [-1.82125432e-01 -4.68762177e-01  1.82459801e+00  6.43021506e-01\n   3.77151833e-01]\n [-8.04835208e-01  5.09455102e-01 -7.08877610e-01  5.00556011e-05\n  -6.70240363e-01]\n [ 6.47176246e-01  5.46942910e-01 -2.41019302e-01  3.65651866e-01\n  -1.12924567e+00]\n [-1.52900059e+00  4.09206695e-01  1.35420868e-01  6.05612310e-01\n   2.36056906e+00]\n [ 9.16271769e-01 -9.48300800e-01  1.08948401e+00 -1.35296396e+00\n  -4.95296700e-01]\n [-1.00413865e-01  1.68814490e+00 -7.79575456e-01 -8.61578943e-01\n  -1.30743052e-01]\n [-6.97980744e-01  1.09914130e+00 -1.11606427e+00 -1.18386581e+00\n  -4.71439108e-01]\n [-5.31887230e-01  1.90518056e+00  9.21232433e-01  5.59888708e-02\n  -1.26213789e+00]\n [ 8.15763328e-01 -1.03603604e+00 -1.58272359e+00  1.16077551e+00\n   2.86278249e-01]\n [ 8.92558637e-01  2.88070278e-01  8.28279771e-01 -6.85479301e-01\n  -1.07019675e+00]\n [ 6.52357674e-01 -8.38459917e-01 -7.24154298e-01 -4.89220907e-01\n  -1.43575257e-02]\n [-3.87284817e-01 -1.41223898e+00 -6.78043114e-01 -2.26401231e+00\n   5.95773960e-01]\n [-1.64023441e+00 -1.14061183e+00  2.04641810e-02 -7.74363306e-01\n   1.51714999e+00]\n [-1.32982322e+00  2.36191193e-01 -7.13417114e-02 -1.20457139e+00\n   4.93420042e-01]\n [-2.04123002e-01  7.42906801e-01  7.94822849e-01  2.13979935e+00\n   1.30985500e+00]\n [-4.02532201e-01 -2.72221396e-01  1.07205937e+00  6.25923808e-01\n   6.10732365e-01]\n [-1.65519112e+00 -5.63264660e-02 -7.72825221e-01  2.49115320e-01\n  -1.30439734e-01]\n [ 8.81836912e-01  2.86554931e-01  7.57501122e-01 -5.00150118e-01\n  -9.80048630e-01]\n [-4.43560043e-01 -4.89921555e-02  3.48730906e-01  2.23624845e+00\n  -7.43276886e-02]\n [-9.91592389e-01 -3.79241316e-01 -4.97315944e-01  4.51461238e-01\n  -1.57873395e+00]\n [ 3.16045375e-02  1.25214110e-01  2.01184854e-01 -6.31559518e-01\n  -2.70758243e-01]\n [-1.46154085e+00 -5.27156214e-01 -5.76891750e-01  3.85773664e-01\n  -1.19261370e+00]\n [ 7.52351179e-01  1.46842995e+00 -2.10999359e+00  3.96022313e-01\n   6.47652844e-01]\n [-6.71837538e-01 -4.30732142e-01 -1.65305882e-01 -3.30861765e-01\n  -3.42127786e-01]\n [-1.71447004e+00  1.12493753e+00  1.05193991e+00 -8.48453481e-01\n  -1.50407011e+00]]", "y": "[1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1\n 1 0 0 1 0 0 0 0 1 0 0 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[ 0.95134321 -1.39960164  0.27882757 -0.90738076  1.54523356]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 1.1535077  -1.64543861  0.2879577  -1.07773516  1.83210481]]", "[1.]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "[ 0  1  0  0  0  1  0  0  1  1  0  0 -1  0  1  1 -1 -1 -1  1  0 -1 -1  1\n  1 -1 -1  0 -1 -1 -1  0 -1 -1  1  1  0  1  0  1  0 -1  1 -1  1 -1 -1  0\n  1  0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.02477608  0.2866221   0.51778518  0.60872518 -0.52325568\n    0.15619861]\n  [-0.02154888 -0.08287461 -0.53432502  1.02081585  0.19463256\n   -0.59501162]\n  [-0.00322719 -0.20374748  0.01653984 -1.62954103  0.32862312\n    0.43881302]]]", "[1.]", "[19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "[1 1 1 1 1 2 2 2 1 0 0 2 2 0 0 1 0 0 0 1 0 0 2 2 1 2 1 2 1 0 2 0 2 0 0 1 2\n 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 7.16866467e-05  6.96518493e-04  1.40081464e-03  1.06905076e-03\n   -1.29845289e-03  2.80675625e-02]\n  [-7.11750626e-05 -1.97570794e-04 -8.25057970e-04  8.38540637e-04\n    4.77899111e-04  2.53796798e-02]\n  [-5.11584029e-07 -4.98947699e-04 -5.75756671e-04 -1.90759140e-03\n    8.20553776e-04 -5.34472423e-02]]\n\n [[ 6.12941061e-04  5.18728577e-03  1.05448201e-02  8.01854820e-03\n   -9.81471344e-03  3.68844826e-02]\n  [-5.65970035e-04 -1.47995809e-03 -6.28447189e-03  6.44841853e-03\n    3.64252246e-03  1.70969226e-02]\n  [-4.69710259e-05 -3.70732768e-03 -4.26034825e-03 -1.44669667e-02\n    6.17219098e-03 -5.39814052e-02]]\n\n [[ 6.72638402e-03  3.10801577e-02  6.75778041e-02  5.00458959e-02\n   -6.43923924e-02  8.90700175e-02]\n  [-4.84429661e-03 -9.26534334e-03 -4.34602331e-02  4.69516390e-02\n    2.52890499e-02 -3.24640869e-02]\n  [-1.88208742e-03 -2.18148144e-02 -2.41175711e-02 -9.69975349e-02\n    3.91033425e-02 -5.66059306e-02]]\n\n [[ 5.03265104e-02  9.57302873e-02  2.51630097e-01  1.70743960e-01\n   -2.52538674e-01  2.43712821e-01]\n  [-3.20771356e-02 -3.17173921e-02 -1.97173314e-01  2.37047819e-01\n    1.16134011e-01 -2.07170025e-01]\n  [-1.82493748e-02 -6.40128951e-02 -5.44567836e-02 -4.07791780e-01\n    1.36404663e-01 -3.65427959e-02]]\n\n [[ 1.49643555e-01  1.67712867e-01  5.23293036e-01  3.59539051e-01\n   -5.54603850e-01  5.02914148e-01]\n  [-8.78960362e-02 -5.11280531e-02 -4.58928035e-01  6.53341938e-01\n    2.57568306e-01 -5.85690279e-01]\n  [-6.17475186e-02 -1.16584814e-01 -6.43650010e-02 -1.01288099e+00\n    2.97035544e-01  8.27761306e-02]]\n\n [[ 2.68260989e-01  2.40039645e-01  7.46027390e-01  8.17929980e-01\n   -8.88933640e-01  7.65217403e-01]\n  [-1.08967953e-01 -4.69688787e-02 -7.01330679e-01  1.37425699e+00\n    2.99427185e-01 -9.97915882e-01]\n  [-1.59293036e-01 -1.93070767e-01 -4.46967111e-02 -2.19218697e+00\n    5.89506455e-01  2.32698479e-01]]\n\n [[ 4.02539009e-01  3.26952392e-01  8.40741785e-01  1.89717736e+00\n   -1.26804223e+00  1.04159882e+00]\n  [-6.16547811e-02  1.38288784e-02 -8.45464278e-01  2.57354545e+00\n    1.26211013e-01 -1.06597798e+00]\n  [-3.40884228e-01 -3.40781270e-01  4.72249359e-03 -4.47072281e+00\n    1.14183122e+00  2.43791520e-02]]\n\n [[ 5.31800803e-01  4.20994190e-01  8.60118823e-01  3.25340843e+00\n   -1.64611485e+00  1.33331398e+00]\n  [ 1.77356780e-02  1.05632286e-01 -9.23617505e-01  3.96522783e+00\n   -1.55871737e-01 -8.99572195e-01]\n  [-5.49536481e-01 -5.26626476e-01  6.34986816e-02 -7.21863626e+00\n    1.80198659e+00 -4.33741783e-01]]\n\n [[ 5.92831819e-01  4.70420004e-01  8.63311725e-01  3.95189332e+00\n   -1.83232535e+00  1.47784224e+00]\n  [ 6.29513099e-02  1.53158573e-01 -9.54390606e-01  4.67592928e+00\n   -3.09609371e-01 -7.95656492e-01]\n  [-6.55783128e-01 -6.23578577e-01  9.10788810e-02 -8.62782260e+00\n    2.14193472e+00 -6.82185746e-01]]\n\n [[ 6.05409604e-01  4.80977980e-01  8.63834156e-01  4.09913467e+00\n   -1.87128568e+00  1.50783296e+00]\n  [ 7.28305703e-02  1.63109332e-01 -9.60375360e-01  4.82545048e+00\n   -3.42545884e-01 -7.73012743e-01]\n  [-6.78240175e-01 -6.44087312e-01  9.65412042e-02 -8.92458515e+00\n    2.21383157e+00 -7.34820218e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 8  9 13 13 15 19 22 24 20 16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "[1 2 1 1 1 2 2 2 0 1 0 0 0 1 2 2 1 0 0 0 1 0 0 2 2 1 2 1 2 1 0 2 0 2 0 0 1\n 2 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 1.51664269e-04  6.09419159e-04  1.27697293e-03  1.24805722e-03\n   -1.29519528e-03  9.44358992e-07]\n  [-1.27494170e-04 -1.42141313e-04 -7.93187233e-04  8.50790548e-04\n    4.87574865e-04 -1.29507700e-06]\n  [-2.41700985e-05 -4.67277846e-04 -4.83785702e-04 -2.09884777e-03\n    8.07620416e-04  3.50718012e-07]]\n\n [[ 1.14341157e-03  4.58287299e-03  9.61550182e-03  9.35944265e-03\n   -9.74562909e-03  5.35924483e-03]\n  [-9.52336402e-04 -1.10134952e-03 -6.07128678e-03  6.53790233e-03\n    3.71178534e-03 -7.43516150e-03]\n  [-1.91075169e-04 -3.48152346e-03 -3.54421504e-03 -1.58973450e-02\n    6.03384374e-03  2.07591667e-03]]\n\n [[ 7.19655460e-03  2.92083821e-02  6.14630292e-02  5.85621186e-02\n   -6.19609334e-02  2.91000970e-02]\n  [-5.55871018e-03 -8.53295114e-03 -4.29654897e-02  4.70308278e-02\n    2.53610627e-02 -4.40047528e-02]\n  [-1.63784442e-03 -2.06754309e-02 -1.84975395e-02 -1.05592946e-01\n    3.65998706e-02  1.49046557e-02]]\n\n [[ 1.71514470e-02  1.12041138e-01  2.23659800e-01  2.08023207e-01\n   -2.18691553e-01  5.57524417e-02]\n  [-9.38805495e-03 -5.16342280e-02 -2.03306981e-01  2.28332082e-01\n    1.08087209e-01 -1.64846931e-01]\n  [-7.76339203e-03 -6.04069102e-02 -2.03528187e-02 -4.36355288e-01\n    1.10604344e-01  1.09094489e-01]]\n\n [[-1.18472443e-02  2.54473178e-01  4.21610823e-01  4.83002011e-01\n   -4.03150360e-01 -8.84034868e-03]\n  [ 1.75579950e-03 -1.19879153e-01 -4.57305532e-01  6.09207158e-01\n    2.08760041e-01 -4.08765160e-01]\n  [ 1.00914448e-02 -1.34594025e-01  3.56947093e-02 -1.09220917e+00\n    1.94390319e-01  4.17605508e-01]]\n\n [[-4.07273110e-02  3.64046468e-01  4.62529002e-01  1.02802809e+00\n   -5.28267112e-01 -1.87809588e-01]\n  [ 2.35854238e-02 -1.37296457e-01 -6.52884607e-01  1.24290591e+00\n    2.07118162e-01 -7.12366148e-01]\n  [ 1.71418872e-02 -2.26750010e-01  1.90355605e-01 -2.27093400e+00\n    3.21148950e-01  9.00175736e-01]]\n\n [[-4.91672432e-02  4.48163008e-01  3.27418192e-01  2.07296123e+00\n   -6.40719088e-01 -4.66476430e-01]\n  [ 4.41921376e-02 -9.47696112e-02 -8.37117832e-01  2.29049576e+00\n    1.11861997e-01 -9.89438465e-01]\n  [ 4.97510561e-03 -3.53393397e-01  5.09699640e-01 -4.36345698e+00\n    5.28857091e-01  1.45591489e+00]]\n\n [[-5.10715993e-02  5.75192016e-01  4.13453907e-03  4.10510264e+00\n   -8.24062825e-01 -8.29391021e-01]\n  [ 4.66905427e-02  2.84919136e-02 -1.15586873e+00  4.30271917e+00\n   -7.34655475e-02 -1.31767673e+00]\n  [ 4.38105659e-03 -6.03683930e-01  1.15173420e+00 -8.40782182e+00\n    8.97528372e-01  2.14706775e+00]]\n\n [[ 6.22975086e-03  1.17177016e+00 -1.53317405e+00  1.40715800e+01\n   -1.80094733e+00 -2.19309747e+00]\n  [ 6.05096638e-02  6.76640825e-01 -2.62176074e+00  1.41905555e+01\n   -1.05901157e+00 -2.56205046e+00]\n  [-6.67394147e-02 -1.84841098e+00  4.15493479e+00 -2.82621354e+01\n    2.85995890e+00  4.75514792e+00]]\n\n [[ 1.08940321e-01  2.58592021e+00 -5.06039711e+00  3.71292862e+01\n   -4.06370229e+00 -5.35191352e+00]\n  [ 1.06307813e-01  2.15494598e+00 -6.07047576e+00  3.71693844e+01\n   -3.32709009e+00 -5.60753183e+00]\n  [-2.15248134e-01 -4.74086620e+00  1.11308729e+01 -7.42986705e+01\n    7.39079238e+00  1.09594453e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  9 12 15 16 18 20 24 32]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "[1 2 1 1 1 2 1 1 2 2 1 1 0 2 2 0 0 0 2 0 0 0 0 1 0 0 2 1 2 1 2 1 0 2 0 2 0\n 0 1 2 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 7.30231078e-05  7.66842510e-04  1.57562476e-03  1.03431267e-03\n   -1.42071452e-03  2.56673938e-02]\n  [-2.81697396e-04 -8.09884163e-05 -9.85011919e-04  1.11690975e-03\n    6.71089230e-04  2.35383015e-02]\n  [ 2.08674289e-04 -6.85854094e-04 -5.90612843e-04 -2.15122242e-03\n    7.49625290e-04 -4.92056954e-02]]\n\n [[ 6.11692915e-04  5.70582044e-03  1.18261764e-02  7.72735185e-03\n   -1.06962924e-02  3.17411329e-02]\n  [-2.12021211e-03 -6.24442595e-04 -7.49368473e-03  8.55774189e-03\n    5.07837061e-03  1.61926926e-02]\n  [ 1.50851920e-03 -5.08137785e-03 -4.33249163e-03 -1.62850937e-02\n    5.61792177e-03 -4.79338255e-02]]\n\n [[ 5.88775042e-03  3.42473054e-02  7.44298141e-02  4.69858305e-02\n   -6.82671858e-02  6.47299841e-02]\n  [-1.31863442e-02 -4.92046182e-03 -5.13165857e-02  6.09145201e-02\n    3.34518326e-02 -2.58942990e-02]\n  [ 7.29859376e-03 -2.93268435e-02 -2.31132284e-02 -1.07900351e-01\n    3.48153532e-02 -3.88356851e-02]]\n\n [[ 2.57542161e-02  1.14816656e-01  2.63709590e-01  1.43179917e-01\n   -2.40132423e-01  1.47543841e-01]\n  [-3.71332756e-02 -3.09604178e-02 -2.20691547e-01  2.93343606e-01\n    1.24940188e-01 -1.69465140e-01]\n  [ 1.13790595e-02 -8.38562385e-02 -4.30180436e-02 -4.36523524e-01\n    1.15192235e-01  2.19212988e-02]]\n\n [[ 1.32571025e-02  2.41867525e-01  5.10370250e-01  2.28722444e-01\n   -4.31507526e-01  3.20070678e-01]\n  [-4.21342002e-02 -7.58952053e-02 -4.90911975e-01  8.18500190e-01\n    2.17783541e-01 -5.42110601e-01]\n  [ 2.88770977e-02 -1.65972320e-01 -1.94582752e-02 -1.04722263e+00\n    2.13723985e-01  2.22039923e-01]]\n\n [[-3.96061218e-02  3.64832672e-01  6.55989720e-01  3.98836570e-01\n   -5.40541348e-01  5.99600025e-01]\n  [-1.07660295e-02 -1.09783488e-01 -7.81014705e-01  1.69142552e+00\n    2.29925534e-01 -1.21635803e+00]\n  [ 5.03721513e-02 -2.55049184e-01  1.25024985e-01 -2.09026209e+00\n    3.10615815e-01  6.16758009e-01]]\n\n [[-8.23996652e-02  4.71494100e-01  6.56923991e-01  9.78615303e-01\n   -6.34646436e-01  6.89592982e-01]\n  [ 1.12388967e-02 -9.64426054e-02 -1.01163846e+00  2.67732038e+00\n    1.80745989e-01 -1.68444393e+00]\n  [ 7.11607685e-02 -3.75051494e-01  3.54714473e-01 -3.65593568e+00\n    4.53900446e-01  9.94850952e-01]]\n\n [[-1.10734692e-01  5.43249180e-01  6.20461580e-01  1.49406689e+00\n   -6.97018901e-01  6.95614457e-01]\n  [ 9.04260052e-03 -6.55299360e-02 -1.13489073e+00  3.31021447e+00\n    1.41267689e-01 -1.82812375e+00]\n  [ 1.01692091e-01 -4.77719244e-01  5.14429146e-01 -4.80428135e+00\n    5.55751212e-01  1.13250929e+00]]\n\n [[-1.18684879e-01  5.62042500e-01  6.08850955e-01  1.63302786e+00\n   -7.12326384e-01  6.98538426e-01]\n  [ 6.84150616e-03 -5.58849736e-02 -1.16521284e+00  3.47249190e+00\n    1.31240571e-01 -1.85414860e+00]\n  [ 1.11843372e-01 -5.06157526e-01  5.56361889e-01 -5.10551976e+00\n    5.81085813e-01  1.15561018e+00]]\n\n [[-1.19910476e-01  5.64905394e-01  6.07108830e-01  1.65402974e+00\n   -7.14633957e-01  6.99027297e-01]\n  [ 6.49876916e-03 -5.44112394e-02 -1.16979896e+00  3.49709684e+00\n    1.29717543e-01 -1.85799086e+00]\n  [ 1.13411707e-01 -5.10494155e-01  5.62690133e-01 -5.15112658e+00\n    5.84916414e-01  1.15896356e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 7 10  9 13 14 18 17 19 17 14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "[1 2 1 1 1 2 1 1 2 2 1 1 0 1 2 2 0 0 0 2 1 0 0 2 2 0 0 1 0 0 0 2 1 2 0 2 0\n 0 1 2 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 3.50206331e-04  4.35754971e-04  1.25413876e-03  1.07429697e-03\n   -1.36803560e-03  2.49790577e-02]\n  [-3.40012863e-04  1.51311096e-04 -5.26480849e-04  1.05579795e-03\n    3.83316145e-04  2.37520116e-02]\n  [-1.01934679e-05 -5.87066067e-04 -7.27657909e-04 -2.13009492e-03\n    9.84719457e-04 -4.87310693e-02]]\n\n [[ 2.63684632e-03  3.28472031e-03  9.45690287e-03  8.07108688e-03\n   -1.03070995e-02  2.67464503e-02]\n  [-2.55592530e-03  1.11970511e-03 -4.03799643e-03  8.06753273e-03\n    2.91335801e-03  1.77175794e-02]\n  [-8.09210193e-05 -4.40442542e-03 -5.41890644e-03 -1.61386196e-02\n    7.39374149e-03 -4.44640297e-02]]\n\n [[ 1.67012057e-02  2.12807615e-02  6.10661604e-02  5.08865265e-02\n   -6.60939147e-02  3.57716860e-02]\n  [-1.59566996e-02  6.06305782e-03 -2.91535608e-02  5.63532446e-02\n    1.98459207e-02 -1.53165533e-02]\n  [-7.44506071e-04 -2.73438194e-02 -3.19125996e-02 -1.07239771e-01\n    4.62479939e-02 -2.04551327e-02]]\n\n [[ 5.07628296e-02  8.62209899e-02  2.26744954e-01  1.82924934e-01\n   -2.37035168e-01  4.72695836e-02]\n  [-4.60656863e-02  3.61916287e-03 -1.44839797e-01  2.57701373e-01\n    8.21911103e-02 -1.07668766e-01]\n  [-4.69714331e-03 -8.98401528e-02 -8.19051574e-02 -4.40626307e-01\n    1.54844058e-01  6.03991826e-02]]\n\n [[ 5.35599532e-02  2.00865016e-01  4.18975894e-01  4.37097113e-01\n   -4.33100230e-01  1.95118357e-02]\n  [-5.69441011e-02 -1.38625093e-02 -3.24235803e-01  6.59702350e-01\n    1.37524759e-01 -2.91892831e-01]\n  [ 3.38414790e-03 -1.87002507e-01 -9.47400909e-02 -1.09679946e+00\n    2.95575471e-01  2.72380995e-01]]\n\n [[ 3.67333194e-02  3.04370838e-01  4.82301158e-01  9.26909940e-01\n   -5.70862912e-01 -6.39997179e-02]\n  [-4.69863266e-02  2.40503683e-03 -4.52946540e-01  1.26474170e+00\n    1.00154733e-01 -5.19142161e-01]\n  [ 1.02530072e-02 -3.06775875e-01 -2.93546182e-02 -2.19165164e+00\n    4.70708179e-01  5.83141879e-01]]\n\n [[ 9.48741226e-03  4.16957939e-01  4.56236377e-01  1.72587750e+00\n   -7.00513978e-01 -1.28364813e-01]\n  [-5.19067869e-02  7.74877966e-02 -5.45233638e-01  2.11778510e+00\n   -6.14888361e-03 -6.57796822e-01]\n  [ 4.24193747e-02 -4.94445736e-01  8.89972611e-02 -3.84366260e+00\n    7.06662862e-01  7.86161635e-01]]\n\n [[-4.09751807e-02  5.63646505e-01  3.76259827e-01  2.83814607e+00\n   -8.40916142e-01 -1.48979308e-01]\n  [-9.34251067e-02  2.12688860e-01 -6.43632689e-01  3.25188028e+00\n   -1.43197587e-01 -7.09088485e-01]\n  [ 1.34400287e-01 -7.76335365e-01  2.67372862e-01 -6.09002635e+00\n    9.84113729e-01  8.58067793e-01]]\n\n [[-9.44680662e-02  7.20803347e-01  2.83439217e-01  4.05654644e+00\n   -9.92010058e-01 -1.52514919e-01]\n  [-1.43595895e-01  3.66891319e-01 -7.39532382e-01  4.47594222e+00\n   -2.95307000e-01 -7.19701473e-01]\n  [ 2.38063961e-01 -1.08769467e+00  4.56093165e-01 -8.53248867e+00\n    1.28731706e+00  8.72216392e-01]]\n\n [[-1.22599751e-01  8.07324209e-01  2.33178441e-01  4.73169242e+00\n   -1.07755498e+00 -1.52927312e-01]\n  [-1.70599405e-01  4.52532618e-01 -7.90148850e-01  5.15166948e+00\n   -3.81425646e-01 -7.20179250e-01]\n  [ 2.93199156e-01 -1.25985683e+00  5.56970409e-01 -9.88336190e+00\n    1.45898062e+00  8.73106562e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 7  9 11 13 15 18 18 13 18 13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]]", "y": "[1 2 1 1 1 2 1 1 2 2 1 1 0 1 2 2 0 0 0 2 1 0 0 2 2 0 0 1 0 0 0 1 0 0 2 2 1\n 2 1 2 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.50046879e-04  9.33057469e-04  1.53413662e-03  1.23120233e-03\n   -1.28981291e-03  2.55731386e-02]\n  [-2.32728593e-05 -2.44318795e-04 -9.06610617e-04  1.01163492e-03\n    4.71584621e-04  2.35961491e-02]\n  [ 1.73319739e-04 -6.88738674e-04 -6.27526000e-04 -2.24283725e-03\n    8.18228288e-04 -4.91692877e-02]]\n\n [[-1.05329591e-03  6.93056745e-03  1.14830793e-02  9.18640085e-03\n   -9.69245661e-03  3.10025512e-02]\n  [-1.83274304e-04 -1.84377141e-03 -6.89038936e-03  7.75392054e-03\n    3.57459174e-03  1.67039294e-02]\n  [ 1.23657022e-03 -5.08679603e-03 -4.59268998e-03 -1.69403214e-02\n    6.11786488e-03 -4.77064806e-02]]\n\n [[-4.11572939e-03  4.11184642e-02  7.12337545e-02  5.57890416e-02\n   -6.14087305e-02  5.82183861e-02]\n  [-1.27055814e-03 -1.23154580e-02 -4.70425944e-02  5.49159187e-02\n    2.40058106e-02 -1.98912514e-02]\n  [ 5.38628753e-03 -2.88030062e-02 -2.41911601e-02 -1.10704960e-01\n    3.74029199e-02 -3.83271347e-02]]\n\n [[-1.22400013e-03  1.31689601e-01  2.45021512e-01  1.87627039e-01\n   -2.18531148e-01  9.14022547e-02]\n  [-2.31315089e-03 -5.27466164e-02 -2.00399464e-01  2.48599953e-01\n    9.72528459e-02 -1.19544612e-01]\n  [ 3.53715102e-03 -7.89429846e-02 -4.46220480e-02 -4.36226992e-01\n    1.21278302e-01  2.81423575e-02]]\n\n [[-9.81399962e-03  2.56912704e-01  4.45535060e-01  4.33380134e-01\n   -4.11727853e-01  2.78086062e-02]\n  [ 1.00868471e-02 -1.04681249e-01 -4.05776177e-01  5.99777552e-01\n    1.67524465e-01 -2.75801165e-01]\n  [-2.72847504e-04 -1.52231455e-01 -3.97588828e-02 -1.03315769e+00\n    2.44203389e-01  2.47992559e-01]]\n\n [[-2.64869254e-02  3.64173331e-01  5.21284343e-01  9.11541155e-01\n   -5.56308102e-01 -1.11308576e-01]\n  [ 3.96613460e-02 -1.17318106e-01 -5.44136681e-01  1.12238761e+00\n    1.41964779e-01 -4.22220883e-01]\n  [-1.31744206e-02 -2.46855225e-01  2.28523380e-02 -2.03392877e+00\n    4.14343322e-01  5.33529459e-01]]\n\n [[-4.40287429e-02  4.50636332e-01  4.91017876e-01  1.57745659e+00\n   -6.61355305e-01 -1.94810774e-01]\n  [ 5.16264110e-02 -8.06431009e-02 -6.40312324e-01  1.78644555e+00\n    6.71130380e-02 -4.78027059e-01]\n  [-7.59766816e-03 -3.69993231e-01  1.49294449e-01 -3.36390214e+00\n    5.94242267e-01  6.72837833e-01]]\n\n [[-5.37416985e-02  4.97166193e-01  4.58729780e-01  1.98737406e+00\n   -7.16656975e-01 -2.13230705e-01]\n  [ 5.28343603e-02 -5.05287145e-02 -6.92086723e-01  2.19478311e+00\n    1.95613251e-02 -4.84906010e-01]\n  [ 9.07338180e-04 -4.46637479e-01  2.33356943e-01 -4.18215717e+00\n    6.97095650e-01  6.98136715e-01]]\n\n [[-5.58525472e-02  5.07430110e-01  4.51161682e-01  2.07944652e+00\n   -7.28890866e-01 -2.15463817e-01]\n  [ 5.29235632e-02 -4.35638790e-02 -7.03673288e-01  2.28690534e+00\n    8.88053008e-03 -4.85375474e-01]\n  [ 2.92898400e-03 -4.63866231e-01  2.52511606e-01 -4.36635186e+00\n    7.20010336e-01  7.00839292e-01]]\n\n [[-5.61377610e-02  5.08884264e-01  4.50066405e-01  2.09264259e+00\n   -7.30647433e-01 -2.15659981e-01]\n  [ 5.29333333e-02 -4.25507185e-02 -7.05308517e-01  2.30012222e+00\n    7.33011512e-03 -4.85363687e-01]\n  [ 3.20442766e-03 -4.66333546e-01  2.55242112e-01 -4.39276481e+00\n    7.23317318e-01  7.01023668e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 7 10  9 14 15 17 16 13  9 11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "[1 2 1 1 1 2 1 1 2 2 1 1 0 1 2 2 0 0 0 2 1 0 0 2 2 0 0 1 0 0 0 1 0 0 2 2 1\n 2 1 2 1 0 2 0 2 0 0 1 2 1]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[ 0.03963479  0.32749259  0.57362632  0.81664915 -0.61698262  0.20033991]\n [-0.02069471 -0.08179238 -0.62646264  1.33914355  0.19571808 -0.77360062]\n [-0.01894008 -0.24570021  0.05283632 -2.15579269  0.42126454  0.57326071]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 0.01816192  0.3329585   0.5317101   0.88079878 -0.58587168\n    0.13742539]\n  [-0.00928261 -0.07811504 -0.60902712  1.3714058   0.16895233\n   -0.72717651]\n  [-0.00887931 -0.25484346  0.07731701 -2.25220458  0.41691935\n    0.58975111]]]", "[2.7825594]", "[16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "['baz' 'foo' 'baz' 'baz' 'baz' 'foo' 'baz' 'baz' 'foo' 'foo' 'baz' 'baz'\n 'bar' 'baz' 'foo' 'foo' 'bar' 'bar' 'bar' 'foo' 'baz' 'bar' 'bar' 'foo'\n 'foo' 'bar' 'bar' 'baz' 'bar' 'bar' 'bar' 'baz' 'bar' 'bar' 'foo' 'foo'\n 'baz' 'foo' 'baz' 'foo' 'baz' 'bar' 'foo' 'bar' 'foo' 'bar' 'bar' 'baz'\n 'foo' 'baz']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.02477608  0.2866221   0.51778518  0.60872518 -0.52325568\n    0.15619861]\n  [-0.02154888 -0.08287461 -0.53432502  1.02081585  0.19463256\n   -0.59501162]\n  [-0.00322719 -0.20374748  0.01653984 -1.62954103  0.32862312\n    0.43881302]]]", "[1.]", "[19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 str"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": {"bar": "int", "baz": "int", "foo": "int"}, "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.96726972  0.47760212 -0.84590487  1.20321211  0.98505396]\n [-0.70215506  0.24189384 -0.21130768 -1.26259935  0.8627369 ]\n [-0.61399305 -0.06498837 -1.57149581  1.37935004  1.25859471]\n [ 1.47028744 -0.77759999  0.24219467  1.23589123 -1.36647945]\n [-0.13928527  0.62226025  0.66709017  1.78837269 -0.77442657]\n [ 1.27253392 -0.96588364 -0.16716135  0.08027977 -0.69975492]\n [-0.73020963  0.14527361 -1.28776624  1.41491808  1.11603076]\n [-1.27187583  0.69863164 -0.97954012  1.68185296  1.17684095]\n [ 2.02240807 -2.37173141 -1.22773713 -3.07783901  0.26219546]\n [-0.65430208  0.29439193 -0.02271607 -1.22673614  0.6861919 ]\n [-1.92979187  2.15313722  1.09728363  2.34238843 -0.0719804 ]\n [ 1.97960564 -2.5763622  -2.78838477  0.29911518  0.73572909]\n [ 2.18952433 -0.78305426  1.57105235  0.69380186 -2.68724148]\n [ 0.24718575 -0.80004592 -1.68941336  0.82742536  0.91459502]\n [ 0.5036028  -1.13004396 -1.35408422 -1.41421871  0.97140785]\n [-1.06109623  0.54927551  0.18422645 -2.17305696  0.98831194]\n [ 1.14096485 -0.09474121  1.21156666  1.45374122 -1.91648577]\n [-0.72745509  1.03635451  0.71385149  1.60520086 -0.39818818]\n [-0.91437611  1.04629855  0.45783371  1.51511603 -0.07266377]\n [ 0.65584464 -1.69493016 -2.78421203 -0.16442737  1.66754363]\n [ 0.72756362 -0.66007902 -0.67544883  1.14387735 -0.20161971]\n [-1.86560424  2.04946261  1.73611818 -0.21913738 -0.05024313]\n [ 1.73096293 -0.66026941  1.23134591  0.26889362 -2.05846235]\n [-1.26788092  0.28683049 -1.43543071  0.06743277  1.84539042]\n [-0.05282117 -0.03977694 -0.07951714 -0.32717119  0.15998538]\n [-1.08082503  0.97301399  0.03485724  1.45350848  0.35683178]\n [-0.18919038  0.45091133  0.05644425  2.23205241 -0.38569485]\n [-1.74383651  1.47813611  0.19900263  1.17064249  0.71482368]\n [-0.01801266  0.19045605 -0.42776285  2.77578202 -0.25084608]\n [-0.67008805  0.35912308 -0.76715192  1.64996063  0.64598531]\n [-0.27830389  0.88312206  1.12414669  1.51233112 -0.96531423]\n [ 0.06780054 -1.23743152 -2.88605056  0.47739423  1.9815515 ]\n [-2.13297073  1.84850052  0.69938016  0.23010191  0.78862742]\n [ 1.11751698 -0.66232424  0.14222752  0.5332073  -0.92338385]\n [-1.28215531 -0.28723795 -2.00570825 -2.50716542  2.80928799]\n [ 2.09108825 -2.56088206 -1.76549237 -2.36806994  0.46685806]\n [-0.04684135 -1.06646036 -2.87555889  1.1269538   1.91141903]\n [ 1.04352505 -1.22904356 -1.09588769 -0.09565178  0.16529736]\n [ 2.57291621 -3.21776653 -3.18707613 -0.06050012  0.72804183]\n [-0.94960168 -0.23263624 -1.31795707 -2.56429487  2.10442002]\n [-2.87500845  1.72687339 -0.99018705  0.87284478  2.3683416 ]\n [ 0.02969645  0.37980495  0.14697723  2.57677194 -0.66262703]\n [ 0.12902996 -0.68232737 -1.37416137  0.04068691  0.92100479]\n [ 1.26523818 -0.13125687  1.22776055  1.79562248 -2.07819249]\n [-1.38934215  0.79634771 -0.04598844 -1.30356732  1.18489292]\n [-0.04503425 -0.19670913 -0.67703697  0.49637402  0.42354697]\n [ 0.36371636 -0.0657794   0.05297738  1.29615747 -0.53882273]\n [ 0.97543681 -1.17478696 -1.39061931  0.92637014  0.212851  ]\n [-0.7035454  -0.26229354 -1.48032195 -0.91698481  1.72559269]\n [-1.15921635  0.95694292 -0.30444313  2.02983724  0.53635929]]", "y": "['baz' 'foo' 'baz' 'baz' 'baz' 'foo' 'baz' 'baz' 'foo' 'foo' 'baz' 'baz'\n 'bar' 'baz' 'foo' 'foo' 'bar' 'bar' 'bar' 'foo' 'baz' 'bar' 'bar' 'foo'\n 'foo' 'bar' 'bar' 'baz' 'bar' 'bar' 'bar' 'baz' 'bar' 'bar' 'foo' 'foo'\n 'baz' 'foo' 'baz' 'foo' 'baz' 'bar' 'foo' 'bar' 'foo' 'bar' 'bar' 'baz'\n 'foo' 'baz']"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": {"bar": 1, "baz": 2, "foo": 0}, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 6.95370937e-02  1.17765049e-01  4.39548881e-01 -1.79477458e-01\n   -3.30185823e-01  6.48874114e+00]\n  [-6.95524385e-02 -1.17800176e-01 -4.39646750e-01  1.79450113e-01\n    3.30273246e-01  6.46451549e+00]\n  [ 1.53447330e-05  3.51263175e-05  9.78693628e-05  2.73451604e-05\n   -8.74230208e-05 -1.29532566e+01]]]", "[1.]", "[48]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.14115334]\n [1.27638401 1.3359988  0.         0.         0.        ]\n [0.         0.         0.         1.40357103 1.66873628]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         2.38314477 1.08678051 1.20719779]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.1616032 ]\n [0.         0.         1.84926373 0.         0.        ]\n [1.38585905 0.         1.92953205 0.         1.12049186]\n [0.         0.         1.11701629 1.22350722 1.4116954 ]\n [0.         0.         0.         0.         0.        ]\n [1.43845611 1.41522589 0.         0.         0.        ]\n [1.20568398 1.26171292 0.         0.         0.        ]\n [0.         0.         0.         1.19811586 1.3512674 ]\n [0.         0.         0.         0.         1.08048271]\n [0.         0.         0.         0.         1.32806016]\n [0.         0.         1.71334272 1.82016301 2.25325619]\n [0.         0.         1.3263859  0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.19595682 0.         0.         1.27255325 1.79797132]\n [1.35339573 0.         0.         0.         0.        ]\n [0.         0.         0.         1.24386492 1.43994634]\n [0.         0.         1.12663592 0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.70789413 1.75384676 0.         0.         0.        ]\n [1.4152163  1.43188362 0.         0.         0.        ]\n [1.65492163 1.76124918 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         1.12793525 1.54483432]\n [1.64252894 1.73011739 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.12379522 1.16550583 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.32083783 1.35200433 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]]", "y": "[1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.35275221e-04  6.59651459e-04 -2.66492032e-04 -2.78614969e-04\n  -1.15733099e-04 -3.64592632e-07]\n [ 6.43629555e-03  5.07699063e-03 -2.04901113e-03 -2.14326291e-03\n  -8.76229683e-04 -2.81963990e-03]\n [ 4.80042970e-02  3.75247119e-02 -1.50988113e-02 -1.58544599e-02\n  -5.74703115e-03 -2.13490323e-02]\n [ 2.93781638e-01  2.15975201e-01 -8.63751975e-02 -9.48010259e-02\n  -6.09197883e-03 -1.38685927e-01]\n [ 1.04175587e+00  6.15637190e-01 -2.68113049e-01 -4.26806586e-01\n   2.56982967e-01 -4.86284330e-01]\n [ 2.15420145e+00  1.00197679e+00 -4.43348110e-01 -1.49910727e+00\n   1.11420490e+00 -8.60941418e-01]\n [ 3.40980092e+00  1.29234444e+00 -3.86447512e-01 -2.62864632e+00\n   1.89656261e+00 -1.07351950e+00]\n [ 4.75706043e+00  1.48769412e+00 -3.35723822e-01 -3.01011286e+00\n   2.14189870e+00 -1.13070853e+00]\n [ 6.15272085e+00  1.65977492e+00 -3.25508651e-01 -3.07479231e+00\n   2.18101088e+00 -1.13996601e+00]\n [ 7.54371651e+00  2.03235443e+00 -3.23973674e-01 -3.08361687e+00\n   2.18597010e+00 -1.14125721e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  8  7  9 13 15 16 21 16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.         0.         0.         0.         1.31194333]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.10083721]\n [0.         0.         0.         0.         0.        ]\n [1.00745522 1.06238655 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.01227546 0.         0.         0.         1.26791822]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         1.84926373 0.         0.        ]\n [1.38585905 0.         1.92953205 0.         1.12049186]\n [0.         0.         1.11701629 1.22350722 1.4116954 ]\n [0.         0.         0.         0.         0.        ]\n [1.43845611 1.41522589 0.         0.         0.        ]\n [1.20568398 1.26171292 0.         0.         0.        ]\n [0.         0.         0.         1.19811586 1.3512674 ]\n [0.         0.         0.         0.         1.08048271]\n [0.         0.         0.         0.         1.32806016]\n [0.         0.         1.71334272 1.82016301 2.25325619]\n [0.         0.         1.3263859  0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.19595682 0.         0.         1.27255325 1.79797132]\n [1.35339573 0.         0.         0.         0.        ]\n [0.         0.         0.         1.24386492 1.43994634]\n [0.         0.         1.12663592 0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.70789413 1.75384676 0.         0.         0.        ]\n [1.4152163  1.43188362 0.         0.         0.        ]\n [1.65492163 1.76124918 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         1.12793525 1.54483432]\n [1.64252894 1.73011739 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.12379522 1.16550583 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.32083783 1.35200433 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]]", "y": "[1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.72393101e-04  6.45984402e-04 -1.47498463e-04 -1.54265600e-04\n   9.66796205e-05 -5.66592368e-07]\n [ 6.72732815e-03  4.97562072e-03 -1.13534441e-03 -1.18883201e-03\n   7.58228573e-04 -4.38904240e-03]\n [ 5.03736748e-02  3.69521656e-02 -8.42692073e-03 -8.89926344e-03\n   6.29838436e-03 -3.29430141e-02]\n [ 3.14241820e-01  2.18074570e-01 -5.05007835e-02 -5.79652015e-02\n   6.27898052e-02 -2.08684215e-01]\n [ 1.12698804e+00  6.54094602e-01 -1.80856847e-01 -3.42259873e-01\n   4.50212059e-01 -7.07605545e-01]\n [ 2.28238697e+00  1.13837445e+00 -2.99141829e-01 -1.39083722e+00\n   1.38836056e+00 -1.22684233e+00]\n [ 3.56491960e+00  1.55100181e+00 -1.53705519e-01 -2.55738732e+00\n   2.22566581e+00 -1.52492816e+00]\n [ 4.91962922e+00  1.87421800e+00 -7.15480514e-02 -2.96081523e+00\n   2.49496873e+00 -1.60950468e+00]\n [ 6.32220838e+00  2.17263691e+00 -5.61804758e-02 -3.02886490e+00\n   2.53876015e+00 -1.62378766e+00]\n [ 7.72147893e+00  2.65174697e+00 -5.38847208e-02 -3.03832892e+00\n   2.54459795e+00 -1.62582832e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  8  8  7  8 13 16 20 19 16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.         0.         0.         0.         1.31194333]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.10083721]\n [0.         0.         0.         0.         0.        ]\n [1.00745522 1.06238655 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.01227546 0.         0.         0.         1.26791822]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.14115334]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.27638401 1.3359988  0.         0.         0.        ]\n [0.         0.         0.         1.40357103 1.66873628]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         2.38314477 1.08678051 1.20719779]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.1616032 ]\n [0.         0.         1.71334272 1.82016301 2.25325619]\n [0.         0.         1.3263859  0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.35339573 0.         0.         0.         0.        ]\n [0.         0.         0.         1.24386492 1.43994634]\n [0.         0.         1.12663592 0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.70789413 1.75384676 0.         0.         0.        ]\n [1.4152163  1.43188362 0.         0.         0.        ]\n [1.65492163 1.76124918 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         1.12793525 1.54483432]\n [1.64252894 1.73011739 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.12379522 1.16550583 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.32083783 1.35200433 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]]", "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 6.75174309e-04  5.79117927e-04 -2.14725871e-04 -2.21253726e-04\n   4.80093631e-05 -3.40510834e-07]\n [ 5.20535086e-03  4.46216744e-03 -1.65475938e-03 -1.70614476e-03\n   3.81532195e-04 -2.63082873e-03]\n [ 3.89735982e-02  3.32590038e-02 -1.23916927e-02 -1.28425934e-02\n   3.45270339e-03 -1.98379230e-02]\n [ 2.42704456e-01  2.00669953e-01 -7.76613121e-02 -8.46626602e-02\n   4.54413460e-02 -1.27272928e-01]\n [ 8.71557184e-01  6.38818573e-01 -2.79370841e-01 -4.60082216e-01\n   4.39521614e-01 -4.50809377e-01]\n [ 1.84023048e+00  1.15737471e+00 -3.60732914e-01 -1.88605701e+00\n   1.61418130e+00 -8.33559549e-01]\n [ 2.99090606e+00  1.61008956e+00 -1.55702547e-01 -4.25420176e+00\n   3.35250901e+00 -1.06241320e+00]\n [ 4.22194463e+00  2.00658685e+00  3.92648624e-02 -9.64966076e+00\n   7.59036288e+00 -1.13759042e+00]\n [ 5.53970202e+00  2.40586329e+00  4.68666231e-01 -2.74762741e+01\n   2.15404022e+01 -1.20616535e+00]\n [ 6.84141102e+00  2.96576656e+00  7.95392678e-01 -5.09244091e+01\n   3.97078911e+01 -1.26938040e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  7  6  8 14 15 26 33 23]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.         0.         0.         0.         1.31194333]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.10083721]\n [0.         0.         0.         0.         0.        ]\n [1.00745522 1.06238655 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.01227546 0.         0.         0.         1.26791822]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.14115334]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.27638401 1.3359988  0.         0.         0.        ]\n [0.         0.         0.         1.40357103 1.66873628]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         2.38314477 1.08678051 1.20719779]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.1616032 ]\n [0.         0.         1.84926373 0.         0.        ]\n [1.38585905 0.         1.92953205 0.         1.12049186]\n [0.         0.         1.11701629 1.22350722 1.4116954 ]\n [0.         0.         0.         0.         0.        ]\n [1.43845611 1.41522589 0.         0.         0.        ]\n [1.20568398 1.26171292 0.         0.         0.        ]\n [0.         0.         0.         1.19811586 1.3512674 ]\n [0.         0.         0.         0.         1.08048271]\n [0.         0.         0.         0.         1.32806016]\n [1.19595682 0.         0.         1.27255325 1.79797132]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         1.12793525 1.54483432]\n [1.64252894 1.73011739 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.12379522 1.16550583 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.32083783 1.35200433 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]]", "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 6.30047667e-04  4.65806687e-04 -1.71005981e-04 -1.25622829e-04\n   2.52597807e-04 -3.69718424e-07]\n [ 4.86394335e-03  3.59404079e-03 -1.32123820e-03 -9.71790873e-04\n   1.95701981e-03 -2.86427163e-03]\n [ 3.67572448e-02  2.70581641e-02 -1.00538437e-02 -7.46317122e-03\n   1.51347745e-02 -2.16938650e-02]\n [ 2.41055709e-01  1.72965560e-01 -6.94778180e-02 -5.57922424e-02\n   1.13934502e-01 -1.45239625e-01]\n [ 9.37257175e-01  6.18879533e-01 -3.24134238e-01 -3.92871273e-01\n   6.24471120e-01 -5.60842473e-01]\n [ 1.98957918e+00  1.18673527e+00 -8.04872157e-01 -1.54167715e+00\n   1.66501101e+00 -1.02846602e+00]\n [ 3.29744416e+00  1.57138253e+00 -1.44669036e+00 -2.61081218e+00\n   2.44155270e+00 -1.23909298e+00]\n [ 5.11788674e+00  1.57973217e+00 -2.29709952e+00 -2.90122518e+00\n   2.65147595e+00 -1.28237746e+00]\n [ 7.61519950e+00  1.19695885e+00 -3.42051507e+00 -2.92144545e+00\n   2.67556536e+00 -1.28794840e+00]\n [ 1.06617689e+01  6.44143822e-01 -4.79414336e+00 -2.91704552e+00\n   2.67655619e+00 -1.28851374e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  8  8  7  8 12 14 19 18 39]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.         0.         0.         0.         1.31194333]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.10083721]\n [0.         0.         0.         0.         0.        ]\n [1.00745522 1.06238655 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.01227546 0.         0.         0.         1.26791822]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.14115334]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.27638401 1.3359988  0.         0.         0.        ]\n [0.         0.         0.         1.40357103 1.66873628]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         2.38314477 1.08678051 1.20719779]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.1616032 ]\n [0.         0.         1.84926373 0.         0.        ]\n [1.38585905 0.         1.92953205 0.         1.12049186]\n [0.         0.         1.11701629 1.22350722 1.4116954 ]\n [0.         0.         0.         0.         0.        ]\n [1.43845611 1.41522589 0.         0.         0.        ]\n [1.20568398 1.26171292 0.         0.         0.        ]\n [0.         0.         0.         1.19811586 1.3512674 ]\n [0.         0.         0.         0.         1.08048271]\n [0.         0.         0.         0.         1.32806016]\n [0.         0.         1.71334272 1.82016301 2.25325619]\n [0.         0.         1.3263859  0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.19595682 0.         0.         1.27255325 1.79797132]\n [1.35339573 0.         0.         0.         0.        ]\n [0.         0.         0.         1.24386492 1.43994634]\n [0.         0.         1.12663592 0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.70789413 1.75384676 0.         0.         0.        ]\n [1.4152163  1.43188362 0.         0.         0.        ]\n [1.65492163 1.76124918 0.         0.         0.        ]]", "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0\n 1 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 7.32161368e-04  5.00669628e-04 -2.66503122e-04 -3.35044486e-04\n  -9.01781812e-06 -2.35128193e-07]\n [ 5.64732681e-03  3.85679974e-03 -2.05186515e-03 -2.58434249e-03\n  -5.66688491e-05 -1.82614514e-03]\n [ 4.24462882e-02  2.87103810e-02 -1.52547729e-02 -1.94731398e-02\n   2.39835934e-04 -1.39916070e-02]\n [ 2.70662866e-01  1.71556990e-01 -9.10515057e-02 -1.28666372e-01\n   2.76230734e-02 -9.88473204e-02]\n [ 1.02459730e+00  5.24569331e-01 -2.82673908e-01 -6.51936409e-01\n   3.77893891e-01 -4.16821725e-01]\n [ 2.20818759e+00  9.06523854e-01 -3.52335897e-01 -2.15779609e+00\n   1.33420023e+00 -8.49067745e-01]\n [ 3.91450206e+00  1.02725158e+00 -8.88263221e-02 -4.04374690e+00\n   2.16401207e+00 -1.13135886e+00]\n [ 6.30505525e+00  7.65010666e-01  7.77691427e-02 -5.59249825e+00\n   2.43704401e+00 -1.21886171e+00]\n [ 9.11157578e+00  4.17919477e-01  1.23375263e-01 -7.03469665e+00\n   2.48581221e+00 -1.23570689e+00]\n [ 1.21290373e+01  5.30319628e-01  1.32864945e-01 -8.52501966e+00\n   2.49312262e+00 -1.23852159e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  8  7  8 13 15 19 25 19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[0.         0.         0.         0.         1.31194333]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.10083721]\n [0.         0.         0.         0.         0.        ]\n [1.00745522 1.06238655 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.01227546 0.         0.         0.         1.26791822]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.14115334]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.27638401 1.3359988  0.         0.         0.        ]\n [0.         0.         0.         1.40357103 1.66873628]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         2.38314477 1.08678051 1.20719779]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         1.1616032 ]\n [0.         0.         1.84926373 0.         0.        ]\n [1.38585905 0.         1.92953205 0.         1.12049186]\n [0.         0.         1.11701629 1.22350722 1.4116954 ]\n [0.         0.         0.         0.         0.        ]\n [1.43845611 1.41522589 0.         0.         0.        ]\n [1.20568398 1.26171292 0.         0.         0.        ]\n [0.         0.         0.         1.19811586 1.3512674 ]\n [0.         0.         0.         0.         1.08048271]\n [0.         0.         0.         0.         1.32806016]\n [0.         0.         1.71334272 1.82016301 2.25325619]\n [0.         0.         1.3263859  0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.19595682 0.         0.         1.27255325 1.79797132]\n [1.35339573 0.         0.         0.         0.        ]\n [0.         0.         0.         1.24386492 1.43994634]\n [0.         0.         1.12663592 0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.70789413 1.75384676 0.         0.         0.        ]\n [1.4152163  1.43188362 0.         0.         0.        ]\n [1.65492163 1.76124918 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         1.12793525 1.54483432]\n [1.64252894 1.73011739 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.12379522 1.16550583 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]\n [1.32083783 1.35200433 0.         0.         0.        ]\n [0.         0.         0.         0.         0.        ]]", "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0\n 1 1 1 0 1 1 0 1 0 0 0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[ 2.09491713  1.07819701 -0.45208618 -1.69509495  1.4231916  -0.95977541]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 2.21176304  1.12604806 -0.44835686 -1.86713416  1.54110442 -0.98442348]]", "[2.7825594]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [40, 5], "maxprint": 50, "indices": "[4 0 1 3 4 2 3 4 4 2 0 2 4 2 3 4 0 1 0 1 3 4 4 4 2 3 4 2 0 3 4 0 3 4 2 0 1\n 0 1 0 1 3 4 0 1 0 1 0 1]", "indptr": "[ 0  0  1  3  5  5  8  8  8  8  9 10 13 16 16 18 20 22 23 24 27 28 28 31\n 32 34 35 35 37 39 41 41 43 45 45 47 47 47 47 49 49]", "data": "[1.14115334 1.27638401 1.3359988  1.40357103 1.66873628 2.38314477\n 1.08678051 1.20719779 1.1616032  1.84926373 1.38585905 1.92953205\n 1.12049186 1.11701629 1.22350722 1.4116954  1.43845611 1.41522589\n 1.20568398 1.26171292 1.19811586 1.3512674  1.08048271 1.32806016\n 1.71334272 1.82016301 2.25325619 1.3263859  1.19595682 1.27255325\n 1.79797132 1.35339573 1.24386492 1.43994634 1.12663592 1.70789413\n 1.75384676 1.4152163  1.43188362 1.65492163 1.76124918 1.12793525\n 1.54483432 1.64252894 1.73011739 1.12379522 1.16550583 1.32083783\n 1.35200433]"}, "y": "[1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.35275221e-04  6.59651459e-04 -2.66492032e-04 -2.78614969e-04\n  -1.15733099e-04 -3.64592632e-07]\n [ 6.43629555e-03  5.07699063e-03 -2.04901113e-03 -2.14326291e-03\n  -8.76229683e-04 -2.81963990e-03]\n [ 4.80042970e-02  3.75247119e-02 -1.50988113e-02 -1.58544599e-02\n  -5.74703115e-03 -2.13490323e-02]\n [ 2.93781638e-01  2.15975201e-01 -8.63751975e-02 -9.48010259e-02\n  -6.09197883e-03 -1.38685927e-01]\n [ 1.04175587e+00  6.15637190e-01 -2.68113049e-01 -4.26806586e-01\n   2.56982967e-01 -4.86284330e-01]\n [ 2.15420145e+00  1.00197679e+00 -4.43348110e-01 -1.49910727e+00\n   1.11420490e+00 -8.60941418e-01]\n [ 3.40980092e+00  1.29234444e+00 -3.86447512e-01 -2.62864632e+00\n   1.89656261e+00 -1.07351950e+00]\n [ 4.75706043e+00  1.48769412e+00 -3.35723822e-01 -3.01011286e+00\n   2.14189870e+00 -1.13070853e+00]\n [ 6.15272085e+00  1.65977492e+00 -3.25508651e-01 -3.07479231e+00\n   2.18101088e+00 -1.13996601e+00]\n [ 7.54371651e+00  2.03235443e+00 -3.23973674e-01 -3.08361687e+00\n   2.18597010e+00 -1.14125721e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  8  7  9 13 15 16 21 16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [40, 5], "maxprint": 50, "indices": "[4 4 0 1 0 4 2 0 2 4 2 3 4 0 1 0 1 3 4 4 4 2 3 4 2 0 3 4 0 3 4 2 0 1 0 1 0\n 1 3 4 0 1 0 1 0 1]", "indptr": "[ 0  1  1  2  2  4  4  4  6  6  6  7 10 13 13 15 17 19 20 21 24 25 25 28\n 29 31 32 32 34 36 38 38 40 42 42 44 44 44 44 46 46]", "data": "[1.31194333 1.10083721 1.00745522 1.06238655 1.01227546 1.26791822\n 1.84926373 1.38585905 1.92953205 1.12049186 1.11701629 1.22350722\n 1.4116954  1.43845611 1.41522589 1.20568398 1.26171292 1.19811586\n 1.3512674  1.08048271 1.32806016 1.71334272 1.82016301 2.25325619\n 1.3263859  1.19595682 1.27255325 1.79797132 1.35339573 1.24386492\n 1.43994634 1.12663592 1.70789413 1.75384676 1.4152163  1.43188362\n 1.65492163 1.76124918 1.12793525 1.54483432 1.64252894 1.73011739\n 1.12379522 1.16550583 1.32083783 1.35200433]"}, "y": "[1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.72393101e-04  6.45984402e-04 -1.47498463e-04 -1.54265600e-04\n   9.66796205e-05 -5.66592368e-07]\n [ 6.72732815e-03  4.97562072e-03 -1.13534441e-03 -1.18883201e-03\n   7.58228573e-04 -4.38904240e-03]\n [ 5.03736748e-02  3.69521656e-02 -8.42692073e-03 -8.89926344e-03\n   6.29838436e-03 -3.29430141e-02]\n [ 3.14241820e-01  2.18074570e-01 -5.05007835e-02 -5.79652015e-02\n   6.27898052e-02 -2.08684215e-01]\n [ 1.12698804e+00  6.54094602e-01 -1.80856847e-01 -3.42259873e-01\n   4.50212059e-01 -7.07605545e-01]\n [ 2.28238697e+00  1.13837445e+00 -2.99141829e-01 -1.39083722e+00\n   1.38836056e+00 -1.22684233e+00]\n [ 3.56491960e+00  1.55100181e+00 -1.53705519e-01 -2.55738732e+00\n   2.22566581e+00 -1.52492816e+00]\n [ 4.91962922e+00  1.87421800e+00 -7.15480514e-02 -2.96081523e+00\n   2.49496873e+00 -1.60950468e+00]\n [ 6.32220838e+00  2.17263691e+00 -5.61804758e-02 -3.02886490e+00\n   2.53876015e+00 -1.62378766e+00]\n [ 7.72147893e+00  2.65174697e+00 -5.38847208e-02 -3.03832892e+00\n   2.54459795e+00 -1.62582832e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  8  8  7  8 13 16 20 19 16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [40, 5], "maxprint": 50, "indices": "[4 4 0 1 0 4 4 0 1 3 4 2 3 4 4 2 3 4 2 0 3 4 2 0 1 0 1 0 1 3 4 0 1 0 1 0 1]", "indptr": "[ 0  1  1  2  2  4  4  4  6  6  7  7  7  9 11 11 14 14 14 14 15 18 19 19\n 20 22 23 23 25 27 29 29 31 33 33 35 35 35 35 37 37]", "data": "[1.31194333 1.10083721 1.00745522 1.06238655 1.01227546 1.26791822\n 1.14115334 1.27638401 1.3359988  1.40357103 1.66873628 2.38314477\n 1.08678051 1.20719779 1.1616032  1.71334272 1.82016301 2.25325619\n 1.3263859  1.35339573 1.24386492 1.43994634 1.12663592 1.70789413\n 1.75384676 1.4152163  1.43188362 1.65492163 1.76124918 1.12793525\n 1.54483432 1.64252894 1.73011739 1.12379522 1.16550583 1.32083783\n 1.35200433]"}, "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 6.75174309e-04  5.79117927e-04 -2.14725871e-04 -2.21253726e-04\n   4.80093631e-05 -3.40510834e-07]\n [ 5.20535086e-03  4.46216744e-03 -1.65475938e-03 -1.70614476e-03\n   3.81532195e-04 -2.63082873e-03]\n [ 3.89735982e-02  3.32590038e-02 -1.23916927e-02 -1.28425934e-02\n   3.45270339e-03 -1.98379230e-02]\n [ 2.42704456e-01  2.00669953e-01 -7.76613121e-02 -8.46626602e-02\n   4.54413460e-02 -1.27272928e-01]\n [ 8.71557184e-01  6.38818573e-01 -2.79370841e-01 -4.60082216e-01\n   4.39521614e-01 -4.50809377e-01]\n [ 1.84023048e+00  1.15737471e+00 -3.60732914e-01 -1.88605701e+00\n   1.61418130e+00 -8.33559549e-01]\n [ 2.99090606e+00  1.61008956e+00 -1.55702547e-01 -4.25420176e+00\n   3.35250901e+00 -1.06241320e+00]\n [ 4.22194463e+00  2.00658685e+00  3.92648624e-02 -9.64966076e+00\n   7.59036288e+00 -1.13759042e+00]\n [ 5.53970204e+00  2.40586331e+00  4.68666232e-01 -2.74762741e+01\n   2.15404022e+01 -1.20616535e+00]\n [ 6.84139471e+00  2.96575900e+00  7.95392690e-01 -5.09244070e+01\n   3.97078895e+01 -1.26938035e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  7  6  8 14 15 26 33 23]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [40, 5], "maxprint": 50, "indices": "[4 4 0 1 0 4 4 0 1 3 4 2 3 4 4 2 0 2 4 2 3 4 0 1 0 1 3 4 4 4 0 3 4 3 4 0 1\n 0 1 0 1]", "indptr": "[ 0  1  1  2  2  4  4  4  6  6  7  7  7  9 11 11 14 14 14 14 15 16 19 22\n 22 24 26 28 29 30 33 33 35 37 37 39 39 39 39 41 41]", "data": "[1.31194333 1.10083721 1.00745522 1.06238655 1.01227546 1.26791822\n 1.14115334 1.27638401 1.3359988  1.40357103 1.66873628 2.38314477\n 1.08678051 1.20719779 1.1616032  1.84926373 1.38585905 1.92953205\n 1.12049186 1.11701629 1.22350722 1.4116954  1.43845611 1.41522589\n 1.20568398 1.26171292 1.19811586 1.3512674  1.08048271 1.32806016\n 1.19595682 1.27255325 1.79797132 1.12793525 1.54483432 1.64252894\n 1.73011739 1.12379522 1.16550583 1.32083783 1.35200433]"}, "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0\n 0 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 6.30047667e-04  4.65806687e-04 -1.71005981e-04 -1.25622829e-04\n   2.52597807e-04 -3.69718424e-07]\n [ 4.86394335e-03  3.59404079e-03 -1.32123820e-03 -9.71790873e-04\n   1.95701981e-03 -2.86427163e-03]\n [ 3.67572448e-02  2.70581641e-02 -1.00538437e-02 -7.46317122e-03\n   1.51347745e-02 -2.16938650e-02]\n [ 2.41055709e-01  1.72965560e-01 -6.94778180e-02 -5.57922424e-02\n   1.13934502e-01 -1.45239625e-01]\n [ 9.37257175e-01  6.18879533e-01 -3.24134238e-01 -3.92871273e-01\n   6.24471120e-01 -5.60842473e-01]\n [ 1.98957918e+00  1.18673527e+00 -8.04872157e-01 -1.54167715e+00\n   1.66501101e+00 -1.02846602e+00]\n [ 3.29744416e+00  1.57138253e+00 -1.44669036e+00 -2.61081218e+00\n   2.44155270e+00 -1.23909298e+00]\n [ 5.11788674e+00  1.57973217e+00 -2.29709952e+00 -2.90122518e+00\n   2.65147595e+00 -1.28237746e+00]\n [ 7.61519950e+00  1.19695885e+00 -3.42051507e+00 -2.92144545e+00\n   2.67556536e+00 -1.28794840e+00]\n [ 1.06617701e+01  6.44143904e-01 -4.79414387e+00 -2.91704552e+00\n   2.67655619e+00 -1.28851374e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  8  8  7  8 12 14 19 18 39]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [40, 5], "maxprint": 50, "indices": "[4 4 0 1 0 4 4 0 1 3 4 2 3 4 4 2 0 2 4 2 3 4 0 1 0 1 3 4 4 4 2 3 4 2 0 3 4\n 0 3 4 2 0 1 0 1 0 1]", "indptr": "[ 0  1  1  2  2  4  4  4  6  6  7  7  7  9 11 11 14 14 14 14 15 16 19 22\n 22 24 26 28 29 30 33 34 34 37 38 40 41 41 43 45 47]", "data": "[1.31194333 1.10083721 1.00745522 1.06238655 1.01227546 1.26791822\n 1.14115334 1.27638401 1.3359988  1.40357103 1.66873628 2.38314477\n 1.08678051 1.20719779 1.1616032  1.84926373 1.38585905 1.92953205\n 1.12049186 1.11701629 1.22350722 1.4116954  1.43845611 1.41522589\n 1.20568398 1.26171292 1.19811586 1.3512674  1.08048271 1.32806016\n 1.71334272 1.82016301 2.25325619 1.3263859  1.19595682 1.27255325\n 1.79797132 1.35339573 1.24386492 1.43994634 1.12663592 1.70789413\n 1.75384676 1.4152163  1.43188362 1.65492163 1.76124918]"}, "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0\n 1 1 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 7.32161368e-04  5.00669628e-04 -2.66503122e-04 -3.35044486e-04\n  -9.01781812e-06 -2.35128193e-07]\n [ 5.64732681e-03  3.85679974e-03 -2.05186515e-03 -2.58434249e-03\n  -5.66688491e-05 -1.82614514e-03]\n [ 4.24462882e-02  2.87103810e-02 -1.52547729e-02 -1.94731398e-02\n   2.39835934e-04 -1.39916070e-02]\n [ 2.70662866e-01  1.71556990e-01 -9.10515057e-02 -1.28666372e-01\n   2.76230734e-02 -9.88473204e-02]\n [ 1.02459730e+00  5.24569331e-01 -2.82673908e-01 -6.51936409e-01\n   3.77893891e-01 -4.16821725e-01]\n [ 2.20818759e+00  9.06523854e-01 -3.52335897e-01 -2.15779609e+00\n   1.33420023e+00 -8.49067745e-01]\n [ 3.91450206e+00  1.02725158e+00 -8.88263221e-02 -4.04374690e+00\n   2.16401207e+00 -1.13135886e+00]\n [ 6.30505525e+00  7.65010666e-01  7.77691427e-02 -5.59249825e+00\n   2.43704401e+00 -1.21886171e+00]\n [ 9.11157578e+00  4.17919477e-01  1.23375263e-01 -7.03469665e+00\n   2.48581221e+00 -1.23570689e+00]\n [ 1.21290373e+01  5.30319629e-01  1.32864945e-01 -8.52501966e+00\n   2.49312262e+00 -1.23852159e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  9  8  7  8 13 15 19 25 19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [50, 5], "maxprint": 50, "data": "[1.31194333 1.10083721 1.00745522 1.06238655 1.01227546 1.26791822\n 1.14115334 1.27638401 1.3359988  1.40357103 1.66873628 2.38314477\n 1.08678051 1.20719779 1.1616032  1.84926373 1.38585905 1.92953205\n 1.12049186 1.11701629 1.22350722 1.4116954  1.43845611 1.41522589\n 1.20568398 1.26171292 1.19811586 1.3512674  1.08048271 1.32806016\n 1.71334272 1.82016301 2.25325619 1.3263859  1.19595682 1.27255325\n 1.79797132 1.35339573 1.24386492 1.43994634 1.12663592 1.70789413\n 1.75384676 1.4152163  1.43188362 1.65492163 1.76124918 1.12793525\n 1.54483432 1.64252894 1.73011739 1.12379522 1.16550583 1.32083783\n 1.35200433]", "indices": "[4 4 0 1 0 4 4 0 1 3 4 2 3 4 4 2 0 2 4 2 3 4 0 1 0 1 3 4 4 4 2 3 4 2 0 3 4\n 0 3 4 2 0 1 0 1 0 1 3 4 0 1 0 1 0 1]", "indptr": "[ 0  1  1  2  2  4  4  4  6  6  7  7  7  9 11 11 14 14 14 14 15 16 19 22\n 22 24 26 28 29 30 33 34 34 37 38 40 41 41 43 45 47 47 49 51 51 53 53 53\n 53 55 55]"}, "y": "[1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0\n 1 1 1 0 1 1 0 1 0 0 0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[ 2.09491713  1.07819701 -0.45208618 -1.69509495  1.4231916  -0.95977541]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 2.21176304  1.12604806 -0.44835686 -1.86713416  1.54110442 -0.98442348]]", "[2.7825594]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.06119795e-03  8.03514608e-04 -5.58329864e-03 -2.34097750e-03\n  -6.60139747e-01]\n [-1.51922190e-02  6.06129867e-03 -4.14019600e-02 -1.73443198e-02\n  -4.50560050e-01]\n [-8.57223481e-02  3.95419328e-02 -2.43064307e-01 -1.01258152e-01\n   6.58099762e-01]\n [-2.39925825e-01  1.68417483e-01 -7.74620256e-01 -3.16849369e-01\n   3.02196805e+00]\n [-3.91248036e-01  4.72563893e-01 -1.55464586e+00 -6.33382084e-01\n   5.35858286e+00]\n [-4.97759303e-01  9.88306056e-01 -2.52457860e+00 -1.08028449e+00\n   7.19058486e+00]\n [-5.81734208e-01  1.64927715e+00 -3.66827317e+00 -1.69716467e+00\n   8.89295308e+00]\n [-6.91378903e-01  2.35820802e+00 -4.98527360e+00 -2.46358919e+00\n   1.10369831e+01]\n [-4.07336947e-01  3.16945337e+00 -6.44246714e+00 -3.34774702e+00\n   1.12862422e+01]\n [-1.91666144e-01  4.19766191e+00 -7.96227941e+00 -4.16888546e+00\n   1.13945039e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[14 13 15 21 20 28 28 25 16  6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.09253559e-03  1.04170515e-03 -5.81787473e-03 -2.39272896e-03\n  -6.59050391e-01]\n [-1.53417336e-02  7.81546920e-03 -4.29600756e-02 -1.76705537e-02\n  -4.43925716e-01]\n [-8.43108403e-02  4.94712220e-02 -2.47152350e-01 -1.01674722e-01\n   6.58423592e-01]\n [-2.27870203e-01  1.96801394e-01 -7.69571066e-01 -3.14656427e-01\n   2.90887798e+00]\n [-3.57354054e-01  5.06207369e-01 -1.52504790e+00 -6.20951112e-01\n   5.10287424e+00]\n [-4.17644243e-01  9.81295543e-01 -2.45394677e+00 -1.01774437e+00\n   6.79042600e+00]\n [-4.14959046e-01  1.57356044e+00 -3.53117669e+00 -1.51018781e+00\n   8.16754850e+00]\n [-3.84955766e-01  2.24494900e+00 -4.73592816e+00 -2.08204618e+00\n   9.51519663e+00]\n [-1.79869510e-01  3.10890626e+00 -6.00882467e+00 -2.67512064e+00\n   9.58346603e+00]\n [ 3.44856568e-02  4.00373329e+00 -7.32558766e+00 -3.30400630e+00\n   9.65487856e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[14 13 16 20 18 27 24 24  9  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.11279154e-04 -7.23869011e-04  1.23261295e-03  2.98122509e-04\n  -6.96506911e-01]\n [ 7.11715860e-04 -5.55519669e-03  9.18856078e-03  2.17352067e-03\n  -7.17070516e-01]\n [-5.39000929e-04 -4.11944431e-02  5.58341298e-02  1.03474570e-02\n  -7.85825542e-01]\n [-8.24548663e-02 -2.71062487e-01  1.93879595e-01 -1.79809993e-02\n  -1.03174344e-01]\n [-4.39188469e-01 -1.20141184e+00  5.12327991e-01 -3.91630526e-01\n   3.99864616e+00]\n [-7.28872393e-01 -2.55015667e+00  1.13728414e+00 -1.62802152e+00\n   8.76524081e+00]\n [-9.01303902e-01 -3.14977777e+00  1.77334992e+00 -2.98481869e+00\n   1.07175993e+01]\n [-9.73016155e-01 -3.26075844e+00  1.99424712e+00 -3.44223827e+00\n   1.11596143e+01]\n [-9.85610667e-01 -3.27585220e+00  2.03027941e+00 -3.51586690e+00\n   1.12268044e+01]\n [-9.86713988e-01 -3.27664304e+00  2.03508673e+00 -3.52612592e+00\n   1.12293595e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 11 12 15 23 29 30 28 28 15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.46467898e-04 -7.12138418e-04  1.26121466e-03  3.26422266e-04\n  -6.98196265e-01]\n [ 2.50844886e-03 -5.45454429e-03  9.33146025e-03  2.35080821e-03\n  -7.29602985e-01]\n [ 1.22387489e-02 -3.96160447e-02  5.41328216e-02  1.08502204e-02\n  -8.65400084e-01]\n [ 3.84466359e-03 -2.48794082e-01  1.56189243e-01 -1.96318378e-02\n  -5.44687551e-01]\n [ 2.03329806e-02 -1.05544329e+00  2.65450517e-01 -3.66027505e-01\n   1.78241343e+00]\n [ 3.21101829e-01 -2.18915220e+00  3.65166609e-01 -1.14677784e+00\n   3.96056009e+00]\n [ 4.69608494e-01 -2.67174610e+00  4.60052844e-01 -1.63928254e+00\n   4.74927482e+00]\n [ 4.89258291e-01 -2.75396887e+00  4.92146965e-01 -1.75656866e+00\n   4.89469396e+00]\n [ 4.96672596e-01 -2.76541032e+00  4.92979029e-01 -1.76863880e+00\n   4.89629216e+00]\n [ 4.96676542e-01 -2.76541288e+00  4.92991088e-01 -1.76864406e+00\n   4.89629964e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[13 13 13 18 20 29 29 28  9  1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.95078170e-03 -8.09646895e-05  4.35051077e-03  2.04069888e-03\n  -7.22831545e-01]\n [ 1.44809942e-02 -5.12360790e-04  3.22280007e-02  1.51767290e-02\n  -9.14408243e-01]\n [ 8.58697246e-02  3.91018626e-04  1.89039960e-01  9.15131670e-02\n  -2.03902438e+00]\n [ 2.77322767e-01  4.14440142e-02  6.13834503e-01  3.36119906e-01\n  -5.48604568e+00]\n [ 4.39047271e-01  1.13281348e-01  1.48570238e+00  9.97795917e-01\n  -1.19267608e+01]\n [-3.78475814e-02 -1.41332100e-01  3.13622675e+00  2.64465890e+00\n  -1.89876680e+01]\n [-1.08208098e+00 -5.91284559e-01  4.89890283e+00  5.88581058e+00\n  -2.51951136e+01]\n [-2.07594639e+00 -6.11594413e-01  6.56179840e+00  1.00467416e+01\n  -3.41021897e+01]\n [-2.65581443e+00 -2.36923856e-01  7.75182929e+00  1.24449314e+01\n  -4.14800545e+01]\n [-2.79485474e+00 -1.05199276e-01  8.06024028e+00  1.29977960e+01\n  -4.34481601e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[13 14 12 18 29 36 32 34 35 36]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.74607407e-03 -3.29575346e-04  4.55669529e-03  2.06632396e-03\n  -7.22249932e-01]\n [ 1.28277193e-02 -2.36773293e-03  3.36385605e-02  1.53266483e-02\n  -9.08883591e-01]\n [ 7.12594285e-02 -1.13938858e-02  1.94248563e-01  9.14569547e-02\n  -1.96460602e+00]\n [ 1.69618803e-01 -1.79620456e-02  6.25730391e-01  3.42223686e-01\n  -4.80756669e+00]\n [-4.55945604e-02 -1.67061076e-01  1.55577088e+00  1.09363964e+00\n  -8.77680418e+00]\n [-9.43648981e-01 -9.96717349e-01  3.34326841e+00  2.77449624e+00\n  -1.24199208e+01]\n [-2.12197820e+00 -2.64187979e+00  5.79924272e+00  5.78498811e+00\n  -1.76603721e+01]\n [-3.43254054e+00 -6.10846442e+00  9.25620997e+00  1.29281089e+01\n  -2.91521463e+01]\n [-5.12604755e+00 -1.21624387e+01  1.43883049e+01  2.59891736e+01\n  -4.94956566e+01]\n [-7.00570498e+00 -1.90206372e+01  2.00994707e+01  4.09542159e+01\n  -7.25285269e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[13 13 13 19 24 24 23 26 29 43]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[-0.23389801  0.18260944 -0.77209566 -0.3157529   2.96542302]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.28556886  0.26559653 -1.00973761 -0.4110215   3.7769573 ]]", "[0.04641589]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[-0.2158477  -2.91076193  1.11670138 -2.31205061  7.73343707]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.22259784 -2.76055317  1.23132409 -2.59918506  7.24154032]]", "[21.5443469]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[ -1.60202959  -1.61658217   5.34907277   5.83539935 -21.42774286]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ -1.88081078  -2.43937062   5.90947111   7.34015847 -22.52679814]]", "[21.5443469]", "[35]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.95078170e-03 -8.09646895e-05  4.35051077e-03  2.04069888e-03\n  -7.22831545e-01]\n [ 1.44809942e-02 -5.12360790e-04  3.22280007e-02  1.51767290e-02\n  -9.14408243e-01]\n [ 8.58697246e-02  3.91018626e-04  1.89039960e-01  9.15131670e-02\n  -2.03902438e+00]\n [ 2.77322767e-01  4.14440142e-02  6.13834503e-01  3.36119906e-01\n  -5.48604568e+00]\n [ 4.39047271e-01  1.13281348e-01  1.48570238e+00  9.97795917e-01\n  -1.19267608e+01]\n [-3.78475814e-02 -1.41332100e-01  3.13622675e+00  2.64465890e+00\n  -1.89876680e+01]\n [-1.08208098e+00 -5.91284559e-01  4.89890283e+00  5.88581058e+00\n  -2.51951136e+01]\n [-2.07594639e+00 -6.11594413e-01  6.56179840e+00  1.00467416e+01\n  -3.41021897e+01]\n [-2.65581443e+00 -2.36923856e-01  7.75182929e+00  1.24449314e+01\n  -4.14800545e+01]\n [-2.79485474e+00 -1.05199276e-01  8.06024028e+00  1.29977960e+01\n  -4.34481601e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[13 14 12 18 29 36 32 34 35 36]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.74607407e-03 -3.29575346e-04  4.55669529e-03  2.06632396e-03\n  -7.22249932e-01]\n [ 1.28277193e-02 -2.36773293e-03  3.36385605e-02  1.53266483e-02\n  -9.08883591e-01]\n [ 7.12594285e-02 -1.13938858e-02  1.94248563e-01  9.14569547e-02\n  -1.96460602e+00]\n [ 1.69618803e-01 -1.79620456e-02  6.25730391e-01  3.42223686e-01\n  -4.80756669e+00]\n [-4.55945604e-02 -1.67061076e-01  1.55577088e+00  1.09363964e+00\n  -8.77680418e+00]\n [-9.43648981e-01 -9.96717349e-01  3.34326841e+00  2.77449624e+00\n  -1.24199208e+01]\n [-2.12197820e+00 -2.64187979e+00  5.79924272e+00  5.78498811e+00\n  -1.76603721e+01]\n [-3.43254054e+00 -6.10846442e+00  9.25620997e+00  1.29281089e+01\n  -2.91521463e+01]\n [-5.12604755e+00 -1.21624387e+01  1.43883049e+01  2.59891736e+01\n  -4.94956566e+01]\n [-7.00570498e+00 -1.90206372e+01  2.00994707e+01  4.09542159e+01\n  -7.25285269e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[13 13 13 19 24 24 23 26 29 43]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[ -1.60202959  -1.61658217   5.34907277   5.83539935 -21.42774286]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ -1.88081078  -2.43937062   5.90947111   7.34015847 -22.52679814]]", "[21.5443469]", "[35]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 15, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.05260572e-03  8.02375595e-04 -5.56438053e-03 -2.33295287e-03\n    3.28026876e-02]\n  [ 1.05954515e-04 -7.23706965e-04  1.22721730e-03  2.98123572e-04\n   -3.08566349e-03]\n  [ 1.94665121e-03 -7.86686305e-05  4.33716323e-03  2.03482930e-03\n   -2.97170241e-02]]\n\n [[-1.47591496e-02  5.99668051e-03 -4.04308513e-02 -1.69315982e-02\n    2.35481943e-01]\n  [ 6.15792745e-04 -5.54067048e-03  8.97544605e-03  2.08386658e-03\n   -1.98317888e-02]\n  [ 1.41433569e-02 -4.56010028e-04  3.14554052e-02  1.48477316e-02\n   -2.15650155e-01]]\n\n [[-7.64081878e-02  3.53552648e-02 -2.16192003e-01 -8.98953729e-02\n    1.19876406e+00]\n  [ 9.50410943e-04 -3.56081457e-02  4.88861850e-02  8.55999229e-03\n   -3.41836024e-02]\n  [ 7.54577769e-02  2.52880918e-04  1.67305818e-01  8.13353807e-02\n   -1.16458046e+00]]\n\n [[-5.38862777e-02  2.63270161e-01 -6.25850941e-01 -2.51098587e-01\n    1.96896467e+00]\n  [ 3.26479352e-02 -2.84687216e-01  1.95360969e-01 -1.45007294e-01\n    3.78933489e-01]\n  [ 2.12383424e-02  2.14170544e-02  4.30489972e-01  3.96105881e-01\n   -2.34789816e+00]]\n\n [[ 1.38101981e-01  7.46900118e-01 -1.33941578e+00 -5.81392726e-01\n    2.13846142e+00]\n  [ 2.12836095e-01 -2.83010338e-01  1.34061235e-01 -3.90692318e-01\n    5.88978048e-01]\n  [-3.50938077e-01 -4.63889781e-01  1.20535455e+00  9.72085044e-01\n   -2.72743947e+00]]\n\n [[ 6.03976633e-01  1.77273139e+00 -2.73826893e+00 -1.22014304e+00\n    2.42703876e+00]\n  [ 5.82367049e-01 -2.01341419e-01 -6.20676884e-02 -1.20345964e+00\n    1.15294303e+00]\n  [-1.18634368e+00 -1.57138998e+00  2.80033662e+00  2.42360268e+00\n   -3.57998179e+00]]\n\n [[ 1.18572062e+00  3.14569744e+00 -4.77005391e+00 -2.17649073e+00\n    2.74167687e+00]\n  [ 6.96202139e-01 -7.52566162e-02  2.26658656e-01 -2.10855111e+00\n    1.99687618e+00]\n  [-1.88192276e+00 -3.07044083e+00  4.54339525e+00  4.28504184e+00\n   -4.73855305e+00]]\n\n [[ 1.67398034e+00  3.77022429e+00 -5.40649408e+00 -2.56307343e+00\n    2.94285771e+00]\n  [ 5.68242836e-01  1.08636749e+00 -3.05951853e-01 -3.74306955e+00\n    4.06905236e+00]\n  [-2.24222318e+00 -4.85659177e+00  5.71244593e+00  6.30614298e+00\n   -7.01191006e+00]]\n\n [[ 2.35990274e+00  6.27354143e+00 -1.02361887e+01 -5.08319942e+00\n    3.50990128e+00]\n  [-7.20459461e-01 -1.90720915e+00  2.84562651e+00 -2.75749575e+00\n    1.16886297e+01]\n  [-1.63944328e+00 -4.36633228e+00  7.39056223e+00  7.84069517e+00\n   -1.51985310e+01]]\n\n [[ 2.54938946e+00  6.36680041e+00 -1.01684017e+01 -5.06494689e+00\n    3.55233744e+00]\n  [-8.08175224e-02 -1.97580049e+00  1.97890634e+00 -3.05019366e+00\n    1.17697693e+01]\n  [-2.46857194e+00 -4.39099992e+00  8.18949536e+00  8.11514055e+00\n   -1.53221068e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[11 15 15 15 15 15 15 15 15 15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 15, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.08271169e-03  1.03981232e-03 -5.79641815e-03 -2.38402098e-03\n    3.38752545e-02]\n  [ 3.41667949e-04 -7.12567168e-04  1.25509024e-03  3.24432678e-04\n   -4.77171157e-03]\n  [ 1.74104374e-03 -3.27245153e-04  4.54132791e-03  2.05958830e-03\n   -2.91035430e-02]]\n\n [[-1.48592803e-02  7.70206029e-03 -4.18497429e-02 -1.72170607e-02\n    2.41277579e-01]\n  [ 2.39078646e-03 -5.42959128e-03  9.07193404e-03  2.24547975e-03\n   -3.16716450e-02]\n  [ 1.24684939e-02 -2.27246901e-03  3.27778088e-02  1.49715810e-02\n   -2.09605934e-01]]\n\n [[-7.46531079e-02  4.40113439e-02 -2.19180217e-01 -9.00653877e-02\n    1.18702438e+00]\n  [ 1.34193867e-02 -3.20006054e-02  4.67674710e-02  8.93557542e-03\n   -1.05728347e-01]\n  [ 6.12337212e-02 -1.20107384e-02  1.72412746e-01  8.11298123e-02\n   -1.08129603e+00]]\n\n [[-2.08106819e-02  2.99732874e-01 -6.02421719e-01 -2.57806944e-01\n    1.52982886e+00]\n  [ 1.12748323e-01 -2.27052560e-01  1.23922385e-01 -9.11506279e-02\n    9.40766836e-05]\n  [-9.19376413e-02 -7.26803132e-02  4.78499334e-01  3.48957572e-01\n   -1.52992293e+00]]\n\n [[ 1.55783048e-01  8.13487250e-01 -1.32602014e+00 -5.90042710e-01\n    1.76916755e+00]\n  [ 3.39651400e-01 -2.87274425e-01  4.87839637e-02 -3.29906337e-01\n    1.98195808e-01]\n  [-4.95434448e-01 -5.26212825e-01  1.27723617e+00  9.19949047e-01\n   -1.96736336e+00]]\n\n [[ 5.79049129e-01  1.78487995e+00 -2.52649753e+00 -1.15922422e+00\n    2.03614855e+00]\n  [ 8.39783550e-01 -2.25551593e-01 -3.24649877e-01 -1.00256488e+00\n    5.42020635e-01]\n  [-1.41883268e+00 -1.55932835e+00  2.85114741e+00  2.16178910e+00\n   -2.57816918e+00]]\n\n [[ 1.19750257e+00  3.12396825e+00 -4.21053413e+00 -2.01283497e+00\n    2.43806564e+00]\n  [ 1.25209495e+00  2.50017106e-01 -6.58203690e-01 -2.28422801e+00\n    1.37851854e+00]\n  [-2.44959752e+00 -3.37398535e+00  4.86873782e+00  4.29706298e+00\n   -3.81658418e+00]]\n\n [[ 2.34647403e+00  5.84551612e+00 -7.88539651e+00 -3.99607308e+00\n    3.15042154e+00]\n  [ 1.53138596e+00  9.13902730e-01 -1.21375974e-01 -5.45527943e+00\n    3.54076743e+00]\n  [-3.87785999e+00 -6.75941885e+00  8.00677248e+00  9.45135251e+00\n   -6.69118897e+00]]\n\n [[ 2.74228976e+00  6.19242226e+00 -7.87948046e+00 -4.09697945e+00\n    3.29592147e+00]\n  [ 2.26809878e+00  1.27507761e+00 -7.90150471e-01 -8.52579842e+00\n    5.08269175e+00]\n  [-5.01038854e+00 -7.46749987e+00  8.66963093e+00  1.26227779e+01\n   -8.37861322e+00]]\n\n [[ 3.53133789e+00  9.84271253e+00 -1.36537289e+01 -7.69201048e+00\n    4.07459738e+00]\n  [ 1.28136607e+00  2.33760174e+00  2.25853992e+00 -1.16454356e+01\n    8.03926145e+00]\n  [-4.81270395e+00 -1.21803143e+01  1.13951890e+01  1.93374461e+01\n   -1.21138588e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[11 15 15 15 15 15 15 15 15 15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[ 0.14694251  0.78019368 -1.33271796 -0.58571772  1.95381448]\n [ 0.27624375 -0.28514238  0.0914226  -0.36029933  0.39358693]\n [-0.42318626 -0.4950513   1.24129536  0.94601705 -2.34740141]]", "max_iter": 15, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 0.28320269  1.08755548 -1.73274291 -0.77278782  2.14478572]\n  [ 0.41825753 -0.26652073 -0.02340331 -0.63136573  0.66025693]\n  [-0.70146022 -0.82103475  1.75614623  1.40415355 -2.80504265]]]", "[0.35938137]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 15, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.05339796e-03  8.02034186e-04 -5.56504525e-03 -2.33318192e-03\n    3.28719819e-02]\n  [ 1.07977537e-04 -7.22699007e-04  1.22856144e-03  2.98531239e-04\n   -3.22183272e-03]\n  [ 1.94542042e-03 -7.93351790e-05  4.33648381e-03  2.03465068e-03\n   -2.96501491e-02]]\n\n [[-1.47819350e-02  5.97504274e-03 -4.04234002e-02 -1.69262888e-02\n    2.35988315e-01]\n  [ 6.35490762e-04 -5.52549183e-03  8.97973448e-03  2.08513031e-03\n   -2.03883228e-02]\n  [ 1.41464442e-02 -4.49550916e-04  3.14436658e-02  1.48411585e-02\n   -2.15599992e-01]]\n\n [[-7.46935224e-02  3.68224373e-02 -2.15999762e-01 -8.97413027e-02\n    1.18282084e+00]\n  [-2.31927366e-03 -3.90363348e-02  4.81015132e-02  7.28681584e-03\n    6.03138715e-03]\n  [ 7.70127961e-02  2.21389745e-03  1.67898248e-01  8.24544869e-02\n   -1.18885223e+00]]\n\n [[-1.94368033e-01  1.47041814e-01 -6.46381184e-01 -2.62621093e-01\n    3.13641074e+00]\n  [-4.87504437e-02 -1.96978109e-01  1.20802037e-01 -3.43366870e-02\n    8.88020015e-01]\n  [ 2.43118476e-01  4.99362958e-02  5.25579147e-01  2.96957780e-01\n   -4.02443076e+00]]\n\n [[-3.79659050e-01  4.20604826e-01 -1.47068451e+00 -5.97709723e-01\n    6.68982282e+00]\n  [-1.32599941e-02 -4.62368885e-01  6.44455720e-02 -3.12260408e-01\n    2.90131039e+00]\n  [ 3.92919044e-01  4.17640593e-02  1.40623894e+00  9.09970131e-01\n   -9.59113321e+00]]\n\n [[-4.43959791e-01  1.01613754e+00 -2.71400140e+00 -1.19025030e+00\n    1.06111905e+01]\n  [ 3.61869550e-01 -6.02156365e-01 -1.97478120e-01 -1.00993609e+00\n    4.31198727e+00]\n  [ 8.20902410e-02 -4.13981172e-01  2.91147952e+00  2.20018639e+00\n   -1.49231778e+01]]\n\n [[-3.41679139e-01  1.86152950e+00 -4.27655282e+00 -2.07959667e+00\n    1.43740321e+01]\n  [ 8.15124135e-01 -7.41556110e-01 -3.60294063e-01 -2.34433541e+00\n    6.05163131e+00]\n  [-4.73444995e-01 -1.11997339e+00  4.63684688e+00  4.42393208e+00\n   -2.04256634e+01]]\n\n [[ 3.14677886e-01  2.71071728e+00 -5.95113877e+00 -3.23266767e+00\n    1.57387914e+01]\n  [ 9.50300985e-01 -1.09458920e+00 -3.70213764e-01 -3.69738597e+00\n    9.68278124e+00]\n  [-1.26497887e+00 -1.61612808e+00  6.32135253e+00  6.93005364e+00\n   -2.54215726e+01]]\n\n [[ 8.43200665e-01  3.37052047e+00 -7.28236286e+00 -4.04557844e+00\n    1.61851296e+01]\n  [ 9.12375926e-01 -1.52172924e+00 -1.83142616e-01 -4.20073025e+00\n    1.22240208e+01]\n  [-1.75557659e+00 -1.84879123e+00  7.46550547e+00  8.24630869e+00\n   -2.84091504e+01]]\n\n [[ 8.43200665e-01  3.37052047e+00 -7.28236286e+00 -4.04557844e+00\n    1.61851296e+01]\n  [ 9.12375926e-01 -1.52172924e+00 -1.83142616e-01 -4.20073025e+00\n    1.22240208e+01]\n  [-1.75557659e+00 -1.84879123e+00  7.46550547e+00  8.24630869e+00\n   -2.84091504e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[5 9 5 7 8 8 7 7 3 0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 15, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.08397411e-03  1.03921052e-03 -5.79708932e-03 -2.38420347e-03\n    3.39594807e-02]\n  [ 3.43890107e-04 -7.11986698e-04  1.25628808e-03  3.24446979e-04\n   -4.90397473e-03]\n  [ 1.74008401e-03 -3.27223824e-04  4.54080124e-03  2.05975649e-03\n   -2.90555060e-02]]\n\n [[-1.49126660e-02  7.66697622e-03 -4.18683588e-02 -1.72210105e-02\n    2.42304424e-01]\n  [ 2.41951552e-03 -5.41242365e-03  9.08453681e-03  2.24846605e-03\n   -3.24113990e-02]\n  [ 1.24931505e-02 -2.25455257e-03  3.27838220e-02  1.49725444e-02\n   -2.09893025e-01]]\n\n [[-7.29812055e-02  4.55324696e-02 -2.18447064e-01 -8.98394089e-02\n    1.17528278e+00]\n  [ 1.05134062e-02 -3.68807977e-02  4.61237739e-02  7.48556825e-03\n   -6.73843849e-02]\n  [ 6.24677993e-02 -8.65167188e-03  1.72323290e-01  8.23538406e-02\n   -1.10789840e+00]]\n\n [[-1.84655199e-01  1.71462577e-01 -6.41900950e-01 -2.61964967e-01\n    3.04220607e+00]\n  [ 3.80481159e-02 -1.66424092e-01  9.52716213e-02 -4.34651186e-02\n    4.03830915e-01]\n  [ 1.46607083e-01 -5.03848432e-03  5.46629328e-01  3.05430086e-01\n   -3.44603698e+00]]\n\n [[-3.12191107e-01  5.02868709e-01 -1.46622000e+00 -6.02455250e-01\n    6.18226823e+00]\n  [ 2.89052413e-01 -2.90760586e-01 -2.11196305e-02 -3.85859252e-01\n    1.06192817e+00]\n  [ 2.31386938e-02 -2.12108123e-01  1.48733963e+00  9.88314502e-01\n   -7.24419639e+00]]\n\n [[-3.19558272e-01  1.16888661e+00 -2.75909262e+00 -1.17724214e+00\n    9.84777519e+00]\n  [ 7.57961948e-01 -1.06661440e-01 -3.02365148e-01 -1.10039127e+00\n    1.12324689e+00]\n  [-4.38403676e-01 -1.06222517e+00  3.06145777e+00  2.27763341e+00\n   -1.09710221e+01]]\n\n [[ 4.18249430e-02  2.28686125e+00 -4.42924172e+00 -2.09193495e+00\n    1.23381249e+01]\n  [ 1.10076969e+00  3.47714114e-01 -6.43245416e-01 -2.39470667e+00\n    2.54756314e+00]\n  [-1.14259463e+00 -2.63457536e+00  5.07248714e+00  4.48664162e+00\n   -1.48856880e+01]]\n\n [[ 9.49384632e-01  4.33067881e+00 -6.72986472e+00 -3.87651888e+00\n    1.38327088e+01]\n  [ 1.20470398e+00  1.30399036e+00 -1.07175092e+00 -5.54943617e+00\n    7.56456436e+00]\n  [-2.15408862e+00 -5.63466917e+00  7.80161564e+00  9.42595506e+00\n   -2.13972731e+01]]\n\n [[ 2.12084634e+00  6.97402541e+00 -9.75795776e+00 -5.83571635e+00\n    1.44737031e+01]\n  [ 1.64267135e+00  2.59264764e+00 -8.16202899e-01 -1.00390749e+01\n    9.27184472e+00]\n  [-3.76351768e+00 -9.56667305e+00  1.05741607e+01  1.58747912e+01\n   -2.37455479e+01]]\n\n [[ 3.02790262e+00  8.99018314e+00 -1.18617758e+01 -7.33339130e+00\n    1.49066359e+01]\n  [ 2.01492545e+00  3.76798281e+00 -7.53982758e-01 -1.42151314e+01\n    1.12181610e+01]\n  [-5.04282807e+00 -1.27581660e+01  1.26157585e+01  2.15485227e+01\n   -2.61247969e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[5 7 7 8 7 9 8 6 3 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[[ -0.1499271    2.07419538  -4.35289727  -2.08576581  13.3560785 ]\n [  0.95794691  -0.196921    -0.50176974  -2.36952104   4.29959722]\n [ -0.80801981  -1.87727438   4.85466701   4.45528685 -17.65567572]]", "max_iter": 15, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ -0.35918864   2.52447514  -4.92936828  -2.43894667  15.60670074]\n  [  1.16481573   0.07330747  -0.50806829  -2.94144568   3.76608002]\n  [ -0.80562709  -2.59778261   5.43743657   5.38039235 -19.37278076]]]", "[21.5443469]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-2.05358492e-03  8.01927208e-04 -5.56515164e-03 -2.33321731e-03\n    3.28862379e-02]\n  [ 1.09281960e-04 -7.21991031e-04  1.22937991e-03  2.98806816e-04\n   -3.32267409e-03]\n  [ 1.94430296e-03 -7.99361768e-05  4.33577173e-03  2.03441049e-03\n   -2.95635638e-02]]\n\n [[-1.47795860e-02  5.97638728e-03 -4.04223526e-02 -1.69261268e-02\n    2.35949840e-01]\n  [ 6.33728500e-04 -5.52620190e-03  8.97915067e-03  2.08556301e-03\n   -2.03608243e-02]\n  [ 1.41458575e-02 -4.50185378e-04  3.14432019e-02  1.48405638e-02\n   -2.15589016e-01]]\n\n [[-7.48251192e-02  3.67379252e-02 -2.16045998e-01 -8.97498712e-02\n    1.18418246e+00]\n  [-2.24296550e-03 -3.89878806e-02  4.81317586e-02  7.29263901e-03\n    5.24224936e-03]\n  [ 7.70680847e-02  2.24995533e-03  1.67914239e-01  8.24572322e-02\n   -1.18942471e+00]]\n\n [[-1.94555543e-01  1.46920842e-01 -6.46418980e-01 -2.62621343e-01\n    3.13801911e+00]\n  [-4.86848443e-02 -1.96926857e-01  1.20792268e-01 -3.43212212e-02\n    8.87555635e-01]\n  [ 2.43240387e-01  5.00060144e-02  5.25626712e-01  2.96942564e-01\n   -4.02557475e+00]]\n\n [[-3.71790871e-01  4.22582914e-01 -1.47139268e+00 -5.97316453e-01\n    6.64144384e+00]\n  [-1.61984343e-02 -4.62927017e-01  6.54841076e-02 -3.12157766e-01\n    2.91403874e+00]\n  [ 3.87989306e-01  4.03441024e-02  1.40590858e+00  9.09474219e-01\n   -9.55548258e+00]]\n\n [[-2.72571319e-01  1.10881782e+00 -2.69659557e+00 -1.18313062e+00\n    9.29890988e+00]\n  [ 3.15793185e-01 -5.86949512e-01 -1.59775654e-01 -1.02444887e+00\n    4.33189711e+00]\n  [-4.32218656e-02 -5.21868303e-01  2.85637123e+00  2.20757949e+00\n   -1.36308070e+01]]\n\n [[ 1.86043453e-01  2.13142879e+00 -4.17452213e+00 -2.05916170e+00\n    1.01952809e+01]\n  [ 6.29745201e-01 -5.43917157e-01 -2.12374017e-01 -2.28386039e+00\n    5.58531955e+00]\n  [-8.15788653e-01 -1.58751163e+00  4.38689615e+00  4.34302209e+00\n   -1.57806004e+01]]\n\n [[ 7.01222950e-01  3.14995509e+00 -5.68867879e+00 -2.94431330e+00\n    1.05457391e+01]\n  [ 7.32017479e-01 -5.03953253e-01  1.94733203e-02 -3.45140745e+00\n    6.84445262e+00]\n  [-1.43324043e+00 -2.64600184e+00  5.66920547e+00  6.39572074e+00\n   -1.73901917e+01]]\n\n [[ 1.00398823e+00  3.71036074e+00 -6.60170943e+00 -3.47485388e+00\n    1.06948945e+01]\n  [ 6.92296714e-01 -6.69954792e-01  2.41423904e-01 -3.82319720e+00\n    7.96772398e+00]\n  [-1.69628494e+00 -3.04040595e+00  6.36028553e+00  7.29805108e+00\n   -1.86626184e+01]]\n\n [[ 1.17764045e+00  3.99465354e+00 -7.10400384e+00 -3.76360382e+00\n    1.07713562e+01]\n  [ 6.41979335e-01 -8.89799959e-01  3.64720648e-01 -3.89870848e+00\n    8.93054430e+00]\n  [-1.81961979e+00 -3.10485358e+00  6.73928320e+00  7.66231230e+00\n   -1.97019005e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  56   31   94  393 1673 2000 2000 2000 2000 2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-2.08394754e-03  1.03921575e-03 -5.79706501e-03 -2.38419542e-03\n    3.39570560e-02]\n  [ 3.45020736e-04 -7.11364793e-04  1.25701547e-03  3.24692843e-04\n   -4.99087438e-03]\n  [ 1.73892681e-03 -3.27850953e-04  4.54004954e-03  2.05950257e-03\n   -2.89661816e-02]]\n\n [[-1.48827383e-02  7.68309063e-03 -4.18508054e-02 -1.72156845e-02\n    2.41711406e-01]\n  [ 2.41618953e-03 -5.41280358e-03  9.08341400e-03  2.24913621e-03\n   -3.23008142e-02]\n  [ 1.24665488e-02 -2.27028705e-03  3.27673914e-02  1.49665483e-02\n   -2.09410592e-01]]\n\n [[-7.30306378e-02  4.55010061e-02 -2.18466730e-01 -8.98453449e-02\n    1.17581500e+00]\n  [ 1.05488012e-02 -3.68554263e-02  4.61334455e-02  7.48784284e-03\n   -6.77449432e-02]\n  [ 6.24818366e-02 -8.64557984e-03  1.72333285e-01  8.23575020e-02\n   -1.10807006e+00]]\n\n [[-1.84245483e-01  1.71760949e-01 -6.41822979e-01 -2.61988375e-01\n    3.03869795e+00]\n  [ 3.76360878e-02 -1.66666404e-01  9.52337079e-02 -4.34256672e-02\n    4.07099385e-01]\n  [ 1.46609396e-01 -5.09454502e-03  5.46589271e-01  3.05414043e-01\n   -3.44579733e+00]]\n\n [[-3.12292892e-01  5.02974234e-01 -1.46608170e+00 -6.02665814e-01\n    6.18166743e+00]\n  [ 2.90328395e-01 -2.90077160e-01 -2.10047904e-02 -3.86046553e-01\n    1.05198785e+00]\n  [ 2.19644975e-02 -2.12897074e-01  1.48708649e+00  9.88712367e-01\n   -7.23365528e+00]]\n\n [[-1.57868505e-01  1.26802699e+00 -2.71522449e+00 -1.18689694e+00\n    8.52347914e+00]\n  [ 6.93727367e-01 -1.46660900e-01 -2.97875302e-01 -1.08788763e+00\n    1.51273715e+00]\n  [-5.35858862e-01 -1.12136609e+00  3.01309979e+00  2.27478458e+00\n   -1.00362163e+01]]\n\n [[ 3.90135182e-01  2.49635525e+00 -4.29218246e+00 -2.05663454e+00\n    9.17617309e+00]\n  [ 1.02608199e+00  2.97796645e-01 -5.21896668e-01 -2.42710085e+00\n    2.46458947e+00]\n  [-1.41621717e+00 -2.79415189e+00  4.81407912e+00  4.48373538e+00\n   -1.16407626e+01]]\n\n [[ 1.15987182e+00  4.10807860e+00 -6.21767487e+00 -3.17543036e+00\n    9.60340300e+00]\n  [ 1.39374462e+00  1.06278829e+00 -6.05148490e-01 -4.98978216e+00\n    3.74124680e+00]\n  [-2.55361644e+00 -5.17086690e+00  6.82282336e+00  8.16521252e+00\n   -1.33446498e+01]]\n\n [[ 1.72806852e+00  5.28835901e+00 -7.56597372e+00 -4.01632642e+00\n    9.84638078e+00]\n  [ 1.65278741e+00  1.67548562e+00 -6.40493265e-01 -7.11556460e+00\n    4.78185997e+00]\n  [-3.38085593e+00 -6.96384462e+00  8.20646698e+00  1.11318910e+01\n   -1.46282407e+01]]\n\n [[ 2.13066260e+00  6.13039028e+00 -8.49487822e+00 -4.62797433e+00\n    1.00106348e+01]\n  [ 1.82849019e+00  2.13528245e+00 -6.64449992e-01 -8.72778761e+00\n    5.61590971e+00]\n  [-3.95915279e+00 -8.26567273e+00  9.15932821e+00  1.33557619e+01\n   -1.56265445e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  56   32   92  385 1472 2000 1430 2000 2000 2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[[  0.28808932   2.31389202  -4.23335229  -2.05789812   9.68572697]\n [  0.82791359  -0.12306026  -0.36713534  -2.35548062   4.02495451]\n [ -1.11600291  -2.19083176   4.60048763   4.41337874 -13.71068149]]", "max_iter": 2000, "tol": 1e-05, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 3.99480360e-01  2.77330003e+00 -4.80855839e+00 -2.47294611e+00\n    1.04317386e+01]\n  [ 8.22087346e-01 -3.67298163e-03 -4.39597817e-01 -2.83511855e+00\n    5.20893513e+00]\n  [-1.22156771e+00 -2.76962704e+00  5.24815621e+00  5.30806465e+00\n   -1.56406737e+01]]]", "[21.5443469]", "[1524]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-2.05129246e-03  8.03136825e-04 -5.56370228e-03 -2.33275604e-03\n    3.27092683e-02]\n  [ 1.11329847e-04 -7.20913444e-04  1.23068137e-03  2.99221885e-04\n   -3.48348458e-03]\n  [ 1.93996261e-03 -8.22233812e-05  4.33302091e-03  2.03353416e-03\n   -2.92257837e-02]]\n\n [[-1.47735648e-02  5.97962885e-03 -4.04187482e-02 -1.69250083e-02\n    2.35835654e-01]\n  [ 6.33462596e-04 -5.52637454e-03  8.97906118e-03  2.08554625e-03\n   -2.03561518e-02]\n  [ 1.41401022e-02 -4.53254317e-04  3.14396870e-02  1.48394620e-02\n   -2.15479502e-01]]\n\n [[-7.47860268e-02  3.67619059e-02 -2.16029609e-01 -8.97459895e-02\n    1.18376190e+00]\n  [-2.22496954e-03 -3.89781452e-02  4.81424448e-02  7.29578987e-03\n    5.02353783e-03]\n  [ 7.70109963e-02  2.21623934e-03  1.67887164e-01  8.24501996e-02\n   -1.18878544e+00]]\n\n [[-1.93881944e-01  1.47355426e-01 -6.46217891e-01 -2.62595028e-01\n    3.13176374e+00]\n  [-4.85329908e-02 -1.96855081e-01  1.20914256e-01 -3.43037774e-02\n    8.85535829e-01]\n  [ 2.42414935e-01  4.94996543e-02  5.25303635e-01  2.96898805e-01\n   -4.01729957e+00]]\n\n [[-3.34247449e-01  4.45706971e-01 -1.46326611e+00 -5.96654493e-01\n    6.32373810e+00]\n  [-2.17348783e-02 -4.65991235e-01  7.17614253e-02 -3.12862150e-01\n    2.91407258e+00]\n  [ 3.55982327e-01  2.02842643e-02  1.39150469e+00  9.09516643e-01\n   -9.23781068e+00]]\n\n [[-1.12972665e-01  1.20070086e+00 -2.67456960e+00 -1.18159995e+00\n    8.02613766e+00]\n  [ 2.88169253e-01 -5.54489729e-01 -1.20208259e-01 -1.03304139e+00\n    4.17886105e+00]\n  [-1.75196588e-01 -6.46211127e-01  2.79477786e+00  2.21464134e+00\n   -1.22049987e+01]]\n\n [[ 3.75279502e-01  2.24755399e+00 -4.15724677e+00 -2.02522324e+00\n    8.64210492e+00]\n  [ 5.77854942e-01 -4.29976882e-01 -1.40288065e-01 -2.27836291e+00\n    5.15837189e+00]\n  [-9.53134444e-01 -1.81757711e+00  4.29753483e+00  4.30358614e+00\n   -1.38004768e+01]]\n\n [[ 8.21360406e-01  3.15575367e+00 -5.48575046e+00 -2.77457511e+00\n    8.89869289e+00]\n  [ 6.70575081e-01 -3.41641265e-01  6.52226774e-02 -3.28854591e+00\n    6.05067110e+00]\n  [-1.49193549e+00 -2.81411241e+00  5.42052778e+00  6.06312102e+00\n   -1.49493640e+01]]\n\n [[ 1.06334145e+00  3.62599353e+00 -6.21867882e+00 -3.19507731e+00\n    9.01022406e+00]\n  [ 6.34321146e-01 -3.95297586e-01  2.47772073e-01 -3.68257586e+00\n    6.85677106e+00]\n  [-1.69766259e+00 -3.23069594e+00  5.97090675e+00  6.87765318e+00\n   -1.58669951e+01]]\n\n [[ 1.20819735e+00  3.88780630e+00 -6.65224047e+00 -3.44352351e+00\n    9.07245590e+00]\n  [ 5.86253611e-01 -5.17578458e-01  3.65535029e-01 -3.81735743e+00\n    7.57312820e+00]\n  [-1.79445096e+00 -3.37022784e+00  6.28670545e+00  7.26088094e+00\n   -1.66455841e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 105   88  243  996 2000 2000 2000 2000 2000 2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-2.08146690e-03  1.04051537e-03 -5.79547425e-03 -2.38369087e-03\n    3.37664244e-02]\n  [ 3.47009800e-04 -7.10326761e-04  1.25829914e-03  3.25100942e-04\n   -5.14650721e-03]\n  [ 1.73445710e-03 -3.30188610e-04  4.53717511e-03  2.05858993e-03\n   -2.86199172e-02]]\n\n [[-1.48757699e-02  7.68684888e-03 -4.18465619e-02 -1.72143691e-02\n    2.41578517e-01]\n  [ 2.41558305e-03 -5.41316963e-03  9.08312859e-03  2.24905873e-03\n   -3.22896024e-02]\n  [ 1.24601869e-02 -2.27367926e-03  3.27634333e-02  1.49653103e-02\n   -2.09288914e-01]]\n\n [[-7.29876153e-02  4.55278239e-02 -2.18448522e-01 -8.98408037e-02\n    1.17534402e+00]\n  [ 1.05641731e-02 -3.68473944e-02  4.61432105e-02  7.49099164e-03\n   -6.79407503e-02]\n  [ 6.24234422e-02 -8.68042951e-03  1.72305311e-01  8.23498121e-02\n   -1.10740327e+00]]\n\n [[-1.83459866e-01  1.72283397e-01 -6.41576798e-01 -2.61952410e-01\n    3.03128124e+00]\n  [ 3.77008153e-02 -1.66672049e-01  9.53309559e-02 -4.33812640e-02\n    4.05858359e-01]\n  [ 1.45759051e-01 -5.61134837e-03  5.46245842e-01  3.05333674e-01\n   -3.43713960e+00]]\n\n [[-2.89828357e-01  5.17999876e-01 -1.45998924e+00 -6.02581530e-01\n    5.98481565e+00]\n  [ 2.84155402e-01 -2.95605854e-01 -1.96253884e-02 -3.84454924e-01\n    1.08760852e+00]\n  [ 5.67295525e-03 -2.22394022e-01  1.47961463e+00  9.87036454e-01\n   -7.07242417e+00]]\n\n [[-3.88652737e-02  1.34373633e+00 -2.68217210e+00 -1.19171057e+00\n    7.51514697e+00]\n  [ 6.59436243e-01 -1.67421784e-01 -2.85289660e-01 -1.07998856e+00\n    1.66038959e+00]\n  [-6.20570970e-01 -1.17631455e+00  2.96746176e+00  2.27169912e+00\n   -9.17553656e+00]]\n\n [[ 5.11699780e-01  2.56945679e+00 -4.25122625e+00 -2.05015886e+00\n    8.10400317e+00]\n  [ 1.00605431e+00  2.71641122e-01 -4.98291434e-01 -2.41009381e+00\n    2.47038108e+00]\n  [-1.51775409e+00 -2.84109791e+00  4.74951769e+00  4.46025268e+00\n   -1.05743842e+01]]\n\n [[ 1.11591222e+00  3.84296754e+00 -5.79494522e+00 -2.91456122e+00\n    8.39662592e+00]\n  [ 1.36468755e+00  8.02795766e-01 -6.20985599e-01 -4.21413072e+00\n    3.22909387e+00]\n  [-2.48059977e+00 -4.64576330e+00  6.41593082e+00  7.12869194e+00\n   -1.16257198e+01]]\n\n [[ 1.52714533e+00  4.68877913e+00 -6.78342272e+00 -3.50386990e+00\n    8.56111865e+00]\n  [ 1.55221630e+00  1.23197799e+00 -6.29395490e-01 -5.71057433e+00\n    3.89591534e+00]\n  [-3.07936163e+00 -5.92075712e+00  7.41281821e+00  9.21444422e+00\n   -1.24570340e+01]]\n\n [[ 1.82943919e+00  5.30517368e+00 -7.48151559e+00 -3.94031197e+00\n    8.67795322e+00]\n  [ 1.67543829e+00  1.57791432e+00 -6.27237757e-01 -6.91167656e+00\n    4.46684013e+00]\n  [-3.50487747e+00 -6.88308800e+00  8.10875335e+00  1.08519885e+01\n   -1.31447933e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 105   88  240  950 2000 2000 2000 2000 2000 2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[[  0.44348964   2.40850539  -4.20423651  -2.03769105   8.37305404]\n [  0.79195463  -0.07916788  -0.31928975  -2.34422836   3.81437648]\n [ -1.23544427  -2.32933751   4.52352626   4.38191941 -12.18743053]]", "max_iter": 2000, "tol": 1e-05, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 5.82030361e-01  2.84864950e+00 -4.77038364e+00 -2.44393754e+00\n    8.97911051e+00]\n  [ 7.68301774e-01 -1.64958833e-03 -3.84085904e-01 -2.79428703e+00\n    5.12991444e+00]\n  [-1.35033213e+00 -2.84699991e+00  5.15446955e+00  5.23822457e+00\n   -1.41090249e+01]]]", "[21.5443469]", "[2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-5.40719736e-01 -2.07547725e-01 -1.16313571e+00 -3.92126755e-01\n   2.65687975e-01  7.23100494e-01 -5.73061867e-01  4.91262934e-01\n  -1.85401812e+00  2.46121252e-02]\n [ 2.40281873e-01  3.92493901e-01 -1.87612282e+00 -4.21275393e-01\n   1.92793845e-02  1.84959125e+00  1.78904119e+00  1.75133091e+00\n  -3.17351904e+00 -2.14166656e-01]\n [-1.58055773e+00 -1.99422200e+00 -2.26192155e-01 -1.20353079e+00\n   8.20321797e-01  1.35994854e+00  2.05118865e+00  1.42894316e+00\n  -3.11976811e+00 -9.03820073e-02]\n [-3.25766370e+00 -3.24839979e+00 -2.64248480e+00 -3.43623483e+00\n   2.22594433e+00  1.37098901e+00 -1.16939231e+00 -5.31139918e-01\n  -5.90978642e+00 -5.09843242e-01]\n [-1.56837590e+00 -1.72314539e+00 -1.00215947e+00 -1.43977522e+00\n  -5.85865511e-02 -3.17543094e-01  1.64483367e+00  8.23798385e-01\n  -3.45612926e+00 -1.63242330e+00]\n [-7.42445952e-01 -1.11292264e+00 -1.69317121e+00 -1.90678419e+00\n   1.01184243e+00 -6.57951045e-01  2.03225445e+00  4.22033882e-01\n  -3.64744991e+00  4.68385234e-01]\n [ 1.98061677e+00  2.14268413e+00 -2.48771332e+00 -5.64732027e-01\n   4.48195284e-01  1.69618157e+00 -1.14340196e+00 -6.83505427e-01\n  -7.88078317e-01 -1.48577034e-02]\n [ 9.16168819e-02 -4.30798100e-01  2.38779825e-01 -5.72194530e-01\n  -8.48320523e-01 -3.25669469e-01  1.90701161e+00  5.83762152e-02\n  -3.60536232e-01  4.70433145e-01]\n [-2.84765716e-01 -2.45449107e-01 -3.95285955e-01  3.24590724e-01\n   1.15418403e+00  1.72504416e-01 -2.55835140e+00  3.07522428e+00\n  -2.24993392e+00  2.10620213e-02]\n [-1.84918860e-01 -2.80193775e-02 -1.75170324e+00 -8.26275185e-01\n  -6.67720286e-01  3.26962595e-01  1.11963770e+00  5.68059391e-01\n  -2.66564275e+00  3.30035115e-01]\n [ 1.44865494e+00  1.25107298e+00 -1.02590188e-01  9.70819795e-01\n  -2.00421572e+00  3.76876521e-01  9.00210151e-01  2.70304375e+00\n  -6.50746054e-01 -5.45711974e-01]\n [-6.42658892e-01 -1.29979677e+00 -1.51346018e-01 -9.22684936e-01\n  -2.41337791e-01 -8.78190343e-01 -6.70286357e-01  2.33179222e+00\n  -2.73853240e+00  6.99380484e-01]\n [ 2.89826530e-01 -2.38143411e+00  1.87807873e+00 -2.25604927e+00\n  -8.03141387e-01 -4.64337691e-01 -3.28028169e+00  2.81913451e+00\n  -1.52508866e+00  1.02179059e+00]\n [-9.75594369e-01 -4.99933228e-01 -2.40705928e+00 -7.22074398e-01\n   3.24869616e-01  9.97117981e-01 -2.64059090e+00  2.68297514e+00\n  -4.76209932e+00  3.06018243e-02]\n [ 3.80502581e-01 -2.22771751e+00  3.18104879e+00 -2.39557550e+00\n   8.67407411e-01 -6.56463675e-01 -1.14778339e+00 -2.25935277e+00\n   2.99723877e+00 -2.83455451e+00]\n [-9.72695965e-02 -5.14060999e-02  5.63553700e-02  2.76243219e-01\n   1.15147873e-01 -3.79147563e-01  1.12850804e+00  8.43422120e-01\n  -5.31738568e-01 -1.74235620e+00]\n [-2.75089949e-01  2.81315520e-01 -6.37272915e-01  9.92286919e-01\n   1.92753849e-01 -3.65055217e-01  1.81744782e+00  2.74263959e+00\n  -2.16173077e+00 -1.79132755e+00]\n [ 1.61372392e-01 -1.62110266e-01  1.64712804e+00  7.25240014e-01\n  -6.47181432e-01  4.72247150e-01 -9.04806491e-01  4.58857984e-01\n   1.73340365e+00  9.30408496e-01]\n [-1.09154341e+00 -6.85835510e-01 -4.69778885e-01  4.48004183e-02\n  -5.00840943e-02 -8.97400927e-01  8.48524599e-01  9.99100432e-01\n  -1.77456353e+00  1.31247037e+00]\n [-2.30947161e+00 -1.96136438e+00 -1.75642672e-01 -4.18403168e-01\n  -6.71341546e-02  1.48935596e+00  1.37200779e+00  1.10121757e+00\n  -2.64389923e+00  5.21303748e-01]\n [ 3.46514296e-01  4.64970954e-01 -2.50360785e+00 -5.62747666e-01\n   1.09074973e+00 -3.46249448e-01  1.86059960e-01  3.04055670e+00\n  -4.52222864e+00 -7.94636321e-01]\n [-1.36745452e+00 -1.10038709e-01 -1.55248025e+00  5.89443077e-01\n  -6.72756089e-02 -1.31839587e+00  2.02620466e+00  1.08358693e+00\n  -2.64150323e+00 -3.70704003e-01]\n [-5.78231096e-01 -1.16881345e-01 -2.64237436e-01  5.54276871e-01\n   6.76460732e-01 -3.82008956e-01  7.43356147e-01  1.17097261e+00\n  -1.08004544e+00 -2.24258934e-01]\n [-3.15803437e+00 -2.20828795e+00  1.00144500e+00  1.19462953e+00\n   1.48449581e-01  5.29045238e-01  1.57419161e+00  2.47945962e+00\n  -2.02853341e+00  4.22628622e-01]\n [-1.09828810e+00 -1.46664705e+00 -4.29858614e-02 -3.58124761e-01\n  -1.75316402e-01 -1.42191987e+00 -4.49272853e+00  3.79443104e+00\n  -3.21049772e+00  1.99795608e+00]\n [ 2.79421119e-01 -1.30568494e-01  1.28250817e+00  3.06339286e-01\n   8.65652923e-01  1.08137603e+00  3.95100471e-01 -1.03819672e-01\n   1.48776923e+00 -6.31375988e-01]\n [-1.43505375e-01 -1.56340254e+00 -1.39795502e-01 -1.76241483e+00\n  -8.15791542e-01 -5.07517602e-01 -1.24749791e+00  2.84722635e+00\n  -3.34479603e+00 -1.05188010e+00]\n [ 3.98629684e-01 -1.48153244e+00  1.91880431e+00 -1.96884044e+00\n   2.49720039e+00 -2.24532165e+00 -4.63584238e-01 -1.92205545e+00\n   1.92503028e+00  5.64008535e-01]\n [-2.72499730e+00 -3.71643688e+00  1.49079409e-01 -2.95851931e+00\n   9.94544570e-02  2.27392775e-01 -4.10487163e-01 -6.69633290e-01\n  -2.89678440e+00 -1.01673865e+00]\n [-2.55233995e+00 -1.35806555e+00 -2.03468662e+00 -2.68015048e-01\n  -1.78589092e-01 -1.55042935e+00  2.93831142e+00  1.59279151e+00\n  -4.74952324e+00  4.17318821e-01]\n [-3.18713733e-01  2.67219161e+00 -2.25687002e+00  3.34358664e+00\n  -9.45615796e-01 -9.32740911e-01  4.18552525e-01  1.09140489e+00\n  -6.19898290e-01 -1.26306835e+00]\n [ 1.24150332e+00 -3.23759982e-01  5.40407232e-01 -1.53475533e+00\n  -1.88458584e+00 -1.94570308e+00 -2.63152051e+00  7.88439847e-02\n   2.85179664e-01 -9.12783494e-01]\n [ 2.18454598e+00  7.16411400e-01  2.17445769e+00  3.86820279e-01\n  -7.04921353e-01  6.79974844e-01 -7.66706677e-02  9.50874860e-01\n   2.63993565e+00 -6.96326654e-01]\n [ 1.26598701e+00  1.35524226e+00  2.01380939e-02  5.67797707e-01\n  -9.64606424e-01  5.98946831e-02  3.27539712e+00 -1.16536304e+00\n   1.64464743e+00 -2.12523045e-01]\n [-7.07814669e-01 -7.13933313e-01 -1.45208404e+00 -8.94041023e-01\n  -7.49690345e-01  3.28087476e-02 -8.18746000e-01  1.81874418e+00\n  -3.47065784e+00 -2.58279663e+00]\n [ 1.41016335e+00  5.17727752e-01  2.97449018e-01  1.97103484e-02\n  -1.50239657e+00 -1.77766695e+00 -1.25051994e-01  2.35767947e+00\n  -6.40623011e-01 -5.32702792e-01]\n [-1.80634223e+00 -9.54011273e-01 -5.21880648e-01  2.04338374e-01\n  -1.38504274e-03 -6.87299037e-01  1.04161376e+00  2.92215760e-01\n  -1.61473902e+00 -1.17474546e-01]\n [-6.95926614e-01 -3.76985142e-01 -9.17926196e-01 -6.44954718e-02\n   1.14988999e-02 -8.37678042e-01 -2.86511092e+00  1.84350933e+00\n  -2.26948325e+00 -5.91183104e-01]\n [-2.52026333e-01 -2.31775019e+00  1.69543265e+00 -2.19734285e+00\n   1.01702099e+00  1.42298350e+00 -5.54136240e-01  3.76351358e-01\n  -4.33128488e-01  3.96086585e-01]\n [-1.27217561e+00 -1.49690370e+00 -1.20900231e+00 -1.54360900e+00\n  -3.91217052e-01  9.40917615e-01  1.00788069e+00  8.54735843e-01\n  -3.50000727e+00  4.05204080e-01]\n [ 1.72766139e+00  1.03096709e-02  2.46800095e+00  1.61769760e-01\n  -5.52540673e-01 -3.86870847e-01  9.07110053e-02  1.80924204e+00\n   1.84430777e+00 -5.10292740e-01]\n [-2.77248257e+00 -1.80852871e-01 -1.43693490e+00  1.67295273e+00\n   1.83339199e-01  1.67094303e+00  6.07333834e-02 -4.97606123e-01\n  -1.25673744e+00 -5.61330204e-02]\n [ 2.50458836e-01  1.62928730e+00 -1.49142487e+00  1.71992882e+00\n   5.20040615e-01  2.25608654e-01  1.43380612e+00  1.60096526e+00\n  -1.23247802e+00  4.49712100e-01]\n [ 1.97567941e+00  5.54372516e-01  2.39598796e+00  6.75444644e-01\n  -1.32988422e-01 -7.65702194e-01  8.99176641e-01  1.62667363e+00\n   2.32957933e+00  5.55786964e-01]\n [ 5.11748501e-01  2.98187991e+00 -2.73085139e+00  3.16968908e+00\n  -1.30324275e+00  6.05120084e-01  1.04589892e+00  3.41080543e+00\n  -2.41099931e+00  8.95555986e-01]\n [-1.75836596e+00 -2.74488828e+00  1.33268021e-01 -2.32504192e+00\n  -4.06071796e-01 -5.35270165e-01  2.34192962e-01 -1.56738914e-02\n  -2.47053475e+00  2.54052084e-02]\n [-2.45651522e-01 -2.52005007e-03 -1.65115469e+00 -3.07831308e-01\n   5.09542770e-02 -1.79422927e+00 -1.38503506e+00  2.28710593e+00\n  -3.26484831e+00  1.32646164e+00]\n [ 8.27529803e-01  2.86963730e-01 -9.04269082e-01 -1.01366924e+00\n   2.19509556e-01  3.93062934e-01 -5.29818774e-01  1.15104057e-01\n  -1.03264910e+00 -9.38981573e-01]\n [ 5.14302791e-01 -5.32400591e-01 -8.67029313e-02 -1.37884976e+00\n  -1.21054299e+00 -7.88669255e-01 -6.47452517e-01  3.62365274e-01\n  -9.33506921e-01  1.09463837e+00]\n [-2.59112515e+00 -2.66794491e+00 -7.29070837e-01 -1.93733584e+00\n  -1.07709907e+00 -4.24663302e-01  6.91861067e-01 -3.85363185e-01\n  -3.17317233e+00 -8.29964598e-01]\n [-3.89209400e-01 -7.53322298e-01 -1.10146119e+00 -9.31894378e-01\n   8.21405937e-01  6.70570450e-01  1.55968186e+00  2.23954430e+00\n  -3.54978454e+00 -7.07505698e-01]\n [ 3.46135602e-01  1.49608283e-01  4.29888226e-01  1.17173768e+00\n   9.72535789e-01  2.13386825e+00 -3.77668148e+00  4.80596056e+00\n  -1.75539019e+00  4.06415494e-01]\n [-2.87027884e-01 -1.19320501e-01 -1.11019755e+00 -2.23099099e-01\n   1.03493146e-02  7.20033759e-01  8.61250916e-01  1.55021611e+00\n  -2.45117982e+00 -1.82425666e+00]\n [-2.68801430e+00  1.18159795e+00 -3.70978398e+00  2.51761655e+00\n   2.86904488e-01 -2.32059428e+00  2.00671584e+00  4.97767401e-01\n  -3.45334430e+00  3.17160626e-01]\n [-3.62802299e+00 -4.30455219e+00 -5.81707158e-01 -3.61686284e+00\n   3.03603904e-01  7.72694837e-01 -3.35308722e-02 -1.73621062e+00\n  -3.73394798e+00 -1.66159829e+00]\n [-3.12679267e+00  1.18204184e-01 -1.65931992e+00  1.94714369e+00\n  -1.21793851e+00 -3.04963638e-01  4.79344437e-01 -2.42696397e+00\n  -1.00424198e-01  1.02893549e+00]\n [-2.50183006e+00 -2.42594288e+00 -2.08244607e+00 -2.70371999e+00\n  -1.93176702e-01  7.55740289e-01 -3.33534320e-01 -1.05723715e+00\n  -4.21211817e+00 -5.39132637e-01]\n [ 1.57348038e+00  2.45658557e+00 -1.30041756e+00  2.21831721e+00\n  -1.06122229e+00 -2.22477010e-01 -2.56671816e+00  4.13359522e+00\n  -1.44607036e+00 -8.58919908e-01]\n [-1.08528377e+00 -2.36443725e+00  1.24193251e+00 -1.46249746e+00\n  -5.90057646e-01 -1.10489405e-01  5.65235864e-01  1.15389878e+00\n  -1.44254145e+00 -1.66069981e+00]\n [-8.59594567e-01  1.58762747e+00 -1.35952991e+00  2.63251290e+00\n  -7.22870076e-02 -6.00657558e-01 -3.52851374e-01  4.04968931e-01\n  -8.18174283e-02  1.55224318e+00]\n [ 3.16644365e+00  1.87150288e+00  2.32027111e+00  1.70137944e+00\n   2.11679102e+00 -1.61087840e+00 -4.15368298e-02  2.97962363e+00\n   2.74314339e+00 -3.57680719e-02]\n [-3.21496449e-01 -9.16711694e-02 -1.18510746e-02  4.35480050e-01\n  -6.49337928e-01 -2.34231050e-02  6.50426070e-01  9.87375684e-01\n  -6.64028802e-01  1.07919473e+00]\n [-1.36042415e+00 -1.57432078e+00  3.10975913e-01 -6.07006825e-01\n   3.29622982e-01  1.28598401e+00  8.28108553e-01  7.76594592e-01\n  -1.54843347e+00 -1.50699840e+00]\n [-7.73219279e-01 -2.62385236e+00 -6.63995013e-01 -3.28635103e+00\n  -3.50951769e-02  1.26507784e+00 -3.45817641e+00  2.16449210e+00\n  -4.48310670e+00  2.11497013e-01]\n [-1.76878361e+00  1.15858344e+00 -3.28947145e+00  2.00728267e+00\n  -9.44368491e-01  2.38103148e-01  2.41255523e+00  1.54613528e+00\n  -3.73133928e+00 -1.40596292e+00]\n [-3.95792874e+00 -3.06314813e+00 -3.97730255e-01 -1.10773228e+00\n   4.03264540e-01 -9.18004770e-01  1.44301665e+00 -1.50482501e+00\n  -2.34694246e+00  2.52496627e-01]\n [ 9.01653686e-01  5.61621907e-01 -1.62718504e+00 -1.67288554e+00\n  -1.35978073e+00 -4.14008116e-02 -2.97524355e+00 -2.04405161e+00\n  -2.66671403e-01 -7.57870860e-01]\n [-1.06827715e+00 -9.01488862e-01 -8.64171465e-01 -5.08300770e-01\n   1.73587900e+00 -6.67712721e-01  2.26870415e+00  1.17099597e+00\n  -2.73166331e+00  1.68192174e+00]\n [ 5.33160920e-01  6.40349473e-02  9.59815471e-01  4.23974236e-01\n  -6.96415784e-02  5.15749428e-02  6.24164464e-02  1.20838326e+00\n   5.20748004e-01  8.67276629e-01]\n [-1.05213971e+00 -1.15539732e+00 -9.34807917e-01 -1.29774033e+00\n  -1.12465983e-01 -5.32489919e-01 -2.98756694e-01 -3.97472894e-02\n  -2.20889786e+00  6.45055273e-01]\n [-1.68998451e+00 -2.28503916e+00 -1.37912247e+00 -2.64430912e+00\n  -8.58972388e-01 -8.98942156e-01  1.25749952e+00 -5.21927708e-02\n  -3.99979861e+00  7.45864065e-02]\n [-1.12084915e+00 -1.26335539e+00 -2.36396575e-01 -7.62349883e-01\n  -7.62114512e-01 -8.87780137e-01 -1.79056507e+00  8.60352823e-01\n  -1.79927802e+00  9.36398544e-01]\n [-1.57846968e+00 -1.90764384e+00 -1.72238591e+00 -2.37900112e+00\n   7.19983730e-01 -1.10290621e+00  1.68849052e+00 -2.28030482e-02\n  -4.10771460e+00 -1.01697275e-01]\n [ 3.79202559e-01 -1.24900820e+00  1.57963563e+00 -1.15843402e+00\n  -5.91402668e-01  1.12441918e+00  3.66660545e-01  8.08789908e-01\n   1.33994346e-01  7.55395696e-01]\n [-1.49176879e+00 -1.79796854e+00  1.09635970e-01 -7.39518871e-01\n  -3.02249730e-01 -3.75147117e-01  9.15219051e-01  1.67133299e+00\n  -2.53664955e+00 -1.22619619e+00]\n [ 7.65703113e-01  3.43107235e-01 -9.46974483e-01 -1.82989894e-01\n  -1.17762896e+00 -1.14019630e+00  3.96746765e-01  3.09783484e+00\n  -2.77356943e+00  1.75498615e+00]\n [-1.74684647e+00 -5.02093390e-01 -5.70473828e-01  8.71130699e-01\n  -1.31908640e-01  4.04761812e-01  2.10680785e-01  5.87867468e-01\n  -1.30096559e+00  2.23843563e-01]\n [-1.70368664e+00 -1.31896726e+00 -1.92071459e-02  2.81548802e-01\n   4.98052405e-01 -2.61922373e-02  1.54518087e+00  2.15027851e+00\n  -2.46815777e+00 -1.68823003e+00]\n [ 5.59889117e-01 -1.80614879e+00  2.65356566e+00 -1.18655831e+00\n   8.12674042e-01  5.87259379e-01 -7.37784715e-01  2.41422692e+00\n   6.79726053e-02 -5.05358317e-01]\n [-5.11241337e-02 -2.83356832e+00  1.47726172e+00 -3.23877000e+00\n   2.34821526e-01  2.13215341e+00 -4.30465039e+00  1.24433504e+00\n  -1.49465772e+00  9.36445726e-01]\n [ 1.54487004e-01  4.42533475e-02 -2.04485819e+00 -1.53104452e+00\n   6.11927193e-01 -1.34149673e+00 -8.51210566e-01 -4.05534685e-01\n  -2.32026861e+00  4.76898369e-01]\n [-1.31003437e+00 -1.00153714e+00 -2.02967593e+00 -1.41359114e+00\n  -5.25640593e-01  2.71170185e-01 -8.40368309e-01  3.18420619e-01\n  -3.56527697e+00 -8.01496885e-01]\n [-4.52014664e-01 -1.98860563e+00 -8.44442960e-02 -2.33477934e+00\n   1.83925494e-01 -3.85489760e-01 -1.39377639e+00  1.66872403e+00\n  -2.99767891e+00 -1.60183605e+00]\n [ 1.87877751e-01 -3.73446073e-01 -2.11069768e+00 -1.55266945e+00\n   1.97967290e-01  1.08193522e+00 -1.83805274e+00  2.78189316e+00\n  -4.58047077e+00 -1.44494020e+00]\n [ 1.06397783e+00 -3.74942041e-01  1.37789442e+00 -1.10116224e+00\n   2.38074535e+00  3.30576756e-01 -3.62751801e-01 -1.06744659e+00\n   1.80645858e+00  9.49246474e-01]\n [-1.49281977e+00  1.70363308e+00 -2.51702180e+00  2.72787192e+00\n   4.52489093e-01  9.78961454e-02  1.16637563e+00  1.79530891e-01\n  -1.32718154e+00 -4.48165363e-01]\n [ 1.71524210e+00  8.45078725e-01  2.10328600e-01 -2.76365607e-01\n  -1.28455230e+00 -1.04343491e-01 -8.18455545e-01  5.69762395e-01\n   6.08087224e-01 -9.88001942e-01]\n [-1.25953667e+00 -2.30000934e+00 -2.13652480e+00 -4.07181293e+00\n   3.97667346e-02 -1.56699471e+00 -1.91783687e-01 -1.88006981e+00\n  -3.92414799e+00 -4.51303037e-01]\n [ 2.40063618e+00  9.41978055e-01  2.50206672e+00  8.10885445e-01\n  -8.87180942e-01 -9.32789042e-01  3.65052929e-01  1.31119741e+00\n   3.02640011e+00  1.24331938e+00]\n [-6.45458750e-01  3.89871890e-01 -1.30933368e+00  1.06457702e+00\n   4.66166426e-01 -3.70242441e-01  1.13171224e+00  2.52039526e+00\n  -2.66169119e+00 -4.53804041e-01]\n [-1.73747810e+00 -2.13573452e+00 -2.75690754e-01 -1.60094792e+00\n  -4.99016638e-01  2.13512238e-02  4.96193999e-01  1.96795196e-01\n  -2.48612615e+00 -9.19113445e-01]\n [-5.92002088e-01 -9.41395537e-01 -1.05079744e-01 -1.43430210e-01\n   3.11447072e-01  2.39582760e-01 -2.80743285e+00  3.55555703e+00\n  -2.81977981e+00 -3.69801166e-01]\n [ 2.26121003e+00  9.17216403e-01  3.12200426e-01  9.70775445e-02\n  -4.70032883e-01 -2.16731471e-01  1.62544223e+00  3.78329942e+00\n  -1.29493186e+00 -9.30156503e-01]\n [-2.13169865e-01  6.66407504e-02 -9.59088052e-01  3.63783178e-01\n  -1.03264310e+00 -4.36748337e-01 -2.94108911e+00  3.06808222e+00\n  -2.61886880e+00 -1.64296529e+00]\n [ 1.75218462e-01 -1.48207863e+00  8.70882256e-01 -1.94570019e+00\n  -2.90397101e-01  1.32778270e+00 -1.03272165e+00  1.29461393e-01\n  -4.96932710e-01 -1.01281486e-01]\n [-1.88539219e-01 -4.71972657e-02 -4.48703648e-01 -1.75052390e-01\n  -1.15395036e+00 -3.47961856e-01  2.76479447e-01 -8.54719937e-02\n  -5.68551115e-01 -1.35338886e+00]\n [-1.15821122e+00 -1.77545756e+00 -3.86467113e-01 -1.64486602e+00\n  -8.52585847e-01  2.29597556e-02  2.26330097e-01  6.03659507e-01\n  -2.55601345e+00 -1.11456118e-02]\n [-2.53972616e-01 -4.09670903e-01 -7.35009990e-01 -1.10742113e+00\n   1.41117206e+00  7.85803827e-01 -1.71717090e+00 -9.99464041e-01\n  -6.39567988e-01 -5.74695185e-02]\n [-8.97057585e-01  4.45653065e-01 -1.26207490e+00  1.00071970e+00\n   1.36759724e+00  1.03440989e+00  1.61438906e+00  5.03085351e-01\n  -1.39457236e+00 -9.96212640e-01]\n [ 5.74235454e-01  1.50488206e+00 -7.99041364e-01  1.69177155e+00\n  -1.14775325e-01  3.08751242e-01 -3.34211432e+00  2.29843342e+00\n  -5.41669705e-01 -1.37075998e+00]]", "y": "[0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0\n 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1\n 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.57847251 -0.22315111  0.47353342 -0.59858994 -0.17760497 -0.07767291\n  -0.86064628  0.38337532  0.11574632  0.25869736]]", "[1.]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-5.40719736e-01 -2.07547725e-01 -1.16313571e+00 -3.92126755e-01\n   2.65687975e-01  7.23100494e-01 -5.73061867e-01  4.91262934e-01\n  -1.85401812e+00  2.46121252e-02]\n [ 2.40281873e-01  3.92493901e-01 -1.87612282e+00 -4.21275393e-01\n   1.92793845e-02  1.84959125e+00  1.78904119e+00  1.75133091e+00\n  -3.17351904e+00 -2.14166656e-01]\n [-1.58055773e+00 -1.99422200e+00 -2.26192155e-01 -1.20353079e+00\n   8.20321797e-01  1.35994854e+00  2.05118865e+00  1.42894316e+00\n  -3.11976811e+00 -9.03820073e-02]\n [-3.25766370e+00 -3.24839979e+00 -2.64248480e+00 -3.43623483e+00\n   2.22594433e+00  1.37098901e+00 -1.16939231e+00 -5.31139918e-01\n  -5.90978642e+00 -5.09843242e-01]\n [-1.56837590e+00 -1.72314539e+00 -1.00215947e+00 -1.43977522e+00\n  -5.85865511e-02 -3.17543094e-01  1.64483367e+00  8.23798385e-01\n  -3.45612926e+00 -1.63242330e+00]\n [-7.42445952e-01 -1.11292264e+00 -1.69317121e+00 -1.90678419e+00\n   1.01184243e+00 -6.57951045e-01  2.03225445e+00  4.22033882e-01\n  -3.64744991e+00  4.68385234e-01]\n [ 1.98061677e+00  2.14268413e+00 -2.48771332e+00 -5.64732027e-01\n   4.48195284e-01  1.69618157e+00 -1.14340196e+00 -6.83505427e-01\n  -7.88078317e-01 -1.48577034e-02]\n [ 9.16168819e-02 -4.30798100e-01  2.38779825e-01 -5.72194530e-01\n  -8.48320523e-01 -3.25669469e-01  1.90701161e+00  5.83762152e-02\n  -3.60536232e-01  4.70433145e-01]\n [-2.84765716e-01 -2.45449107e-01 -3.95285955e-01  3.24590724e-01\n   1.15418403e+00  1.72504416e-01 -2.55835140e+00  3.07522428e+00\n  -2.24993392e+00  2.10620213e-02]\n [-1.84918860e-01 -2.80193775e-02 -1.75170324e+00 -8.26275185e-01\n  -6.67720286e-01  3.26962595e-01  1.11963770e+00  5.68059391e-01\n  -2.66564275e+00  3.30035115e-01]\n [ 1.44865494e+00  1.25107298e+00 -1.02590188e-01  9.70819795e-01\n  -2.00421572e+00  3.76876521e-01  9.00210151e-01  2.70304375e+00\n  -6.50746054e-01 -5.45711974e-01]\n [-6.42658892e-01 -1.29979677e+00 -1.51346018e-01 -9.22684936e-01\n  -2.41337791e-01 -8.78190343e-01 -6.70286357e-01  2.33179222e+00\n  -2.73853240e+00  6.99380484e-01]\n [ 2.89826530e-01 -2.38143411e+00  1.87807873e+00 -2.25604927e+00\n  -8.03141387e-01 -4.64337691e-01 -3.28028169e+00  2.81913451e+00\n  -1.52508866e+00  1.02179059e+00]\n [-9.75594369e-01 -4.99933228e-01 -2.40705928e+00 -7.22074398e-01\n   3.24869616e-01  9.97117981e-01 -2.64059090e+00  2.68297514e+00\n  -4.76209932e+00  3.06018243e-02]\n [ 3.80502581e-01 -2.22771751e+00  3.18104879e+00 -2.39557550e+00\n   8.67407411e-01 -6.56463675e-01 -1.14778339e+00 -2.25935277e+00\n   2.99723877e+00 -2.83455451e+00]\n [-9.72695965e-02 -5.14060999e-02  5.63553700e-02  2.76243219e-01\n   1.15147873e-01 -3.79147563e-01  1.12850804e+00  8.43422120e-01\n  -5.31738568e-01 -1.74235620e+00]\n [-2.75089949e-01  2.81315520e-01 -6.37272915e-01  9.92286919e-01\n   1.92753849e-01 -3.65055217e-01  1.81744782e+00  2.74263959e+00\n  -2.16173077e+00 -1.79132755e+00]\n [ 1.61372392e-01 -1.62110266e-01  1.64712804e+00  7.25240014e-01\n  -6.47181432e-01  4.72247150e-01 -9.04806491e-01  4.58857984e-01\n   1.73340365e+00  9.30408496e-01]\n [-1.09154341e+00 -6.85835510e-01 -4.69778885e-01  4.48004183e-02\n  -5.00840943e-02 -8.97400927e-01  8.48524599e-01  9.99100432e-01\n  -1.77456353e+00  1.31247037e+00]\n [-2.30947161e+00 -1.96136438e+00 -1.75642672e-01 -4.18403168e-01\n  -6.71341546e-02  1.48935596e+00  1.37200779e+00  1.10121757e+00\n  -2.64389923e+00  5.21303748e-01]\n [ 3.46514296e-01  4.64970954e-01 -2.50360785e+00 -5.62747666e-01\n   1.09074973e+00 -3.46249448e-01  1.86059960e-01  3.04055670e+00\n  -4.52222864e+00 -7.94636321e-01]\n [-1.36745452e+00 -1.10038709e-01 -1.55248025e+00  5.89443077e-01\n  -6.72756089e-02 -1.31839587e+00  2.02620466e+00  1.08358693e+00\n  -2.64150323e+00 -3.70704003e-01]\n [-5.78231096e-01 -1.16881345e-01 -2.64237436e-01  5.54276871e-01\n   6.76460732e-01 -3.82008956e-01  7.43356147e-01  1.17097261e+00\n  -1.08004544e+00 -2.24258934e-01]\n [-3.15803437e+00 -2.20828795e+00  1.00144500e+00  1.19462953e+00\n   1.48449581e-01  5.29045238e-01  1.57419161e+00  2.47945962e+00\n  -2.02853341e+00  4.22628622e-01]\n [-1.09828810e+00 -1.46664705e+00 -4.29858614e-02 -3.58124761e-01\n  -1.75316402e-01 -1.42191987e+00 -4.49272853e+00  3.79443104e+00\n  -3.21049772e+00  1.99795608e+00]\n [ 2.79421119e-01 -1.30568494e-01  1.28250817e+00  3.06339286e-01\n   8.65652923e-01  1.08137603e+00  3.95100471e-01 -1.03819672e-01\n   1.48776923e+00 -6.31375988e-01]\n [-1.43505375e-01 -1.56340254e+00 -1.39795502e-01 -1.76241483e+00\n  -8.15791542e-01 -5.07517602e-01 -1.24749791e+00  2.84722635e+00\n  -3.34479603e+00 -1.05188010e+00]\n [ 3.98629684e-01 -1.48153244e+00  1.91880431e+00 -1.96884044e+00\n   2.49720039e+00 -2.24532165e+00 -4.63584238e-01 -1.92205545e+00\n   1.92503028e+00  5.64008535e-01]\n [-2.72499730e+00 -3.71643688e+00  1.49079409e-01 -2.95851931e+00\n   9.94544570e-02  2.27392775e-01 -4.10487163e-01 -6.69633290e-01\n  -2.89678440e+00 -1.01673865e+00]\n [-2.55233995e+00 -1.35806555e+00 -2.03468662e+00 -2.68015048e-01\n  -1.78589092e-01 -1.55042935e+00  2.93831142e+00  1.59279151e+00\n  -4.74952324e+00  4.17318821e-01]\n [-3.18713733e-01  2.67219161e+00 -2.25687002e+00  3.34358664e+00\n  -9.45615796e-01 -9.32740911e-01  4.18552525e-01  1.09140489e+00\n  -6.19898290e-01 -1.26306835e+00]\n [ 1.24150332e+00 -3.23759982e-01  5.40407232e-01 -1.53475533e+00\n  -1.88458584e+00 -1.94570308e+00 -2.63152051e+00  7.88439847e-02\n   2.85179664e-01 -9.12783494e-01]\n [ 2.18454598e+00  7.16411400e-01  2.17445769e+00  3.86820279e-01\n  -7.04921353e-01  6.79974844e-01 -7.66706677e-02  9.50874860e-01\n   2.63993565e+00 -6.96326654e-01]\n [ 1.26598701e+00  1.35524226e+00  2.01380939e-02  5.67797707e-01\n  -9.64606424e-01  5.98946831e-02  3.27539712e+00 -1.16536304e+00\n   1.64464743e+00 -2.12523045e-01]\n [-7.07814669e-01 -7.13933313e-01 -1.45208404e+00 -8.94041023e-01\n  -7.49690345e-01  3.28087476e-02 -8.18746000e-01  1.81874418e+00\n  -3.47065784e+00 -2.58279663e+00]\n [ 1.41016335e+00  5.17727752e-01  2.97449018e-01  1.97103484e-02\n  -1.50239657e+00 -1.77766695e+00 -1.25051994e-01  2.35767947e+00\n  -6.40623011e-01 -5.32702792e-01]\n [-1.80634223e+00 -9.54011273e-01 -5.21880648e-01  2.04338374e-01\n  -1.38504274e-03 -6.87299037e-01  1.04161376e+00  2.92215760e-01\n  -1.61473902e+00 -1.17474546e-01]\n [-6.95926614e-01 -3.76985142e-01 -9.17926196e-01 -6.44954718e-02\n   1.14988999e-02 -8.37678042e-01 -2.86511092e+00  1.84350933e+00\n  -2.26948325e+00 -5.91183104e-01]\n [-2.52026333e-01 -2.31775019e+00  1.69543265e+00 -2.19734285e+00\n   1.01702099e+00  1.42298350e+00 -5.54136240e-01  3.76351358e-01\n  -4.33128488e-01  3.96086585e-01]\n [-1.27217561e+00 -1.49690370e+00 -1.20900231e+00 -1.54360900e+00\n  -3.91217052e-01  9.40917615e-01  1.00788069e+00  8.54735843e-01\n  -3.50000727e+00  4.05204080e-01]\n [ 1.72766139e+00  1.03096709e-02  2.46800095e+00  1.61769760e-01\n  -5.52540673e-01 -3.86870847e-01  9.07110053e-02  1.80924204e+00\n   1.84430777e+00 -5.10292740e-01]\n [-2.77248257e+00 -1.80852871e-01 -1.43693490e+00  1.67295273e+00\n   1.83339199e-01  1.67094303e+00  6.07333834e-02 -4.97606123e-01\n  -1.25673744e+00 -5.61330204e-02]\n [ 2.50458836e-01  1.62928730e+00 -1.49142487e+00  1.71992882e+00\n   5.20040615e-01  2.25608654e-01  1.43380612e+00  1.60096526e+00\n  -1.23247802e+00  4.49712100e-01]\n [ 1.97567941e+00  5.54372516e-01  2.39598796e+00  6.75444644e-01\n  -1.32988422e-01 -7.65702194e-01  8.99176641e-01  1.62667363e+00\n   2.32957933e+00  5.55786964e-01]\n [ 5.11748501e-01  2.98187991e+00 -2.73085139e+00  3.16968908e+00\n  -1.30324275e+00  6.05120084e-01  1.04589892e+00  3.41080543e+00\n  -2.41099931e+00  8.95555986e-01]\n [-1.75836596e+00 -2.74488828e+00  1.33268021e-01 -2.32504192e+00\n  -4.06071796e-01 -5.35270165e-01  2.34192962e-01 -1.56738914e-02\n  -2.47053475e+00  2.54052084e-02]\n [-2.45651522e-01 -2.52005007e-03 -1.65115469e+00 -3.07831308e-01\n   5.09542770e-02 -1.79422927e+00 -1.38503506e+00  2.28710593e+00\n  -3.26484831e+00  1.32646164e+00]\n [ 8.27529803e-01  2.86963730e-01 -9.04269082e-01 -1.01366924e+00\n   2.19509556e-01  3.93062934e-01 -5.29818774e-01  1.15104057e-01\n  -1.03264910e+00 -9.38981573e-01]\n [ 5.14302791e-01 -5.32400591e-01 -8.67029313e-02 -1.37884976e+00\n  -1.21054299e+00 -7.88669255e-01 -6.47452517e-01  3.62365274e-01\n  -9.33506921e-01  1.09463837e+00]\n [-2.59112515e+00 -2.66794491e+00 -7.29070837e-01 -1.93733584e+00\n  -1.07709907e+00 -4.24663302e-01  6.91861067e-01 -3.85363185e-01\n  -3.17317233e+00 -8.29964598e-01]\n [-3.89209400e-01 -7.53322298e-01 -1.10146119e+00 -9.31894378e-01\n   8.21405937e-01  6.70570450e-01  1.55968186e+00  2.23954430e+00\n  -3.54978454e+00 -7.07505698e-01]\n [ 3.46135602e-01  1.49608283e-01  4.29888226e-01  1.17173768e+00\n   9.72535789e-01  2.13386825e+00 -3.77668148e+00  4.80596056e+00\n  -1.75539019e+00  4.06415494e-01]\n [-2.87027884e-01 -1.19320501e-01 -1.11019755e+00 -2.23099099e-01\n   1.03493146e-02  7.20033759e-01  8.61250916e-01  1.55021611e+00\n  -2.45117982e+00 -1.82425666e+00]\n [-2.68801430e+00  1.18159795e+00 -3.70978398e+00  2.51761655e+00\n   2.86904488e-01 -2.32059428e+00  2.00671584e+00  4.97767401e-01\n  -3.45334430e+00  3.17160626e-01]\n [-3.62802299e+00 -4.30455219e+00 -5.81707158e-01 -3.61686284e+00\n   3.03603904e-01  7.72694837e-01 -3.35308722e-02 -1.73621062e+00\n  -3.73394798e+00 -1.66159829e+00]\n [-3.12679267e+00  1.18204184e-01 -1.65931992e+00  1.94714369e+00\n  -1.21793851e+00 -3.04963638e-01  4.79344437e-01 -2.42696397e+00\n  -1.00424198e-01  1.02893549e+00]\n [-2.50183006e+00 -2.42594288e+00 -2.08244607e+00 -2.70371999e+00\n  -1.93176702e-01  7.55740289e-01 -3.33534320e-01 -1.05723715e+00\n  -4.21211817e+00 -5.39132637e-01]\n [ 1.57348038e+00  2.45658557e+00 -1.30041756e+00  2.21831721e+00\n  -1.06122229e+00 -2.22477010e-01 -2.56671816e+00  4.13359522e+00\n  -1.44607036e+00 -8.58919908e-01]\n [-1.08528377e+00 -2.36443725e+00  1.24193251e+00 -1.46249746e+00\n  -5.90057646e-01 -1.10489405e-01  5.65235864e-01  1.15389878e+00\n  -1.44254145e+00 -1.66069981e+00]\n [-8.59594567e-01  1.58762747e+00 -1.35952991e+00  2.63251290e+00\n  -7.22870076e-02 -6.00657558e-01 -3.52851374e-01  4.04968931e-01\n  -8.18174283e-02  1.55224318e+00]\n [ 3.16644365e+00  1.87150288e+00  2.32027111e+00  1.70137944e+00\n   2.11679102e+00 -1.61087840e+00 -4.15368298e-02  2.97962363e+00\n   2.74314339e+00 -3.57680719e-02]\n [-3.21496449e-01 -9.16711694e-02 -1.18510746e-02  4.35480050e-01\n  -6.49337928e-01 -2.34231050e-02  6.50426070e-01  9.87375684e-01\n  -6.64028802e-01  1.07919473e+00]\n [-1.36042415e+00 -1.57432078e+00  3.10975913e-01 -6.07006825e-01\n   3.29622982e-01  1.28598401e+00  8.28108553e-01  7.76594592e-01\n  -1.54843347e+00 -1.50699840e+00]\n [-7.73219279e-01 -2.62385236e+00 -6.63995013e-01 -3.28635103e+00\n  -3.50951769e-02  1.26507784e+00 -3.45817641e+00  2.16449210e+00\n  -4.48310670e+00  2.11497013e-01]\n [-1.76878361e+00  1.15858344e+00 -3.28947145e+00  2.00728267e+00\n  -9.44368491e-01  2.38103148e-01  2.41255523e+00  1.54613528e+00\n  -3.73133928e+00 -1.40596292e+00]\n [-3.95792874e+00 -3.06314813e+00 -3.97730255e-01 -1.10773228e+00\n   4.03264540e-01 -9.18004770e-01  1.44301665e+00 -1.50482501e+00\n  -2.34694246e+00  2.52496627e-01]\n [ 9.01653686e-01  5.61621907e-01 -1.62718504e+00 -1.67288554e+00\n  -1.35978073e+00 -4.14008116e-02 -2.97524355e+00 -2.04405161e+00\n  -2.66671403e-01 -7.57870860e-01]\n [-1.06827715e+00 -9.01488862e-01 -8.64171465e-01 -5.08300770e-01\n   1.73587900e+00 -6.67712721e-01  2.26870415e+00  1.17099597e+00\n  -2.73166331e+00  1.68192174e+00]\n [ 5.33160920e-01  6.40349473e-02  9.59815471e-01  4.23974236e-01\n  -6.96415784e-02  5.15749428e-02  6.24164464e-02  1.20838326e+00\n   5.20748004e-01  8.67276629e-01]\n [-1.05213971e+00 -1.15539732e+00 -9.34807917e-01 -1.29774033e+00\n  -1.12465983e-01 -5.32489919e-01 -2.98756694e-01 -3.97472894e-02\n  -2.20889786e+00  6.45055273e-01]\n [-1.68998451e+00 -2.28503916e+00 -1.37912247e+00 -2.64430912e+00\n  -8.58972388e-01 -8.98942156e-01  1.25749952e+00 -5.21927708e-02\n  -3.99979861e+00  7.45864065e-02]\n [-1.12084915e+00 -1.26335539e+00 -2.36396575e-01 -7.62349883e-01\n  -7.62114512e-01 -8.87780137e-01 -1.79056507e+00  8.60352823e-01\n  -1.79927802e+00  9.36398544e-01]\n [-1.57846968e+00 -1.90764384e+00 -1.72238591e+00 -2.37900112e+00\n   7.19983730e-01 -1.10290621e+00  1.68849052e+00 -2.28030482e-02\n  -4.10771460e+00 -1.01697275e-01]\n [ 3.79202559e-01 -1.24900820e+00  1.57963563e+00 -1.15843402e+00\n  -5.91402668e-01  1.12441918e+00  3.66660545e-01  8.08789908e-01\n   1.33994346e-01  7.55395696e-01]\n [-1.49176879e+00 -1.79796854e+00  1.09635970e-01 -7.39518871e-01\n  -3.02249730e-01 -3.75147117e-01  9.15219051e-01  1.67133299e+00\n  -2.53664955e+00 -1.22619619e+00]\n [ 7.65703113e-01  3.43107235e-01 -9.46974483e-01 -1.82989894e-01\n  -1.17762896e+00 -1.14019630e+00  3.96746765e-01  3.09783484e+00\n  -2.77356943e+00  1.75498615e+00]\n [-1.74684647e+00 -5.02093390e-01 -5.70473828e-01  8.71130699e-01\n  -1.31908640e-01  4.04761812e-01  2.10680785e-01  5.87867468e-01\n  -1.30096559e+00  2.23843563e-01]\n [-1.70368664e+00 -1.31896726e+00 -1.92071459e-02  2.81548802e-01\n   4.98052405e-01 -2.61922373e-02  1.54518087e+00  2.15027851e+00\n  -2.46815777e+00 -1.68823003e+00]\n [ 5.59889117e-01 -1.80614879e+00  2.65356566e+00 -1.18655831e+00\n   8.12674042e-01  5.87259379e-01 -7.37784715e-01  2.41422692e+00\n   6.79726053e-02 -5.05358317e-01]\n [-5.11241337e-02 -2.83356832e+00  1.47726172e+00 -3.23877000e+00\n   2.34821526e-01  2.13215341e+00 -4.30465039e+00  1.24433504e+00\n  -1.49465772e+00  9.36445726e-01]\n [ 1.54487004e-01  4.42533475e-02 -2.04485819e+00 -1.53104452e+00\n   6.11927193e-01 -1.34149673e+00 -8.51210566e-01 -4.05534685e-01\n  -2.32026861e+00  4.76898369e-01]\n [-1.31003437e+00 -1.00153714e+00 -2.02967593e+00 -1.41359114e+00\n  -5.25640593e-01  2.71170185e-01 -8.40368309e-01  3.18420619e-01\n  -3.56527697e+00 -8.01496885e-01]\n [-4.52014664e-01 -1.98860563e+00 -8.44442960e-02 -2.33477934e+00\n   1.83925494e-01 -3.85489760e-01 -1.39377639e+00  1.66872403e+00\n  -2.99767891e+00 -1.60183605e+00]\n [ 1.87877751e-01 -3.73446073e-01 -2.11069768e+00 -1.55266945e+00\n   1.97967290e-01  1.08193522e+00 -1.83805274e+00  2.78189316e+00\n  -4.58047077e+00 -1.44494020e+00]\n [ 1.06397783e+00 -3.74942041e-01  1.37789442e+00 -1.10116224e+00\n   2.38074535e+00  3.30576756e-01 -3.62751801e-01 -1.06744659e+00\n   1.80645858e+00  9.49246474e-01]\n [-1.49281977e+00  1.70363308e+00 -2.51702180e+00  2.72787192e+00\n   4.52489093e-01  9.78961454e-02  1.16637563e+00  1.79530891e-01\n  -1.32718154e+00 -4.48165363e-01]\n [ 1.71524210e+00  8.45078725e-01  2.10328600e-01 -2.76365607e-01\n  -1.28455230e+00 -1.04343491e-01 -8.18455545e-01  5.69762395e-01\n   6.08087224e-01 -9.88001942e-01]\n [-1.25953667e+00 -2.30000934e+00 -2.13652480e+00 -4.07181293e+00\n   3.97667346e-02 -1.56699471e+00 -1.91783687e-01 -1.88006981e+00\n  -3.92414799e+00 -4.51303037e-01]\n [ 2.40063618e+00  9.41978055e-01  2.50206672e+00  8.10885445e-01\n  -8.87180942e-01 -9.32789042e-01  3.65052929e-01  1.31119741e+00\n   3.02640011e+00  1.24331938e+00]\n [-6.45458750e-01  3.89871890e-01 -1.30933368e+00  1.06457702e+00\n   4.66166426e-01 -3.70242441e-01  1.13171224e+00  2.52039526e+00\n  -2.66169119e+00 -4.53804041e-01]\n [-1.73747810e+00 -2.13573452e+00 -2.75690754e-01 -1.60094792e+00\n  -4.99016638e-01  2.13512238e-02  4.96193999e-01  1.96795196e-01\n  -2.48612615e+00 -9.19113445e-01]\n [-5.92002088e-01 -9.41395537e-01 -1.05079744e-01 -1.43430210e-01\n   3.11447072e-01  2.39582760e-01 -2.80743285e+00  3.55555703e+00\n  -2.81977981e+00 -3.69801166e-01]\n [ 2.26121003e+00  9.17216403e-01  3.12200426e-01  9.70775445e-02\n  -4.70032883e-01 -2.16731471e-01  1.62544223e+00  3.78329942e+00\n  -1.29493186e+00 -9.30156503e-01]\n [-2.13169865e-01  6.66407504e-02 -9.59088052e-01  3.63783178e-01\n  -1.03264310e+00 -4.36748337e-01 -2.94108911e+00  3.06808222e+00\n  -2.61886880e+00 -1.64296529e+00]\n [ 1.75218462e-01 -1.48207863e+00  8.70882256e-01 -1.94570019e+00\n  -2.90397101e-01  1.32778270e+00 -1.03272165e+00  1.29461393e-01\n  -4.96932710e-01 -1.01281486e-01]\n [-1.88539219e-01 -4.71972657e-02 -4.48703648e-01 -1.75052390e-01\n  -1.15395036e+00 -3.47961856e-01  2.76479447e-01 -8.54719937e-02\n  -5.68551115e-01 -1.35338886e+00]\n [-1.15821122e+00 -1.77545756e+00 -3.86467113e-01 -1.64486602e+00\n  -8.52585847e-01  2.29597556e-02  2.26330097e-01  6.03659507e-01\n  -2.55601345e+00 -1.11456118e-02]\n [-2.53972616e-01 -4.09670903e-01 -7.35009990e-01 -1.10742113e+00\n   1.41117206e+00  7.85803827e-01 -1.71717090e+00 -9.99464041e-01\n  -6.39567988e-01 -5.74695185e-02]\n [-8.97057585e-01  4.45653065e-01 -1.26207490e+00  1.00071970e+00\n   1.36759724e+00  1.03440989e+00  1.61438906e+00  5.03085351e-01\n  -1.39457236e+00 -9.96212640e-01]\n [ 5.74235454e-01  1.50488206e+00 -7.99041364e-01  1.69177155e+00\n  -1.14775325e-01  3.08751242e-01 -3.34211432e+00  2.29843342e+00\n  -5.41669705e-01 -1.37075998e+00]]", "y": "[0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0\n 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1\n 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.5785327  -0.22313174  0.4735143  -0.59864234 -0.17760012 -0.07765704\n  -0.86063873  0.38335156  0.11574416  0.25862752]]", "[1.]", "[13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-5.40719736e-01 -2.07547725e-01 -1.16313571e+00 -3.92126755e-01\n   2.65687975e-01  7.23100494e-01 -5.73061867e-01  4.91262934e-01\n  -1.85401812e+00  2.46121252e-02]\n [ 2.40281873e-01  3.92493901e-01 -1.87612282e+00 -4.21275393e-01\n   1.92793845e-02  1.84959125e+00  1.78904119e+00  1.75133091e+00\n  -3.17351904e+00 -2.14166656e-01]\n [-1.58055773e+00 -1.99422200e+00 -2.26192155e-01 -1.20353079e+00\n   8.20321797e-01  1.35994854e+00  2.05118865e+00  1.42894316e+00\n  -3.11976811e+00 -9.03820073e-02]\n [-3.25766370e+00 -3.24839979e+00 -2.64248480e+00 -3.43623483e+00\n   2.22594433e+00  1.37098901e+00 -1.16939231e+00 -5.31139918e-01\n  -5.90978642e+00 -5.09843242e-01]\n [-1.56837590e+00 -1.72314539e+00 -1.00215947e+00 -1.43977522e+00\n  -5.85865511e-02 -3.17543094e-01  1.64483367e+00  8.23798385e-01\n  -3.45612926e+00 -1.63242330e+00]\n [-7.42445952e-01 -1.11292264e+00 -1.69317121e+00 -1.90678419e+00\n   1.01184243e+00 -6.57951045e-01  2.03225445e+00  4.22033882e-01\n  -3.64744991e+00  4.68385234e-01]\n [ 1.98061677e+00  2.14268413e+00 -2.48771332e+00 -5.64732027e-01\n   4.48195284e-01  1.69618157e+00 -1.14340196e+00 -6.83505427e-01\n  -7.88078317e-01 -1.48577034e-02]\n [ 9.16168819e-02 -4.30798100e-01  2.38779825e-01 -5.72194530e-01\n  -8.48320523e-01 -3.25669469e-01  1.90701161e+00  5.83762152e-02\n  -3.60536232e-01  4.70433145e-01]\n [-2.84765716e-01 -2.45449107e-01 -3.95285955e-01  3.24590724e-01\n   1.15418403e+00  1.72504416e-01 -2.55835140e+00  3.07522428e+00\n  -2.24993392e+00  2.10620213e-02]\n [-1.84918860e-01 -2.80193775e-02 -1.75170324e+00 -8.26275185e-01\n  -6.67720286e-01  3.26962595e-01  1.11963770e+00  5.68059391e-01\n  -2.66564275e+00  3.30035115e-01]\n [ 1.44865494e+00  1.25107298e+00 -1.02590188e-01  9.70819795e-01\n  -2.00421572e+00  3.76876521e-01  9.00210151e-01  2.70304375e+00\n  -6.50746054e-01 -5.45711974e-01]\n [-6.42658892e-01 -1.29979677e+00 -1.51346018e-01 -9.22684936e-01\n  -2.41337791e-01 -8.78190343e-01 -6.70286357e-01  2.33179222e+00\n  -2.73853240e+00  6.99380484e-01]\n [ 2.89826530e-01 -2.38143411e+00  1.87807873e+00 -2.25604927e+00\n  -8.03141387e-01 -4.64337691e-01 -3.28028169e+00  2.81913451e+00\n  -1.52508866e+00  1.02179059e+00]\n [-9.75594369e-01 -4.99933228e-01 -2.40705928e+00 -7.22074398e-01\n   3.24869616e-01  9.97117981e-01 -2.64059090e+00  2.68297514e+00\n  -4.76209932e+00  3.06018243e-02]\n [ 3.80502581e-01 -2.22771751e+00  3.18104879e+00 -2.39557550e+00\n   8.67407411e-01 -6.56463675e-01 -1.14778339e+00 -2.25935277e+00\n   2.99723877e+00 -2.83455451e+00]\n [-9.72695965e-02 -5.14060999e-02  5.63553700e-02  2.76243219e-01\n   1.15147873e-01 -3.79147563e-01  1.12850804e+00  8.43422120e-01\n  -5.31738568e-01 -1.74235620e+00]\n [-2.75089949e-01  2.81315520e-01 -6.37272915e-01  9.92286919e-01\n   1.92753849e-01 -3.65055217e-01  1.81744782e+00  2.74263959e+00\n  -2.16173077e+00 -1.79132755e+00]\n [ 1.61372392e-01 -1.62110266e-01  1.64712804e+00  7.25240014e-01\n  -6.47181432e-01  4.72247150e-01 -9.04806491e-01  4.58857984e-01\n   1.73340365e+00  9.30408496e-01]\n [-1.09154341e+00 -6.85835510e-01 -4.69778885e-01  4.48004183e-02\n  -5.00840943e-02 -8.97400927e-01  8.48524599e-01  9.99100432e-01\n  -1.77456353e+00  1.31247037e+00]\n [-2.30947161e+00 -1.96136438e+00 -1.75642672e-01 -4.18403168e-01\n  -6.71341546e-02  1.48935596e+00  1.37200779e+00  1.10121757e+00\n  -2.64389923e+00  5.21303748e-01]\n [ 3.46514296e-01  4.64970954e-01 -2.50360785e+00 -5.62747666e-01\n   1.09074973e+00 -3.46249448e-01  1.86059960e-01  3.04055670e+00\n  -4.52222864e+00 -7.94636321e-01]\n [-1.36745452e+00 -1.10038709e-01 -1.55248025e+00  5.89443077e-01\n  -6.72756089e-02 -1.31839587e+00  2.02620466e+00  1.08358693e+00\n  -2.64150323e+00 -3.70704003e-01]\n [-5.78231096e-01 -1.16881345e-01 -2.64237436e-01  5.54276871e-01\n   6.76460732e-01 -3.82008956e-01  7.43356147e-01  1.17097261e+00\n  -1.08004544e+00 -2.24258934e-01]\n [-3.15803437e+00 -2.20828795e+00  1.00144500e+00  1.19462953e+00\n   1.48449581e-01  5.29045238e-01  1.57419161e+00  2.47945962e+00\n  -2.02853341e+00  4.22628622e-01]\n [-1.09828810e+00 -1.46664705e+00 -4.29858614e-02 -3.58124761e-01\n  -1.75316402e-01 -1.42191987e+00 -4.49272853e+00  3.79443104e+00\n  -3.21049772e+00  1.99795608e+00]\n [ 2.79421119e-01 -1.30568494e-01  1.28250817e+00  3.06339286e-01\n   8.65652923e-01  1.08137603e+00  3.95100471e-01 -1.03819672e-01\n   1.48776923e+00 -6.31375988e-01]\n [-1.43505375e-01 -1.56340254e+00 -1.39795502e-01 -1.76241483e+00\n  -8.15791542e-01 -5.07517602e-01 -1.24749791e+00  2.84722635e+00\n  -3.34479603e+00 -1.05188010e+00]\n [ 3.98629684e-01 -1.48153244e+00  1.91880431e+00 -1.96884044e+00\n   2.49720039e+00 -2.24532165e+00 -4.63584238e-01 -1.92205545e+00\n   1.92503028e+00  5.64008535e-01]\n [-2.72499730e+00 -3.71643688e+00  1.49079409e-01 -2.95851931e+00\n   9.94544570e-02  2.27392775e-01 -4.10487163e-01 -6.69633290e-01\n  -2.89678440e+00 -1.01673865e+00]\n [-2.55233995e+00 -1.35806555e+00 -2.03468662e+00 -2.68015048e-01\n  -1.78589092e-01 -1.55042935e+00  2.93831142e+00  1.59279151e+00\n  -4.74952324e+00  4.17318821e-01]\n [-3.18713733e-01  2.67219161e+00 -2.25687002e+00  3.34358664e+00\n  -9.45615796e-01 -9.32740911e-01  4.18552525e-01  1.09140489e+00\n  -6.19898290e-01 -1.26306835e+00]\n [ 1.24150332e+00 -3.23759982e-01  5.40407232e-01 -1.53475533e+00\n  -1.88458584e+00 -1.94570308e+00 -2.63152051e+00  7.88439847e-02\n   2.85179664e-01 -9.12783494e-01]\n [ 2.18454598e+00  7.16411400e-01  2.17445769e+00  3.86820279e-01\n  -7.04921353e-01  6.79974844e-01 -7.66706677e-02  9.50874860e-01\n   2.63993565e+00 -6.96326654e-01]\n [ 1.26598701e+00  1.35524226e+00  2.01380939e-02  5.67797707e-01\n  -9.64606424e-01  5.98946831e-02  3.27539712e+00 -1.16536304e+00\n   1.64464743e+00 -2.12523045e-01]\n [-7.07814669e-01 -7.13933313e-01 -1.45208404e+00 -8.94041023e-01\n  -7.49690345e-01  3.28087476e-02 -8.18746000e-01  1.81874418e+00\n  -3.47065784e+00 -2.58279663e+00]\n [ 1.41016335e+00  5.17727752e-01  2.97449018e-01  1.97103484e-02\n  -1.50239657e+00 -1.77766695e+00 -1.25051994e-01  2.35767947e+00\n  -6.40623011e-01 -5.32702792e-01]\n [-1.80634223e+00 -9.54011273e-01 -5.21880648e-01  2.04338374e-01\n  -1.38504274e-03 -6.87299037e-01  1.04161376e+00  2.92215760e-01\n  -1.61473902e+00 -1.17474546e-01]\n [-6.95926614e-01 -3.76985142e-01 -9.17926196e-01 -6.44954718e-02\n   1.14988999e-02 -8.37678042e-01 -2.86511092e+00  1.84350933e+00\n  -2.26948325e+00 -5.91183104e-01]\n [-2.52026333e-01 -2.31775019e+00  1.69543265e+00 -2.19734285e+00\n   1.01702099e+00  1.42298350e+00 -5.54136240e-01  3.76351358e-01\n  -4.33128488e-01  3.96086585e-01]\n [-1.27217561e+00 -1.49690370e+00 -1.20900231e+00 -1.54360900e+00\n  -3.91217052e-01  9.40917615e-01  1.00788069e+00  8.54735843e-01\n  -3.50000727e+00  4.05204080e-01]\n [ 1.72766139e+00  1.03096709e-02  2.46800095e+00  1.61769760e-01\n  -5.52540673e-01 -3.86870847e-01  9.07110053e-02  1.80924204e+00\n   1.84430777e+00 -5.10292740e-01]\n [-2.77248257e+00 -1.80852871e-01 -1.43693490e+00  1.67295273e+00\n   1.83339199e-01  1.67094303e+00  6.07333834e-02 -4.97606123e-01\n  -1.25673744e+00 -5.61330204e-02]\n [ 2.50458836e-01  1.62928730e+00 -1.49142487e+00  1.71992882e+00\n   5.20040615e-01  2.25608654e-01  1.43380612e+00  1.60096526e+00\n  -1.23247802e+00  4.49712100e-01]\n [ 1.97567941e+00  5.54372516e-01  2.39598796e+00  6.75444644e-01\n  -1.32988422e-01 -7.65702194e-01  8.99176641e-01  1.62667363e+00\n   2.32957933e+00  5.55786964e-01]\n [ 5.11748501e-01  2.98187991e+00 -2.73085139e+00  3.16968908e+00\n  -1.30324275e+00  6.05120084e-01  1.04589892e+00  3.41080543e+00\n  -2.41099931e+00  8.95555986e-01]\n [-1.75836596e+00 -2.74488828e+00  1.33268021e-01 -2.32504192e+00\n  -4.06071796e-01 -5.35270165e-01  2.34192962e-01 -1.56738914e-02\n  -2.47053475e+00  2.54052084e-02]\n [-2.45651522e-01 -2.52005007e-03 -1.65115469e+00 -3.07831308e-01\n   5.09542770e-02 -1.79422927e+00 -1.38503506e+00  2.28710593e+00\n  -3.26484831e+00  1.32646164e+00]\n [ 8.27529803e-01  2.86963730e-01 -9.04269082e-01 -1.01366924e+00\n   2.19509556e-01  3.93062934e-01 -5.29818774e-01  1.15104057e-01\n  -1.03264910e+00 -9.38981573e-01]\n [ 5.14302791e-01 -5.32400591e-01 -8.67029313e-02 -1.37884976e+00\n  -1.21054299e+00 -7.88669255e-01 -6.47452517e-01  3.62365274e-01\n  -9.33506921e-01  1.09463837e+00]\n [-2.59112515e+00 -2.66794491e+00 -7.29070837e-01 -1.93733584e+00\n  -1.07709907e+00 -4.24663302e-01  6.91861067e-01 -3.85363185e-01\n  -3.17317233e+00 -8.29964598e-01]\n [-3.89209400e-01 -7.53322298e-01 -1.10146119e+00 -9.31894378e-01\n   8.21405937e-01  6.70570450e-01  1.55968186e+00  2.23954430e+00\n  -3.54978454e+00 -7.07505698e-01]\n [ 3.46135602e-01  1.49608283e-01  4.29888226e-01  1.17173768e+00\n   9.72535789e-01  2.13386825e+00 -3.77668148e+00  4.80596056e+00\n  -1.75539019e+00  4.06415494e-01]\n [-2.87027884e-01 -1.19320501e-01 -1.11019755e+00 -2.23099099e-01\n   1.03493146e-02  7.20033759e-01  8.61250916e-01  1.55021611e+00\n  -2.45117982e+00 -1.82425666e+00]\n [-2.68801430e+00  1.18159795e+00 -3.70978398e+00  2.51761655e+00\n   2.86904488e-01 -2.32059428e+00  2.00671584e+00  4.97767401e-01\n  -3.45334430e+00  3.17160626e-01]\n [-3.62802299e+00 -4.30455219e+00 -5.81707158e-01 -3.61686284e+00\n   3.03603904e-01  7.72694837e-01 -3.35308722e-02 -1.73621062e+00\n  -3.73394798e+00 -1.66159829e+00]\n [-3.12679267e+00  1.18204184e-01 -1.65931992e+00  1.94714369e+00\n  -1.21793851e+00 -3.04963638e-01  4.79344437e-01 -2.42696397e+00\n  -1.00424198e-01  1.02893549e+00]\n [-2.50183006e+00 -2.42594288e+00 -2.08244607e+00 -2.70371999e+00\n  -1.93176702e-01  7.55740289e-01 -3.33534320e-01 -1.05723715e+00\n  -4.21211817e+00 -5.39132637e-01]\n [ 1.57348038e+00  2.45658557e+00 -1.30041756e+00  2.21831721e+00\n  -1.06122229e+00 -2.22477010e-01 -2.56671816e+00  4.13359522e+00\n  -1.44607036e+00 -8.58919908e-01]\n [-1.08528377e+00 -2.36443725e+00  1.24193251e+00 -1.46249746e+00\n  -5.90057646e-01 -1.10489405e-01  5.65235864e-01  1.15389878e+00\n  -1.44254145e+00 -1.66069981e+00]\n [-8.59594567e-01  1.58762747e+00 -1.35952991e+00  2.63251290e+00\n  -7.22870076e-02 -6.00657558e-01 -3.52851374e-01  4.04968931e-01\n  -8.18174283e-02  1.55224318e+00]\n [ 3.16644365e+00  1.87150288e+00  2.32027111e+00  1.70137944e+00\n   2.11679102e+00 -1.61087840e+00 -4.15368298e-02  2.97962363e+00\n   2.74314339e+00 -3.57680719e-02]\n [-3.21496449e-01 -9.16711694e-02 -1.18510746e-02  4.35480050e-01\n  -6.49337928e-01 -2.34231050e-02  6.50426070e-01  9.87375684e-01\n  -6.64028802e-01  1.07919473e+00]\n [-1.36042415e+00 -1.57432078e+00  3.10975913e-01 -6.07006825e-01\n   3.29622982e-01  1.28598401e+00  8.28108553e-01  7.76594592e-01\n  -1.54843347e+00 -1.50699840e+00]\n [-7.73219279e-01 -2.62385236e+00 -6.63995013e-01 -3.28635103e+00\n  -3.50951769e-02  1.26507784e+00 -3.45817641e+00  2.16449210e+00\n  -4.48310670e+00  2.11497013e-01]\n [-1.76878361e+00  1.15858344e+00 -3.28947145e+00  2.00728267e+00\n  -9.44368491e-01  2.38103148e-01  2.41255523e+00  1.54613528e+00\n  -3.73133928e+00 -1.40596292e+00]\n [-3.95792874e+00 -3.06314813e+00 -3.97730255e-01 -1.10773228e+00\n   4.03264540e-01 -9.18004770e-01  1.44301665e+00 -1.50482501e+00\n  -2.34694246e+00  2.52496627e-01]\n [ 9.01653686e-01  5.61621907e-01 -1.62718504e+00 -1.67288554e+00\n  -1.35978073e+00 -4.14008116e-02 -2.97524355e+00 -2.04405161e+00\n  -2.66671403e-01 -7.57870860e-01]\n [-1.06827715e+00 -9.01488862e-01 -8.64171465e-01 -5.08300770e-01\n   1.73587900e+00 -6.67712721e-01  2.26870415e+00  1.17099597e+00\n  -2.73166331e+00  1.68192174e+00]\n [ 5.33160920e-01  6.40349473e-02  9.59815471e-01  4.23974236e-01\n  -6.96415784e-02  5.15749428e-02  6.24164464e-02  1.20838326e+00\n   5.20748004e-01  8.67276629e-01]\n [-1.05213971e+00 -1.15539732e+00 -9.34807917e-01 -1.29774033e+00\n  -1.12465983e-01 -5.32489919e-01 -2.98756694e-01 -3.97472894e-02\n  -2.20889786e+00  6.45055273e-01]\n [-1.68998451e+00 -2.28503916e+00 -1.37912247e+00 -2.64430912e+00\n  -8.58972388e-01 -8.98942156e-01  1.25749952e+00 -5.21927708e-02\n  -3.99979861e+00  7.45864065e-02]\n [-1.12084915e+00 -1.26335539e+00 -2.36396575e-01 -7.62349883e-01\n  -7.62114512e-01 -8.87780137e-01 -1.79056507e+00  8.60352823e-01\n  -1.79927802e+00  9.36398544e-01]\n [-1.57846968e+00 -1.90764384e+00 -1.72238591e+00 -2.37900112e+00\n   7.19983730e-01 -1.10290621e+00  1.68849052e+00 -2.28030482e-02\n  -4.10771460e+00 -1.01697275e-01]\n [ 3.79202559e-01 -1.24900820e+00  1.57963563e+00 -1.15843402e+00\n  -5.91402668e-01  1.12441918e+00  3.66660545e-01  8.08789908e-01\n   1.33994346e-01  7.55395696e-01]\n [-1.49176879e+00 -1.79796854e+00  1.09635970e-01 -7.39518871e-01\n  -3.02249730e-01 -3.75147117e-01  9.15219051e-01  1.67133299e+00\n  -2.53664955e+00 -1.22619619e+00]\n [ 7.65703113e-01  3.43107235e-01 -9.46974483e-01 -1.82989894e-01\n  -1.17762896e+00 -1.14019630e+00  3.96746765e-01  3.09783484e+00\n  -2.77356943e+00  1.75498615e+00]\n [-1.74684647e+00 -5.02093390e-01 -5.70473828e-01  8.71130699e-01\n  -1.31908640e-01  4.04761812e-01  2.10680785e-01  5.87867468e-01\n  -1.30096559e+00  2.23843563e-01]\n [-1.70368664e+00 -1.31896726e+00 -1.92071459e-02  2.81548802e-01\n   4.98052405e-01 -2.61922373e-02  1.54518087e+00  2.15027851e+00\n  -2.46815777e+00 -1.68823003e+00]\n [ 5.59889117e-01 -1.80614879e+00  2.65356566e+00 -1.18655831e+00\n   8.12674042e-01  5.87259379e-01 -7.37784715e-01  2.41422692e+00\n   6.79726053e-02 -5.05358317e-01]\n [-5.11241337e-02 -2.83356832e+00  1.47726172e+00 -3.23877000e+00\n   2.34821526e-01  2.13215341e+00 -4.30465039e+00  1.24433504e+00\n  -1.49465772e+00  9.36445726e-01]\n [ 1.54487004e-01  4.42533475e-02 -2.04485819e+00 -1.53104452e+00\n   6.11927193e-01 -1.34149673e+00 -8.51210566e-01 -4.05534685e-01\n  -2.32026861e+00  4.76898369e-01]\n [-1.31003437e+00 -1.00153714e+00 -2.02967593e+00 -1.41359114e+00\n  -5.25640593e-01  2.71170185e-01 -8.40368309e-01  3.18420619e-01\n  -3.56527697e+00 -8.01496885e-01]\n [-4.52014664e-01 -1.98860563e+00 -8.44442960e-02 -2.33477934e+00\n   1.83925494e-01 -3.85489760e-01 -1.39377639e+00  1.66872403e+00\n  -2.99767891e+00 -1.60183605e+00]\n [ 1.87877751e-01 -3.73446073e-01 -2.11069768e+00 -1.55266945e+00\n   1.97967290e-01  1.08193522e+00 -1.83805274e+00  2.78189316e+00\n  -4.58047077e+00 -1.44494020e+00]\n [ 1.06397783e+00 -3.74942041e-01  1.37789442e+00 -1.10116224e+00\n   2.38074535e+00  3.30576756e-01 -3.62751801e-01 -1.06744659e+00\n   1.80645858e+00  9.49246474e-01]\n [-1.49281977e+00  1.70363308e+00 -2.51702180e+00  2.72787192e+00\n   4.52489093e-01  9.78961454e-02  1.16637563e+00  1.79530891e-01\n  -1.32718154e+00 -4.48165363e-01]\n [ 1.71524210e+00  8.45078725e-01  2.10328600e-01 -2.76365607e-01\n  -1.28455230e+00 -1.04343491e-01 -8.18455545e-01  5.69762395e-01\n   6.08087224e-01 -9.88001942e-01]\n [-1.25953667e+00 -2.30000934e+00 -2.13652480e+00 -4.07181293e+00\n   3.97667346e-02 -1.56699471e+00 -1.91783687e-01 -1.88006981e+00\n  -3.92414799e+00 -4.51303037e-01]\n [ 2.40063618e+00  9.41978055e-01  2.50206672e+00  8.10885445e-01\n  -8.87180942e-01 -9.32789042e-01  3.65052929e-01  1.31119741e+00\n   3.02640011e+00  1.24331938e+00]\n [-6.45458750e-01  3.89871890e-01 -1.30933368e+00  1.06457702e+00\n   4.66166426e-01 -3.70242441e-01  1.13171224e+00  2.52039526e+00\n  -2.66169119e+00 -4.53804041e-01]\n [-1.73747810e+00 -2.13573452e+00 -2.75690754e-01 -1.60094792e+00\n  -4.99016638e-01  2.13512238e-02  4.96193999e-01  1.96795196e-01\n  -2.48612615e+00 -9.19113445e-01]\n [-5.92002088e-01 -9.41395537e-01 -1.05079744e-01 -1.43430210e-01\n   3.11447072e-01  2.39582760e-01 -2.80743285e+00  3.55555703e+00\n  -2.81977981e+00 -3.69801166e-01]\n [ 2.26121003e+00  9.17216403e-01  3.12200426e-01  9.70775445e-02\n  -4.70032883e-01 -2.16731471e-01  1.62544223e+00  3.78329942e+00\n  -1.29493186e+00 -9.30156503e-01]\n [-2.13169865e-01  6.66407504e-02 -9.59088052e-01  3.63783178e-01\n  -1.03264310e+00 -4.36748337e-01 -2.94108911e+00  3.06808222e+00\n  -2.61886880e+00 -1.64296529e+00]\n [ 1.75218462e-01 -1.48207863e+00  8.70882256e-01 -1.94570019e+00\n  -2.90397101e-01  1.32778270e+00 -1.03272165e+00  1.29461393e-01\n  -4.96932710e-01 -1.01281486e-01]\n [-1.88539219e-01 -4.71972657e-02 -4.48703648e-01 -1.75052390e-01\n  -1.15395036e+00 -3.47961856e-01  2.76479447e-01 -8.54719937e-02\n  -5.68551115e-01 -1.35338886e+00]\n [-1.15821122e+00 -1.77545756e+00 -3.86467113e-01 -1.64486602e+00\n  -8.52585847e-01  2.29597556e-02  2.26330097e-01  6.03659507e-01\n  -2.55601345e+00 -1.11456118e-02]\n [-2.53972616e-01 -4.09670903e-01 -7.35009990e-01 -1.10742113e+00\n   1.41117206e+00  7.85803827e-01 -1.71717090e+00 -9.99464041e-01\n  -6.39567988e-01 -5.74695185e-02]\n [-8.97057585e-01  4.45653065e-01 -1.26207490e+00  1.00071970e+00\n   1.36759724e+00  1.03440989e+00  1.61438906e+00  5.03085351e-01\n  -1.39457236e+00 -9.96212640e-01]\n [ 5.74235454e-01  1.50488206e+00 -7.99041364e-01  1.69177155e+00\n  -1.14775325e-01  3.08751242e-01 -3.34211432e+00  2.29843342e+00\n  -5.41669705e-01 -1.37075998e+00]]", "y": "[0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0\n 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1\n 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 83.62445230231828, "sample_weight": null}}, "return": ["[[ 0.57845072 -0.22316152  0.47353171 -0.59858687 -0.17753419 -0.07769778\n  -0.86067283  0.3833643   0.1157453   0.25862788]]", "[1.]", "[28]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-5.40719736e-01 -2.07547725e-01 -1.16313571e+00 -3.92126755e-01\n   2.65687975e-01  7.23100494e-01 -5.73061867e-01  4.91262934e-01\n  -1.85401812e+00  2.46121252e-02]\n [ 2.40281873e-01  3.92493901e-01 -1.87612282e+00 -4.21275393e-01\n   1.92793845e-02  1.84959125e+00  1.78904119e+00  1.75133091e+00\n  -3.17351904e+00 -2.14166656e-01]\n [-1.58055773e+00 -1.99422200e+00 -2.26192155e-01 -1.20353079e+00\n   8.20321797e-01  1.35994854e+00  2.05118865e+00  1.42894316e+00\n  -3.11976811e+00 -9.03820073e-02]\n [-3.25766370e+00 -3.24839979e+00 -2.64248480e+00 -3.43623483e+00\n   2.22594433e+00  1.37098901e+00 -1.16939231e+00 -5.31139918e-01\n  -5.90978642e+00 -5.09843242e-01]\n [-1.56837590e+00 -1.72314539e+00 -1.00215947e+00 -1.43977522e+00\n  -5.85865511e-02 -3.17543094e-01  1.64483367e+00  8.23798385e-01\n  -3.45612926e+00 -1.63242330e+00]\n [-7.42445952e-01 -1.11292264e+00 -1.69317121e+00 -1.90678419e+00\n   1.01184243e+00 -6.57951045e-01  2.03225445e+00  4.22033882e-01\n  -3.64744991e+00  4.68385234e-01]\n [ 1.98061677e+00  2.14268413e+00 -2.48771332e+00 -5.64732027e-01\n   4.48195284e-01  1.69618157e+00 -1.14340196e+00 -6.83505427e-01\n  -7.88078317e-01 -1.48577034e-02]\n [ 9.16168819e-02 -4.30798100e-01  2.38779825e-01 -5.72194530e-01\n  -8.48320523e-01 -3.25669469e-01  1.90701161e+00  5.83762152e-02\n  -3.60536232e-01  4.70433145e-01]\n [-2.84765716e-01 -2.45449107e-01 -3.95285955e-01  3.24590724e-01\n   1.15418403e+00  1.72504416e-01 -2.55835140e+00  3.07522428e+00\n  -2.24993392e+00  2.10620213e-02]\n [-1.84918860e-01 -2.80193775e-02 -1.75170324e+00 -8.26275185e-01\n  -6.67720286e-01  3.26962595e-01  1.11963770e+00  5.68059391e-01\n  -2.66564275e+00  3.30035115e-01]\n [ 1.44865494e+00  1.25107298e+00 -1.02590188e-01  9.70819795e-01\n  -2.00421572e+00  3.76876521e-01  9.00210151e-01  2.70304375e+00\n  -6.50746054e-01 -5.45711974e-01]\n [-6.42658892e-01 -1.29979677e+00 -1.51346018e-01 -9.22684936e-01\n  -2.41337791e-01 -8.78190343e-01 -6.70286357e-01  2.33179222e+00\n  -2.73853240e+00  6.99380484e-01]\n [ 2.89826530e-01 -2.38143411e+00  1.87807873e+00 -2.25604927e+00\n  -8.03141387e-01 -4.64337691e-01 -3.28028169e+00  2.81913451e+00\n  -1.52508866e+00  1.02179059e+00]\n [-9.75594369e-01 -4.99933228e-01 -2.40705928e+00 -7.22074398e-01\n   3.24869616e-01  9.97117981e-01 -2.64059090e+00  2.68297514e+00\n  -4.76209932e+00  3.06018243e-02]\n [ 3.80502581e-01 -2.22771751e+00  3.18104879e+00 -2.39557550e+00\n   8.67407411e-01 -6.56463675e-01 -1.14778339e+00 -2.25935277e+00\n   2.99723877e+00 -2.83455451e+00]\n [-9.72695965e-02 -5.14060999e-02  5.63553700e-02  2.76243219e-01\n   1.15147873e-01 -3.79147563e-01  1.12850804e+00  8.43422120e-01\n  -5.31738568e-01 -1.74235620e+00]\n [-2.75089949e-01  2.81315520e-01 -6.37272915e-01  9.92286919e-01\n   1.92753849e-01 -3.65055217e-01  1.81744782e+00  2.74263959e+00\n  -2.16173077e+00 -1.79132755e+00]\n [ 1.61372392e-01 -1.62110266e-01  1.64712804e+00  7.25240014e-01\n  -6.47181432e-01  4.72247150e-01 -9.04806491e-01  4.58857984e-01\n   1.73340365e+00  9.30408496e-01]\n [-1.09154341e+00 -6.85835510e-01 -4.69778885e-01  4.48004183e-02\n  -5.00840943e-02 -8.97400927e-01  8.48524599e-01  9.99100432e-01\n  -1.77456353e+00  1.31247037e+00]\n [-2.30947161e+00 -1.96136438e+00 -1.75642672e-01 -4.18403168e-01\n  -6.71341546e-02  1.48935596e+00  1.37200779e+00  1.10121757e+00\n  -2.64389923e+00  5.21303748e-01]\n [ 3.46514296e-01  4.64970954e-01 -2.50360785e+00 -5.62747666e-01\n   1.09074973e+00 -3.46249448e-01  1.86059960e-01  3.04055670e+00\n  -4.52222864e+00 -7.94636321e-01]\n [-1.36745452e+00 -1.10038709e-01 -1.55248025e+00  5.89443077e-01\n  -6.72756089e-02 -1.31839587e+00  2.02620466e+00  1.08358693e+00\n  -2.64150323e+00 -3.70704003e-01]\n [-5.78231096e-01 -1.16881345e-01 -2.64237436e-01  5.54276871e-01\n   6.76460732e-01 -3.82008956e-01  7.43356147e-01  1.17097261e+00\n  -1.08004544e+00 -2.24258934e-01]\n [-3.15803437e+00 -2.20828795e+00  1.00144500e+00  1.19462953e+00\n   1.48449581e-01  5.29045238e-01  1.57419161e+00  2.47945962e+00\n  -2.02853341e+00  4.22628622e-01]\n [-1.09828810e+00 -1.46664705e+00 -4.29858614e-02 -3.58124761e-01\n  -1.75316402e-01 -1.42191987e+00 -4.49272853e+00  3.79443104e+00\n  -3.21049772e+00  1.99795608e+00]\n [ 2.79421119e-01 -1.30568494e-01  1.28250817e+00  3.06339286e-01\n   8.65652923e-01  1.08137603e+00  3.95100471e-01 -1.03819672e-01\n   1.48776923e+00 -6.31375988e-01]\n [-1.43505375e-01 -1.56340254e+00 -1.39795502e-01 -1.76241483e+00\n  -8.15791542e-01 -5.07517602e-01 -1.24749791e+00  2.84722635e+00\n  -3.34479603e+00 -1.05188010e+00]\n [ 3.98629684e-01 -1.48153244e+00  1.91880431e+00 -1.96884044e+00\n   2.49720039e+00 -2.24532165e+00 -4.63584238e-01 -1.92205545e+00\n   1.92503028e+00  5.64008535e-01]\n [-2.72499730e+00 -3.71643688e+00  1.49079409e-01 -2.95851931e+00\n   9.94544570e-02  2.27392775e-01 -4.10487163e-01 -6.69633290e-01\n  -2.89678440e+00 -1.01673865e+00]\n [-2.55233995e+00 -1.35806555e+00 -2.03468662e+00 -2.68015048e-01\n  -1.78589092e-01 -1.55042935e+00  2.93831142e+00  1.59279151e+00\n  -4.74952324e+00  4.17318821e-01]\n [-3.18713733e-01  2.67219161e+00 -2.25687002e+00  3.34358664e+00\n  -9.45615796e-01 -9.32740911e-01  4.18552525e-01  1.09140489e+00\n  -6.19898290e-01 -1.26306835e+00]\n [ 1.24150332e+00 -3.23759982e-01  5.40407232e-01 -1.53475533e+00\n  -1.88458584e+00 -1.94570308e+00 -2.63152051e+00  7.88439847e-02\n   2.85179664e-01 -9.12783494e-01]\n [ 2.18454598e+00  7.16411400e-01  2.17445769e+00  3.86820279e-01\n  -7.04921353e-01  6.79974844e-01 -7.66706677e-02  9.50874860e-01\n   2.63993565e+00 -6.96326654e-01]\n [ 1.26598701e+00  1.35524226e+00  2.01380939e-02  5.67797707e-01\n  -9.64606424e-01  5.98946831e-02  3.27539712e+00 -1.16536304e+00\n   1.64464743e+00 -2.12523045e-01]\n [-7.07814669e-01 -7.13933313e-01 -1.45208404e+00 -8.94041023e-01\n  -7.49690345e-01  3.28087476e-02 -8.18746000e-01  1.81874418e+00\n  -3.47065784e+00 -2.58279663e+00]\n [ 1.41016335e+00  5.17727752e-01  2.97449018e-01  1.97103484e-02\n  -1.50239657e+00 -1.77766695e+00 -1.25051994e-01  2.35767947e+00\n  -6.40623011e-01 -5.32702792e-01]\n [-1.80634223e+00 -9.54011273e-01 -5.21880648e-01  2.04338374e-01\n  -1.38504274e-03 -6.87299037e-01  1.04161376e+00  2.92215760e-01\n  -1.61473902e+00 -1.17474546e-01]\n [-6.95926614e-01 -3.76985142e-01 -9.17926196e-01 -6.44954718e-02\n   1.14988999e-02 -8.37678042e-01 -2.86511092e+00  1.84350933e+00\n  -2.26948325e+00 -5.91183104e-01]\n [-2.52026333e-01 -2.31775019e+00  1.69543265e+00 -2.19734285e+00\n   1.01702099e+00  1.42298350e+00 -5.54136240e-01  3.76351358e-01\n  -4.33128488e-01  3.96086585e-01]\n [-1.27217561e+00 -1.49690370e+00 -1.20900231e+00 -1.54360900e+00\n  -3.91217052e-01  9.40917615e-01  1.00788069e+00  8.54735843e-01\n  -3.50000727e+00  4.05204080e-01]\n [ 1.72766139e+00  1.03096709e-02  2.46800095e+00  1.61769760e-01\n  -5.52540673e-01 -3.86870847e-01  9.07110053e-02  1.80924204e+00\n   1.84430777e+00 -5.10292740e-01]\n [-2.77248257e+00 -1.80852871e-01 -1.43693490e+00  1.67295273e+00\n   1.83339199e-01  1.67094303e+00  6.07333834e-02 -4.97606123e-01\n  -1.25673744e+00 -5.61330204e-02]\n [ 2.50458836e-01  1.62928730e+00 -1.49142487e+00  1.71992882e+00\n   5.20040615e-01  2.25608654e-01  1.43380612e+00  1.60096526e+00\n  -1.23247802e+00  4.49712100e-01]\n [ 1.97567941e+00  5.54372516e-01  2.39598796e+00  6.75444644e-01\n  -1.32988422e-01 -7.65702194e-01  8.99176641e-01  1.62667363e+00\n   2.32957933e+00  5.55786964e-01]\n [ 5.11748501e-01  2.98187991e+00 -2.73085139e+00  3.16968908e+00\n  -1.30324275e+00  6.05120084e-01  1.04589892e+00  3.41080543e+00\n  -2.41099931e+00  8.95555986e-01]\n [-1.75836596e+00 -2.74488828e+00  1.33268021e-01 -2.32504192e+00\n  -4.06071796e-01 -5.35270165e-01  2.34192962e-01 -1.56738914e-02\n  -2.47053475e+00  2.54052084e-02]\n [-2.45651522e-01 -2.52005007e-03 -1.65115469e+00 -3.07831308e-01\n   5.09542770e-02 -1.79422927e+00 -1.38503506e+00  2.28710593e+00\n  -3.26484831e+00  1.32646164e+00]\n [ 8.27529803e-01  2.86963730e-01 -9.04269082e-01 -1.01366924e+00\n   2.19509556e-01  3.93062934e-01 -5.29818774e-01  1.15104057e-01\n  -1.03264910e+00 -9.38981573e-01]\n [ 5.14302791e-01 -5.32400591e-01 -8.67029313e-02 -1.37884976e+00\n  -1.21054299e+00 -7.88669255e-01 -6.47452517e-01  3.62365274e-01\n  -9.33506921e-01  1.09463837e+00]\n [-2.59112515e+00 -2.66794491e+00 -7.29070837e-01 -1.93733584e+00\n  -1.07709907e+00 -4.24663302e-01  6.91861067e-01 -3.85363185e-01\n  -3.17317233e+00 -8.29964598e-01]\n [-3.89209400e-01 -7.53322298e-01 -1.10146119e+00 -9.31894378e-01\n   8.21405937e-01  6.70570450e-01  1.55968186e+00  2.23954430e+00\n  -3.54978454e+00 -7.07505698e-01]\n [ 3.46135602e-01  1.49608283e-01  4.29888226e-01  1.17173768e+00\n   9.72535789e-01  2.13386825e+00 -3.77668148e+00  4.80596056e+00\n  -1.75539019e+00  4.06415494e-01]\n [-2.87027884e-01 -1.19320501e-01 -1.11019755e+00 -2.23099099e-01\n   1.03493146e-02  7.20033759e-01  8.61250916e-01  1.55021611e+00\n  -2.45117982e+00 -1.82425666e+00]\n [-2.68801430e+00  1.18159795e+00 -3.70978398e+00  2.51761655e+00\n   2.86904488e-01 -2.32059428e+00  2.00671584e+00  4.97767401e-01\n  -3.45334430e+00  3.17160626e-01]\n [-3.62802299e+00 -4.30455219e+00 -5.81707158e-01 -3.61686284e+00\n   3.03603904e-01  7.72694837e-01 -3.35308722e-02 -1.73621062e+00\n  -3.73394798e+00 -1.66159829e+00]\n [-3.12679267e+00  1.18204184e-01 -1.65931992e+00  1.94714369e+00\n  -1.21793851e+00 -3.04963638e-01  4.79344437e-01 -2.42696397e+00\n  -1.00424198e-01  1.02893549e+00]\n [-2.50183006e+00 -2.42594288e+00 -2.08244607e+00 -2.70371999e+00\n  -1.93176702e-01  7.55740289e-01 -3.33534320e-01 -1.05723715e+00\n  -4.21211817e+00 -5.39132637e-01]\n [ 1.57348038e+00  2.45658557e+00 -1.30041756e+00  2.21831721e+00\n  -1.06122229e+00 -2.22477010e-01 -2.56671816e+00  4.13359522e+00\n  -1.44607036e+00 -8.58919908e-01]\n [-1.08528377e+00 -2.36443725e+00  1.24193251e+00 -1.46249746e+00\n  -5.90057646e-01 -1.10489405e-01  5.65235864e-01  1.15389878e+00\n  -1.44254145e+00 -1.66069981e+00]\n [-8.59594567e-01  1.58762747e+00 -1.35952991e+00  2.63251290e+00\n  -7.22870076e-02 -6.00657558e-01 -3.52851374e-01  4.04968931e-01\n  -8.18174283e-02  1.55224318e+00]\n [ 3.16644365e+00  1.87150288e+00  2.32027111e+00  1.70137944e+00\n   2.11679102e+00 -1.61087840e+00 -4.15368298e-02  2.97962363e+00\n   2.74314339e+00 -3.57680719e-02]\n [-3.21496449e-01 -9.16711694e-02 -1.18510746e-02  4.35480050e-01\n  -6.49337928e-01 -2.34231050e-02  6.50426070e-01  9.87375684e-01\n  -6.64028802e-01  1.07919473e+00]\n [-1.36042415e+00 -1.57432078e+00  3.10975913e-01 -6.07006825e-01\n   3.29622982e-01  1.28598401e+00  8.28108553e-01  7.76594592e-01\n  -1.54843347e+00 -1.50699840e+00]\n [-7.73219279e-01 -2.62385236e+00 -6.63995013e-01 -3.28635103e+00\n  -3.50951769e-02  1.26507784e+00 -3.45817641e+00  2.16449210e+00\n  -4.48310670e+00  2.11497013e-01]\n [-1.76878361e+00  1.15858344e+00 -3.28947145e+00  2.00728267e+00\n  -9.44368491e-01  2.38103148e-01  2.41255523e+00  1.54613528e+00\n  -3.73133928e+00 -1.40596292e+00]\n [-3.95792874e+00 -3.06314813e+00 -3.97730255e-01 -1.10773228e+00\n   4.03264540e-01 -9.18004770e-01  1.44301665e+00 -1.50482501e+00\n  -2.34694246e+00  2.52496627e-01]\n [ 9.01653686e-01  5.61621907e-01 -1.62718504e+00 -1.67288554e+00\n  -1.35978073e+00 -4.14008116e-02 -2.97524355e+00 -2.04405161e+00\n  -2.66671403e-01 -7.57870860e-01]\n [-1.06827715e+00 -9.01488862e-01 -8.64171465e-01 -5.08300770e-01\n   1.73587900e+00 -6.67712721e-01  2.26870415e+00  1.17099597e+00\n  -2.73166331e+00  1.68192174e+00]\n [ 5.33160920e-01  6.40349473e-02  9.59815471e-01  4.23974236e-01\n  -6.96415784e-02  5.15749428e-02  6.24164464e-02  1.20838326e+00\n   5.20748004e-01  8.67276629e-01]\n [-1.05213971e+00 -1.15539732e+00 -9.34807917e-01 -1.29774033e+00\n  -1.12465983e-01 -5.32489919e-01 -2.98756694e-01 -3.97472894e-02\n  -2.20889786e+00  6.45055273e-01]\n [-1.68998451e+00 -2.28503916e+00 -1.37912247e+00 -2.64430912e+00\n  -8.58972388e-01 -8.98942156e-01  1.25749952e+00 -5.21927708e-02\n  -3.99979861e+00  7.45864065e-02]\n [-1.12084915e+00 -1.26335539e+00 -2.36396575e-01 -7.62349883e-01\n  -7.62114512e-01 -8.87780137e-01 -1.79056507e+00  8.60352823e-01\n  -1.79927802e+00  9.36398544e-01]\n [-1.57846968e+00 -1.90764384e+00 -1.72238591e+00 -2.37900112e+00\n   7.19983730e-01 -1.10290621e+00  1.68849052e+00 -2.28030482e-02\n  -4.10771460e+00 -1.01697275e-01]\n [ 3.79202559e-01 -1.24900820e+00  1.57963563e+00 -1.15843402e+00\n  -5.91402668e-01  1.12441918e+00  3.66660545e-01  8.08789908e-01\n   1.33994346e-01  7.55395696e-01]\n [-1.49176879e+00 -1.79796854e+00  1.09635970e-01 -7.39518871e-01\n  -3.02249730e-01 -3.75147117e-01  9.15219051e-01  1.67133299e+00\n  -2.53664955e+00 -1.22619619e+00]\n [ 7.65703113e-01  3.43107235e-01 -9.46974483e-01 -1.82989894e-01\n  -1.17762896e+00 -1.14019630e+00  3.96746765e-01  3.09783484e+00\n  -2.77356943e+00  1.75498615e+00]\n [-1.74684647e+00 -5.02093390e-01 -5.70473828e-01  8.71130699e-01\n  -1.31908640e-01  4.04761812e-01  2.10680785e-01  5.87867468e-01\n  -1.30096559e+00  2.23843563e-01]\n [-1.70368664e+00 -1.31896726e+00 -1.92071459e-02  2.81548802e-01\n   4.98052405e-01 -2.61922373e-02  1.54518087e+00  2.15027851e+00\n  -2.46815777e+00 -1.68823003e+00]\n [ 5.59889117e-01 -1.80614879e+00  2.65356566e+00 -1.18655831e+00\n   8.12674042e-01  5.87259379e-01 -7.37784715e-01  2.41422692e+00\n   6.79726053e-02 -5.05358317e-01]\n [-5.11241337e-02 -2.83356832e+00  1.47726172e+00 -3.23877000e+00\n   2.34821526e-01  2.13215341e+00 -4.30465039e+00  1.24433504e+00\n  -1.49465772e+00  9.36445726e-01]\n [ 1.54487004e-01  4.42533475e-02 -2.04485819e+00 -1.53104452e+00\n   6.11927193e-01 -1.34149673e+00 -8.51210566e-01 -4.05534685e-01\n  -2.32026861e+00  4.76898369e-01]\n [-1.31003437e+00 -1.00153714e+00 -2.02967593e+00 -1.41359114e+00\n  -5.25640593e-01  2.71170185e-01 -8.40368309e-01  3.18420619e-01\n  -3.56527697e+00 -8.01496885e-01]\n [-4.52014664e-01 -1.98860563e+00 -8.44442960e-02 -2.33477934e+00\n   1.83925494e-01 -3.85489760e-01 -1.39377639e+00  1.66872403e+00\n  -2.99767891e+00 -1.60183605e+00]\n [ 1.87877751e-01 -3.73446073e-01 -2.11069768e+00 -1.55266945e+00\n   1.97967290e-01  1.08193522e+00 -1.83805274e+00  2.78189316e+00\n  -4.58047077e+00 -1.44494020e+00]\n [ 1.06397783e+00 -3.74942041e-01  1.37789442e+00 -1.10116224e+00\n   2.38074535e+00  3.30576756e-01 -3.62751801e-01 -1.06744659e+00\n   1.80645858e+00  9.49246474e-01]\n [-1.49281977e+00  1.70363308e+00 -2.51702180e+00  2.72787192e+00\n   4.52489093e-01  9.78961454e-02  1.16637563e+00  1.79530891e-01\n  -1.32718154e+00 -4.48165363e-01]\n [ 1.71524210e+00  8.45078725e-01  2.10328600e-01 -2.76365607e-01\n  -1.28455230e+00 -1.04343491e-01 -8.18455545e-01  5.69762395e-01\n   6.08087224e-01 -9.88001942e-01]\n [-1.25953667e+00 -2.30000934e+00 -2.13652480e+00 -4.07181293e+00\n   3.97667346e-02 -1.56699471e+00 -1.91783687e-01 -1.88006981e+00\n  -3.92414799e+00 -4.51303037e-01]\n [ 2.40063618e+00  9.41978055e-01  2.50206672e+00  8.10885445e-01\n  -8.87180942e-01 -9.32789042e-01  3.65052929e-01  1.31119741e+00\n   3.02640011e+00  1.24331938e+00]\n [-6.45458750e-01  3.89871890e-01 -1.30933368e+00  1.06457702e+00\n   4.66166426e-01 -3.70242441e-01  1.13171224e+00  2.52039526e+00\n  -2.66169119e+00 -4.53804041e-01]\n [-1.73747810e+00 -2.13573452e+00 -2.75690754e-01 -1.60094792e+00\n  -4.99016638e-01  2.13512238e-02  4.96193999e-01  1.96795196e-01\n  -2.48612615e+00 -9.19113445e-01]\n [-5.92002088e-01 -9.41395537e-01 -1.05079744e-01 -1.43430210e-01\n   3.11447072e-01  2.39582760e-01 -2.80743285e+00  3.55555703e+00\n  -2.81977981e+00 -3.69801166e-01]\n [ 2.26121003e+00  9.17216403e-01  3.12200426e-01  9.70775445e-02\n  -4.70032883e-01 -2.16731471e-01  1.62544223e+00  3.78329942e+00\n  -1.29493186e+00 -9.30156503e-01]\n [-2.13169865e-01  6.66407504e-02 -9.59088052e-01  3.63783178e-01\n  -1.03264310e+00 -4.36748337e-01 -2.94108911e+00  3.06808222e+00\n  -2.61886880e+00 -1.64296529e+00]\n [ 1.75218462e-01 -1.48207863e+00  8.70882256e-01 -1.94570019e+00\n  -2.90397101e-01  1.32778270e+00 -1.03272165e+00  1.29461393e-01\n  -4.96932710e-01 -1.01281486e-01]\n [-1.88539219e-01 -4.71972657e-02 -4.48703648e-01 -1.75052390e-01\n  -1.15395036e+00 -3.47961856e-01  2.76479447e-01 -8.54719937e-02\n  -5.68551115e-01 -1.35338886e+00]\n [-1.15821122e+00 -1.77545756e+00 -3.86467113e-01 -1.64486602e+00\n  -8.52585847e-01  2.29597556e-02  2.26330097e-01  6.03659507e-01\n  -2.55601345e+00 -1.11456118e-02]\n [-2.53972616e-01 -4.09670903e-01 -7.35009990e-01 -1.10742113e+00\n   1.41117206e+00  7.85803827e-01 -1.71717090e+00 -9.99464041e-01\n  -6.39567988e-01 -5.74695185e-02]\n [-8.97057585e-01  4.45653065e-01 -1.26207490e+00  1.00071970e+00\n   1.36759724e+00  1.03440989e+00  1.61438906e+00  5.03085351e-01\n  -1.39457236e+00 -9.96212640e-01]\n [ 5.74235454e-01  1.50488206e+00 -7.99041364e-01  1.69177155e+00\n  -1.14775325e-01  3.08751242e-01 -3.34211432e+00  2.29843342e+00\n  -5.41669705e-01 -1.37075998e+00]]", "y": "[0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0\n 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1\n 0 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 83.62445230231828, "sample_weight": null}}, "return": ["[[ 0.57838017 -0.22311602  0.47349857 -0.59845983 -0.17726073 -0.07810012\n  -0.8606452   0.38336464  0.11576231  0.2584079 ]]", "[1.]", "[42]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.11879382 -0.26301631 -0.63141075 -0.03976126  0.73899724  0.49571665\n  -0.221827   -0.13827369 -0.05464084 -0.46253184 -0.30262816 -0.51831625\n   0.06256539 -0.41372728 -0.31699507 -0.8633778   0.44991235 -0.00420716\n   0.02169597 -0.31874289]]", "[1.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.01907642  0.26428096 -0.13523075  0.27232988 -0.20159385 -0.52389077\n  -0.61557519  0.16000714 -0.31684769 -0.40840017  0.16119649 -0.65182859\n   0.23133461 -0.04460058  1.08549105  0.300057   -0.66759044  0.08215454\n   0.23519879  0.5964343 ]]", "[1.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.14573611 -0.40751396  0.17719092  0.05011436 -0.0977129  -0.26857376\n   1.00479041  0.10690194 -0.48318366  0.55928407  0.59431326  0.88187993\n  -0.04399232  0.71696271 -0.47225812 -0.13758395 -0.0204004   0.22978163\n  -0.26649881 -0.04171074]]", "[1.]", "[11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.11879422 -0.26303321 -0.63142054 -0.03975941  0.73900074  0.49570349\n  -0.22182768 -0.13826946 -0.05463882 -0.46251251 -0.30261647 -0.51831257\n   0.06255299 -0.41372959 -0.31699757 -0.8633775   0.44989625 -0.00420533\n   0.02168985 -0.31874675]]", "[1.]", "[34]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.0190829   0.26426827 -0.13522238  0.27232293 -0.20160773 -0.52389639\n  -0.61556684  0.16000356 -0.31683973 -0.40839598  0.16120219 -0.65179985\n   0.23138318 -0.04458511  1.08548586  0.3000486  -0.66758664  0.08215756\n   0.23518853  0.59642432]]", "[1.]", "[38]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.14573626 -0.4075017   0.17715261  0.05012169 -0.09774524 -0.26850452\n   1.00483984  0.10690562 -0.48319754  0.55927133  0.59428986  0.88185192\n  -0.0440015   0.71695782 -0.47219525 -0.13760584 -0.02043476  0.22978339\n  -0.26644423 -0.04169759]]", "[1.]", "[33]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 438.39997681412706, "sample_weight": null}}, "return": ["[[ 0.11879612 -0.26301994 -0.63141354 -0.03975992  0.73899974  0.49571188\n  -0.22182871 -0.13827291 -0.05463447 -0.46253203 -0.30262633 -0.51832017\n   0.06255714 -0.41372649 -0.31699501 -0.86337485  0.44990565 -0.0042055\n   0.0216947  -0.3187384 ]]", "[1.]", "[962]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 438.39997681412706, "sample_weight": null}}, "return": ["[[-0.0190811   0.26428579 -0.13522843  0.27232827 -0.2015963  -0.52388678\n  -0.61557566  0.16000579 -0.31685689 -0.40840083  0.1611937  -0.65182438\n   0.23134387 -0.04460268  1.08549145  0.30005122 -0.66758013  0.0821524\n   0.23520057  0.5964278 ]]", "[1.]", "[981]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 438.39997681412706, "sample_weight": null}}, "return": ["[[ 0.14573702 -0.40751563  0.17718673  0.05011537 -0.09771047 -0.26856298\n   1.00479296  0.10690443 -0.48317916  0.55928781  0.59431219  0.88187792\n  -0.04399017  0.71696416 -0.47225711 -0.13757897 -0.02041006  0.22978471\n  -0.26649558 -0.04170618]]", "[1.]", "[864]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 10000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 438.39997681412706, "sample_weight": null}}, "return": ["[[ 0.118798   -0.26302319 -0.63141657 -0.03975855  0.73900136  0.49570671\n  -0.22182889 -0.13827222 -0.05462847 -0.46253256 -0.30262508 -0.51832433\n   0.0625486  -0.41372567 -0.31699436 -0.86337216  0.44989917 -0.00420379\n   0.0216941  -0.31873471]]", "[1.]", "[1806]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 10000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 438.39997681412706, "sample_weight": null}}, "return": ["[[-0.01908614  0.264291   -0.13522647  0.27232668 -0.20159896 -0.52388301\n  -0.61557535  0.16000446 -0.31686556 -0.40840115  0.16119043 -0.65182025\n   0.23135242 -0.04460459  1.08549155  0.30004546 -0.66756952  0.08215036\n   0.23520299  0.59642214]]", "[1.]", "[1845]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.68392246e+00 -5.56796765e+00 -3.10620503e+00  8.30818585e+00\n  -6.08917010e-01  1.11319836e+00 -1.29947161e+00 -1.54612051e+01\n  -1.15738312e+00  2.37775784e+00 -1.22753061e+00 -2.14147069e-01\n  -5.52499373e-03  1.18491217e-01  1.28237242e+00  6.56839663e+00\n   4.92700010e+00 -2.92418872e-01  2.39016161e+00 -3.43690224e-01]\n [ 1.62118288e-01  3.65254556e+00 -4.21031271e+00 -1.35343515e+01\n   1.10726865e-01 -1.01704708e+00  7.50761402e-01  1.66325824e+00\n   7.90211266e-01 -3.18378903e+00 -5.05757552e+00  2.16778210e+00\n  -1.08937084e+00 -3.44003328e+00  6.23900444e-01 -2.04885928e+00\n  -3.66599851e+00 -4.01853709e+00 -5.82797800e+00  8.50464703e-01]\n [ 9.10395829e-01  1.11566761e+00  5.61627039e-01 -3.72344395e+00\n  -1.39994935e-01 -2.30105665e+00  1.24011278e-01  4.32591456e+00\n   1.99339379e-01  1.52654179e+00 -1.83749099e+00 -3.56902253e+00\n   2.65181314e+00  4.25428947e-01  5.45170045e-01  4.74469286e-01\n  -9.82083695e-01 -2.33642723e+00 -7.71982764e-02  7.89964813e-01]\n [-8.73317724e-01 -1.05728883e+00  1.66512278e+00 -1.32228796e+00\n  -3.27425388e-01  1.02256840e+00  1.90105139e+00  3.05425931e+00\n  -1.09348814e-02  4.08823710e-01 -6.26866747e-01 -1.27558168e+00\n  -1.47905171e+00 -4.84229388e-01 -8.18601322e-02  3.66136127e-01\n   1.51264999e+00  6.64732101e-01 -2.62224163e+00  1.17189492e+00]\n [ 2.72855164e-01  1.07600884e+00 -2.03919446e+00  2.02409156e+00\n  -1.98897469e+00 -2.38254846e-01 -8.62574894e-01 -4.93044662e+00\n  -1.88771897e-01  8.04925382e-01  1.40389059e+00  2.16497922e+00\n   3.31508150e-01 -5.91578136e-01 -1.95718820e+00  2.16500285e+00\n  -8.29016407e-01 -3.02745464e-01  9.42689607e-01 -4.51991358e-01]\n [ 1.08060125e+00  6.62785871e-01  3.04665230e+00 -4.57415628e+00\n   1.10593412e+00 -6.53126506e-01 -1.73271971e-01  4.89856931e+00\n   1.97513784e+00 -1.97627499e+00 -3.70343384e+00 -4.08710261e-01\n   4.29766650e-01  5.64372276e-01 -2.89279430e+00 -2.84031384e+00\n  -2.58639013e+00 -1.80950327e+00  1.81590396e+00 -7.61401332e-01]\n [-9.37661759e-01 -9.93361089e-01  1.92978485e+00 -1.51616509e+00\n  -9.05112893e-01 -1.13065905e-01 -5.71847002e-02 -2.46325721e+00\n  -4.40111295e-01  1.07110324e-01 -1.35051943e+00 -2.24254405e-01\n  -3.09592764e-01 -2.05876302e+00 -5.63310038e-01  1.55349402e+00\n  -1.63803077e+00 -3.84246485e+00 -1.90235803e-02  8.93263427e-01]\n [ 1.56672894e+00 -8.81605515e-01 -1.27463098e+00  1.49816833e+00\n  -8.88071635e-01 -3.24566482e-01 -7.97924624e-01 -4.42875677e+00\n   1.23322873e+00  1.66092445e+00 -1.83446235e-01  1.35594491e+00\n   2.83288178e-01 -7.09486126e-01  1.11945991e+00  1.06877427e+00\n  -9.61258949e-02 -1.22863774e+00  1.61928776e+00 -9.68579604e-01]\n [-1.13613554e+00  2.69283419e+00  2.21285681e-01 -9.62858949e+00\n  -2.34924655e-01  1.39899247e-01 -1.19974717e+00  7.60414720e+00\n   6.83384035e-01 -5.32649462e-01 -1.53054396e+00 -1.42673703e+00\n  -1.34673130e+00  1.99559587e+00 -2.08212975e+00 -5.18584170e+00\n  -4.89439521e+00 -5.34899097e+00  2.26071928e-02 -1.65279195e+00]\n [-1.68086937e+00 -2.38100345e+00 -2.64185189e-01 -1.86156442e+00\n  -6.82961987e-01  9.20402707e-01  6.21740853e-01  6.56374530e-02\n   1.18991667e+00  1.28852500e+00 -2.29146894e-01 -2.16574963e+00\n   9.37379898e-01  8.28092776e-01  6.61217747e-01 -5.57052405e-01\n   1.39033929e+00 -2.22095463e+00 -1.86772902e+00  6.24507479e-01]\n [-7.74727167e-01  1.68757591e+00  2.13202989e+00  3.66632242e+00\n   8.26930893e-02 -8.36044283e-02 -1.26851699e+00  7.01823619e-02\n  -1.14763415e+00 -1.63684682e+00  9.86556871e-02  1.95536342e+00\n  -1.08565485e+00 -1.22779616e+00 -6.02698660e-01  1.97597479e+00\n  -1.20095757e+00  3.40201992e+00  2.04404249e+00 -3.79525367e-01]\n [-5.92664816e-01  1.92516283e+00 -7.77734691e-01 -4.52283878e-01\n  -2.60894165e+00  1.01641982e-01 -3.20779869e-01 -5.26502749e+00\n  -3.11160999e-01 -2.59966374e+00 -5.58297785e-01  8.56774816e-01\n   5.60163343e-01  1.36272255e+00 -3.92029426e-01  3.91453461e+00\n  -1.26066991e+00 -1.00911427e+00 -2.79880521e-01 -3.54314898e-02]\n [ 5.74871852e-01 -2.53574781e+00  4.69493802e+00  3.69169534e+00\n  -1.39804320e+00 -2.71683402e-01  3.56005595e-01 -9.24439039e-02\n   1.61204613e-01  3.92019899e-01 -1.52431678e+00  1.50547965e+00\n   1.44934635e-01 -2.16344022e+00  3.48210100e-02  5.20716233e-01\n  -1.94731149e-01  1.17665477e+00  2.88187841e+00  4.39764393e-04]\n [ 9.92744768e-01  2.24001938e+00  2.78669375e+00 -7.35685768e+00\n  -1.29482133e+00 -1.00218322e+00 -1.97161176e+00  1.20102789e+01\n   1.09854667e+00  1.92033838e+00 -2.93812716e+00 -2.30677823e+00\n  -5.11008522e-01  2.69142690e+00  1.21169846e+00 -2.22556769e+00\n  -1.79322033e-01 -2.89528952e-01 -1.25472976e+00 -7.42269288e-01]\n [ 5.43921150e-01 -1.73050237e+00 -1.20607145e+00  7.58869588e-01\n   5.00572525e-02  1.07790748e+00 -4.66046593e-01 -3.72030817e+00\n   1.72756670e+00 -1.69868731e+00 -3.25517271e-01  1.34183064e-01\n  -2.20251153e-02 -1.04450035e+00 -1.10468650e+00  2.81017818e-01\n   5.64536069e-01  5.42770329e-02 -1.10978919e+00 -7.23721365e-01]\n [ 1.69546183e+00  2.86536736e+00  2.09383239e+00 -4.56891378e+00\n   1.04600797e+00  3.45050086e-02  8.88980112e-01  8.76206726e+00\n   5.53468585e-02  2.87459904e-01 -2.25336760e+00 -1.03116921e+00\n  -9.30303747e-01 -4.18449722e+00 -1.36275092e-02 -1.15861699e+00\n  -3.77485478e-01  9.19260127e-01 -2.35049609e+00 -2.76192007e-01]\n [ 7.73246330e-01  3.70371485e+00  1.23702874e+00  4.98276645e-01\n   1.20127110e+00  5.11219351e-01 -8.06606856e-01 -1.82774303e+00\n  -3.30370129e-02 -1.76638801e+00 -8.13471854e-01  3.94077484e+00\n  -1.47832026e+00 -2.37372923e+00  1.51207245e+00  2.85718389e+00\n  -4.07794750e-01  1.77339522e+00  5.59521941e-03  1.30498247e+00]\n [-1.06136058e+00  3.07397792e+00  2.45256460e+00 -4.22094746e-01\n   5.03479124e-01  7.31955483e-01 -7.52133713e-01 -4.33038412e-01\n   1.77751719e+00  8.47612956e-01  4.29675837e+00  3.00249553e+00\n  -5.51449180e-01  3.42357318e+00  6.75133304e-01  5.43327258e-01\n   7.84600369e-01 -2.04418763e+00 -9.53977448e-01  9.13890330e-01]\n [-5.66190674e-01  7.31734877e-02 -2.01846067e+00  4.53158813e+00\n   7.34698736e-02 -5.45084673e-01 -8.66789568e-01 -1.02223775e+01\n   1.17151627e+00  1.98425626e+00  2.69698129e+00  2.40395537e+00\n   6.08529041e-01  2.64334170e+00 -2.76452748e-01  2.61826253e+00\n  -4.52641992e-01 -3.25248532e+00  4.26252450e+00 -2.14204050e+00]\n [ 1.93478628e-01 -7.05902447e-01 -1.36770842e-01 -6.90116288e+00\n  -5.17311351e-01  6.91955581e-03 -9.71076399e-02  1.49881821e+00\n  -3.11302987e-01  5.60369458e-01 -3.44024243e+00  9.36574284e-02\n  -3.01307206e-01  3.61150428e+00  5.76733349e-01  1.82459013e+00\n  -5.54467769e-01 -1.61396766e+00 -3.26029488e+00 -9.45930329e-01]]", "y": "[0 0 1 2 2 0 1 1 0 0 1 1 2 1 0 0 1 2 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 10000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 438.39997681412706, "sample_weight": null}}, "return": ["[[ 0.14573622 -0.40751828  0.17718204  0.0501163  -0.09770699 -0.26855425\n   1.00479387  0.106907   -0.48317347  0.55929199  0.59431089  0.88187612\n  -0.04398772  0.71696497 -0.4722562  -0.13757349 -0.02042047  0.22978842\n  -0.266493   -0.04170118]]", "[1.]", "[1592]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[9.43439921e-06 3.33507038e-06 1.31076907e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.90765923e-07 -6.04471861e-05  8.28301626e-05]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.12146649e-05 -2.94050491e-05  1.22570278e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.17576237e-06 -3.96654717e-05  1.50536906e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-3.58264184e-07 -4.34954143e-05  8.89978808e-05]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[ 5.55515927e-06 -3.39356102e-05  1.15202427e-04]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 6.94660149e-06 -4.24200328e-05  1.43995234e-04]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[9.43440037e-06 3.33506845e-06 1.31076906e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.90773086e-07 -6.04478130e-05  8.28310216e-05]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.12146656e-05 -2.94050497e-05  1.22570276e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.17576339e-06 -3.96654723e-05  1.50536903e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-3.58267718e-07 -4.34958434e-05  8.89987587e-05]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[ 5.55515771e-06 -3.39358220e-05  1.15202773e-04]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 6.94662133e-06 -4.24201536e-05  1.43995644e-04]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[9.43440037e-06 3.33506845e-06 1.31076906e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.83800760e-07 -6.04512345e-05  8.28285828e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.12146656e-05 -2.94050497e-05  1.22570276e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.17576339e-06 -3.96654723e-05  1.50536903e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-3.51387057e-07 -4.35022096e-05  8.89956750e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[ 5.55792831e-06 -3.39377795e-05  1.15201669e-04]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 6.94905818e-06 -4.24231107e-05  1.43994653e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[9.43441740e-06 3.33503453e-06 1.31076914e-04]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-6.83789009e-07 -6.04512585e-05  8.28285875e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 1.12146796e-05 -2.94050775e-05  1.22570282e-04]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 8.17584542e-06 -3.96656264e-05  1.50536742e-04]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-3.51460185e-07 -4.35026026e-05  8.89952937e-05]]", "[0.0001]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[ 5.55793864e-06 -3.39379061e-05  1.15201564e-04]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 6.94905871e-06 -4.24231111e-05  1.43994655e-04]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[9.43435558e-06 3.33511671e-06 1.31076895e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-6.83768154e-07 -6.04511237e-05  8.28285168e-05]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 1.12148220e-05 -2.94055139e-05  1.22569762e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 8.17599538e-06 -3.96660909e-05  1.50536268e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-3.51217622e-07 -4.35025304e-05  8.89954153e-05]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[ 5.55803744e-06 -3.39380284e-05  1.15201372e-04]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 6.94904148e-06 -4.24230929e-05  1.43994679e-04]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 5.03200440e-06 -1.94807198e-05  5.79645371e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00010446 -0.00044093  0.00025146]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 7.89960867e-05 -2.47342247e-04  4.37305719e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.17569501e-05 -2.99977138e-04  7.13063948e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-3.23662571e-05 -3.62367389e-04  2.01023513e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[-1.29110783e-05 -2.74018522e-04  4.36499221e-04]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-1.60928555e-05 -3.42531844e-04  5.45473171e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 5.03216836e-06 -1.94810809e-05  5.79644966e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00010446 -0.00044093  0.00025146]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 7.89959234e-05 -2.47341973e-04  4.37305595e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.17569944e-05 -2.99976900e-04  7.13063563e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-3.23662942e-05 -3.62367336e-04  2.01023453e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[-1.29110882e-05 -2.74018472e-04  4.36499022e-04]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-1.60928973e-05 -3.42531745e-04  5.45473132e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 5.03216836e-06 -1.94810809e-05  5.79644966e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00010446 -0.00044093  0.00025146]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 7.89959234e-05 -2.47341973e-04  4.37305595e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.17569944e-05 -2.99976900e-04  7.13063563e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-3.23662942e-05 -3.62367336e-04  2.01023453e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[-1.29110882e-05 -2.74018472e-04  4.36499022e-04]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-1.60930864e-05 -3.42531678e-04  5.45472766e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 5.03403329e-06 -1.94846182e-05  5.79646086e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-0.00010446 -0.00044093  0.00025146]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 7.89976156e-05 -2.47345144e-04  4.37306415e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-1.17493805e-05 -2.99990862e-04  7.13049231e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-3.23651362e-05 -3.62367982e-04  2.01023920e-04]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[-1.29083275e-05 -2.74023334e-04  4.36496753e-04]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-1.60928603e-05 -3.42531747e-04  5.45473244e-04]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.48509007  1.30235655  4.28811312]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 5.03222672e-06 -1.94810658e-05  5.79645363e-04]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-0.00010446 -0.00044093  0.00025146]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[ 7.89960585e-05 -2.47342032e-04  4.37305825e-04]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-1.17568241e-05 -2.99976994e-04  7.13063967e-04]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null}}, "return": ["[[-3.23662317e-05 -3.62367450e-04  2.01023399e-04]]", "[0.0001]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.45302814  2.20543339  1.09476436]\n [ 2.78691802  0.47274494  0.27674533]\n [-2.67716335 -2.05630368  1.95068775]\n [ 0.11510393  2.6817675   2.27112759]\n [-0.18286858 -1.09944655  1.04384355]\n [-0.48509007  1.30235655  4.28811312]\n [ 0.68997659 -1.09997867  0.5918911 ]\n [ 1.13263532  1.45772055  0.93270056]\n [ 0.46356342 -1.34754595 -1.37740328]\n [-0.88760513 -1.12739918  1.12303407]\n [ 2.6742073   1.01387996  0.33261361]\n [-0.85002776 -0.72780558  0.80972995]\n [-0.77239855 -0.98489205  0.97583269]\n [-1.32703535 -0.32578286  0.55717105]\n [ 1.20916387 -0.60730928  0.51129591]\n [-1.75694314 -0.3360546   0.39976468]\n [-0.7126616   1.34142878  1.42651782]\n [ 1.18650852 -1.2219892  -1.55946253]\n [ 0.3756593   3.05075973  2.58036202]\n [ 1.39530239 -0.62287547 -1.0713812 ]\n [ 0.67784966 -1.37822805  0.22155229]\n [-0.04164973  1.23529067  0.97903043]\n [ 0.10873434  2.11102146  2.99955258]\n [-0.86022822  0.4229346   2.18169862]\n [ 0.90193206 -1.19881175 -1.43797384]\n [-0.97672799  1.48672646  0.44334929]\n [ 0.88918675 -0.8748584  -1.81180454]\n [-0.82124402 -1.40000589  1.32196167]\n [ 0.45701962  0.37647331  3.72782723]\n [ 1.50112497  0.8383779  -0.95049927]]", "y": "[0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[-1.29110040e-05 -2.74018533e-04  4.36499221e-04]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 20.319359063296123, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-1.60945206e-05 -3.42529933e-04  5.45475535e-04]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.56858181e-04 2.07350050e-04 1.41072245e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.48472592e-04 2.58992114e-04 3.64484915e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[4.09103893e-04 2.36377095e-04 4.50587000e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.15083649e-04  1.91572497e-04 -3.77375446e-06]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.97507805e-04  2.63621210e-04 -5.33309253e-06]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.94125948e-05  2.81448392e-04 -1.06083336e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 4.96418462e-05  3.30392565e-04 -1.12534841e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.0001216   0.00032347 -0.00011339]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.84946025e-06  2.94127233e-04 -5.67312500e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.06612600e-04  3.31446076e-04 -3.06822596e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.54404481e-04 -4.04831986e-04  7.39436861e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.76153632e-04 -4.28002214e-04  8.86150875e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.12098334e-04 -4.28247442e-04  8.45096259e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.06145072e-04 -3.95230344e-04  5.06699406e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.13736123e-04 -4.44558824e-04  3.01924348e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[3.65405224e-04 2.31582593e-04 1.73015138e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[4.56695844e-04 2.89439293e-04 2.16250230e-05]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[ 6.38235637e-05  3.12177153e-04 -8.38835906e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 7.97564319e-05  3.90181939e-04 -1.04844083e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[-1.72507528e-04 -4.20174162e-04  6.55861550e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.15592979e-04 -5.25158919e-04  8.19715365e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.56858181e-04 2.07350042e-04 1.41072300e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.48472595e-04 2.58992103e-04 3.64484990e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[4.09103895e-04 2.36377079e-04 4.50587036e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.15083648e-04  1.91572491e-04 -3.77375196e-06]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.97507811e-04  2.63621194e-04 -5.33309092e-06]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.94125895e-05  2.81448386e-04 -1.06083334e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 4.96418342e-05  3.30392554e-04 -1.12534838e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.0001216   0.00032347 -0.00011339]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.84945701e-06  2.94127229e-04 -5.67312489e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.06612581e-04  3.31446071e-04 -3.06822601e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.54404466e-04 -4.04831985e-04  7.39436814e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.76153609e-04 -4.28002214e-04  8.86150880e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.12098317e-04 -4.28247442e-04  8.45096298e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.06145064e-04 -3.95230343e-04  5.06699386e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.13736098e-04 -4.44558825e-04  3.01924357e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[3.65405226e-04 2.31582582e-04 1.73015179e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[4.56705317e-04 2.89431185e-04 2.16302564e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[ 6.38235536e-05  3.12177147e-04 -8.38835900e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 7.97564281e-05  3.90181937e-04 -1.04844083e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[-1.72507511e-04 -4.20174162e-04  6.55861547e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.15592972e-04 -5.25158919e-04  8.19715362e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.56858181e-04 2.07350042e-04 1.41072300e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[3.48472595e-04 2.58992103e-04 3.64484990e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[4.09103895e-04 2.36377079e-04 4.50587036e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.15083648e-04  1.91572491e-04 -3.77375196e-06]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.97507811e-04  2.63621194e-04 -5.33309092e-06]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.94125895e-05  2.81448386e-04 -1.06083334e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 4.96418342e-05  3.30392554e-04 -1.12534838e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.0001216   0.00032347 -0.00011339]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.84945701e-06  2.94127229e-04 -5.67312489e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.06612581e-04  3.31446071e-04 -3.06822601e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.54404466e-04 -4.04831985e-04  7.39436814e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.76153609e-04 -4.28002214e-04  8.86150880e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.12098317e-04 -4.28247442e-04  8.45096298e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.06145064e-04 -3.95230343e-04  5.06699386e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.13736098e-04 -4.44558825e-04  3.01924357e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[3.65405226e-04 2.31582582e-04 1.73015179e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[4.56705312e-04 2.89431182e-04 2.16302579e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[ 6.38235536e-05  3.12177147e-04 -8.38835900e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 7.97564259e-05  3.90181924e-04 -1.04844083e-04]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[-1.72507511e-04 -4.20174162e-04  6.55861547e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.15592968e-04 -5.25158910e-04  8.19715385e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[3.56856853e-04 2.07347706e-04 1.41085033e-05]]", "[0.0001]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[3.48471201e-04 2.58989658e-04 3.64497970e-05]]", "[0.0001]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[4.09103918e-04 2.36377067e-04 4.50586947e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 3.15083223e-04  1.91572901e-04 -3.77367474e-06]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 3.97507380e-04  2.63621610e-04 -5.33301283e-06]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 3.94125694e-05  2.81448410e-04 -1.06083326e-04]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 4.96418157e-05  3.30392583e-04 -1.12534830e-04]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 0.0001216   0.00032347 -0.00011339]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 1.84920160e-06  2.94127476e-04 -5.67312033e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 1.06612301e-04  3.31446351e-04 -3.06822096e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-1.54404448e-04 -4.04832008e-04  7.39436712e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-1.76153591e-04 -4.28002239e-04  8.86150768e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-2.12098296e-04 -4.28247466e-04  8.45096196e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-1.06144807e-04 -3.95230591e-04  5.06698920e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-2.13735819e-04 -4.44559103e-04  3.01923849e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[3.65404515e-04 2.31581789e-04 1.73020615e-05]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[4.56710274e-04 2.89424680e-04 2.16385509e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[ 6.38234346e-05  3.12177267e-04 -8.38835661e-05]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 7.97543184e-05  3.90182684e-04 -1.04845790e-04]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[-1.72507392e-04 -4.20174282e-04  6.55861289e-05]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.15592597e-04 -5.25157654e-04  8.19709480e-05]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[3.56858185e-04 2.07350043e-04 1.41072388e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[3.48472598e-04 2.58992106e-04 3.64485075e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[4.09103903e-04 2.36377079e-04 4.50587093e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 3.15084015e-04  1.91572145e-04 -3.77381615e-06]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 3.97508447e-04  2.63620592e-04 -5.33320380e-06]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 3.94126166e-05  2.81448375e-04 -1.06083351e-04]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 4.96418603e-05  3.30392551e-04 -1.12534854e-04]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 0.0001216   0.00032347 -0.00011339]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 1.84963349e-06  2.94127064e-04 -5.67312799e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[ 1.06613054e-04  3.31445633e-04 -3.06823439e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-1.54404496e-04 -4.04831973e-04  7.39436969e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-1.76153639e-04 -4.28002204e-04  8.86151027e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-2.12098347e-04 -4.28247429e-04  8.45096464e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-1.06145246e-04 -3.95230173e-04  5.06699698e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-2.13734808e-04 -4.44560067e-04  3.01928181e-05]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[3.65405430e-04 2.31582393e-04 1.73014871e-05]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[4.56705339e-04 2.89431171e-04 2.16302347e-05]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[ 6.38237001e-05  3.12177021e-04 -8.38836236e-05]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 7.97564495e-05  3.90181924e-04 -1.04844105e-04]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[-1.72507307e-04 -4.20174369e-04  6.55862468e-05]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 0.1, "1": 0.2, "2": 0.5}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.15592995e-04 -5.25158906e-04  8.19715577e-05]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.00147548 0.00061086 0.00028849]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.00145952 0.00065364 0.00035574]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.0014741  0.00060311 0.00039948]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[1.35947552e-03 4.81288007e-04 8.69942475e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[1.49731470e-03 7.06976002e-04 2.85573528e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.0006841  0.0003653 -0.0004723]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00066464  0.00052349 -0.00050776]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00041391  0.00051507 -0.00053608]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00072636  0.00048895 -0.00020786]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00049058  0.00048151 -0.00010054]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00046409 -0.00159736  0.00015112]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00059863 -0.00149804  0.00026881]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00048991 -0.0015615   0.00024752]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00031548 -0.00149871  0.00014721]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-5.79099003e-04 -1.61103270e-03  9.56398539e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[0.00145318 0.00061117 0.00023185]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[0.00181578 0.00076346 0.00028975]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[-0.00059592  0.00047486 -0.00036491]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00074472  0.00059345 -0.00045601]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[-0.00048944 -0.00155333  0.00018206]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00061136 -0.00194088  0.00022746]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.00147548 0.00061086 0.00028849]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.00145952 0.00065364 0.00035574]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.0014741  0.00060311 0.00039948]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[1.35947539e-03 4.81287880e-04 8.69942549e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[1.49731472e-03 7.06975388e-04 2.85573887e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.0006841  0.0003653 -0.0004723]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00066464  0.00052349 -0.00050776]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00041391  0.00051507 -0.00053608]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00072636  0.00048895 -0.00020786]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00049058  0.00048151 -0.00010054]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00046409 -0.00159736  0.00015112]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00059863 -0.00149804  0.00026881]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00048991 -0.0015615   0.00024752]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00031548 -0.00149871  0.00014721]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-5.79098337e-04 -1.61103257e-03  9.56398790e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[0.00145318 0.00061117 0.00023185]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[0.00181578 0.00076346 0.00028975]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[-0.00059592  0.00047486 -0.00036491]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00074472  0.00059345 -0.00045601]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[-0.00048944 -0.00155333  0.00018206]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00061136 -0.00194088  0.00022746]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.00147548 0.00061086 0.00028849]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.00145952 0.00065364 0.00035574]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.0014741  0.00060311 0.00039948]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[1.35947539e-03 4.81287880e-04 8.69942549e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[1.49731472e-03 7.06975388e-04 2.85573887e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.0006841  0.0003653 -0.0004723]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00066464  0.00052349 -0.00050776]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00041391  0.00051507 -0.00053608]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00072636  0.00048895 -0.00020786]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00049058  0.00048151 -0.00010054]]", "[0.0001]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00046409 -0.00159736  0.00015112]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00059863 -0.00149804  0.00026881]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00048991 -0.0015615   0.00024752]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.00031548 -0.00149871  0.00014721]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-5.79098337e-04 -1.61103257e-03  9.56398790e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[0.00145318 0.00061117 0.00023185]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[0.00181578 0.00076346 0.00028975]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[-0.00059592  0.00047486 -0.00036491]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00074472  0.00059345 -0.00045601]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[-0.00048944 -0.00155333  0.00018206]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00061136 -0.00194088  0.00022746]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[0.00147548 0.00061086 0.00028849]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[0.00145952 0.00065364 0.00035574]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[0.0014741  0.00060311 0.00039948]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[1.35946994e-03 4.81293282e-04 8.69952425e-05]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[1.49730949e-03 7.06980718e-04 2.85583593e-05]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.0006841   0.0003653  -0.00047229]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00066464  0.00052349 -0.00050776]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00041391  0.00051507 -0.00053608]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00072636  0.00048895 -0.00020786]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00049058  0.00048151 -0.00010054]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00046409 -0.00159736  0.00015112]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00059863 -0.00149804  0.00026881]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00048991 -0.0015615   0.00024752]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00031548 -0.00149871  0.00014721]]", "[0.0001]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-5.79096780e-04 -1.61103451e-03  9.56395835e-05]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[0.00145318 0.00061117 0.00023185]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[0.00181578 0.00076346 0.00028975]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[-0.00059592  0.00047487 -0.00036491]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00074472  0.00059345 -0.00045601]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[-0.00048944 -0.00155333  0.00018206]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00061136 -0.00194088  0.00022746]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[0.00147548 0.00061086 0.00028849]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[0.00145952 0.00065364 0.00035574]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[0.0014741  0.00060311 0.00039948]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[1.35947555e-03 4.81287931e-04 8.69942385e-05]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "0", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[1.49731494e-03 7.06975492e-04 2.85573801e-05]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.0006841   0.0003653  -0.00047229]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00066464  0.00052349 -0.00050776]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00041391  0.00051507 -0.00053608]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00072636  0.00048895 -0.00020786]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "1", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00049058  0.00048151 -0.00010054]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[0 0 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00046409 -0.00159736  0.00015112]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [-1.31653411  1.18852229 -0.19312473]\n [ 1.48672646  0.44334929 -0.97672799]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 1 0 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00059863 -0.00149804  0.00026881]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 2 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00048991 -0.0015615   0.00024752]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 0.56084694 -0.04903602 -0.25953599]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 2 2 0 1 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-0.00031548 -0.00149871  0.00014721]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.47762591  1.12106644  1.56630967]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 0]"}, "kwargs": {"Cs": 1, "l1_ratio": null, "fit_intercept": false, "solver": "saga", "max_iter": 10000, "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "pos_class": "2", "multi_class": "ovr", "tol": 1e-05, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null}}, "return": ["[[-5.79101954e-04 -1.61102957e-03  9.56405122e-05]]", "[0.0001]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[0.00145318 0.00061117 0.00023185]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[0.00181578 0.00076346 0.00028975]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[-0.00059592  0.00047486 -0.00036491]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00074472  0.00059345 -0.00045601]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "float", "1": "float", "2": "float"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.61692741  0.7246871  -0.58486483]\n [ 1.34142878  1.42651782 -0.7126616 ]\n [ 0.74594471 -0.2637563  -0.21382145]\n [-1.82520376 -2.62212998 -1.17767117]\n [-0.98197643 -1.19831516  1.00239265]\n [ 0.51191746  1.55786946  0.75511559]\n [ 0.4229346   2.18169862 -0.86022822]\n [-1.31653411  1.18852229 -0.19312473]\n [-1.40000589  1.32196167 -0.82124402]\n [ 1.48672646  0.44334929 -0.97672799]\n [-1.72316625 -1.25589945  0.52704268]\n [-1.04624059 -0.55108477 -0.38423154]\n [-2.04093961  2.01512624  1.89435104]\n [-0.990577   -1.97831171  1.17878131]\n [-1.40962563  1.34548659  0.25373744]\n [ 3.05075973  2.58036202  0.3756593 ]\n [ 0.87380103 -0.41940863 -0.88025625]\n [-0.79633948  0.84843797  1.04462172]\n [ 2.6817675   2.27112759  0.11510393]\n [-3.09815029 -2.4627744  -0.38487435]\n [ 0.44642884 -0.34634697 -0.15957558]\n [-1.29753083 -1.42049554  0.83948029]\n [-2.05630368  1.95068775 -2.67716335]\n [ 0.56084694 -0.04903602 -0.25953599]\n [ 0.47762591  1.12106644  1.56630967]\n [-1.2090449  -1.64396286  1.20436803]\n [ 1.56646467  2.82839369  0.20221748]\n [-1.22538802  1.25997898 -2.77878646]\n [-1.64272163  1.48105291 -1.16013889]\n [ 1.30739526 -0.63942652  2.03599551]]", "y": "[1 0 0 2 2 0 0 1 1 0 2 2 1 2 1 0 2 1 0 2 1 2 1 2 0 2 0 1 1 0]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "saga", "fit_intercept": false, "coef": "[-0.00048944 -0.00155333  0.00018206]", "max_iter": 10000, "tol": 1e-05, "penalty": "l2", "class_weight": {"0": 1.0, "1": 1.0, "2": 1.0}, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 16.10652302527233, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.00061136 -0.00194088  0.00022746]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.23280321 0.43303953 0.1900185  0.51760567 0.14944669]]", "[1.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[0.23280321 0.43303953 0.1900185  0.51760567 0.14944669]]", "[1.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[0.07703095 0.3914445  0.39449047 0.5362445  0.19890909]]", "[1.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[0.07703082 0.39144351 0.39448993 0.53624355 0.19890865]]", "[1.]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-10, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 15.501076693992202, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[0.07703082 0.39144354 0.39448995 0.53624358 0.19890866]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.07703095 0.3914445  0.39449047 0.5362445  0.19890909]]", "[1.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[2.85868389e-04 1.28846032e-04 2.12357111e-04 4.38065392e-04\n  2.49601335e-05]\n [2.19074191e-03 9.95024522e-04 1.62954068e-03 3.36217116e-03\n  1.94563789e-04]\n [1.57059374e-02 7.55383189e-03 1.18094476e-02 2.43903993e-02\n  1.57732930e-03]\n [7.58937439e-02 5.09840647e-02 6.26134923e-02 1.28619023e-01\n  1.41005093e-02]\n [1.19757204e-01 2.21155688e-01 1.75419497e-01 3.24839888e-01\n  8.88842392e-02]\n [5.49274132e-02 4.51223068e-01 2.95314989e-01 4.70610228e-01\n  2.10382240e-01]\n [2.11943298e-02 5.38725819e-01 3.39785756e-01 5.18271523e-01\n  2.58287223e-01]\n [1.53104600e-02 5.53555485e-01 3.47306933e-01 5.26209890e-01\n  2.66438010e-01]\n [1.45130852e-02 5.55559893e-01 3.48318499e-01 5.27277430e-01\n  2.67539307e-01]\n [1.44064075e-02 5.55810287e-01 3.48454958e-01 5.27413106e-01\n  2.67679986e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 6 7 5 5 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 6.49458132e-04  2.32700745e-04  1.97952389e-04  7.50985673e-04\n  -1.26495691e-05]\n [ 4.97021992e-03  1.78146285e-03  1.51924464e-03  5.75079647e-03\n  -9.58559517e-05]\n [ 3.53126825e-02  1.26965845e-02  1.10228884e-02  4.10511249e-02\n  -6.28609017e-04]\n [ 1.69560073e-01  6.33527071e-02  5.89921481e-02  2.02819486e-01\n  -1.11327065e-03]\n [ 3.69144796e-01  1.81298800e-01  1.63614248e-01  4.87955874e-01\n   1.99975578e-02]\n [ 4.44271360e-01  3.29089129e-01  2.59838535e-01  6.85263055e-01\n   7.69966846e-02]\n [ 4.48660975e-01  3.89548840e-01  2.94077144e-01  7.41986641e-01\n   1.04934233e-01]\n [ 4.48488684e-01  4.00053627e-01  2.99857866e-01  7.51001228e-01\n   1.09954534e-01]\n [ 4.48450935e-01  4.01484460e-01  3.00619757e-01  7.52198740e-01\n   1.10637151e-01]\n [ 4.48509251e-01  4.01579488e-01  3.00691738e-01  7.52340955e-01\n   1.10673372e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 6 6 6 6 4 2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[5.14811594e-04 2.53106974e-04 1.05027857e-04 5.86605241e-04\n  7.97391847e-06]\n [3.93733647e-03 1.94397145e-03 8.02121252e-04 4.48923490e-03\n  6.39497827e-05]\n [2.78430762e-02 1.41913231e-02 5.61845345e-03 3.19050079e-02\n  6.14614601e-04]\n [1.28898773e-01 7.97751712e-02 2.57215223e-02 1.53824496e-01\n  8.21883917e-03]\n [2.25373200e-01 2.69239039e-01 7.32483260e-02 3.48998338e-01\n  6.89305796e-02]\n [1.73953007e-01 5.23903789e-01 1.60653828e-01 4.91265730e-01\n  1.91843380e-01]\n [1.36352550e-01 6.31215483e-01 2.01864029e-01 5.42414040e-01\n  2.47646568e-01]\n [1.29389711e-01 6.50177533e-01 2.09276224e-01 5.51308479e-01\n  2.57594204e-01]\n [1.28441204e-01 6.52751388e-01 2.10284643e-01 5.52514964e-01\n  2.58945545e-01]\n [1.28312290e-01 6.53081907e-01 2.10427335e-01 5.52674547e-01\n  2.59122693e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 7 7 6 5 5 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[6.06799655e-04 3.13529897e-04 1.02669119e-04 6.82139346e-04\n  1.18166863e-05]\n [4.64845748e-03 2.41012610e-03 7.81158290e-04 5.22525794e-03\n  9.28474531e-05]\n [3.32643271e-02 1.76956274e-02 5.31061301e-03 3.73808120e-02\n  7.91818343e-04]\n [1.64691745e-01 1.01651930e-01 1.95075372e-02 1.86217599e-01\n  8.22398247e-03]\n [3.65349921e-01 3.51114308e-01 3.50101584e-02 4.63381278e-01\n  6.52687055e-02]\n [4.00035733e-01 7.23234214e-01 1.16623063e-01 7.19771292e-01\n  2.14644646e-01]\n [3.61216617e-01 9.34699103e-01 1.89271776e-01 8.40915022e-01\n  3.15915839e-01]\n [3.50285411e-01 9.80717833e-01 2.06640083e-01 8.66575212e-01\n  3.38721736e-01]\n [3.48689420e-01 9.87275599e-01 2.09153645e-01 8.70232099e-01\n  3.41985810e-01]\n [3.48474453e-01 9.88154698e-01 2.09481324e-01 8.70714464e-01\n  3.42422078e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 7 7 6 5 5 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 2.78174191e-04  1.90269254e-04  1.65531385e-04  4.24122441e-04\n   4.25932426e-05]\n [ 2.13570614e-03  1.46988598e-03  1.27032270e-03  3.25989929e-03\n   3.30417870e-04]\n [ 1.55164940e-02  1.11818918e-02  9.21435972e-03  2.38992028e-02\n   2.59175366e-03]\n [ 8.00110980e-02  7.55457424e-02  4.95196116e-02  1.32825748e-01\n   2.05777074e-02]\n [ 1.38684712e-01  3.17740486e-01  1.54318093e-01  3.66668529e-01\n   1.18727768e-01]\n [ 5.12009494e-02  6.63933081e-01  3.01959213e-01  5.68670246e-01\n   2.94140360e-01]\n [-5.93394134e-03  8.21948241e-01  3.71569394e-01  6.49454185e-01\n   3.78127286e-01]\n [-1.70291318e-02  8.51754508e-01  3.84788800e-01  6.64517967e-01\n   3.94049917e-01]\n [-1.85619178e-02  8.55859672e-01  3.86611633e-01  6.66590759e-01\n   3.96244227e-01]\n [-1.87836918e-02  8.56390898e-01  3.86876826e-01  6.66863510e-01\n   3.96537793e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 6 6 5 4 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[4.67022392e-04 2.23690580e-04 1.56707572e-04 5.76383618e-04\n 1.49388823e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[5.83584521e-04 2.79563768e-04 1.95808841e-04 7.20252042e-04\n  1.86823121e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[2.85868389e-04 1.28846032e-04 2.12357111e-04 4.38065392e-04\n  2.49601335e-05]\n [2.19074191e-03 9.95024522e-04 1.62954068e-03 3.36217116e-03\n  1.94563789e-04]\n [1.57059374e-02 7.55383189e-03 1.18094476e-02 2.43903993e-02\n  1.57732930e-03]\n [7.58937439e-02 5.09840647e-02 6.26134923e-02 1.28619023e-01\n  1.41005093e-02]\n [1.19757204e-01 2.21155688e-01 1.75419497e-01 3.24839888e-01\n  8.88842392e-02]\n [5.49274132e-02 4.51223068e-01 2.95314989e-01 4.70610228e-01\n  2.10382240e-01]\n [2.11943298e-02 5.38725819e-01 3.39785756e-01 5.18271523e-01\n  2.58287223e-01]\n [1.53104600e-02 5.53555485e-01 3.47306933e-01 5.26209890e-01\n  2.66438010e-01]\n [1.45130852e-02 5.55559893e-01 3.48318499e-01 5.27277430e-01\n  2.67539307e-01]\n [1.44064075e-02 5.55810287e-01 3.48454958e-01 5.27413106e-01\n  2.67679986e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 6 7 5 5 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[ 6.49458132e-04  2.32700745e-04  1.97952389e-04  7.50985673e-04\n  -1.26495691e-05]\n [ 4.97021992e-03  1.78146285e-03  1.51924464e-03  5.75079647e-03\n  -9.58559517e-05]\n [ 3.53126825e-02  1.26965845e-02  1.10228884e-02  4.10511249e-02\n  -6.28609017e-04]\n [ 1.69560073e-01  6.33527071e-02  5.89921481e-02  2.02819486e-01\n  -1.11327065e-03]\n [ 3.69144796e-01  1.81298800e-01  1.63614248e-01  4.87955874e-01\n   1.99975578e-02]\n [ 4.44271360e-01  3.29089129e-01  2.59838535e-01  6.85263055e-01\n   7.69966846e-02]\n [ 4.48660975e-01  3.89548840e-01  2.94077144e-01  7.41986641e-01\n   1.04934233e-01]\n [ 4.48488684e-01  4.00053627e-01  2.99857866e-01  7.51001228e-01\n   1.09954534e-01]\n [ 4.48450935e-01  4.01484460e-01  3.00619757e-01  7.52198740e-01\n   1.10637151e-01]\n [ 4.48509251e-01  4.01579488e-01  3.00691738e-01  7.52340955e-01\n   1.10673372e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 6 6 6 6 4 2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[5.14811594e-04 2.53106974e-04 1.05027857e-04 5.86605241e-04\n  7.97391847e-06]\n [3.93733647e-03 1.94397145e-03 8.02121252e-04 4.48923490e-03\n  6.39497827e-05]\n [2.78430762e-02 1.41913231e-02 5.61845345e-03 3.19050079e-02\n  6.14614601e-04]\n [1.28898773e-01 7.97751712e-02 2.57215223e-02 1.53824496e-01\n  8.21883917e-03]\n [2.25373200e-01 2.69239039e-01 7.32483260e-02 3.48998338e-01\n  6.89305796e-02]\n [1.73953007e-01 5.23903789e-01 1.60653828e-01 4.91265730e-01\n  1.91843380e-01]\n [1.36352550e-01 6.31215483e-01 2.01864029e-01 5.42414040e-01\n  2.47646568e-01]\n [1.29389711e-01 6.50177533e-01 2.09276224e-01 5.51308479e-01\n  2.57594204e-01]\n [1.28441204e-01 6.52751388e-01 2.10284643e-01 5.52514964e-01\n  2.58945545e-01]\n [1.28312290e-01 6.53081907e-01 2.10427335e-01 5.52674547e-01\n  2.59122693e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 7 7 6 5 5 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[6.06799655e-04 3.13529897e-04 1.02669119e-04 6.82139346e-04\n  1.18166863e-05]\n [4.64845748e-03 2.41012610e-03 7.81158290e-04 5.22525794e-03\n  9.28474531e-05]\n [3.32643271e-02 1.76956274e-02 5.31061301e-03 3.73808120e-02\n  7.91818343e-04]\n [1.64691745e-01 1.01651930e-01 1.95075372e-02 1.86217599e-01\n  8.22398247e-03]\n [3.65349921e-01 3.51114308e-01 3.50101584e-02 4.63381278e-01\n  6.52687055e-02]\n [4.00035733e-01 7.23234214e-01 1.16623063e-01 7.19771292e-01\n  2.14644646e-01]\n [3.61216617e-01 9.34699103e-01 1.89271776e-01 8.40915022e-01\n  3.15915839e-01]\n [3.50285411e-01 9.80717833e-01 2.06640083e-01 8.66575212e-01\n  3.38721736e-01]\n [3.48689420e-01 9.87275599e-01 2.09153645e-01 8.70232099e-01\n  3.41985810e-01]\n [3.48474453e-01 9.88154698e-01 2.09481324e-01 8.70714464e-01\n  3.42422078e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 7 7 6 5 5 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[ 2.78174191e-04  1.90269254e-04  1.65531385e-04  4.24122441e-04\n   4.25932426e-05]\n [ 2.13570614e-03  1.46988598e-03  1.27032270e-03  3.25989929e-03\n   3.30417870e-04]\n [ 1.55164940e-02  1.11818918e-02  9.21435972e-03  2.38992028e-02\n   2.59175366e-03]\n [ 8.00110980e-02  7.55457424e-02  4.95196116e-02  1.32825748e-01\n   2.05777074e-02]\n [ 1.38684712e-01  3.17740486e-01  1.54318093e-01  3.66668529e-01\n   1.18727768e-01]\n [ 5.12009494e-02  6.63933081e-01  3.01959213e-01  5.68670246e-01\n   2.94140360e-01]\n [-5.93394134e-03  8.21948241e-01  3.71569394e-01  6.49454185e-01\n   3.78127286e-01]\n [-1.70291318e-02  8.51754508e-01  3.84788800e-01  6.64517967e-01\n   3.94049917e-01]\n [-1.85619178e-02  8.55859672e-01  3.86611633e-01  6.66590759e-01\n   3.96244227e-01]\n [-1.87836918e-02  8.56390898e-01  3.86876826e-01  6.66863510e-01\n   3.96537793e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 6 6 5 4 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[4.67022392e-04 2.23690580e-04 1.56707572e-04 5.76383618e-04\n 1.49388823e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]", "l1_ratio": null}}, "return": ["[[5.83584521e-04 2.79563768e-04 1.95808841e-04 7.20252042e-04\n  1.86823121e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[2.85868316e-04 1.28846130e-04 2.12357093e-04 4.38065367e-04\n  2.49601833e-05]\n [2.19071312e-03 9.95063358e-04 1.62953118e-03 3.36215946e-03\n  1.94583159e-04]\n [1.57061860e-02 7.55375404e-03 1.18092819e-02 2.43904272e-02\n  1.57722091e-03]\n [7.58955262e-02 5.09842882e-02 6.26071975e-02 1.28615676e-01\n  1.40992032e-02]\n [1.19755129e-01 2.21150281e-01 1.75423254e-01 3.24838738e-01\n  8.88831975e-02]\n [5.49273929e-02 4.51223554e-01 2.95314953e-01 4.70610404e-01\n  2.10382426e-01]\n [2.11979057e-02 5.38729176e-01 3.39792238e-01 5.18280710e-01\n  2.58288829e-01]\n [1.53106047e-02 5.53555592e-01 3.47307191e-01 5.26210246e-01\n  2.66438063e-01]\n [1.45150086e-02 5.55552487e-01 3.48318950e-01 5.27275904e-01\n  2.67536131e-01]\n [1.44116360e-02 5.55811836e-01 3.48450347e-01 5.27414270e-01\n  2.67678751e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 4 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 6.49458091e-04  2.32700740e-04  1.97952448e-04  7.50985684e-04\n  -1.26495526e-05]\n [ 4.97020387e-03  1.78145938e-03  1.51926822e-03  5.75080067e-03\n  -9.58501363e-05]\n [ 3.53126212e-02  1.26967817e-02  1.10227869e-02  4.10510896e-02\n  -6.28536891e-04]\n [ 1.69561749e-01  6.33505985e-02  5.89922459e-02  2.02819888e-01\n  -1.11441360e-03]\n [ 3.69146473e-01  1.81295072e-01  1.63614832e-01  4.87955919e-01\n   1.99958702e-02]\n [ 4.44265277e-01  3.29101432e-01  2.59842362e-01  6.85266882e-01\n   7.70033029e-02]\n [ 4.48663647e-01  3.89488866e-01  2.94044605e-01  7.41936816e-01\n   1.04905297e-01]\n [ 4.48555211e-01  3.99911737e-01  2.99788002e-01  7.50934674e-01\n   1.09874771e-01]\n [ 4.48512890e-01  4.01331342e-01  3.00565781e-01  7.52135771e-01\n   1.10556593e-01]\n [ 4.48507078e-01  4.01515810e-01  3.00666792e-01  7.52291566e-01\n   1.10645247e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 5 4 4 5 5 5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[5.14811508e-04 2.53107133e-04 1.05027811e-04 5.86605212e-04\n  7.97398989e-06]\n [3.93730290e-03 1.94403348e-03 8.02100718e-04 4.48922159e-03\n  6.39772815e-05]\n [2.78432914e-02 1.41912192e-02 5.61841003e-03 3.19050920e-02\n  6.14522995e-04]\n [1.28908637e-01 7.97737536e-02 2.57114374e-02 1.53823676e-01\n  8.21461231e-03]\n [2.25374955e-01 2.69239079e-01 7.32446379e-02 3.48996878e-01\n  6.89296324e-02]\n [1.73954706e-01 5.23911036e-01 1.60651811e-01 4.91268750e-01\n  1.91845491e-01]\n [1.36351890e-01 6.31216125e-01 2.01865091e-01 5.42414637e-01\n  2.47647124e-01]\n [1.29393678e-01 6.50167175e-01 2.09272057e-01 5.51303655e-01\n  2.57588717e-01]\n [1.28444649e-01 6.52738515e-01 2.10279402e-01 5.52507788e-01\n  2.58939023e-01]\n [1.28321188e-01 6.53072807e-01 2.10410404e-01 5.52664303e-01\n  2.59114595e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 5 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[6.06799612e-04 3.13530002e-04 1.02669030e-04 6.82139292e-04\n  1.18167209e-05]\n [4.64844090e-03 2.41016561e-03 7.81121226e-04 5.22523480e-03\n  9.28600732e-05]\n [3.32645165e-02 1.76955407e-02 5.31071312e-03 3.73809937e-02\n  7.91762024e-04]\n [1.64696888e-01 1.01647806e-01 1.95150218e-02 1.86225376e-01\n  8.22254647e-03]\n [3.65349854e-01 3.51114903e-01 3.50093088e-02 4.63380846e-01\n  6.52688103e-02]\n [4.00042456e-01 7.23160917e-01 1.16595245e-01 7.19722156e-01\n  2.14610508e-01]\n [3.61213171e-01 9.34704516e-01 1.89274627e-01 8.40917010e-01\n  3.15919100e-01]\n [3.50295758e-01 9.80718662e-01 2.06641801e-01 8.66584784e-01\n  3.38720192e-01]\n [3.48692390e-01 9.87270467e-01 2.09151288e-01 8.70230250e-01\n  3.41982837e-01]\n [3.48481656e-01 9.88128175e-01 2.09480458e-01 8.70707344e-01\n  3.42410233e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 5 4 5 5 5 5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 2.78174147e-04  1.90269287e-04  1.65531355e-04  4.24122399e-04\n   4.25932595e-05]\n [ 2.13569008e-03  1.46989848e-03  1.27030649e-03  3.25988030e-03\n   3.30423374e-04]\n [ 1.55167991e-02  1.11814740e-02  9.21432884e-03  2.38992235e-02\n   2.59152466e-03]\n [ 8.00119377e-02  7.55422196e-02  4.95193097e-02  1.32824570e-01\n   2.05761280e-02]\n [ 1.38685657e-01  3.17741089e-01  1.54318939e-01  3.66670167e-01\n   1.18727942e-01]\n [ 5.11912448e-02  6.63974332e-01  3.01976628e-01  5.68694729e-01\n   2.94161084e-01]\n [-5.93732999e-03  8.21970741e-01  3.71579767e-01  6.49469657e-01\n   3.78138337e-01]\n [-1.70290966e-02  8.51754267e-01  3.84788995e-01  6.64518034e-01\n   3.94049848e-01]\n [-1.85605108e-02  8.55854879e-01  3.86609443e-01  6.66588000e-01\n   3.96241734e-01]\n [-1.87600854e-02  8.56389092e-01  3.86846636e-01  6.66857640e-01\n   3.96527304e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 3 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[4.67022335e-04 2.23690658e-04 1.56707548e-04 5.76383591e-04\n 1.49389202e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[5.83584507e-04 2.79563809e-04 1.95808768e-04 7.20251994e-04\n  1.86823192e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[2.85868316e-04 1.28846130e-04 2.12357093e-04 4.38065367e-04\n  2.49601833e-05]\n [2.19071312e-03 9.95063358e-04 1.62953118e-03 3.36215946e-03\n  1.94583159e-04]\n [1.57061860e-02 7.55375404e-03 1.18092819e-02 2.43904272e-02\n  1.57722091e-03]\n [7.58955262e-02 5.09842882e-02 6.26071975e-02 1.28615676e-01\n  1.40992032e-02]\n [1.19755129e-01 2.21150281e-01 1.75423254e-01 3.24838738e-01\n  8.88831975e-02]\n [5.49273929e-02 4.51223554e-01 2.95314953e-01 4.70610404e-01\n  2.10382426e-01]\n [2.11979057e-02 5.38729176e-01 3.39792238e-01 5.18280710e-01\n  2.58288829e-01]\n [1.53106047e-02 5.53555592e-01 3.47307191e-01 5.26210246e-01\n  2.66438063e-01]\n [1.45150086e-02 5.55552487e-01 3.48318950e-01 5.27275904e-01\n  2.67536131e-01]\n [1.44116360e-02 5.55811836e-01 3.48450347e-01 5.27414270e-01\n  2.67678751e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 4 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[ 6.49458091e-04  2.32700740e-04  1.97952448e-04  7.50985684e-04\n  -1.26495526e-05]\n [ 4.97020387e-03  1.78145938e-03  1.51926822e-03  5.75080067e-03\n  -9.58501363e-05]\n [ 3.53126212e-02  1.26967817e-02  1.10227869e-02  4.10510896e-02\n  -6.28536891e-04]\n [ 1.69561749e-01  6.33505985e-02  5.89922459e-02  2.02819888e-01\n  -1.11441360e-03]\n [ 3.69146473e-01  1.81295072e-01  1.63614832e-01  4.87955919e-01\n   1.99958702e-02]\n [ 4.44265277e-01  3.29101432e-01  2.59842362e-01  6.85266882e-01\n   7.70033029e-02]\n [ 4.48663647e-01  3.89488866e-01  2.94044605e-01  7.41936816e-01\n   1.04905297e-01]\n [ 4.48555211e-01  3.99911737e-01  2.99788002e-01  7.50934674e-01\n   1.09874771e-01]\n [ 4.48512890e-01  4.01331342e-01  3.00565781e-01  7.52135771e-01\n   1.10556593e-01]\n [ 4.48507078e-01  4.01515810e-01  3.00666792e-01  7.52291566e-01\n   1.10645247e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 5 4 4 5 5 5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[5.14811508e-04 2.53107133e-04 1.05027811e-04 5.86605212e-04\n  7.97398989e-06]\n [3.93730290e-03 1.94403348e-03 8.02100718e-04 4.48922159e-03\n  6.39772815e-05]\n [2.78432914e-02 1.41912192e-02 5.61841003e-03 3.19050920e-02\n  6.14522995e-04]\n [1.28908637e-01 7.97737536e-02 2.57114374e-02 1.53823676e-01\n  8.21461231e-03]\n [2.25374955e-01 2.69239079e-01 7.32446379e-02 3.48996878e-01\n  6.89296324e-02]\n [1.73954706e-01 5.23911036e-01 1.60651811e-01 4.91268750e-01\n  1.91845491e-01]\n [1.36351890e-01 6.31216125e-01 2.01865091e-01 5.42414637e-01\n  2.47647124e-01]\n [1.29393678e-01 6.50167175e-01 2.09272057e-01 5.51303655e-01\n  2.57588717e-01]\n [1.28444649e-01 6.52738515e-01 2.10279402e-01 5.52507788e-01\n  2.58939023e-01]\n [1.28321188e-01 6.53072807e-01 2.10410404e-01 5.52664303e-01\n  2.59114595e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 5 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[6.06799612e-04 3.13530002e-04 1.02669030e-04 6.82139292e-04\n  1.18167209e-05]\n [4.64844090e-03 2.41016561e-03 7.81121226e-04 5.22523480e-03\n  9.28600732e-05]\n [3.32645165e-02 1.76955407e-02 5.31071312e-03 3.73809937e-02\n  7.91762024e-04]\n [1.64696888e-01 1.01647806e-01 1.95150218e-02 1.86225376e-01\n  8.22254647e-03]\n [3.65349854e-01 3.51114903e-01 3.50093088e-02 4.63380846e-01\n  6.52688103e-02]\n [4.00042456e-01 7.23160917e-01 1.16595245e-01 7.19722156e-01\n  2.14610508e-01]\n [3.61213171e-01 9.34704516e-01 1.89274627e-01 8.40917010e-01\n  3.15919100e-01]\n [3.50295758e-01 9.80718662e-01 2.06641801e-01 8.66584784e-01\n  3.38720192e-01]\n [3.48692390e-01 9.87270467e-01 2.09151288e-01 8.70230250e-01\n  3.41982837e-01]\n [3.48481656e-01 9.88128175e-01 2.09480458e-01 8.70707344e-01\n  3.42410233e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 5 4 5 5 5 5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]"}}, "return": ["[[ 2.78174147e-04  1.90269287e-04  1.65531355e-04  4.24122399e-04\n   4.25932595e-05]\n [ 2.13569008e-03  1.46989848e-03  1.27030649e-03  3.25988030e-03\n   3.30423374e-04]\n [ 1.55167991e-02  1.11814740e-02  9.21432884e-03  2.38992235e-02\n   2.59152466e-03]\n [ 8.00119377e-02  7.55422196e-02  4.95193097e-02  1.32824570e-01\n   2.05761280e-02]\n [ 1.38685657e-01  3.17741089e-01  1.54318939e-01  3.66670167e-01\n   1.18727942e-01]\n [ 5.11912448e-02  6.63974332e-01  3.01976628e-01  5.68694729e-01\n   2.94161084e-01]\n [-5.93732999e-03  8.21970741e-01  3.71579767e-01  6.49469657e-01\n   3.78138337e-01]\n [-1.70290966e-02  8.51754267e-01  3.84788995e-01  6.64518034e-01\n   3.94049848e-01]\n [-1.85605108e-02  8.55854879e-01  3.86609443e-01  6.66588000e-01\n   3.96241734e-01]\n [-1.87600854e-02  8.56389092e-01  3.86846636e-01  6.66857640e-01\n   3.96527304e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 3 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[float64]", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[4.67022335e-04 2.23690658e-04 1.56707548e-04 5.76383591e-04\n 1.49389202e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]", "l1_ratio": null}}, "return": ["[[5.83584507e-04 2.79563809e-04 1.95808768e-04 7.20251994e-04\n  1.86823192e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[ 2.27680221e-04  4.63541683e-05  6.39642609e-04  6.82770676e-04\n   7.46932763e-05]\n [ 1.72897612e-03  3.64930008e-04  4.88992537e-03  5.21555561e-03\n   5.77479467e-04]\n [ 1.15913122e-02  3.13635178e-03  3.45118730e-02  3.65967302e-02\n   4.41818317e-03]\n [ 3.74364950e-02  3.17642691e-02  1.62930964e-01  1.67237432e-01\n   3.09660608e-02]\n [-2.31897625e-02  1.88800067e-01  3.65796148e-01  3.46655311e-01\n   1.36958576e-01]\n [-1.35224450e-01  3.80109196e-01  4.94450664e-01  4.45672112e-01\n   2.54726816e-01]\n [-1.69415842e-01  4.38526543e-01  5.28072741e-01  4.71598201e-01\n   2.89763536e-01]\n [-1.74671850e-01  4.47584814e-01  5.33158130e-01  4.75555412e-01\n   2.95166085e-01]\n [-1.75364211e-01  4.48792180e-01  5.33826864e-01  4.76082178e-01\n   2.95883008e-01]\n [-1.75428942e-01  4.48893819e-01  5.33908719e-01  4.76141123e-01\n   2.95948849e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 4 6 6 5 5 4 2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[6.84631043e-04 2.68134267e-04 5.94151908e-04 1.09624453e-03\n  5.81147333e-05]\n [5.20442266e-03 2.03706196e-03 4.53672332e-03 8.34821352e-03\n  4.44566895e-04]\n [3.53114897e-02 1.37852992e-02 3.17581674e-02 5.73714696e-02\n  3.16129322e-03]\n [1.42002725e-01 5.90212431e-02 1.45491079e-01 2.45903140e-01\n  1.69829298e-02]\n [2.37965061e-01 1.64924275e-01 3.07103310e-01 4.90142675e-01\n  6.41685669e-02]\n [2.33743929e-01 2.79940549e-01 3.93105452e-01 6.04401235e-01\n  1.23310107e-01]\n [2.24533371e-01 3.15035931e-01 4.13875582e-01 6.29049045e-01\n  1.42106623e-01]\n [2.22887607e-01 3.20423612e-01 4.16995545e-01 6.32603829e-01\n  1.45029011e-01]\n [2.22712799e-01 3.21146965e-01 4.17340543e-01 6.33059863e-01\n  1.45399809e-01]\n [2.22726974e-01 3.21199493e-01 4.17392011e-01 6.33133625e-01\n  1.45425467e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 4 5 6 6 6 5 4 2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 1 1 2 2 1 2 1 2 1 1]"}}, "return": ["[[ 5.88312582e-04  2.59650151e-04  4.71980259e-04  9.25733337e-04\n   5.49261462e-05]\n [ 4.46640805e-03  1.97963807e-03  3.60140680e-03  7.04573733e-03\n   4.23183899e-04]\n [ 3.00067636e-02  1.37501116e-02  2.51079674e-02  4.82350881e-02\n   3.16479946e-03]\n [ 1.11977108e-01  6.64304987e-02  1.14553267e-01  2.02735241e-01\n   2.10221095e-02]\n [ 1.25749924e-01  2.22722479e-01  2.56001652e-01  3.91635546e-01\n   1.01345415e-01]\n [ 3.81784534e-02  4.21254014e-01  3.58044056e-01  4.92234555e-01\n   2.12505447e-01]\n [ 5.34175709e-03  4.87102888e-01  3.87590223e-01  5.19429330e-01\n   2.49460846e-01]\n [ 1.13170301e-04  4.97528079e-01  3.92170615e-01  5.23637701e-01\n   2.55301984e-01]\n [-5.84428997e-04  4.98916778e-01  3.92778436e-01  5.24195660e-01\n   2.56079915e-01]\n [-5.81508181e-04  4.98970762e-01  3.92823439e-01  5.24256565e-01\n   2.56107412e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 5 6 6 6 5 4 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 1 2 2 1 1]"}}, "return": ["[[7.72398135e-04 4.19064666e-04 5.19314943e-04 1.17400077e-03\n  8.59012617e-05]\n [5.87997746e-03 3.19913167e-03 3.95773330e-03 8.94460613e-03\n  6.58092702e-04]\n [4.02881986e-02 2.23893192e-02 2.73425369e-02 6.16697289e-02\n  4.72652096e-03]\n [1.69541270e-01 1.09230971e-01 1.19595721e-01 2.69742759e-01\n  2.64075043e-02]\n [3.11683445e-01 3.47168186e-01 2.55327596e-01 5.88904499e-01\n  1.10669205e-01]\n [2.88613438e-01 6.93414611e-01 3.92118386e-01 8.31743134e-01\n  2.71005943e-01]\n [2.41434379e-01 8.65859973e-01 4.62636372e-01 9.27309482e-01\n  3.58636224e-01]\n [2.31057014e-01 8.99844842e-01 4.76836388e-01 9.45551559e-01\n  3.76178694e-01]\n [2.29599073e-01 9.04535855e-01 4.78814445e-01 9.48063837e-01\n  3.78608332e-01]\n [2.29404553e-01 9.05153701e-01 4.79068771e-01 9.48388089e-01\n  3.78927845e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 5 6 7 6 5 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 1]"}}, "return": ["[[ 2.59274924e-04  1.20748541e-04  6.41222403e-04  7.41573788e-04\n   9.70568583e-05]\n [ 1.97771522e-03  9.43998672e-04  4.89713691e-03  5.67152733e-03\n   7.50143555e-04]\n [ 1.36979441e-02  7.74240382e-03  3.43267091e-02  4.01361172e-02\n   5.72565800e-03]\n [ 5.35800859e-02  6.49272407e-02  1.57759846e-01  1.90534386e-01\n   3.95538189e-02]\n [ 1.02067292e-02  3.12437360e-01  3.53920241e-01  4.18743081e-01\n   1.75723677e-01]\n [-1.36642017e-01  6.25720179e-01  5.09515301e-01  5.66742893e-01\n   3.52044675e-01]\n [-1.92697712e-01  7.38982624e-01  5.61182980e-01  6.14489345e-01\n   4.15659119e-01]\n [-2.02001760e-01  7.57926639e-01  5.69716428e-01  6.22447219e-01\n   4.26266669e-01]\n [-2.03250332e-01  7.60473517e-01  5.70862231e-01  6.23517727e-01\n   4.27692063e-01]\n [-2.03400694e-01  7.60799711e-01  5.71003942e-01  6.23658265e-01\n   4.27871826e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 5 7 7 5 4 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[5.06459381e-04 2.22790359e-04 5.73262424e-04 9.24064620e-04\n 7.41384552e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]", "l1_ratio": null}}, "return": ["[[6.32730081e-04 2.78408803e-04 7.16246782e-04 1.15452991e-03\n  9.26599841e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[ 2.27679878e-04  4.63544882e-05  6.39642628e-04  6.82770573e-04\n   7.46934736e-05]\n [ 1.72896444e-03  3.64925993e-04  4.88989810e-03  5.21552408e-03\n   5.77475906e-04]\n [ 1.15914574e-02  3.13610067e-03  3.45118599e-02  3.65967178e-02\n   4.41805430e-03]\n [ 3.74278937e-02  3.17540697e-02  1.62939789e-01  1.67233019e-01\n   3.09653482e-02]\n [-2.31805352e-02  1.88794110e-01  3.65794256e-01  3.46658216e-01\n   1.36954065e-01]\n [-1.35227353e-01  3.80117661e-01  4.94453528e-01  4.45675899e-01\n   2.54731142e-01]\n [-1.69415277e-01  4.38528080e-01  5.28071975e-01  4.71598739e-01\n   2.89763887e-01]\n [-1.74671855e-01  4.47584831e-01  5.33158165e-01  4.75555442e-01\n   2.95166098e-01]\n [-1.75367398e-01  4.48784916e-01  5.33829485e-01  4.76078477e-01\n   2.95881296e-01]\n [-1.75457903e-01  4.48941514e-01  5.33916980e-01  4.76146842e-01\n   2.95974552e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 5 4 2 3 1 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[6.84630850e-04 2.68134169e-04 5.94152094e-04 1.09624448e-03\n  5.81147656e-05]\n [5.20443123e-03 2.03701311e-03 4.53671399e-03 8.34819092e-03\n  4.44544794e-04]\n [3.53114837e-02 1.37853148e-02 3.17581579e-02 5.73714648e-02\n  3.16129891e-03]\n [1.42003170e-01 5.90213165e-02 1.45491245e-01 2.45903639e-01\n  1.69828931e-02]\n [2.37965706e-01 1.64924601e-01 3.07103594e-01 4.90143531e-01\n  6.41686050e-02]\n [2.33732683e-01 2.79943081e-01 3.93108203e-01 6.04395904e-01\n  1.23313857e-01]\n [2.24535509e-01 3.15034238e-01 4.13875269e-01 6.29049672e-01\n  1.42105477e-01]\n [2.22924040e-01 3.20449487e-01 4.16956899e-01 6.32613751e-01\n  1.45025152e-01]\n [2.22707294e-01 3.21166353e-01 4.17362726e-01 6.33081337e-01\n  1.45412020e-01]\n [2.22679019e-01 3.21259812e-01 4.17415555e-01 6.33142223e-01\n  1.45462447e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 4 5 5 4 4 2 1 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 1 1 2 2 1 2 1 2 1 1]"}}, "return": ["[[ 5.88312145e-04  2.59650267e-04  4.71980582e-04  9.25733304e-04\n   5.49263338e-05]\n [ 4.46639485e-03  1.97957938e-03  3.60142445e-03  7.04571430e-03\n   4.23166899e-04]\n [ 3.00065628e-02  1.37500459e-02  2.51079541e-02  4.82348953e-02\n   3.16481353e-03]\n [ 1.11977730e-01  6.64307849e-02  1.14553338e-01  2.02735899e-01\n   2.10221025e-02]\n [ 1.25751032e-01  2.22723180e-01  2.56002041e-01  3.91637003e-01\n   1.01345518e-01]\n [ 3.81793768e-02  4.21254633e-01  3.58044956e-01  4.92236224e-01\n   2.12505640e-01]\n [ 5.34235918e-03  4.87101093e-01  3.87588710e-01  5.19427825e-01\n   2.49459785e-01]\n [ 1.13113861e-04  4.97528831e-01  3.92171263e-01  5.23638491e-01\n   2.55302391e-01]\n [-5.82662261e-04  4.98915785e-01  3.92778981e-01  5.24196976e-01\n   2.56079255e-01]\n [-6.72873925e-04  4.99095600e-01  3.92857740e-01  5.24269354e-01\n   2.56179970e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 4 5 5 4 2 2 2 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 1 2 2 1 1]"}}, "return": ["[[7.72397940e-04 4.19064908e-04 5.19314982e-04 1.17400076e-03\n  8.59014020e-05]\n [5.87997719e-03 3.19913409e-03 3.95772390e-03 8.94459983e-03\n  6.58092162e-04]\n [4.02880572e-02 2.23893134e-02 2.73424085e-02 6.16695205e-02\n  4.72652711e-03]\n [1.69540568e-01 1.09230277e-01 1.19597465e-01 2.69743243e-01\n  2.64076658e-02]\n [3.11684195e-01 3.47163631e-01 2.55333762e-01 5.88907727e-01\n  1.10668299e-01]\n [2.88614237e-01 6.93409391e-01 3.92118932e-01 8.31741808e-01\n  2.71003856e-01]\n [2.41436964e-01 8.65858568e-01 4.62639925e-01 9.27313533e-01\n  3.58635726e-01]\n [2.31059223e-01 8.99834662e-01 4.76835458e-01 9.45547947e-01\n  3.76174165e-01]\n [2.29603076e-01 9.04539229e-01 4.78807754e-01 9.48063300e-01\n  3.78607715e-01]\n [2.29408108e-01 9.05171286e-01 4.79073630e-01 9.48402430e-01\n  3.78934670e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 5 6 6 4 2 1 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 1]"}}, "return": ["[[ 2.59274788e-04  1.20748906e-04  6.41222174e-04  7.41573674e-04\n   9.70569895e-05]\n [ 1.97771576e-03  9.43998079e-04  4.89713694e-03  5.67152749e-03\n   7.50143221e-04]\n [ 1.36983077e-02  7.74247430e-03  3.43261750e-02  4.01360183e-02\n   5.72552307e-03]\n [ 5.35797455e-02  6.49267489e-02  1.57759817e-01  1.90533883e-01\n   3.95536953e-02]\n [ 1.02084581e-02  3.12434998e-01  3.53918684e-01  4.18742147e-01\n   1.75722156e-01]\n [-1.36642028e-01  6.25719435e-01  5.09516161e-01  5.66743207e-01\n   3.52044530e-01]\n [-1.92698616e-01  7.38989214e-01  5.61186754e-01  6.14494506e-01\n   4.15662457e-01]\n [-2.02002077e-01  7.57928024e-01  5.69717608e-01  6.22448502e-01\n   4.26267459e-01]\n [-2.03249036e-01  7.60469577e-01  5.70860533e-01  6.23515644e-01\n   4.27690001e-01]\n [-2.03412373e-01  7.60804044e-01  5.71010837e-01  6.23656579e-01\n   4.27877032e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 4 5 5 5 3 2 1 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": false, "coef": "[5.06459120e-04 2.22790548e-04 5.73262492e-04 9.24064558e-04\n 7.41385929e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]", "l1_ratio": null}}, "return": ["[[6.32729946e-04 2.78408891e-04 7.16246840e-04 1.15452989e-03\n  9.26600553e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-10, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 15.501076693992202, "sample_weight": "[2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[ 2.27679909e-04  4.63544985e-05  6.39642697e-04  6.82770653e-04\n   7.46934826e-05]\n [ 1.72897611e-03  3.64929995e-04  4.88992538e-03  5.21555561e-03\n   5.77479466e-04]\n [ 1.15912818e-02  3.13631403e-03  3.45119044e-02  3.65967141e-02\n   4.41818003e-03]\n [ 3.74279156e-02  3.17541848e-02  1.62939622e-01  1.67232960e-01\n   3.09653609e-02]\n [-2.31926871e-02  1.88805103e-01  3.65800831e-01  3.46658925e-01\n   1.36961882e-01]\n [-1.35229491e-01  3.80116563e-01  4.94454740e-01  4.45674701e-01\n   2.54731359e-01]\n [-1.69416765e-01  4.38528326e-01  5.28075056e-01  4.71600068e-01\n   2.89764790e-01]\n [-1.74671856e-01  4.47584834e-01  5.33158166e-01  4.75555444e-01\n   2.95166100e-01]\n [-1.75367738e-01  4.48785870e-01  5.33829960e-01  4.76079011e-01\n   2.95881811e-01]\n [-1.75457909e-01  4.48941530e-01  5.33916988e-01  4.76146851e-01\n   2.95974561e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 10 17 30 73 80 90 89 78 65]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-10, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 15.501076693992202, "sample_weight": "[1 1 2 2 2 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[6.84630828e-04 2.68134296e-04 5.94152119e-04 1.09624454e-03\n  5.81148227e-05]\n [5.20442236e-03 2.03706239e-03 4.53672331e-03 8.34821347e-03\n  4.44567121e-04]\n [3.53114837e-02 1.37853153e-02 3.17581573e-02 5.73714646e-02\n  3.16129900e-03]\n [1.42003173e-01 5.90213210e-02 1.45491238e-01 2.45903638e-01\n  1.69828930e-02]\n [2.37965707e-01 1.64924602e-01 3.07103596e-01 4.90143533e-01\n  6.41686055e-02]\n [2.33733593e-01 2.79943160e-01 3.93108529e-01 6.04396882e-01\n  1.23313752e-01]\n [2.24535471e-01 3.15034399e-01 4.13875375e-01 6.29049797e-01\n  1.42105564e-01]\n [2.22924039e-01 3.20449488e-01 4.16956901e-01 6.32613752e-01\n  1.45025152e-01]\n [2.22707176e-01 3.21166860e-01 4.17362974e-01 6.33081665e-01\n  1.45412280e-01]\n [2.22679017e-01 3.21259821e-01 4.17415559e-01 6.33142228e-01\n  1.45462452e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 12  11  18  30  82  72 100 100  54  67]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-10, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 15.501076693992202, "sample_weight": "[1 1 2 2 2 2 1 1 2 2 1 2 1 2 1 1]"}}, "return": ["[[ 5.88312179e-04  2.59650417e-04  4.71980537e-04  9.25733362e-04\n   5.49263771e-05]\n [ 4.46640789e-03  1.97963823e-03  3.60140670e-03  7.04573721e-03\n   4.23183979e-04]\n [ 3.00065629e-02  1.37500462e-02  2.51079537e-02  4.82348952e-02\n   3.16481357e-03]\n [ 1.11977711e-01  6.64308438e-02  1.14553361e-01  2.02735928e-01\n   2.10221329e-02]\n [ 1.25751035e-01  2.22723179e-01  2.56002042e-01  3.91637005e-01\n   1.01345518e-01]\n [ 3.81793750e-02  4.21254695e-01  3.58045028e-01  4.92236306e-01\n   2.12505676e-01]\n [ 5.34158106e-03  4.87103171e-01  3.87590339e-01  5.19429412e-01\n   2.49461011e-01]\n [ 1.13115336e-04  4.97528818e-01  3.92171277e-01  5.23638497e-01\n   2.55302388e-01]\n [-5.82661931e-04  4.98915785e-01  3.92778982e-01  5.24196976e-01\n   2.56079255e-01]\n [-6.72877923e-04  4.99095616e-01  3.92857747e-01  5.24269363e-01\n   2.56179978e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 12  13  18  25  64 100  86 100 100  81]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-10, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 15.501076693992202, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 1 2 2 1 1]"}}, "return": ["[[7.72397940e-04 4.19064903e-04 5.19315006e-04 1.17400078e-03\n  8.59014038e-05]\n [5.87997707e-03 3.19913180e-03 3.95773332e-03 8.94460591e-03\n  6.58092837e-04]\n [4.02880559e-02 2.23893262e-02 2.73425345e-02 6.16696216e-02\n  4.72655280e-03]\n [1.69540615e-01 1.09230349e-01 1.19597381e-01 2.69743246e-01\n  2.64076701e-02]\n [3.11683991e-01 3.47163916e-01 2.55333888e-01 5.88907795e-01\n  1.10668471e-01]\n [2.88613919e-01 6.93410905e-01 3.92119640e-01 8.31742787e-01\n  2.71004620e-01]\n [2.41436818e-01 8.65859182e-01 4.62640208e-01 9.27313914e-01\n  3.58636038e-01]\n [2.31059062e-01 8.99835297e-01 4.76835752e-01 9.45548335e-01\n  3.76174491e-01]\n [2.29598815e-01 9.04555826e-01 4.78815406e-01 9.48073371e-01\n  3.78616231e-01]\n [2.29408031e-01 9.05171586e-01 4.79073768e-01 9.48402612e-01\n  3.78934824e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 11 18 24 46 66 71 60 62 42]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-10, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 15.501076693992202, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 1]"}}, "return": ["[[ 2.59274625e-04  1.20748907e-04  6.41222451e-04  7.41573762e-04\n   9.70570687e-05]\n [ 1.97771535e-03  9.43998711e-04  4.89713669e-03  5.67152728e-03\n   7.50143509e-04]\n [ 1.36983076e-02  7.74247422e-03  3.43261750e-02  4.01360182e-02\n   5.72552306e-03]\n [ 5.35797181e-02  6.49267275e-02  1.57759831e-01  1.90533863e-01\n   3.95536951e-02]\n [ 1.02067194e-02  3.12437242e-01  3.53920367e-01  4.18743117e-01\n   1.75723654e-01]\n [-1.36642028e-01  6.25719438e-01  5.09516163e-01  5.66743209e-01\n   3.52044532e-01]\n [-1.92698616e-01  7.38989215e-01  5.61186755e-01  6.14494507e-01\n   4.15662458e-01]\n [-2.02002088e-01  7.57928061e-01  5.69717624e-01  6.22448523e-01\n   4.26267478e-01]\n [-2.03250359e-01  7.60473599e-01  5.70862278e-01  6.23517778e-01\n   4.27692107e-01]\n [-2.03412396e-01  7.60804113e-01  5.71010867e-01  6.23656616e-01\n   4.27877069e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 10 18 27 61 78 98 71 85 98]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "np.ndarray[int64]", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": false, "coef": "[5.06459096e-04 2.22790604e-04 5.73262562e-04 9.24064619e-04\n 7.41386310e-05]", "max_iter": 100, "tol": 1e-10, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 15.501076693992202, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]", "l1_ratio": null}}, "return": ["[[6.32729962e-04 2.78408914e-04 7.16246834e-04 1.15452991e-03\n  9.26600599e-05]]", "[0.0001]", "[16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[ 2.27679878e-04  4.63544882e-05  6.39642628e-04  6.82770573e-04\n   7.46934736e-05]\n [ 1.72896271e-03  3.64925408e-04  4.88989410e-03  5.21551944e-03\n   5.77475389e-04]\n [ 1.15914797e-02  3.13607189e-03  3.45118544e-02  3.65967176e-02\n   4.41803771e-03]\n [ 3.74274099e-02  3.17540101e-02  1.62939020e-01  1.67232036e-01\n   3.09653004e-02]\n [-2.31927911e-02  1.88804526e-01  3.65800552e-01  3.46658373e-01\n   1.36961636e-01]\n [-1.35229489e-01  3.80116553e-01  4.94454736e-01  4.45674694e-01\n   2.54731354e-01]\n [-1.69416739e-01  4.38528232e-01  5.28075011e-01  4.71600012e-01\n   2.89764742e-01]\n [-1.74671819e-01  4.47584704e-01  5.33158105e-01  4.75555368e-01\n   2.95166032e-01]\n [-1.75367698e-01  4.48785735e-01  5.33829896e-01  4.76078931e-01\n   2.95881741e-01]\n [-1.75457869e-01  4.48941394e-01  5.33916924e-01  4.76146771e-01\n   2.95974489e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 3 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 1 2 2 1 1 2 1 2 1 1]"}}, "return": ["[[6.84630850e-04 2.68134169e-04 5.94152094e-04 1.09624448e-03\n  5.81147656e-05]\n [5.20443256e-03 2.03700577e-03 4.53671258e-03 8.34818755e-03\n  4.44541465e-04]\n [3.53123489e-02 1.37853532e-02 3.17579761e-02 5.73720028e-02\n  3.16110507e-03]\n [1.42005934e-01 5.90214553e-02 1.45482880e-01 2.45899421e-01\n  1.69810145e-02]\n [2.37961924e-01 1.64899494e-01 3.07082925e-01 4.90113557e-01\n  6.41563603e-02]\n [2.33741529e-01 2.79932396e-01 3.93104495e-01 6.04395001e-01\n  1.23307309e-01]\n [2.24558216e-01 3.15002302e-01 4.13863151e-01 6.29043341e-01\n  1.42086510e-01]\n [2.22950394e-01 3.20412053e-01 4.16942609e-01 6.32606064e-01\n  1.45002960e-01]\n [2.22708945e-01 3.21157660e-01 4.17358545e-01 6.33075487e-01\n  1.45407651e-01]\n [2.22680793e-01 3.21250591e-01 4.17411115e-01 6.33136031e-01\n  1.45457808e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 3 5 5 5 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 1 1 2 2 1 2 1 2 1 1]"}}, "return": ["[[ 5.88312145e-04  2.59650267e-04  4.71980582e-04  9.25733304e-04\n   5.49263338e-05]\n [ 4.46639295e-03  1.97957058e-03  3.60142711e-03  7.04571092e-03\n   4.23164338e-04]\n [ 3.00075090e-02  1.37497128e-02  2.51078056e-02  4.82353530e-02\n   3.16446529e-03]\n [ 1.11977472e-01  6.64304115e-02  1.14553559e-01  2.02735702e-01\n   2.10220482e-02]\n [ 1.25753667e-01  2.22723533e-01  2.55998032e-01  3.91636109e-01\n   1.01344457e-01]\n [ 3.81796202e-02  4.21253451e-01  3.58044521e-01  4.92235546e-01\n   2.12505064e-01]\n [ 5.34339297e-03  4.87096044e-01  3.87587467e-01  5.19425389e-01\n   2.49457424e-01]\n [ 1.15507119e-04  4.97519662e-01  3.92167589e-01  5.23633379e-01\n   2.55297768e-01]\n [-5.80178520e-04  4.98906317e-01  3.92775170e-01  5.24191694e-01\n   2.56074476e-01]\n [-6.70382412e-04  4.99086108e-01  3.92853918e-01  5.24264059e-01\n   2.56175178e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 5 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 1 2 2 1 1]"}}, "return": ["[[7.72397940e-04 4.19064908e-04 5.19314982e-04 1.17400076e-03\n  8.59014020e-05]\n [5.87997720e-03 3.19913443e-03 3.95772249e-03 8.94459891e-03\n  6.58092060e-04]\n [4.02880500e-02 2.23893073e-02 2.73424081e-02 6.16695119e-02\n  4.72652619e-03]\n [1.69542036e-01 1.09221136e-01 1.19596922e-01 2.69739829e-01\n  2.64037541e-02]\n [3.11747462e-01 3.47122304e-01 2.55283856e-01 5.88899229e-01\n  1.10631178e-01]\n [2.88613965e-01 6.93410609e-01 3.92119507e-01 8.31742588e-01\n  2.71004475e-01]\n [2.41441495e-01 8.65839972e-01 4.62631360e-01 9.27302069e-01\n  3.58626235e-01]\n [2.31068548e-01 8.99797696e-01 4.76818394e-01 9.45525373e-01\n  3.76155227e-01]\n [2.29609239e-01 9.04514683e-01 4.78796407e-01 9.48048276e-01\n  3.78595143e-01]\n [2.29418584e-01 9.05129959e-01 4.79054545e-01 9.48377226e-01\n  3.78913486e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 4 5 5 5 5 5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 1]"}}, "return": ["[[ 2.59274788e-04  1.20748906e-04  6.41222174e-04  7.41573674e-04\n   9.70569895e-05]\n [ 1.97778876e-03  9.43998234e-04  4.89701132e-03  5.67148730e-03\n   7.50107752e-04]\n [ 1.36996226e-02  7.74046063e-03  3.43268482e-02  4.01366273e-02\n   5.72458493e-03]\n [ 5.35873198e-02  6.49136700e-02  1.57762361e-01  1.90535706e-01\n   3.95475048e-02]\n [ 1.02064664e-02  3.12436320e-01  3.53919941e-01  4.18742184e-01\n   1.75723282e-01]\n [-1.36641994e-01  6.25719296e-01  5.09516101e-01  5.66743124e-01\n   3.52044460e-01]\n [-1.92697818e-01  7.38986519e-01  5.61185578e-01  6.14493003e-01\n   4.15661063e-01]\n [-2.02000821e-01  7.57923873e-01  5.69715798e-01  6.22446207e-01\n   4.26265307e-01]\n [-2.03249013e-01  7.60469161e-01  5.70860342e-01  6.23515328e-01\n   4.27689805e-01]\n [-2.03411039e-01  7.60799642e-01  5.71008917e-01  6.23654147e-01\n   4.27874749e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 3 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "np.ndarray[int64]", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[5.06459120e-04 2.22790548e-04 5.73262492e-04 9.24064558e-04\n 7.41385929e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": "[1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 2 1 2 1 1]", "l1_ratio": null}}, "return": ["[[6.32729881e-04 2.78408798e-04 7.16246862e-04 1.15452982e-03\n  9.26600367e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 2.27680221e-04  4.63541683e-05  6.39642609e-04  6.82770676e-04\n   7.46932763e-05]\n [ 1.72897612e-03  3.64930008e-04  4.88992537e-03  5.21555561e-03\n   5.77479467e-04]\n [ 1.15913122e-02  3.13635178e-03  3.45118730e-02  3.65967302e-02\n   4.41818317e-03]\n [ 3.74364950e-02  3.17642691e-02  1.62930964e-01  1.67237432e-01\n   3.09660608e-02]\n [-2.31897625e-02  1.88800067e-01  3.65796148e-01  3.46655311e-01\n   1.36958576e-01]\n [-1.35224450e-01  3.80109196e-01  4.94450664e-01  4.45672112e-01\n   2.54726816e-01]\n [-1.69415842e-01  4.38526543e-01  5.28072741e-01  4.71598201e-01\n   2.89763536e-01]\n [-1.74671850e-01  4.47584814e-01  5.33158130e-01  4.75555412e-01\n   2.95166085e-01]\n [-1.75364211e-01  4.48792180e-01  5.33826864e-01  4.76082178e-01\n   2.95883008e-01]\n [-1.75428942e-01  4.48893819e-01  5.33908719e-01  4.76141123e-01\n   2.95948849e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 4 6 6 5 5 4 2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[6.84631043e-04 2.68134267e-04 5.94151908e-04 1.09624453e-03\n  5.81147333e-05]\n [5.20442266e-03 2.03706196e-03 4.53672332e-03 8.34821352e-03\n  4.44566895e-04]\n [3.53114897e-02 1.37852992e-02 3.17581674e-02 5.73714696e-02\n  3.16129322e-03]\n [1.42002725e-01 5.90212431e-02 1.45491079e-01 2.45903140e-01\n  1.69829298e-02]\n [2.37965061e-01 1.64924275e-01 3.07103310e-01 4.90142675e-01\n  6.41685669e-02]\n [2.33743929e-01 2.79940549e-01 3.93105452e-01 6.04401235e-01\n  1.23310107e-01]\n [2.24533371e-01 3.15035931e-01 4.13875582e-01 6.29049045e-01\n  1.42106623e-01]\n [2.22887607e-01 3.20423612e-01 4.16995545e-01 6.32603829e-01\n  1.45029011e-01]\n [2.22712799e-01 3.21146965e-01 4.17340543e-01 6.33059863e-01\n  1.45399809e-01]\n [2.22726974e-01 3.21199493e-01 4.17392011e-01 6.33133625e-01\n  1.45425467e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 4 5 6 6 6 5 4 2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 5.88312582e-04  2.59650151e-04  4.71980259e-04  9.25733337e-04\n   5.49261462e-05]\n [ 4.46640805e-03  1.97963807e-03  3.60140680e-03  7.04573733e-03\n   4.23183899e-04]\n [ 3.00067636e-02  1.37501116e-02  2.51079674e-02  4.82350881e-02\n   3.16479946e-03]\n [ 1.11977108e-01  6.64304987e-02  1.14553267e-01  2.02735241e-01\n   2.10221095e-02]\n [ 1.25749924e-01  2.22722479e-01  2.56001652e-01  3.91635546e-01\n   1.01345415e-01]\n [ 3.81784534e-02  4.21254014e-01  3.58044056e-01  4.92234555e-01\n   2.12505447e-01]\n [ 5.34175709e-03  4.87102888e-01  3.87590223e-01  5.19429330e-01\n   2.49460846e-01]\n [ 1.13170301e-04  4.97528079e-01  3.92170615e-01  5.23637701e-01\n   2.55301984e-01]\n [-5.84428997e-04  4.98916778e-01  3.92778436e-01  5.24195660e-01\n   2.56079915e-01]\n [-5.81508181e-04  4.98970762e-01  3.92823439e-01  5.24256565e-01\n   2.56107412e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 5 6 6 6 5 4 1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[7.72398135e-04 4.19064666e-04 5.19314943e-04 1.17400077e-03\n  8.59012617e-05]\n [5.87997746e-03 3.19913167e-03 3.95773330e-03 8.94460613e-03\n  6.58092702e-04]\n [4.02881986e-02 2.23893192e-02 2.73425369e-02 6.16697289e-02\n  4.72652096e-03]\n [1.69541270e-01 1.09230971e-01 1.19595721e-01 2.69742759e-01\n  2.64075043e-02]\n [3.11683445e-01 3.47168186e-01 2.55327596e-01 5.88904499e-01\n  1.10669205e-01]\n [2.88613438e-01 6.93414611e-01 3.92118386e-01 8.31743134e-01\n  2.71005943e-01]\n [2.41434379e-01 8.65859973e-01 4.62636372e-01 9.27309482e-01\n  3.58636224e-01]\n [2.31057014e-01 8.99844842e-01 4.76836388e-01 9.45551559e-01\n  3.76178694e-01]\n [2.29599073e-01 9.04535855e-01 4.78814445e-01 9.48063837e-01\n  3.78608332e-01]\n [2.29404553e-01 9.05153701e-01 4.79068771e-01 9.48388089e-01\n  3.78927845e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 5 6 7 6 5 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "lbfgs", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 2.59274924e-04  1.20748541e-04  6.41222403e-04  7.41573788e-04\n   9.70568583e-05]\n [ 1.97771522e-03  9.43998672e-04  4.89713691e-03  5.67152733e-03\n   7.50143555e-04]\n [ 1.36979441e-02  7.74240382e-03  3.43267091e-02  4.01361172e-02\n   5.72565800e-03]\n [ 5.35800859e-02  6.49272407e-02  1.57759846e-01  1.90534386e-01\n   3.95538189e-02]\n [ 1.02067292e-02  3.12437360e-01  3.53920241e-01  4.18743081e-01\n   1.75723677e-01]\n [-1.36642017e-01  6.25720179e-01  5.09515301e-01  5.66742893e-01\n   3.52044675e-01]\n [-1.92697712e-01  7.38982624e-01  5.61182980e-01  6.14489345e-01\n   4.15659119e-01]\n [-2.02001760e-01  7.57926639e-01  5.69716428e-01  6.22447219e-01\n   4.26266669e-01]\n [-2.03250332e-01  7.60473517e-01  5.70862231e-01  6.23517727e-01\n   4.27692063e-01]\n [-2.03400694e-01  7.60799711e-01  5.71003942e-01  6.23658265e-01\n   4.27871826e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 5 7 7 5 4 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "int", "1": "int"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": false, "coef": "[5.06459381e-04 2.22790359e-04 5.73262424e-04 9.24064620e-04\n 7.41384552e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1, "1": 2}, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[6.32730081e-04 2.78408803e-04 7.16246782e-04 1.15452991e-03\n  9.26599841e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 2.27679878e-04  4.63544882e-05  6.39642628e-04  6.82770573e-04\n   7.46934736e-05]\n [ 1.72896271e-03  3.64925408e-04  4.88989410e-03  5.21551944e-03\n   5.77475389e-04]\n [ 1.15914797e-02  3.13607189e-03  3.45118544e-02  3.65967176e-02\n   4.41803771e-03]\n [ 3.74274099e-02  3.17540101e-02  1.62939020e-01  1.67232036e-01\n   3.09653004e-02]\n [-2.31927911e-02  1.88804526e-01  3.65800552e-01  3.46658373e-01\n   1.36961636e-01]\n [-1.35229489e-01  3.80116553e-01  4.94454736e-01  4.45674694e-01\n   2.54731354e-01]\n [-1.69416739e-01  4.38528232e-01  5.28075011e-01  4.71600012e-01\n   2.89764742e-01]\n [-1.74671819e-01  4.47584704e-01  5.33158105e-01  4.75555368e-01\n   2.95166032e-01]\n [-1.75367698e-01  4.48785735e-01  5.33829896e-01  4.76078931e-01\n   2.95881741e-01]\n [-1.75457869e-01  4.48941394e-01  5.33916924e-01  4.76146771e-01\n   2.95974489e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 3 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[6.84630850e-04 2.68134169e-04 5.94152094e-04 1.09624448e-03\n  5.81147656e-05]\n [5.20443256e-03 2.03700577e-03 4.53671258e-03 8.34818755e-03\n  4.44541465e-04]\n [3.53123489e-02 1.37853532e-02 3.17579761e-02 5.73720028e-02\n  3.16110507e-03]\n [1.42005934e-01 5.90214553e-02 1.45482880e-01 2.45899421e-01\n  1.69810145e-02]\n [2.37961924e-01 1.64899494e-01 3.07082925e-01 4.90113557e-01\n  6.41563603e-02]\n [2.33741529e-01 2.79932396e-01 3.93104495e-01 6.04395001e-01\n  1.23307309e-01]\n [2.24558216e-01 3.15002302e-01 4.13863151e-01 6.29043341e-01\n  1.42086510e-01]\n [2.22950394e-01 3.20412053e-01 4.16942609e-01 6.32606064e-01\n  1.45002960e-01]\n [2.22708945e-01 3.21157660e-01 4.17358545e-01 6.33075487e-01\n  1.45407651e-01]\n [2.22680793e-01 3.21250591e-01 4.17411115e-01 6.33136031e-01\n  1.45457808e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 3 5 5 5 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 0 0 1 1 0 1 0 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 5.88312145e-04  2.59650267e-04  4.71980582e-04  9.25733304e-04\n   5.49263338e-05]\n [ 4.46639295e-03  1.97957058e-03  3.60142711e-03  7.04571092e-03\n   4.23164338e-04]\n [ 3.00075090e-02  1.37497128e-02  2.51078056e-02  4.82353530e-02\n   3.16446529e-03]\n [ 1.11977472e-01  6.64304115e-02  1.14553559e-01  2.02735702e-01\n   2.10220482e-02]\n [ 1.25753667e-01  2.22723533e-01  2.55998032e-01  3.91636109e-01\n   1.01344457e-01]\n [ 3.81796202e-02  4.21253451e-01  3.58044521e-01  4.92235546e-01\n   2.12505064e-01]\n [ 5.34339297e-03  4.87096044e-01  3.87587467e-01  5.19425389e-01\n   2.49457424e-01]\n [ 1.15507119e-04  4.97519662e-01  3.92167589e-01  5.23633379e-01\n   2.55297768e-01]\n [-5.80178520e-04  4.98906317e-01  3.92775170e-01  5.24191694e-01\n   2.56074476e-01]\n [-6.70382412e-04  4.99086108e-01  3.92853918e-01  5.24264059e-01\n   2.56175178e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 4 5 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[7.72397940e-04 4.19064908e-04 5.19314982e-04 1.17400076e-03\n  8.59014020e-05]\n [5.87997720e-03 3.19913443e-03 3.95772249e-03 8.94459891e-03\n  6.58092060e-04]\n [4.02880500e-02 2.23893073e-02 2.73424081e-02 6.16695119e-02\n  4.72652619e-03]\n [1.69542036e-01 1.09221136e-01 1.19596922e-01 2.69739829e-01\n  2.64037541e-02]\n [3.11747462e-01 3.47122304e-01 2.55283856e-01 5.88899229e-01\n  1.10631178e-01]\n [2.88613965e-01 6.93410609e-01 3.92119507e-01 8.31742588e-01\n  2.71004475e-01]\n [2.41441495e-01 8.65839972e-01 4.62631360e-01 9.27302069e-01\n  3.58626235e-01]\n [2.31068548e-01 8.99797696e-01 4.76818394e-01 9.45525373e-01\n  3.76155227e-01]\n [2.29609239e-01 9.04514683e-01 4.78796407e-01 9.48048276e-01\n  3.78595143e-01]\n [2.29418584e-01 9.05129959e-01 4.79054545e-01 9.48377226e-01\n  3.78913486e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 4 5 5 5 5 5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": {"0": "int", "1": "int"}, "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": false, "solver": "liblinear", "max_iter": 100, "class_weight": {"0": 1, "1": 2}, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 2.59274788e-04  1.20748906e-04  6.41222174e-04  7.41573674e-04\n   9.70569895e-05]\n [ 1.97778876e-03  9.43998234e-04  4.89701132e-03  5.67148730e-03\n   7.50107752e-04]\n [ 1.36996226e-02  7.74046063e-03  3.43268482e-02  4.01366273e-02\n   5.72458493e-03]\n [ 5.35873198e-02  6.49136700e-02  1.57762361e-01  1.90535706e-01\n   3.95475048e-02]\n [ 1.02064664e-02  3.12436320e-01  3.53919941e-01  4.18742184e-01\n   1.75723282e-01]\n [-1.36641994e-01  6.25719296e-01  5.09516101e-01  5.66743124e-01\n   3.52044460e-01]\n [-1.92697818e-01  7.38986519e-01  5.61185578e-01  6.14493003e-01\n   4.15661063e-01]\n [-2.02000821e-01  7.57923873e-01  5.69715798e-01  6.22446207e-01\n   4.26265307e-01]\n [-2.03249013e-01  7.60469161e-01  5.70860342e-01  6.23515328e-01\n   4.27689805e-01]\n [-2.03411039e-01  7.60799642e-01  5.71008917e-01  6.23654147e-01\n   4.27874749e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 3 4 4 4 4 4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": {"0": "int", "1": "int"}, "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.34005052 -1.45197504  2.21417     0.01493171  0.07817686]\n [-2.46833166  0.06660625 -0.01182376 -1.86039859  0.53464203]\n [ 0.51835374 -0.03662544  1.4069807   1.45278103  0.10730235]\n [ 1.64183897  1.67134737  0.4664669   2.36051028  0.37955473]\n [ 0.05032296 -0.83154236  1.24268696  0.61249464 -0.12861914]\n [ 0.23200618  0.0970142   1.2515783   1.17608571  0.19277271]\n [-0.07511599  1.17226935  1.02278388  1.25172904  0.63319508]\n [ 0.2110531  -0.8584371   1.03818799  0.5667589  -0.20548505]\n [ 1.38835883 -0.81220417  1.49639765  1.83476684 -0.35689119]\n [-0.40982712 -1.32752941  2.05963723  0.66203651 -0.09156792]\n [-0.66866779 -1.62133395  2.12396056  0.38149402 -0.1406687 ]\n [-1.14958531 -0.11872604 -1.00912222 -1.70014365  0.02820541]\n [-1.18143162 -2.02145914  3.09476491  0.55158302 -0.03080584]\n [-1.19585077  0.93630533 -0.86059645 -1.14671174  0.46817779]\n [-1.99238982  0.05433458 -0.13481519 -1.59706152  0.41141043]\n [ 1.76373376  1.69136018  1.01414352  2.88057028  0.45105261]\n [ 0.12195614 -1.51518794  0.355283   -0.31840121 -0.55093687]\n [-0.38945145 -0.3145526  -0.11208102 -0.52412161 -0.05872894]\n [-2.41344426 -0.85786223  0.41941693 -1.90580438  0.23739853]\n [-2.33650481  0.44332008 -0.12626355 -1.67757794  0.6338123 ]]", "y": "[0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": false, "coef": "[5.06459120e-04 2.22790548e-04 5.73262492e-04 9.24064558e-04\n 7.41385929e-05]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": {"0": 1, "1": 2}, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[6.32729881e-04 2.78408798e-04 7.16246862e-04 1.15452982e-03\n  9.26600367e-05]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "str", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": "balanced", "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.45402638   0.83062186  -2.26375356  -0.96570059   9.31034394]\n  [  0.47462623  -0.33962189  -0.16823491  -0.79733812   2.07689704]\n  [ -0.02059985  -0.49099997   2.43198847   1.76303871 -11.38724098]]]", "[1.]", "[89]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": {"0": 7.0, "1": 0.7, "2": 0.7}, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.45402638   0.83062186  -2.26375356  -0.96570059   9.31034394]\n  [  0.47462623  -0.33962189  -0.16823491  -0.79733812   2.07689704]\n  [ -0.02059985  -0.49099997   2.43198847   1.76303871 -11.38724098]]]", "[1.]", "[89]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "str", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": "balanced", "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.45410514   0.83029025  -2.26376561  -0.9666087    9.31319933]\n  [  0.47445645  -0.33927797  -0.16828637  -0.79718664   2.07698747]\n  [ -0.02035131  -0.49101228   2.43205198   1.76379534 -11.3901868 ]]]", "[1.]", "[19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float", "2": "float"}, "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": {"0": 7.0, "1": 0.7, "2": 0.7}, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.45410514   0.83029025  -2.26376561  -0.9666087    9.31319933]\n  [  0.47445645  -0.33927797  -0.16828637  -0.79718664   2.07698747]\n  [ -0.02035131  -0.49101228   2.43205198   1.76379534 -11.3901868 ]]]", "[1.]", "[19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "str", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": "balanced", "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44906951 -0.72630532  2.00066541  0.83552719 -6.26489983]]", "[1.]", "[23]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": {"0": 5.5, "1": 0.55}, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44906951 -0.72630532  2.00066541  0.83552719 -6.26489983]]", "[1.]", "[23]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "str", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": "balanced", "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44876264 -0.72651563  2.00062488  0.83551709 -6.262509  ]]", "[1.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": {"0": "float", "1": "float"}, "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]]", "y": "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": {"0": 5.5, "1": 0.55}, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44876264 -0.72651563  2.00062488  0.83551709 -6.262509  ]]", "[1.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.22305334 -0.33993598 -0.38656071 -0.54920422  0.01438306\n   -0.15309813  0.41210881  0.46362507  0.43140618  0.30837097\n   -0.04531679  0.24469987 -0.03551426 -0.13631681  0.51947201\n   -0.25730767  0.46369498 -0.24308862 -0.08724382 -1.12829218\n    0.98435769]\n  [-0.05013995 -0.29448904  0.06389391  0.56926655  0.31439954\n   -0.34707095 -0.32433734 -0.2037041  -0.4933289  -0.50037513\n    0.10215119  0.0066785   0.32892995  0.15526171 -0.87818788\n    0.23514315 -0.17721838  0.04535248 -0.00720734  1.09166347\n   -1.35254994]\n  [ 0.27319329  0.63442502  0.3226668  -0.02006233 -0.3287826\n    0.50016908 -0.08777147 -0.25992097  0.06192272  0.19200417\n   -0.0568344  -0.25137837 -0.29341569 -0.0189449   0.35871587\n    0.02216452 -0.2864766   0.19773614  0.09445117  0.03662871\n    0.36819225]]]", "[1.]", "[59]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.27195379 -0.49266883 -0.3686056  -0.34286988  0.0871258\n   -0.2568282   0.45414708  0.46438368  0.45014609  0.32112233\n   -0.05867197  0.20969318  0.01702272 -0.24242365  0.48091029\n   -0.1564233   0.34275296 -0.20276205 -0.11476436 -1.19627294]\n  [-0.09322487 -0.16702571  0.0018129   0.32168009  0.27144176\n   -0.21359064 -0.27624733 -0.10757642 -0.48588109 -0.53114044\n    0.05250351  0.12758239  0.2807382   0.30775192 -0.73898722\n    0.12460608  0.00608762 -0.01305792 -0.0345799   1.02215232]\n  [ 0.36517866  0.65969454  0.3667927   0.0211898  -0.35856756\n    0.47041884 -0.17789975 -0.35680725  0.03573501  0.2100181\n    0.00616846 -0.33727556 -0.29776092 -0.06532827  0.25807692\n    0.03181722 -0.34884059  0.21581997  0.14934426  0.17412063]]]", "[1.]", "[43]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-07, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.22308475 -0.33989161 -0.3865632  -0.54925672  0.01439994\n   -0.15305372  0.41210201  0.4636253   0.43140192  0.30835998\n   -0.04531333  0.24470978 -0.03551967 -0.13628453  0.51949017\n   -0.25731313  0.46372683 -0.24309407 -0.08724113 -1.12828051\n    0.98461967]\n  [-0.05010992 -0.29454515  0.06390053  0.56934185  0.31438267\n   -0.34708342 -0.32435085 -0.20374042 -0.49332801 -0.50038514\n    0.10217845  0.00665255  0.32893914  0.15522338 -0.87823109\n    0.23514155 -0.1772653   0.04536868 -0.00717681  1.09166779\n   -1.35285608]\n  [ 0.27319467  0.63443676  0.32266267 -0.02008513 -0.32878261\n    0.50013715 -0.08775115 -0.25988488  0.06192609  0.19202516\n   -0.05686512 -0.25136233 -0.29341947 -0.01893885  0.35874091\n    0.02217158 -0.28646153  0.19772539  0.09441795  0.03661271\n    0.36823641]]]", "[1.]", "[1158]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.27198638 -0.49268028 -0.36861553 -0.34287805  0.08714736\n   -0.25683131  0.45415828  0.46439894  0.45014159  0.32113127\n   -0.05869813  0.20969627  0.01701003 -0.24241216  0.48088406\n   -0.15637211  0.34274734 -0.20276522 -0.11475699 -1.19625402]\n  [-0.09319085 -0.167019    0.0018207   0.32168229  0.27143915\n   -0.21358685 -0.27623652 -0.1075928  -0.48588609 -0.53115551\n    0.05249897  0.12759274  0.28076153  0.30775562 -0.73897113\n    0.12454802  0.00609564 -0.01306056 -0.03459838  1.02214674]\n  [ 0.36517723  0.65969928  0.36679483  0.02119577 -0.35858651\n    0.47041816 -0.17792176 -0.35680614  0.0357445   0.21002424\n    0.00619916 -0.33728901 -0.29777156 -0.06534345  0.25808707\n    0.03182409 -0.34884298  0.21582578  0.14935538  0.17410729]]]", "[1.]", "[376]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-07, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.22309585 -0.33992223 -0.3865562  -0.54921315  0.0144064\n   -0.15307007  0.41210583  0.46361809  0.43140405  0.30836979\n   -0.04531618  0.24469632 -0.03551457 -0.1363123   0.51947662\n   -0.25729102  0.46369751 -0.24308476 -0.08724143 -1.12828191\n    0.98441874]\n  [-0.05010671 -0.29451231  0.06388962  0.56928986  0.31437533\n   -0.34706534 -0.32433869 -0.20371109 -0.49332754 -0.50039854\n    0.10216377  0.0066771   0.32892764  0.1552556  -0.87819447\n    0.23512903 -0.17722832  0.04535803 -0.00719034  1.09165269\n   -1.35260506]\n  [ 0.27320256  0.63443454  0.32266658 -0.0200767  -0.32878173\n    0.50013541 -0.08776714 -0.259907    0.06192349  0.19202875\n   -0.05684759 -0.25137342 -0.29341307 -0.0189433   0.35871785\n    0.02216199 -0.28646919  0.19772673  0.09443177  0.03662922\n    0.36818632]]]", "[1.]", "[2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.27198241 -0.49267981 -0.3686158  -0.34287877  0.08714794\n   -0.25683609  0.45415854  0.46440183  0.45014042  0.32112802\n   -0.05869848  0.20969671  0.0170126  -0.2424106   0.48088376\n   -0.15637636  0.34274682 -0.20276552 -0.11475775 -1.19625254]\n  [-0.0931916  -0.16701969  0.00182101  0.32168212  0.27143764\n   -0.21358437 -0.27623613 -0.10759474 -0.48588507 -0.53115459\n    0.05249889  0.12759258  0.28076185  0.30775421 -0.73897037\n    0.12454809  0.00609619 -0.0130604  -0.03459813  1.02214574]\n  [ 0.36517401  0.65969951  0.36679479  0.02119665 -0.35858557\n    0.47042046 -0.17792241 -0.35680709  0.03574465  0.21002657\n    0.0061996  -0.3372893  -0.29777446 -0.0653436   0.2580866\n    0.03182828 -0.34884301  0.21582592  0.14935589  0.1741068 ]]]", "[1.]", "[731]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-07, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.22308151 -0.33988279 -0.3865652  -0.5492693   0.01439809\n   -0.15304901  0.41210092  0.4636274   0.43140131  0.30835713\n   -0.04531251  0.24471368 -0.03552113 -0.13627652  0.51949408\n   -0.25731953  0.46373529 -0.24309677 -0.08724105 -1.1282801\n    0.98467755]\n  [-0.0501109  -0.29455459  0.06390373  0.56935685  0.31438476\n   -0.34708861 -0.32435435 -0.20374891 -0.49332815 -0.50038125\n    0.10218273  0.00664546  0.32894244  0.15521404 -0.87824165\n    0.23514517 -0.17727594  0.0453717  -0.00717289  1.09167211\n   -1.35292844]\n  [ 0.27319241  0.63443738  0.32266147 -0.02008756 -0.32878284\n    0.50013761 -0.08774657 -0.25987849  0.06192684  0.19202413\n   -0.05687022 -0.25135914 -0.29342131 -0.01893752  0.35874757\n    0.02217436 -0.28645935  0.19772507  0.09441393  0.03660799\n    0.36825089]]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-07, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 2000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.27198945 -0.49268052 -0.36861514 -0.34287733  0.08714677\n   -0.25682666  0.45415805  0.46439544  0.45014263  0.32113301\n   -0.05869771  0.20969536  0.01700873 -0.24241395  0.48088495\n   -0.156371    0.34274715 -0.20276471 -0.1147575  -1.19625541]\n  [-0.09318999 -0.16701873  0.00182039  0.32168202  0.27144009\n   -0.21358954 -0.2762366  -0.10759087 -0.48588677 -0.53115643\n    0.05249885  0.12759309  0.28076126  0.30775679 -0.73897195\n    0.12454873  0.00609564 -0.0130608  -0.03459813  1.02214761]\n  [ 0.36517944  0.65969924  0.36679475  0.02119531 -0.35858686\n    0.47041619 -0.17792145 -0.35680456  0.03574414  0.21002342\n    0.00619886 -0.33728845 -0.29776998 -0.06534283  0.258087\n    0.03182227 -0.3488428   0.2158255   0.14935563  0.1741078 ]]]", "[1.]", "[13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0 0\n 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.32196826 -0.23105022 -0.40425425 -0.45196734  0.07171689\n   -0.26167031  0.26192425  0.31545436  0.36685937  0.24920786\n   -0.04641826  0.16917671  0.15009815  0.00963144  0.23433521\n   -0.15060785  0.28973078 -0.21557912  0.00512468 -0.94436573\n    0.81857353]\n  [-0.14359203 -0.50026588  0.12615747  0.22964768 -0.00748877\n   -0.06672006 -0.03037281 -0.19908809 -0.53100924 -0.30536282\n    0.38987102  0.15053123  0.19538354  0.15735389 -0.55812567\n    0.02330536  0.08143498 -0.03046101  0.08582646  0.97864244\n   -0.80287267]\n  [ 0.46556028  0.7313161   0.27809678  0.22231965 -0.06422812\n    0.32839037 -0.23155144 -0.11636627  0.16414987  0.05615496\n   -0.34345275 -0.31970795 -0.34548169 -0.16698533  0.32379046\n    0.12730249 -0.37116576  0.24604012 -0.09095115 -0.03427671\n   -0.01570086]]]", "[1.]", "[51]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 2 1 1 1 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0\n 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.1488511  -0.42073119 -0.30112622 -0.2588849  -0.1977946\n   -0.08281373  0.48389911  0.55327484  0.30116415  0.23673605\n    0.09418499  0.10352986 -0.03512238 -0.17593164  0.46770052\n   -0.21857102  0.31399757 -0.12656028 -0.03321555 -1.09988011\n    0.70210212]\n  [-0.1645608  -0.05293748  0.03009891  0.35171056  0.35254322\n   -0.19720295 -0.45661692 -0.42047617 -0.27602053 -0.17646301\n   -0.26316963  0.1387748   0.41935278  0.08240286 -0.84165176\n    0.07395759 -0.0964524  -0.14786832 -0.34541862  0.99518243\n   -1.03221511]\n  [ 0.3134119   0.47366867  0.27102731 -0.09282566 -0.15474862\n    0.28001668 -0.02728219 -0.13279867 -0.02514362 -0.06027304\n    0.16898464 -0.24230466 -0.38423039  0.09352878  0.37395124\n    0.14461343 -0.21754516  0.27442861  0.37863417  0.10469768\n    0.330113  ]]]", "[1.]", "[55]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 0 1 2 1 1 2 0 1 1 2 2 1 2 0 0\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-7.85306198e-02 -3.56708023e-01 -3.72215590e-01 -4.89804972e-01\n    1.21291235e-01 -1.18025063e-01  3.83631731e-01  2.46470447e-01\n    3.55813162e-01  3.27325888e-01 -9.03038595e-04  2.33486771e-01\n   -9.07856515e-03 -3.99908974e-02  4.26821082e-01 -1.97574792e-01\n    3.85586672e-01 -1.81226202e-01 -2.74466871e-01 -9.68976612e-01\n    1.14829148e+00]\n  [ 6.49523280e-02 -2.35558041e-01 -1.28049734e-02  4.14826391e-01\n    4.66477944e-01 -1.14543133e-01 -3.24249609e-01 -3.13763030e-01\n   -4.53916950e-01 -2.23829473e-01  5.71544635e-02  8.75968314e-02\n    5.28163484e-01  2.62138321e-01 -6.02596347e-01  2.14856515e-01\n   -1.34368058e-01  1.22464000e-01  1.47693833e-01  1.04134531e+00\n   -5.25788201e-01]\n  [ 1.35782918e-02  5.92266064e-01  3.85020563e-01  7.49785801e-02\n   -5.87769179e-01  2.32568196e-01 -5.93821220e-02  6.72925837e-02\n    9.81037881e-02 -1.03496415e-01 -5.62514249e-02 -3.21083602e-01\n   -5.19084919e-01 -2.22147424e-01  1.75775265e-01 -1.72817227e-02\n   -2.51218614e-01  5.87622020e-02  1.26773037e-01 -7.23686935e-02\n   -6.22503278e-01]]]", "[1.]", "[51]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 0 0 0 1 1 2 1 2\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.20580294 -0.34258811 -0.27973237 -0.46791503  0.06506676\n    0.03388164  0.31503226  0.46117119  0.40683839  0.05037737\n    0.02634978  0.32182949 -0.08613979 -0.07562213  0.50770924\n   -0.21564411  0.33894522 -0.20154046  0.19338565 -0.93819837\n    0.70562234]\n  [-0.12615772 -0.33945094 -0.02848822  0.55722277  0.2424016\n   -0.36176996 -0.32021355  0.04941112 -0.47417203 -0.60706887\n    0.11423863 -0.0304192   0.49173517  0.01781408 -0.66496189\n    0.12762898 -0.15175073  0.02056992 -0.07045622  0.91656903\n   -1.19687191]\n  [ 0.33196066  0.68203905  0.30822059 -0.08930774 -0.30746836\n    0.32788832  0.00518129 -0.51058231  0.06733363  0.5566915\n   -0.1405884  -0.29141029 -0.40559538  0.05780805  0.15725265\n    0.08801513 -0.1871945   0.18097054 -0.12292943  0.02162934\n    0.49124958]]]", "[1.]", "[63]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 2 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.31481312 -0.20315457 -0.43188325 -0.34764658  0.30930054\n   -0.23576174  0.24233997  0.46080066  0.2509229   0.2182036\n   -0.06040581  0.1964225  -0.24350706 -0.07966775  0.4251665\n   -0.4258126   0.4258963  -0.24494204 -0.25232688 -0.95003139\n    0.77117488]\n  [-0.00784626 -0.35325205  0.05057466  0.56347274  0.29848482\n   -0.20169124 -0.24957333 -0.16709949 -0.46436368 -0.45825901\n    0.08105311  0.03546287  0.37002157  0.17092361 -0.90011781\n    0.27082037 -0.16486883  0.03310879  0.04538119  1.00570856\n   -1.20998558]\n  [ 0.32265938  0.55640662  0.38130859 -0.21582615 -0.60778536\n    0.43745297  0.00723336 -0.29370117  0.21344078  0.2400554\n   -0.0206473  -0.23188537 -0.12651451 -0.09125586  0.47495131\n    0.15499222 -0.26102747  0.21183325  0.2069457  -0.05567717\n    0.4388107 ]]]", "[1.]", "[61]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[-2.13993205e-01 -3.10846421e-01 -3.57842335e-01 -4.03243764e-01\n   7.39161650e-02 -1.32877839e-01  3.37365465e-01  4.07434301e-01\n   3.36319594e-01  2.16370155e-01  2.56153011e-03  2.04889068e-01\n  -4.47499286e-02 -7.23161960e-02  4.12346510e-01 -2.41642075e-01\n   3.50831309e-01 -1.93969620e-01 -7.22997934e-02 -9.80290443e-01\n   8.29152867e-01]\n [-7.54408967e-02 -2.96292879e-01  3.31075692e-02  4.23376029e-01\n   2.70483762e-01 -1.88385469e-01 -2.76205244e-01 -2.10203132e-01\n  -4.39896484e-01 -3.54196638e-01  7.58295163e-02  7.63893057e-02\n   4.00931308e-01  1.38126553e-01 -7.13490697e-01  1.42113764e-01\n  -9.32010083e-02 -4.37323720e-04 -2.73946706e-02  9.87489555e-01\n  -9.53546695e-01]\n [ 2.89434102e-01  6.07139300e-01  3.24734766e-01 -2.01322651e-02\n  -3.44399927e-01  3.21263308e-01 -6.11602211e-02 -1.97231168e-01\n   1.03576890e-01  1.37826483e-01 -7.83910464e-02 -2.81278374e-01\n  -3.56181379e-01 -6.58103573e-02  3.01144186e-01  9.95283112e-02\n  -2.57630300e-01  1.94406944e-01  9.96944640e-02 -7.19911132e-03\n   1.24393828e-01]]", "max_iter": 2000, "tol": 1e-06, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.22307479 -0.33988667 -0.38656131 -0.54926713  0.01440541\n   -0.15308627  0.41209374  0.4636308   0.43139786  0.30831515\n   -0.0453081   0.24469466 -0.03549914 -0.13628381  0.51946262\n   -0.25731759  0.46372986 -0.24309141 -0.08722052 -1.12825278\n    0.98464112]\n  [-0.05012726 -0.2945363   0.06390506  0.56932036  0.31439601\n   -0.34709257 -0.32434243 -0.20371628 -0.49331776 -0.50034862\n    0.10216716  0.00666238  0.3289471   0.15522586 -0.87821819\n    0.23517932 -0.177261    0.04536158 -0.00721389  1.0916591\n   -1.35282664]\n  [ 0.27320205  0.63442297  0.32265626 -0.02005322 -0.32880142\n    0.50017884 -0.08775131 -0.25991452  0.0619199   0.19203347\n   -0.05685906 -0.25135704 -0.29344796 -0.01894205  0.35875557\n    0.02213827 -0.28646886  0.19772983  0.09443441  0.03659368\n    0.36818551]]]", "[1.]", "[51]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0 0\n 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.32196113 -0.23109397 -0.40423534 -0.45192659  0.0717235\n   -0.26172625  0.26194712  0.31545034  0.36686657  0.24919692\n   -0.04641722  0.16916606  0.15010308  0.00960189  0.23434059\n   -0.15058261  0.28968831 -0.21556027  0.0051049  -0.94437178\n    0.8183222 ]\n  [-0.14359281 -0.50023112  0.12612534  0.22962026 -0.00752177\n   -0.06665268 -0.03039389 -0.19905982 -0.53101871 -0.30537814\n    0.38986162  0.15054044  0.19535893  0.15738041 -0.55812445\n    0.02329878  0.08147111 -0.03047776  0.08583608  0.97863546\n   -0.80261735]\n  [ 0.46555393  0.73132509  0.27810999  0.22230633 -0.06420173\n    0.32837893 -0.23155324 -0.11639051  0.16415214  0.05618122\n   -0.3434444  -0.3197065  -0.34546202 -0.1669823   0.32378387\n    0.12728383 -0.37115943  0.24603803 -0.09094098 -0.03426368\n   -0.01570486]]]", "[1.]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 2 1 1 1 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0\n 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.14883031 -0.42072986 -0.301124   -0.25889327 -0.19778816\n   -0.08280013  0.48389511  0.55326224  0.30116916  0.23671629\n    0.09419573  0.10351592 -0.0351116  -0.17593664  0.46769792\n   -0.21863223  0.3139905  -0.12655375 -0.03322862 -1.09987632\n    0.70208909]\n  [-0.1645667  -0.05294055  0.03009549  0.35171138  0.35253848\n   -0.19720926 -0.4566053  -0.42044906 -0.27602524 -0.17646762\n   -0.26316165  0.13877658  0.4193302   0.08241326 -0.84164594\n    0.07400714 -0.0964463  -0.1478646  -0.34540251  0.99516927\n   -1.0321688 ]\n  [ 0.31339701  0.47367041  0.27102851 -0.09281811 -0.15475033\n    0.28000938 -0.02728981 -0.13281318 -0.02514392 -0.06024867\n    0.16896592 -0.24229249 -0.3842186   0.09352338  0.37394802\n    0.14462509 -0.2175442   0.27441835  0.37863113  0.10470705\n    0.33007971]]]", "[1.]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 0 1 2 1 1 2 0 1 1 2 2 1 2 0 0\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-7.84705634e-02 -3.56724901e-01 -3.72210758e-01 -4.89796476e-01\n    1.21297924e-01 -1.18049932e-01  3.83615868e-01  2.46426351e-01\n    3.55798793e-01  3.27337597e-01 -8.71644582e-04  2.33478580e-01\n   -9.04073155e-03 -3.99848871e-02  4.26800935e-01 -1.97626921e-01\n    3.85556792e-01 -1.81219281e-01 -2.74489352e-01 -9.68937434e-01\n    1.14833752e+00]\n  [ 6.49074855e-02 -2.35583673e-01 -1.28268572e-02  4.14806834e-01\n    4.66482054e-01 -1.14519790e-01 -3.24230461e-01 -3.13770152e-01\n   -4.53899767e-01 -2.23837252e-01  5.71333752e-02  8.76253949e-02\n    5.28229928e-01  2.62131320e-01 -6.02561783e-01  2.14852000e-01\n   -1.34336734e-01  1.22453438e-01  1.47700988e-01  1.04130468e+00\n   -5.25638912e-01]\n  [ 1.35630779e-02  5.92308574e-01  3.85037615e-01  7.49896422e-02\n   -5.87779978e-01  2.32569722e-01 -5.93854066e-02  6.73438006e-02\n    9.81009734e-02 -1.03500345e-01 -5.62617306e-02 -3.21103975e-01\n   -5.19189196e-01 -2.22146433e-01  1.75760848e-01 -1.72250789e-02\n   -2.51220058e-01  5.87658431e-02  1.26788364e-01 -7.23672437e-02\n   -6.22698610e-01]]]", "[1.]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 0 0 0 1 1 2 1 2\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.20583137 -0.34257274 -0.27974041 -0.46793958  0.06506113\n    0.03386126  0.31502532  0.46117866  0.40683291  0.05040187\n    0.02634675  0.32184002 -0.0861574  -0.07560544  0.5077187\n   -0.21564564  0.33895893 -0.20154651  0.19335275 -0.93818711\n    0.70571424]\n  [-0.12614382 -0.33946366 -0.02848311  0.55724107  0.24239552\n   -0.36173864 -0.32021431  0.04939197 -0.4741661  -0.60706145\n    0.11424233 -0.03043304  0.49172111  0.01780309 -0.66498465\n    0.12764046 -0.15176783  0.0205767  -0.07044656  0.91656924\n   -1.19694962]\n  [ 0.33197518  0.6820364   0.30822352 -0.08930149 -0.30745666\n    0.32787738  0.00518899 -0.51057062  0.0673332   0.55665958\n   -0.14058908 -0.29140698 -0.40556372  0.05780234  0.15726595\n    0.08800518 -0.1871911   0.18096981 -0.12290619  0.02161787\n    0.49123539]]]", "[1.]", "[13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 2 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.31483678 -0.20319487 -0.43189758 -0.34761497  0.30933418\n   -0.23583281  0.24233663  0.46080451  0.25089737  0.21816916\n   -0.06040049  0.19642429 -0.24354555 -0.0796698   0.42514059\n   -0.42579372  0.42588391 -0.24494333 -0.25231146 -0.9500018\n    0.77098392]\n  [-0.0078172  -0.35322053  0.05056298  0.56342451  0.29846964\n   -0.20160912 -0.24954549 -0.16707271 -0.46435587 -0.45826544\n    0.08102362  0.03548326  0.37006061  0.17094783 -0.90007652\n    0.27076809 -0.16483128  0.03309831  0.04536333  1.00567054\n   -1.20970172]\n  [ 0.32265398  0.55641541  0.3813346  -0.21580954 -0.60780382\n    0.43744193  0.00720886 -0.2937318   0.21345851  0.24009628\n   -0.02062313 -0.23190755 -0.12651506 -0.09127803  0.47493593\n    0.15502563 -0.26105264  0.21184501  0.20694813 -0.05566874\n    0.4387178 ]]]", "[1.]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[[-2.13986030e-01 -3.10863270e-01 -3.57841617e-01 -4.03234179e-01\n   7.39257167e-02 -1.32909572e-01  3.37364010e-01  4.07424419e-01\n   3.36312959e-01  2.16364368e-01  2.57062391e-03  2.04884973e-01\n  -4.47504369e-02 -7.23189731e-02  4.12339745e-01 -2.41656224e-01\n   3.50815691e-01 -1.93964628e-01 -7.23143562e-02 -9.80274890e-01\n   8.29089394e-01]\n [-7.54426077e-02 -2.96287906e-01  3.30947703e-02  4.23360811e-01\n   2.70472786e-01 -1.88345898e-01 -2.76197890e-01 -2.10191956e-01\n  -4.39893138e-01 -3.54201981e-01  7.58198602e-02  7.63985274e-02\n   4.00940156e-01  1.38135181e-01 -7.13478669e-01  1.42113294e-01\n  -9.31822054e-02 -4.42781706e-04 -2.73897341e-02  9.87469839e-01\n  -9.53415280e-01]\n [ 2.89428638e-01  6.07151176e-01  3.24746846e-01 -2.01266324e-02\n  -3.44398503e-01  3.21255470e-01 -6.11661206e-02 -1.97232463e-01\n   1.03580180e-01  1.37837613e-01 -7.83904841e-02 -2.81283500e-01\n  -3.56189720e-01 -6.58162074e-02  3.01138923e-01  9.95429299e-02\n  -2.57633486e-01  1.94407410e-01  9.97040902e-02 -7.19494886e-03\n   1.24325886e-01]]", "max_iter": 2000, "tol": 1e-06, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.22308136 -0.33988283 -0.38656521 -0.54926918  0.01439805\n   -0.15304918  0.41210089  0.46362754  0.43140122  0.3083571\n   -0.04531251  0.24471372 -0.03552088 -0.13627646  0.51949403\n   -0.25731967  0.4637352  -0.24309679 -0.08724103 -1.12828004\n    0.98467727]\n  [-0.05011101 -0.29455455  0.06390371  0.56935675  0.31438474\n   -0.34708844 -0.32435432 -0.203749   -0.4933281  -0.50038126\n    0.10218271  0.00664547  0.32894225  0.15521403 -0.87824157\n    0.23514526 -0.17727587  0.0453717  -0.00717287  1.09167203\n   -1.35292798]\n  [ 0.27319237  0.63443738  0.3226615  -0.02008757 -0.32878279\n    0.50013761 -0.08774657 -0.25987855  0.06192688  0.19202416\n   -0.05687021 -0.25135919 -0.29342137 -0.01893757  0.35874754\n    0.02217441 -0.28645934  0.19772508  0.09441391  0.036608\n    0.36825071]]]", "[1.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0 0\n 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.32198057 -0.23114926 -0.40418524 -0.45185501  0.07177675\n   -0.2618092   0.26198123  0.31542208  0.36687515  0.24923997\n   -0.04639735  0.16915103  0.15012066  0.00955995  0.23432163\n   -0.15056987  0.28964757 -0.21553537  0.00507787 -0.94437634\n    0.81784047]\n  [-0.14360772 -0.5001483   0.12598715  0.22945863 -0.00762166\n   -0.06648573 -0.0304638  -0.19900528 -0.53102026 -0.30546635\n    0.38985975  0.15057923  0.1953537   0.1574805  -0.55808901\n    0.02326393  0.08155793 -0.03054103  0.08584665  0.97858139\n   -0.80157399]\n  [ 0.46558829  0.73129755  0.27819809  0.22239638 -0.06415509\n    0.32829493 -0.23151743 -0.1164168   0.16414511  0.05622639\n   -0.3434624  -0.31973026 -0.34547436 -0.16704046  0.32376739\n    0.12730594 -0.3712055   0.2460764  -0.09092451 -0.03420505\n   -0.01626649]]]", "[1.]", "[1068]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 2 1 1 1 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0\n 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.14879659 -0.42083217 -0.30109993 -0.25877275 -0.19779778\n   -0.08284053  0.48387867  0.5532926   0.30119202  0.23676198\n    0.09416383  0.10346166 -0.03508666 -0.17605767  0.46762041\n   -0.2185884   0.31390706 -0.1265288  -0.03323842 -1.09983106\n    0.70141861]\n  [-0.16469438 -0.05279985  0.03005357  0.35155593  0.35261155\n   -0.19712122 -0.45653244 -0.42041828 -0.27603268 -0.1765186\n   -0.26315476  0.13887502  0.41932795  0.08259803 -0.84151134\n    0.07400252 -0.09630433 -0.14789226 -0.34544595  0.99501726\n   -1.03111896]\n  [ 0.31349097  0.47363202  0.27104636 -0.09278318 -0.15481377\n    0.27996175 -0.02734622 -0.13287432 -0.02515934 -0.06024338\n    0.16899093 -0.24233668 -0.38424129  0.09345964  0.37389093\n    0.14458589 -0.21760273  0.27442106  0.37868438  0.1048138\n    0.32970035]]]", "[1.]", "[1125]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 0 1 2 1 1 2 0 1 1 2 2 1 2 0 0\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-7.84605558e-02 -3.56759547e-01 -3.72197598e-01 -4.89744154e-01\n    1.21285814e-01 -1.18096640e-01  3.83633247e-01  2.46457562e-01\n    3.55795955e-01  3.27323125e-01 -8.84616355e-04  2.33461134e-01\n   -9.04609550e-03 -4.00262907e-02  4.26794194e-01 -1.97529410e-01\n    3.85533857e-01 -1.81209095e-01 -2.74523284e-01 -9.68938868e-01\n    1.14800128e+00]\n  [ 6.49161222e-02 -2.35543064e-01 -1.28243215e-02  4.14751580e-01\n    4.66475390e-01 -1.14506012e-01 -3.24222336e-01 -3.13768623e-01\n   -4.53891287e-01 -2.23844907e-01  5.71336878e-02  8.76342814e-02\n    5.28252045e-01  2.62158089e-01 -6.02531016e-01  2.14800869e-01\n   -1.34308020e-01  1.22452448e-01  1.47705975e-01  1.04129331e+00\n   -5.25431538e-01]\n  [ 1.35444336e-02  5.92302611e-01  3.85021920e-01  7.49925740e-02\n   -5.87761204e-01  2.32602653e-01 -5.94109106e-02  6.73110615e-02\n    9.80953317e-02 -1.03478218e-01 -5.62490715e-02 -3.21095415e-01\n   -5.19205949e-01 -2.22131798e-01  1.75736822e-01 -1.72714585e-02\n   -2.51225837e-01  5.87566473e-02  1.26817308e-01 -7.23544373e-02\n   -6.22569739e-01]]]", "[1.]", "[749]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 0 0 0 1 1 2 1 2\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.20587367 -0.34266021 -0.27973373 -0.46783024  0.06506153\n    0.03378739  0.31503951  0.46121765  0.40683757  0.05039013\n    0.02633469  0.32183705 -0.08614032 -0.0756446   0.50771629\n   -0.21561644  0.33885368 -0.20152202  0.19334037 -0.93820318\n    0.70518515]\n  [-0.1261167  -0.33939042 -0.02849665  0.55714333  0.24240221\n   -0.36166587 -0.32020531  0.04942378 -0.47416818 -0.60706939\n    0.11423182 -0.03040408  0.49168345  0.01784264 -0.66491211\n    0.1276333  -0.15169181  0.02055366 -0.07044993  0.91654664\n   -1.19644098]\n  [ 0.33199037  0.68205063  0.30823039 -0.08931309 -0.30746374\n    0.32787848  0.0051658  -0.51064143  0.06733061  0.55667926\n   -0.14056651 -0.29143297 -0.40554313  0.05780196  0.15719582\n    0.08798314 -0.18716187  0.18096836 -0.12289043  0.02165654\n    0.49125583]]]", "[1.]", "[816]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 2 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.31486994 -0.2032617  -0.43189012 -0.34749906  0.30939468\n   -0.23587708  0.24232657  0.46078124  0.25089938  0.21816636\n   -0.06038831  0.1963724  -0.24352911 -0.07973971  0.42508455\n   -0.42577078  0.42580654 -0.24492409 -0.25229897 -0.95001179\n    0.77047871]\n  [-0.00781128 -0.35313924  0.0505291   0.56329521  0.29843012\n   -0.2015604  -0.24950801 -0.16697463 -0.46436845 -0.45829472\n    0.08096778  0.03557488  0.37001424  0.17104908 -0.8999698\n    0.2707707  -0.16471925  0.03306738  0.04531038  1.00564265\n   -1.20899773]\n  [ 0.32268123  0.55640095  0.38136102 -0.21579615 -0.6078248\n    0.43743748  0.00718144 -0.29380661  0.21346907  0.24012836\n   -0.02057947 -0.23194728 -0.12648513 -0.09130936  0.47488526\n    0.15500008 -0.26108729  0.21185672  0.20698859 -0.05563085\n    0.43851903]]]", "[1.]", "[914]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[[-2.13996265e-01 -3.10932578e-01 -3.57821324e-01 -4.03140243e-01\n   7.39441985e-02 -1.32967212e-01  3.37371844e-01  4.07434228e-01\n   3.36320015e-01  2.16376313e-01  2.56564775e-03  2.04856656e-01\n  -4.47363059e-02 -7.23816646e-02  4.12307414e-01 -2.41614980e-01\n   3.50749741e-01 -1.93943876e-01 -7.23284899e-02 -9.80272248e-01\n   8.28584843e-01]\n [-7.54627915e-02 -2.96204175e-01  3.30497690e-02  4.23240937e-01\n   2.70459524e-01 -1.88267847e-01 -2.76186380e-01 -2.10148607e-01\n  -4.39896172e-01 -3.54238794e-01  7.58076561e-02  7.64518667e-02\n   4.00926276e-01  1.38225668e-01 -7.13402657e-01  1.42094264e-01\n  -9.30930955e-02 -4.71961161e-04 -2.74065765e-02  9.87416246e-01\n  -9.52712639e-01]\n [ 2.89459056e-01  6.07136752e-01  3.24771555e-01 -2.01006939e-02\n  -3.44403722e-01  3.21235059e-01 -6.11854642e-02 -1.97285621e-01\n   1.03576158e-01  1.37862482e-01 -7.83733039e-02 -2.81308522e-01\n  -3.56189970e-01 -6.58440033e-02  3.01095243e-01  9.95207163e-02\n  -2.57656645e-01  1.94415837e-01  9.97350665e-02 -7.14399786e-03\n   1.24127796e-01]]", "max_iter": 2000, "tol": 1e-06, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.22311055 -0.33996313 -0.38654679 -0.5491546   0.01441513\n   -0.15309187  0.41211054  0.46360783  0.43140684  0.30838325\n   -0.04531956  0.24467817 -0.03550775 -0.13634944  0.51945765\n   -0.25726144  0.46365866 -0.24307236 -0.08724148 -1.12828356\n    0.98415024]\n  [-0.05010275 -0.29446798  0.0638747   0.5692193   0.31436561\n   -0.34704087 -0.32432185 -0.20367074 -0.49332684 -0.50041677\n    0.1021433   0.00671083  0.32891228  0.15529951 -0.87814447\n    0.23511192 -0.17717824  0.04534355 -0.00720924  1.09163202\n   -1.35226446]\n  [ 0.2732133   0.63443111  0.32267209 -0.0200647  -0.32878074\n    0.50013275 -0.08778868 -0.2599371   0.06192     0.19203352\n   -0.05682374 -0.251389   -0.29340453 -0.01895007  0.35868681\n    0.02214952 -0.28648042  0.19772881  0.09445072  0.03665154\n    0.36811422]]]", "[1.]", "[750]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0 0\n 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.322001   -0.23120934 -0.40413138 -0.45177679  0.07183376\n   -0.26189998  0.2620191   0.31539379  0.36688539  0.24928524\n   -0.0463784   0.16913425  0.15013928  0.0095135   0.23430214\n   -0.15055337  0.28960202 -0.21550792  0.00504931 -0.94438283\n    0.81731439]\n  [-0.14362233 -0.50005989  0.12584231  0.22928797 -0.00772641\n   -0.06631024 -0.03053787 -0.19894779 -0.53102216 -0.30555917\n    0.38985774  0.15061988  0.19534683  0.15758632 -0.55805222\n    0.0232271   0.08164947 -0.03060758  0.08585862  0.97852587\n   -0.80047296]\n  [ 0.46562333  0.73126923  0.27828907  0.22248882 -0.06410735\n    0.32821022 -0.23148123 -0.116446    0.16413677  0.05627394\n   -0.34347935 -0.31975413 -0.34548611 -0.16709983  0.32375008\n    0.12732627 -0.37125149  0.2461155  -0.09090793 -0.03414304\n   -0.01684142]]]", "[1.]", "[1936]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 2 1 1 1 2 2 1 2 0 0 1 1 0 2 0 1 1 2 2 1 2 0 0 2 0\n 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.1487457  -0.42098761 -0.30106334 -0.25859031 -0.19781182\n   -0.08290204  0.48385453  0.55333924  0.30122701  0.23683088\n    0.09411507  0.10337897 -0.03504912 -0.17624196  0.46750472\n   -0.21852162  0.31377975 -0.12649049 -0.0332528  -1.09976315\n    0.70039766]\n  [-0.16488512 -0.05258761  0.02999082  0.35132174  0.35272051\n   -0.19698824 -0.4564227  -0.42037209 -0.27604417 -0.17659546\n   -0.26314401  0.13902343  0.41932372  0.08287656 -0.84130844\n    0.0739953  -0.09609056 -0.147934   -0.34551143  0.99478867\n   -1.02953423]\n  [ 0.31363081  0.47357522  0.27107252 -0.09273143 -0.15490869\n    0.27989028 -0.02743182 -0.13296715 -0.02518284 -0.06023543\n    0.16902894 -0.2424024  -0.38427461  0.09336541  0.37380371\n    0.14452632 -0.21768919  0.27442449  0.37876422  0.10497448\n    0.32913657]]]", "[1.]", "[2000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 0 1 2 1 1 2 0 1 1 2 2 1 2 0 0\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-7.84494590e-02 -3.56797378e-01 -3.72183442e-01 -4.89687218e-01\n    1.21272961e-01 -1.18146201e-01  3.83652019e-01  2.46490911e-01\n    3.55792917e-01  3.27307942e-01 -8.98617521e-04  2.33442392e-01\n   -9.05145373e-03 -4.00709158e-02  4.26786690e-01 -1.97425331e-01\n    3.85508842e-01 -1.81197904e-01 -2.74559260e-01 -9.68940401e-01\n    1.14763723e+00]\n  [ 6.49244912e-02 -2.35498990e-01 -1.28217836e-02  4.14691468e-01\n    4.66468392e-01 -1.14490973e-01 -3.24213530e-01 -3.13766991e-01\n   -4.53882043e-01 -2.23852987e-01  5.71339790e-02  8.76441909e-02\n    5.28275415e-01  2.62187258e-01 -6.02497421e-01  2.14746030e-01\n   -1.34276783e-01  1.22451127e-01  1.47711271e-01  1.04128060e+00\n   -5.25204225e-01]\n  [ 1.35249679e-02  5.92296367e-01  3.85005226e-01  7.49957504e-02\n   -5.87741353e-01  2.32637174e-01 -5.94384892e-02  6.72760801e-02\n    9.80891258e-02 -1.03454955e-01 -5.62353615e-02 -3.21086582e-01\n   -5.19223961e-01 -2.22116342e-01  1.75710731e-01 -1.73206987e-02\n   -2.51232059e-01  5.87467764e-02  1.26847988e-01 -7.23402024e-02\n   -6.22433004e-01]]]", "[1.]", "[1396]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 0 0 0 1 1 2 1 2\n 2 0 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.20591708 -0.34275117 -0.27972669 -0.46771698  0.06506246\n    0.03371123  0.31505458  0.46125771  0.40684268  0.050378\n    0.02632206  0.32183399 -0.0861227  -0.07568546  0.50771402\n   -0.21558613  0.33874451 -0.20149658  0.19332767 -0.93822016\n    0.70463389]\n  [-0.12608865 -0.33931433 -0.02851086  0.55704205  0.24240865\n   -0.36159081 -0.32019597  0.04945675 -0.4741705  -0.60707735\n    0.11422097 -0.03037413  0.49164428  0.01788405 -0.66483696\n    0.12762564 -0.15161293  0.02053002 -0.07045336  0.91652321\n   -1.19591185]\n  [ 0.33200574  0.68206551  0.30823755 -0.08932507 -0.30747111\n    0.32787959  0.00514139 -0.51071446  0.06732782  0.55669935\n   -0.14054303 -0.29145986 -0.40552158  0.05780141  0.15712294\n    0.0879605  -0.18713158  0.18096656 -0.12287431  0.02169695\n    0.49127796]]]", "[1.]", "[1525]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 2 0 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 2000, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 1e-06, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null}}, "return": ["[[[-0.31490607 -0.20333532 -0.43188192 -0.34737201  0.30946105\n   -0.23592574  0.24231592  0.46075594  0.25090159  0.21816308\n   -0.06037496  0.19631552 -0.24351094 -0.07981661  0.42502347\n   -0.4257456   0.42572179 -0.24490297 -0.25228549 -0.95002291\n    0.76992291]\n  [-0.00780504 -0.35305005  0.05049215  0.56315369  0.29838676\n   -0.2015066  -0.24946713 -0.16686775 -0.46438196 -0.45832643\n    0.08090684  0.03567509  0.36996348  0.17115989 -0.8998531\n    0.27077331 -0.16459679  0.03303348  0.04525302  1.00561176\n   -1.20822572]\n  [ 0.3227111   0.55638537  0.38138977 -0.21578167 -0.60784781\n    0.43743234  0.00715122 -0.2938882   0.21348037  0.24016334\n   -0.02053188 -0.23199062 -0.12645254 -0.09134328  0.47482963\n    0.15497229 -0.261125    0.21186949  0.20703247 -0.05558886\n    0.43830282]]]", "[1.]", "[1683]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 8.75092505e-01  2.00422258e+00  6.33711104e+00  1.96587784e+00\n  -4.18724348e-01 -8.61743532e-01  4.76572321e-01 -9.84859281e-01\n   3.45132889e+00  1.51464186e+00  1.69479365e+00  1.95171339e-01\n  -3.46702157e-01 -1.84606633e-01  2.13898721e+00  7.11365794e-01\n  -2.07235499e+00  3.96150644e+00 -6.87565192e-01 -3.25702321e-01]\n [ 1.37204521e+00  3.05745435e+00 -1.06559923e+00 -8.88936306e-01\n  -7.24315098e-03 -5.33776501e-01 -5.03102692e+00  2.76365415e-01\n   2.39762751e-01 -1.18589639e+00  1.83807729e+00 -1.91437729e+00\n   1.74665956e-01 -7.16316130e-01 -2.31023673e+00 -1.40883614e+00\n  -6.27485329e-02 -1.25532984e+00  1.13951624e+00  1.28878743e+00]\n [ 5.68155177e-01  1.61373134e+00  3.80775733e+00 -2.09102779e+00\n  -1.23554773e+00  5.47584173e-01  1.27296915e-01 -2.56096412e-01\n  -1.64522660e+00 -6.79174767e-01  4.11329685e+00  2.57448232e-01\n  -2.17950410e-01 -9.51100574e-01 -2.44034617e+00 -5.17816775e-01\n  -1.01230527e+00 -4.77192207e+00  4.47970273e-01  1.96198762e+00]\n [ 6.03543724e-01  5.14489960e-01  3.24164283e+00  1.28121790e+00\n   5.66162777e-01 -1.50657565e+00  6.55370742e-01 -4.67351283e-01\n   2.00948504e+00 -2.94425109e-01 -1.67134498e+00  8.37880412e-01\n  -1.09739833e-02 -1.35859215e+00 -5.41897278e-01  7.78666881e-01\n  -2.06497923e+00 -3.26342468e-01  1.07588456e+00 -3.16577753e-01]\n [ 1.13202842e+00  5.86289471e-01 -7.16340120e-03  6.79226560e-01\n   1.65774691e+00  7.14584187e-01  8.86219693e-01  1.68528461e+00\n  -3.42057533e+00  4.41534009e-01 -2.12363261e-01 -6.09051488e-01\n  -5.99489119e-01 -3.75695273e+00  3.84209683e+00  3.91086162e-01\n   4.19117479e-01 -3.43537646e+00 -4.47660679e-01 -8.21411621e-02]\n [-5.75767902e-01  1.15938267e+00 -4.10514747e+00 -1.29698831e+00\n   5.96687779e-01  1.04562595e+00 -1.87390110e+00  1.65080687e-01\n  -3.62488042e-01  6.28205254e-01 -2.23796290e-01 -6.09940250e-01\n   9.66481353e-01  7.24336587e-01  4.34469331e+00  7.60782600e-01\n  -5.77568122e-01  3.38002210e-01 -1.33892235e-01 -2.48663492e+00]\n [ 1.28723480e-02 -9.08907654e-01 -6.06263389e+00 -1.63460419e+00\n  -5.47626859e-01  2.61271014e-01 -1.93788630e-01 -1.05937147e+00\n  -4.84543612e+00  2.80526293e-01 -1.79828904e+00 -4.41953934e+00\n   6.91713421e-01 -2.63778298e+00 -1.59632994e+00  6.10642551e-01\n  -1.64344221e+00 -4.08820506e+00  3.69297380e-01  1.26954989e+00]\n [ 5.42708444e-01 -3.51555184e+00 -2.94234026e-01 -1.39757695e+00\n   3.53540107e-01 -3.99352841e-01 -2.01384643e+00  6.75381363e-01\n   4.01349026e+00  3.86551672e-01 -3.75341718e+00  1.50509136e+00\n  -5.02940554e-01 -5.40486217e+00  1.88844779e+00  1.03034223e+00\n   1.03377662e+00 -1.08561659e-01 -2.56005329e-01  1.59084639e+00]\n [ 1.07737976e+00 -1.51257977e+00  3.01329221e-01  1.10201455e+00\n   5.79218276e-01 -5.07083010e-01 -1.77864707e+00 -1.87769771e+00\n   1.02172437e+00 -9.26541726e-01  6.04391772e-01  2.16295828e+00\n   1.49302147e+00 -4.22376189e-01  1.15477333e-01  1.46035095e+00\n  -3.23046434e+00 -1.62650184e+00 -7.57663035e-01 -3.98158488e-01]\n [ 1.38609134e+00  5.35366590e-01  6.62652560e+00  4.03582611e+00\n   1.20285171e+00  5.35408394e-01  1.01788934e+00 -5.00089690e-01\n   4.22718997e+00  3.63254755e-02  3.09542750e-01  1.51264646e+00\n  -1.51082149e+00  4.10220815e-01 -1.19739749e+00 -1.25813641e+00\n  -8.83071852e-01  4.10126605e+00 -1.23405636e+00 -6.00475973e-01]\n [-4.50844088e-02  1.54845745e-01  8.31223036e+00  3.14536319e+00\n   1.50586128e+00  9.95111982e-01  1.27008552e+00  8.30373762e-01\n   3.69637833e+00 -1.04726704e+00 -1.58678555e+00  2.36096900e+00\n   4.47634113e-01 -1.48689842e+00 -1.66019732e+00  5.13665567e-01\n   4.49604461e-01  2.97054639e+00  1.03897256e+00  3.39133176e+00]\n [ 1.29684299e+00 -2.82665835e+00  1.55465553e+00  3.06055620e+00\n   1.03831023e+00 -1.79771052e+00 -1.74791663e-01 -1.13707043e+00\n   2.09168457e+00 -1.23075620e+00 -7.16450233e-01  2.03519470e+00\n  -1.36714098e+00 -2.57110124e+00  2.79798910e-01 -1.00158491e+00\n   1.74825886e+00  7.12543793e-01  3.24271638e-01 -7.70937014e-01]\n [-1.03287888e+00 -7.57123488e-01  2.08225959e+00  6.29276741e-01\n  -7.71888699e-01 -3.68903106e-02  2.83545624e+00  7.82090734e-01\n  -2.21101014e+00  5.71396484e-01 -8.13691977e-01 -1.84613393e+00\n   1.05623998e+00 -1.03394690e+00 -1.95244381e-01  1.77093095e-01\n  -2.01348461e+00  8.40814784e-01  2.26935956e+00  3.59695794e+00]\n [-1.43223234e-01 -2.03888114e+00 -7.72486090e-01  3.49392329e+00\n   2.60087917e+00 -6.30947375e-01  1.31398251e+00 -1.42027726e+00\n  -6.96832934e-01  9.52040078e-01  7.94678009e-01  1.97863808e+00\n  -5.83134624e-01  2.67953487e+00 -8.82156477e-01 -3.04736481e-01\n   3.17985900e-01  8.32146213e-01 -3.79564509e-01 -2.55121124e+00]\n [-8.22190365e-01 -1.15114240e+00 -8.59884006e-01  4.48336290e+00\n   2.88136903e-01 -7.91917510e-01  4.02328650e+00 -2.19909856e-01\n  -3.00076276e+00 -6.55083875e-01  8.33201963e-01 -3.31906478e+00\n   5.46756143e-01  1.68407298e+00  1.75865845e-01  5.66093938e-01\n   2.66725727e+00  5.30693477e+00  7.06380551e-01 -1.16122126e+00]\n [-7.36162423e-01 -4.95883175e-01  4.55401724e+00 -8.10691922e-01\n  -1.91983889e-01  9.36565518e-01  1.65141986e+00  6.66418270e-01\n  -1.93482755e-01 -7.55071959e-01  1.30281142e-01  1.27931451e+00\n   1.17768213e+00 -1.18673679e-01 -4.64271455e-01  4.23367608e-01\n  -4.24508150e+00 -9.04440865e-01  1.84867083e+00  4.14761033e+00]\n [-1.97219866e+00  3.29367264e+00  7.70947155e+00  2.33082467e+00\n  -7.98660853e-01  1.64066333e+00  2.17958684e-01 -1.69292331e-02\n   1.84768188e+00 -2.01612635e+00 -1.45220691e+00  1.98005236e+00\n   8.93054010e-01 -3.25870273e+00 -2.04917829e+00  9.77581731e-01\n  -5.92172760e-01 -3.03200980e+00 -1.63268601e-02  1.13037770e+00]\n [-1.24126964e+00 -3.00905322e+00 -2.88445386e+00 -2.28361220e+00\n   8.99569806e-01  7.71139380e-02  2.41990950e-01  2.91161640e+00\n   3.88939308e+00 -1.87031280e-01  1.97174289e+00 -5.18480282e+00\n  -2.00495362e-01  2.15908638e+00 -2.59313260e+00 -5.40930189e-01\n  -7.54075087e-01  8.14336894e+00 -6.50258832e-01 -5.13335826e-01]\n [ 6.99045602e-01  8.78189688e-01  2.13631610e+00  1.92163650e+00\n  -2.05367588e+00 -1.73945068e+00  8.06859139e-01  2.95930596e-02\n  -1.16563464e+00  3.67954064e-01  1.08926548e+00 -1.21338952e+00\n  -4.46245601e-01 -1.59472866e+00  1.70520707e+00  5.60585568e-02\n  -1.98940848e-01  6.27946024e-01  3.82377041e-01  3.28709498e-01]\n [-1.74971277e+00  1.69317022e+00  2.41361080e+00  1.68512330e+00\n  -6.98597551e-02 -1.15146565e+00  6.66752440e-01 -2.83185876e-01\n  -5.37509377e-01 -1.22614079e+00  1.01133364e+00  2.42209131e+00\n   9.96739464e-01  8.11294524e-01  1.57042854e+00  4.83376747e-01\n   1.08655961e+00 -1.23791373e+00 -5.49801958e-01 -1.68474490e+00]\n [ 2.19731932e-01  1.97808951e+00  6.66838053e+00  1.53298411e+00\n  -1.04739981e+00  4.80105786e-01 -1.61837358e+00 -7.48786385e-01\n   1.15962572e+00 -2.61459686e+00  2.69067814e+00  2.00301812e+00\n   2.48994764e-01  1.30722967e+00 -1.09958490e+00 -1.15052357e-01\n  -2.52995663e+00  1.46430410e+00 -2.19783936e-01  4.66539650e+00]\n [ 1.01713417e+00  1.69019576e+00  6.80211178e+00  1.41413186e+00\n  -1.39600541e+00  4.23278418e-01  3.23915607e+00 -8.64838207e-02\n   2.23720831e-01 -7.58437461e-01  1.07062587e+00  2.24130047e+00\n  -4.20025067e-01 -1.31924757e+00 -4.11429469e+00  7.54799515e-01\n  -4.01834082e+00 -6.68427178e+00 -1.78410498e+00 -2.58456118e+00]\n [ 5.14897658e-01 -5.35162380e-01 -4.37298680e-01 -4.55370374e-01\n   1.06095689e-01  3.90645782e-02  5.49332401e-01 -5.43854978e-01\n   8.26527184e-02  3.68067430e-01 -1.45383673e+00 -4.83764231e-01\n  -1.28908453e+00  9.04855767e-02 -3.44050121e-01 -4.06449839e-01\n  -3.04125084e+00 -2.12975348e-01  1.38250865e+00  4.73561211e-01]\n [-1.05028381e+00 -1.16386054e+00  3.00972968e+00  1.22800732e+00\n  -3.19223384e-01 -5.59799314e-01 -3.71672754e-01 -2.66324885e-01\n   1.79179709e+00 -3.56100817e-01  9.00331097e-01  2.06499984e+00\n   1.22688240e-01 -7.51474570e-01 -1.80563261e+00 -2.98010104e-01\n   1.35570032e-01 -4.47363048e-01 -1.15213442e+00  6.13629474e-01]\n [-9.97194430e-01 -3.31135695e+00  3.05588102e+00  2.08298364e+00\n   2.06189867e+00 -1.89278136e+00  6.51226392e-01 -5.11389589e-01\n   4.75839821e-01 -6.12107842e-02  3.34859096e+00  1.52982114e+00\n   1.90030973e+00 -1.35051732e+00 -1.93662366e+00 -9.70496819e-02\n   3.39193147e+00  7.48499011e-01 -2.78832071e-01  1.37271813e+00]\n [ 4.30177670e-01 -1.80966199e+00 -1.24774286e+00 -1.73913889e-01\n   1.59820354e+00  3.29686042e-01  6.71829651e+00 -1.93610539e+00\n  -5.29065245e+00 -6.55998102e-01 -3.99642997e+00 -4.24932463e+00\n   2.81422175e-01 -2.96605897e+00 -1.44567634e+00  4.93530616e-01\n  -2.98986507e-01 -2.25292583e+00  5.57408871e-01  1.58839509e+00]\n [ 4.85655601e-01 -3.64301941e+00 -3.45150493e+00  5.53541226e-01\n   2.96060703e-01 -8.76158446e-01 -2.45896518e+00  1.86125222e+00\n   2.93215633e+00 -9.26909137e-01 -2.32343589e+00  2.96271690e-01\n   2.68629115e-01 -1.68593510e+00  1.12617368e+00  1.16046856e-01\n  -1.14758865e-02  2.44302685e+00 -5.71806466e-01 -4.71018664e-01]\n [ 2.15445714e+00  4.16683983e-01  4.37355742e+00  1.23169532e+00\n   1.18053117e+00  2.46473943e-01  3.05117570e+00  2.30256316e-01\n  -1.21918165e+00 -6.17505056e-01  2.29751870e+00  1.84069427e+00\n  -4.41486601e-01  9.81358035e-01  3.43789713e+00  2.31950889e+00\n  -8.53561259e-01  5.10749076e-01 -2.29494174e+00 -4.79117979e-03]\n [ 7.54738350e-01 -2.43346067e+00 -3.29438274e+00  1.15778195e+00\n   1.03999233e+00 -6.78867330e-01 -1.11091584e+00 -6.55632937e-01\n   1.58915231e+00  1.64072448e+00 -2.33654475e+00 -1.84045848e+00\n   1.01121696e+00  1.59235634e+00  2.47004424e+00  1.48465689e-01\n   4.15426227e-01  8.26227240e+00  8.45146327e-01  2.31647674e+00]\n [-2.46070877e-01  1.38423038e+00 -6.24096636e-01  1.51589740e+00\n  -1.48888706e+00 -2.06926336e+00  2.96337644e+00 -1.78399435e+00\n  -4.14482440e+00  1.60430270e+00 -1.18311592e+00 -3.63551283e+00\n   2.76093520e-01  2.67505135e-01 -1.91457309e+00 -5.75444965e-01\n   1.52987601e-02  7.15543690e-02  2.59162278e-01  1.08017988e+00]\n [ 2.20199312e-01  2.05508532e+00  3.10457053e+00  1.98045665e+00\n   1.16548211e+00  1.72196301e-01 -8.41603482e-01  4.78796621e-01\n  -6.78241026e-01 -4.69957120e-01  9.68579345e-01 -1.66736006e+00\n   3.83902949e-01 -4.99089843e+00  2.85070260e-01  2.35776285e-01\n   3.07319569e+00 -1.50621886e+00  1.21247273e+00  6.77485395e-01]\n [-1.73058482e+00 -1.39549390e+00  3.16877289e+00  8.19870925e-01\n   9.31319042e-01 -7.71986179e-01  3.00340806e+00  5.24962009e-01\n   1.32203363e+00  2.96066424e-01 -8.77005110e-01  1.32486707e+00\n  -1.29098578e+00  1.28206680e-01  2.53139361e-01 -1.82612078e+00\n  -1.82771049e+00  9.39713577e-01  1.45263304e+00 -2.45215768e-01]\n [ 2.12613731e+00 -9.38027401e-01 -1.04875793e+00  2.13867246e+00\n   1.02068783e+00 -6.29540686e-01 -8.04121125e-01  1.12508588e+00\n   4.55574203e-01  1.30390745e+00 -2.63984186e+00  1.66700771e+00\n   9.65486150e-01 -1.73528021e+00 -8.21415081e-01 -7.69061999e-01\n   5.93277956e-01 -2.28364408e+00  1.91008636e+00 -1.62713568e+00]\n [ 9.17327873e-01 -2.16786249e+00  3.21230493e+00  1.26373895e+00\n   2.38349317e+00  3.97393610e-01 -1.62029645e+00  5.89173268e-01\n   1.73158339e+00 -2.18011504e-01  1.57986044e+00  3.74187598e+00\n   6.21467363e-02 -2.01653370e+00 -8.02697426e-02  7.16794687e-01\n  -2.30779038e+00 -2.74612349e+00 -9.41599244e-02  6.81456915e-01]\n [ 2.01621342e+00  1.33514493e-01  5.24588123e+00 -4.84229388e-01\n   1.15916021e+00  6.53785882e-01 -3.34877219e-01 -1.17395892e+00\n   1.42468764e+00  5.54094560e-01  2.74275377e+00  1.35650822e+00\n  -1.04548079e+00 -2.62224163e+00 -3.05728883e+00  5.90774163e-01\n   2.53912646e+00 -2.32878193e+00 -8.06564789e-01  1.95850523e+00]\n [ 3.34353529e-01  8.58479415e-01 -6.51076527e+00 -6.50287549e+00\n  -2.24126414e-01 -2.57270916e+00  3.60277363e-01  1.39438990e+00\n  -9.26418465e-01  6.05781692e-01 -1.04888011e+00 -3.72648657e+00\n  -4.33824241e-01  1.36476646e+00 -2.44981926e+00 -3.78271462e-01\n   2.12884629e+00 -1.61833233e+00  2.02736543e+00 -1.60553947e+00]\n [ 3.69075903e-01 -9.35699189e-02  7.40798843e+00  1.03984577e+00\n  -2.32027659e-01  4.15858818e-01  1.57430739e+00 -1.01037013e+00\n   4.66086173e+00  3.63458681e-01  1.26779312e+00 -3.50271465e-01\n  -2.27961244e-01 -2.28440236e+00 -1.49643961e+00  6.39048713e-01\n  -9.69242193e-01  3.02173803e+00  1.12592837e-01  6.51682044e-01]\n [ 8.73457390e-02 -1.98193080e+00 -1.21734393e+00  3.14851681e+00\n   1.81206281e+00 -6.68805835e-01 -8.65118927e-01  9.08892689e-01\n   8.50291216e-01  8.83511758e-01 -1.63055269e-01 -8.47418554e-01\n   1.57931981e-01 -1.14386819e+00 -1.15853709e+00 -2.56480417e-01\n   2.48923652e+00  2.54610604e+00 -1.51757763e+00 -8.03820751e-01]\n [-2.85864430e-01 -6.54569432e-01  8.75823136e-01 -2.05630287e-01\n  -2.96165033e+00 -1.05582611e+00 -2.14733235e+00  1.27665099e-01\n  -6.78672638e-01  9.44193155e-01  2.84881058e+00  5.63148431e-01\n   5.80670040e-01 -9.08281988e-01 -1.06771285e+00  2.11029984e+00\n   1.48548178e+00 -9.03599001e-01 -7.34992079e-01  2.82470700e+00]\n [-9.00837785e-01 -2.85248506e+00  3.23860290e+00 -2.30051567e+00\n   8.08132420e-02 -8.33747294e-01 -3.40014383e-02  5.51353518e-03\n  -2.46119044e+00  8.52810831e-01  6.26217811e+00  2.98215939e+00\n   5.90670459e-01 -2.24640017e+00 -2.70208935e+00 -1.37480817e-01\n  -3.17673040e+00 -8.71893591e+00 -2.08940539e-01  2.06862748e+00]\n [-1.82297435e-01 -7.98936352e-01  1.79370410e+00  1.65207636e+00\n  -1.37640777e+00  3.55988829e-02 -1.93122998e+00 -7.74137614e-01\n   1.81917583e+00  3.88498074e-01  3.98176107e+00 -1.90709741e+00\n  -6.47397276e-01 -2.45958709e-01  3.48315187e+00  6.66578562e-01\n  -8.80798894e-01  6.60058820e+00  1.74230351e-01  1.71021356e+00]\n [ 3.14340703e-01  7.01980783e-01 -5.30423800e+00 -2.15642658e-01\n  -2.91638490e+00  6.73751836e-01 -2.67090902e+00  1.66826442e+00\n   1.13994623e+00 -3.02151822e-01 -5.51513280e+00 -2.61700343e+00\n  -7.29050292e-01  1.24967050e+00  1.02316495e+00  4.31663669e-01\n   5.83162064e-01  5.51204830e+00  1.15099427e-01  2.00487852e+00]\n [-1.80526868e+00  9.81394102e-01  4.40845980e+00 -9.10417984e-01\n  -3.72229360e-01 -8.91494890e-01 -1.61480582e+00 -3.65577869e-01\n  -1.65978458e-01 -6.26600624e-01  2.24101527e+00  9.66168345e-01\n  -4.68795552e-02 -9.48745446e-01  6.12955413e-01 -9.91935611e-01\n  -1.70516420e+00 -3.67848993e-01 -7.43218990e-01  5.34649945e+00]\n [-1.45464871e+00  1.11504286e+00  3.86205088e+00  3.38981249e+00\n   2.74953536e-01  6.34880926e-01  1.33857629e+00  4.10199175e-01\n   8.03642208e-01 -4.97199658e-01 -1.14226412e+00 -4.16969334e+00\n   7.93873479e-02 -4.03616190e+00  1.18650085e+00 -1.01838844e-01\n   1.47828437e-01  4.53675989e+00  7.36334435e-01  1.64279458e+00]\n [ 5.12224203e-01 -8.72052511e-01 -2.25847244e+00 -2.18363053e+00\n  -5.90429784e-01  1.02840116e+00  1.25632934e+00  2.15536279e+00\n  -5.26759788e-01 -7.11894313e-01  7.10783434e-01 -3.48036533e+00\n  -6.89120521e-01 -8.78151498e-01 -1.35498665e+00  2.99387071e-01\n  -1.22076252e-01 -1.87402057e-02 -5.34068472e-01 -9.76868176e-01]\n [ 7.38761126e-01 -5.76079683e-01 -2.81041958e+00  2.30404832e-01\n   1.15007142e+00 -1.42191218e+00  3.45932069e+00 -9.43095185e-01\n  -4.83079556e+00  1.99342859e+00  8.10508585e-01 -5.21606559e+00\n   1.37498153e+00 -2.09056913e+00  7.51195456e-01  7.34371782e-01\n   3.87579129e-01 -7.73213027e-01  7.36379949e-01 -1.09889915e+00]\n [-7.45752189e-01  2.60615948e+00  6.25754723e+00 -1.59869062e+00\n  -9.12971527e-01 -2.98444307e-01  3.11368447e+00 -1.44443023e-02\n   2.17941984e+00 -7.00940135e-02  2.91581152e-01  8.70424350e-01\n   4.36544557e-01  1.91876123e+00  8.64677365e-01  4.26739838e-01\n   3.55223382e-01  2.96808019e+00  1.79932201e-01  1.45063979e+00]\n [-1.10363647e+00 -2.58205015e+00 -1.04719124e+01 -1.21073454e-01\n   2.38480635e-01  1.62122393e+00 -2.65743143e+00  4.63539765e-01\n  -2.43912167e+00 -3.08758556e-01 -1.57265052e+00 -3.49470280e+00\n  -7.61709942e-01  3.80304224e-01  1.01562676e+00 -1.67844418e+00\n  -1.94538364e-01  9.29140986e-01  5.74852362e-01 -2.06930554e+00]\n [ 4.42925896e-01 -9.91757233e-01  2.49924690e+00 -1.91600086e+00\n  -2.17123687e+00 -1.66754276e-01  2.00904041e+00  9.24547083e-02\n   2.94379666e+00 -1.31874592e-01 -6.07487828e-01  1.12457763e+00\n   7.74325103e-01  1.01684858e-01  4.38488689e-01  1.38847400e+00\n  -2.82925616e+00  3.60085752e-01  9.39298762e-01 -8.83029110e-01]\n [ 1.67864515e-01 -1.11713843e+00 -8.45421903e-01 -6.80529797e-01\n  -1.00292551e+00  4.03416893e-02  6.59207931e-02  1.67106186e+00\n   6.10353193e-01  3.35635696e-01 -1.39887236e+00  1.61037507e+00\n  -5.18321382e-01 -9.70243703e-01  1.75697129e+00  1.40244569e+00\n   1.60165742e+00 -7.59144934e-01 -1.58978847e+00 -6.60665286e-01]]", "y": "[2 1 2 2 0 0 1 0 1 2 1 0 1 0 1 1 2 0 2 0 1 2 2 1 1 1 0 2 2 1 2 0 0 1 1 0 2\n 0 1 1 2 2 1 2 0 0 2 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[[-2.14003862e-01 -3.11016164e-01 -3.57797354e-01 -4.03028661e-01\n   7.39636825e-02 -1.33032548e-01  3.37379228e-01  4.07447518e-01\n   3.36329916e-01  2.16393030e-01  2.55703002e-03  2.04821024e-01\n  -4.47189845e-02 -7.24602902e-02  4.12266209e-01 -2.41566410e-01\n   3.50671382e-01 -1.93919173e-01 -7.23441139e-02 -9.80265891e-01\n   8.27981214e-01]\n [-7.54953279e-02 -2.96102175e-01  3.29985279e-02  4.23099382e-01\n   2.70451579e-01 -1.88177373e-01 -2.76167440e-01 -2.10099573e-01\n  -4.39900166e-01 -3.54282279e-01  7.57951054e-02  7.65176930e-02\n   4.00910746e-01  1.38338817e-01 -7.13309627e-01  1.42073476e-01\n  -9.29855181e-02 -5.05390596e-04 -2.74283743e-02  9.87346025e-01\n  -9.51869798e-01]\n [ 2.89499190e-01  6.07118339e-01  3.24798826e-01 -2.00707209e-02\n  -3.44415262e-01  3.21209921e-01 -6.12117877e-02 -1.97347944e-01\n   1.03570250e-01  1.37889250e-01 -7.83521354e-02 -2.81338717e-01\n  -3.56191761e-01 -6.58785272e-02  3.01043418e-01  9.94929344e-02\n  -2.57685864e-01  1.94424563e-01  9.97724882e-02 -7.08013396e-03\n   1.23888584e-01]]", "max_iter": 2000, "tol": 1e-06, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": 183.474574981863, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.22314514 -0.34006367 -0.3865242  -0.54901204  0.01443685\n   -0.1531451   0.41212253  0.46358271  0.43141365  0.3084159\n   -0.04532791  0.24463434 -0.03549052 -0.13643919  0.51941072\n   -0.25719021  0.46356401 -0.24304192 -0.08724176 -1.12828742\n    0.98349322]\n  [-0.05009448 -0.29435935  0.06383809  0.56904689  0.31434158\n   -0.34698068 -0.3242809  -0.20357214 -0.4933251  -0.50046104\n    0.10209345  0.00679316  0.32887385  0.15540639 -0.87802148\n    0.23507044 -0.1770559   0.0453079  -0.00725504  1.09158078\n   -1.35142888]\n  [ 0.27323962  0.63442302  0.32268611 -0.02003485 -0.32877843\n    0.50012578 -0.08784162 -0.26001057  0.06191145  0.19204514\n   -0.05676555 -0.2514275  -0.29338332 -0.0189672   0.35861077\n    0.02211978 -0.28650812  0.19773402  0.0944968   0.03670664\n    0.36793566]]]", "[1.]", "[1336]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.30230275 -0.80328386 -0.51203824  1.23271508 -1.60020786 -0.4380743\n -0.01669425 -0.81753611 -0.84862223  0.6476239  -1.42001794 -0.06642482\n  1.50037656  1.77341402 -1.43411205  1.9507754  -0.04621249  1.27804656\n  1.48755048 -1.19536732 -0.38732682 -0.7187573   0.50054121  2.14171734\n -2.24080141  0.77749036  1.00732222  1.22140561 -0.91817318  1.51783379\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 0 1 1 0 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.88493261e-05  1.51903685e-04  2.50023802e-04 -6.71286477e-05\n   1.73333943e-04  2.70713580e-08]\n [ 6.84692736e-04  1.17334024e-03  1.93507351e-03 -5.14367876e-04\n   1.33564070e-03  1.60736984e-06]\n [ 5.11689671e-03  8.92490734e-03  1.49309766e-02 -3.68278420e-03\n   9.98052832e-03  8.64144109e-05]\n [ 3.15219195e-02  6.17392605e-02  1.10931426e-01 -1.71937683e-02\n   6.25911339e-02  2.52018961e-03]\n [ 9.42195258e-02  3.05340385e-01  6.12999083e-01 -1.52897680e-02\n   2.55234750e-01 -8.55476426e-03]\n [ 9.71770680e-02  9.22731269e-01  1.90734118e+00  1.32473301e-02\n   7.25010090e-01 -1.45491855e-01]\n [ 4.18462737e-02  1.96556934e+00  4.02307457e+00 -1.49849647e-02\n   1.57803900e+00 -2.77429670e-01]\n [-5.59995011e-02  3.26542524e+00  6.63719631e+00 -7.51549138e-02\n   2.66076005e+00 -4.11209258e-01]\n [-1.84976322e-01  4.70965355e+00  9.53559631e+00 -1.48581235e-01\n   3.86885631e+00 -5.60742198e-01]\n [-3.35995021e-01  6.22067975e+00  1.25661446e+01 -2.27470262e-01\n   5.13443850e+00 -7.17324718e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 4 4 5 7 8 9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -1.25279536\n  1.46552373  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425\n -0.81753611 -0.84862223  0.6476239   1.9507754  -0.04621249  1.27804656\n  1.48755048 -1.19536732 -0.38732682 -0.7187573   0.50054121  2.14171734\n -2.24080141  0.77749036  1.00732222  1.22140561 -0.91817318  1.51783379\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 1 0 1 0 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.07609958e-04  1.95663005e-04  2.67447302e-04 -1.45625394e-04\n   2.69341054e-04 -3.60618913e-09]\n [ 8.31597135e-04  1.50887827e-03  2.06802141e-03 -1.11697235e-03\n   2.07235500e-03 -2.14279328e-07]\n [ 6.34638091e-03  1.13372363e-02  1.58491369e-02 -8.05597345e-03\n   1.53088668e-02 -1.71135162e-05]\n [ 4.43373676e-02  7.28094049e-02  1.13401245e-01 -3.91514080e-02\n   8.85141096e-02 -1.81809892e-03]\n [ 1.89941203e-01  3.02263418e-01  5.79674272e-01 -4.45490409e-02\n   2.75570538e-01 -6.82272755e-02]\n [ 2.45225283e-01  8.49569466e-01  1.77211561e+00  2.95370469e-02\n   6.54020393e-01 -3.41616626e-01]\n [ 1.02696583e-01  1.92205698e+00  3.96028385e+00  1.38084931e-02\n   1.52093882e+00 -4.70193136e-01]\n [-3.43612718e-02  3.25329272e+00  6.63208881e+00 -5.36910948e-02\n   2.63437507e+00 -5.39192845e-01]\n [-1.77136108e-01  4.71160850e+00  9.55215794e+00 -1.34987518e-01\n   3.85982710e+00 -6.39226342e-01]\n [-3.31508196e-01  6.25292867e+00  1.26386070e+01 -2.20721094e-01\n   5.15488135e+00 -7.69579103e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  2  3  3  4  5  6  7  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -1.42001794 -0.06642482  1.50037656\n  1.77341402 -1.43411205 -0.38732682 -0.7187573   0.50054121  2.14171734\n -2.24080141  0.77749036  1.00732222  1.22140561 -0.91817318  1.51783379\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 0 1 1 0 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.77320152e-05  2.33919244e-04  2.63273490e-04 -2.35276433e-04\n   3.69649976e-04  2.97410215e-08]\n [-5.26679442e-04  1.80184063e-03  2.03489256e-03 -1.80477439e-03\n   2.84149456e-03  1.76344606e-06]\n [-4.19341470e-03  1.34258539e-02  1.55442621e-02 -1.30339451e-02\n   2.08502579e-02  8.88791617e-05]\n [-3.45226778e-02  8.24753684e-02  1.08764777e-01 -6.56838284e-02\n   1.16881039e-01  1.44461700e-03]\n [-1.99015792e-01  3.19670176e-01  5.34685797e-01 -1.32026432e-01\n   3.57571554e-01 -4.49527673e-02]\n [-6.58743339e-01  8.41318301e-01  1.56841806e+00 -1.72801151e-01\n   8.05030916e-01 -3.99997260e-01]\n [-1.41703653e+00  1.64082019e+00  3.11505814e+00 -2.76146885e-01\n   1.52264464e+00 -1.06999441e+00]\n [-2.33153597e+00  2.62532109e+00  4.98405192e+00 -4.41899097e-01\n   2.43628833e+00 -1.83910389e+00]\n [-3.34153727e+00  3.70693096e+00  7.02418829e+00 -6.38314150e-01\n   3.45119943e+00 -2.66429639e+00]\n [-4.45154374e+00  4.81283475e+00  9.10461541e+00 -8.45135154e-01\n   4.49357484e+00 -3.58817054e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  2  3  2  4  5  6  8  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425 -0.81753611\n -0.84862223  0.6476239  -1.42001794 -0.06642482  1.50037656  1.77341402\n -1.43411205  1.9507754  -0.04621249  1.27804656  1.48755048 -1.19536732\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 0 1 0 1 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.45516006e-06  1.46279135e-04  3.31990415e-04  3.41951141e-05\n   8.99383149e-05 -2.79685622e-08]\n [-4.83618193e-05  1.13052127e-03  2.56598636e-03  2.64485328e-04\n   6.94928336e-04 -1.66993769e-06]\n [-2.81083682e-04  8.63162038e-03  1.96030562e-02  2.03187522e-03\n   5.29609149e-03 -9.73069800e-05]\n [ 2.04303809e-03  6.04712188e-02  1.37927869e-01  1.48775813e-02\n   3.66026817e-02 -4.72543893e-03]\n [ 6.11957980e-02  2.90882068e-01  6.69154573e-01  7.77257263e-02\n   1.71270146e-01 -9.15138697e-02]\n [ 1.57643813e-01  8.41538357e-01  1.86399211e+00  1.46952954e-01\n   5.56174018e-01 -3.32313951e-01]\n [ 8.98272419e-02  1.90883728e+00  3.98581981e+00  7.08926177e-02\n   1.46594550e+00 -4.32602819e-01]\n [-3.65931676e-02  3.24999516e+00  6.64716133e+00 -3.00227312e-02\n   2.61331373e+00 -5.18360964e-01]\n [-1.76421042e-01  4.70907161e+00  9.55645714e+00 -1.24684333e-01\n   3.84978107e+00 -6.30394480e-01]\n [-3.12207567e-01  6.20452344e+00  1.25488593e+01 -2.10246727e-01\n   5.10814937e+00 -7.65684724e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 2 3 3 4 5 6 7 8 9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425 -0.81753611\n -0.84862223  0.6476239  -1.42001794 -0.06642482  1.50037656  1.77341402\n -1.43411205  1.9507754  -0.04621249  1.27804656  1.48755048 -1.19536732\n -0.38732682 -0.7187573   0.50054121  2.14171734 -2.24080141  0.77749036\n  1.00732222  1.22140561 -0.91817318  1.51783379]"}, "y": "[0 0 1 0 1 1 0 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 8.46314359e-05  2.02232800e-04  3.59419629e-04 -6.05960026e-05\n   2.08353589e-04 -2.28179928e-08]\n [ 6.54794211e-04  1.56042888e-03  2.77735574e-03 -4.63146173e-04\n   1.60422013e-03 -1.35706847e-06]\n [ 5.04012906e-03  1.17722826e-02  2.11812532e-02 -3.24689596e-03\n   1.19101302e-02 -8.15696743e-05]\n [ 3.68212869e-02  7.70414064e-02  1.47289498e-01 -1.18518825e-02\n   7.06250714e-02 -4.40917146e-03]\n [ 1.75799333e-01  3.20278750e-01  6.88789904e-01  3.35855677e-02\n   2.29073881e-01 -9.97735754e-02]\n [ 3.46790348e-01  7.97912248e-01  1.78782192e+00  1.61503358e-01\n   5.10076027e-01 -4.65170893e-01]\n [ 4.24474489e-01  1.54543857e+00  3.40457743e+00  2.49782667e-01\n   1.03702802e+00 -8.80269647e-01]\n [ 4.97479322e-01  2.50281318e+00  5.41570758e+00  2.98392243e-01\n   1.76210452e+00 -1.21121341e+00]\n [ 5.81194345e-01  3.52859488e+00  7.56278510e+00  3.42074480e-01\n   2.54553237e+00 -1.52464979e+00]\n [ 6.73508594e-01  4.62470744e+00  9.86308837e+00  3.95269032e-01\n   3.37759869e+00 -1.89092647e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  2  3  3  4  5  6  7  8 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [10, 5], "maxprint": 50, "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425 -0.81753611\n -0.84862223  0.6476239  -1.42001794 -0.06642482  1.50037656  1.77341402\n -1.43411205  1.9507754  -0.04621249  1.27804656  1.48755048 -1.19536732\n -0.38732682 -0.7187573   0.50054121  2.14171734 -2.24080141  0.77749036\n  1.00732222  1.22140561 -0.91817318  1.51783379 -1.70627019 -0.0568887\n  0.99958558  1.20960511 -0.98740462 -1.04855297 -0.66261566  0.82768797\n  2.37124104 -2.3748206 ]", "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4 0 1 2 3 4 0 1 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40 45 50]"}, "y": "[0 0 1 0 1 1 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[ 0.06442801  0.30768696  0.61706073 -0.01611079  0.25774417 -0.06260445]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.09324136  0.35456037  0.72752137 -0.00073473  0.2831225  -0.07870852]]", "[0.35938137]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.30230275 -0.80328386 -0.51203824  1.23271508 -1.60020786 -0.4380743\n -0.01669425 -0.81753611 -0.84862223  0.6476239  -1.42001794 -0.06642482\n  1.50037656  1.77341402 -1.43411205  1.9507754  -0.04621249  1.27804656\n  1.48755048 -1.19536732 -0.38732682 -0.7187573   0.50054121  2.14171734\n -2.24080141  0.77749036  1.00732222  1.22140561 -0.91817318  1.51783379\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 0 1 1 0 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 14.297953063360481, "sample_weight": null}}, "return": ["[[ 8.88599617e-05  1.51909449e-04  2.50003388e-04 -6.71635928e-05\n   1.73365752e-04  1.65877014e-04]\n [ 6.84775685e-04  1.17339381e-03  1.93492653e-03 -5.14646325e-04\n   1.33590025e-03  1.69197994e-04]\n [ 5.11757841e-03  8.92497067e-03  1.49290996e-02 -3.68495875e-03\n   9.98227238e-03  3.25276833e-04]\n [ 3.15179764e-02  6.17363558e-02  1.10936310e-01 -1.71820132e-02\n   6.25796640e-02  2.35483479e-03]\n [ 9.45272560e-02  3.05297386e-01  6.12208783e-01 -1.60503462e-02\n   2.55792840e-01 -3.60215082e-03]\n [ 1.12927949e-01  9.26862507e-01  1.89486363e+00 -9.46458917e-03\n   7.45990881e-01 -2.00158377e-02]\n [ 9.73967352e-02  1.88644703e+00  3.82653022e+00 -5.18684495e-02\n   1.54371194e+00 -2.31323794e-02]\n [ 8.07133540e-02  2.56705309e+00  5.19147082e+00 -8.75086447e-02\n   2.11384649e+00 -2.57144105e-02]\n [ 6.58953831e-02  3.00084410e+00  6.05988751e+00 -1.11894661e-01\n   2.47852832e+00 -2.79274539e-02]\n [ 5.33299073e-02  3.30042618e+00  6.65925580e+00 -1.29139334e-01\n   2.73069678e+00 -2.97792772e-02]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  7   5   7   9  24  66 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -1.25279536\n  1.46552373  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425\n -0.81753611 -0.84862223  0.6476239   1.9507754  -0.04621249  1.27804656\n  1.48755048 -1.19536732 -0.38732682 -0.7187573   0.50054121  2.14171734\n -2.24080141  0.77749036  1.00732222  1.22140561 -0.91817318  1.51783379\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 1 0 1 0 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 14.297953063360481, "sample_weight": null}}, "return": ["[[ 1.07613471e-04  1.95662351e-04  2.67441627e-04 -1.45630086e-04\n   2.69344186e-04  4.81739535e-05]\n [ 8.31630427e-04  1.50888395e-03  2.06799524e-03 -1.11701334e-03\n   2.07239145e-03  4.77289452e-05]\n [ 6.34667932e-03  1.13371681e-02  1.58490615e-02 -8.05590349e-03\n   1.53087580e-02  1.47699718e-05]\n [ 4.43383776e-02  7.28083945e-02  1.13399384e-01 -3.91511753e-02\n   8.85131232e-02 -1.76394913e-03]\n [ 1.94857881e-01  3.00820434e-01  5.72665166e-01 -4.89321827e-02\n   2.77834316e-01 -2.14463448e-02]\n [ 2.99787233e-01  8.63362369e-01  1.76021168e+00 -1.40527917e-02\n   6.98960825e-01 -5.06788128e-02]\n [ 2.21546618e-01  1.85243401e+00  3.76321501e+00 -4.47814531e-02\n   1.51108733e+00 -4.89408925e-02]\n [ 1.77729038e-01  2.54956440e+00  5.16584400e+00 -7.63580370e-02\n   2.09122533e+00 -5.13352904e-02]\n [ 1.45820451e-01  2.99307848e+00  6.05503260e+00 -9.98744980e-02\n   2.46297828e+00 -5.40735562e-02]\n [ 1.23460161e-01  3.29841560e+00  6.66632007e+00 -1.17011471e-01\n   2.71964908e+00 -5.64133998e-02]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  9   5   8  11  26  70 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -1.42001794 -0.06642482  1.50037656\n  1.77341402 -1.43411205 -0.38732682 -0.7187573   0.50054121  2.14171734\n -2.24080141  0.77749036  1.00732222  1.22140561 -0.91817318  1.51783379\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 0 1 1 0 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 14.297953063360481, "sample_weight": null}}, "return": ["[[-6.77557800e-05  2.33918434e-04  2.63285744e-04 -2.35261355e-04\n   3.69637587e-04  3.96371918e-05]\n [-5.26632188e-04  1.80186006e-03  2.03487336e-03 -1.80483843e-03\n   2.84155991e-03  4.30020150e-05]\n [-4.19283425e-03  1.34260601e-02  1.55440431e-02 -1.30346414e-02\n   2.08509645e-02  1.99388139e-04]\n [-3.45263990e-02  8.24802079e-02  1.08768245e-01 -6.56908398e-02\n   1.16890357e-01  1.15170994e-03]\n [-1.93939373e-01  3.19411296e-01  5.30946678e-01 -1.35501566e-01\n   3.60071770e-01 -1.42963714e-02]\n [-5.18871920e-01  8.62497158e-01  1.57948112e+00 -2.07942511e-01\n   8.49277358e-01 -4.52782405e-02]\n [-7.67244267e-01  1.72357444e+00  3.24971836e+00 -3.14394514e-01\n   1.61837994e+00 -5.18914960e-02]\n [-9.10492126e-01  2.34241205e+00  4.44849060e+00 -3.92623198e-01\n   2.17245997e+00 -5.61963398e-02]\n [-9.87583235e-01  2.73684405e+00  5.21546141e+00 -4.39339354e-01\n   2.52316774e+00 -5.98111182e-02]\n [-1.03896005e+00  3.00848092e+00  5.74387981e+00 -4.71271206e-01\n   2.76450530e+00 -6.27942622e-02]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  8   5   6  11  24  66 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425 -0.81753611\n -0.84862223  0.6476239  -1.42001794 -0.06642482  1.50037656  1.77341402\n -1.43411205  1.9507754  -0.04621249  1.27804656  1.48755048 -1.19536732\n -1.70627019 -0.0568887   0.99958558  1.20960511 -0.98740462 -1.04855297\n -0.66261566  0.82768797  2.37124104 -2.3748206 ]"}, "y": "[0 0 1 0 1 1 1 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 14.297953063360481, "sample_weight": null}}, "return": ["[[-6.54907609e-06  1.46275048e-04  3.32091993e-04  3.43142668e-05\n   8.98422586e-05  7.84138840e-05]\n [-4.82906372e-05  1.13052391e-03  2.56592352e-03  2.64411376e-04\n   6.94988035e-04  7.36872972e-05]\n [-2.73583309e-04  8.63378292e-03  1.96152760e-02  2.04030280e-03\n   5.29125122e-03 -1.29688251e-04]\n [ 2.06389164e-03  6.04695376e-02  1.37908191e-01  1.48600018e-02\n   3.66150332e-02 -4.30822849e-03]\n [ 7.12864089e-02  2.91172294e-01  6.63107322e-01  7.05279293e-02\n   1.77107247e-01 -2.67683601e-02]\n [ 2.21170769e-01  8.62795220e-01  1.86733144e+00  1.03269617e-01\n   6.07135322e-01 -4.17781688e-02]\n [ 2.11850997e-01  1.83434007e+00  3.79287499e+00  2.76171957e-02\n   1.44028239e+00 -3.90212019e-02]\n [ 1.83167420e-01  2.53138108e+00  5.17324755e+00 -2.78745190e-02\n   2.03897484e+00 -4.16768689e-02]\n [ 1.53412968e-01  2.97700241e+00  6.05736780e+00 -6.15714690e-02\n   2.42033588e+00 -4.41990716e-02]\n [ 1.31486762e-01  3.28453339e+00  6.66704730e+00 -8.53324472e-02\n   2.68391390e+00 -4.64224829e-02]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  6   5   5   9  24  64 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]", "data": "np.ndarray[float64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [8, 5], "maxprint": 50, "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40]", "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425 -0.81753611\n -0.84862223  0.6476239  -1.42001794 -0.06642482  1.50037656  1.77341402\n -1.43411205  1.9507754  -0.04621249  1.27804656  1.48755048 -1.19536732\n -0.38732682 -0.7187573   0.50054121  2.14171734 -2.24080141  0.77749036\n  1.00732222  1.22140561 -0.91817318  1.51783379]"}, "y": "[0 0 1 0 1 1 0 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 14.297953063360481, "sample_weight": null}}, "return": ["[[ 8.46345132e-05  2.02232389e-04  3.59413707e-04 -6.06015045e-05\n   2.08357546e-04  6.67455141e-05]\n [ 6.54822907e-04  1.56041967e-03  2.77730948e-03 -4.63175814e-04\n   1.60423588e-03  6.39568093e-05]\n [ 5.04002108e-03  1.17720977e-02  2.11809852e-02 -3.24677475e-03\n   1.19098884e-02 -8.35591396e-05]\n [ 3.68222968e-02  7.70412684e-02  1.47281184e-01 -1.18605842e-02\n   7.06317385e-02 -4.15598383e-03]\n [ 1.81421036e-01  3.19059306e-01  6.80386051e-01  2.71938392e-02\n   2.33080135e-01 -2.96639043e-02]\n [ 4.16531159e-01  8.18710132e-01  1.77528243e+00  1.01637236e-01\n   5.73275115e-01 -5.73060246e-02]\n [ 6.23124725e-01  1.59313080e+00  3.38274169e+00  1.19998334e-01\n   1.17611329e+00 -5.79606354e-02]\n [ 7.66513208e-01  2.14409509e+00  4.52129387e+00  1.27557027e-01\n   1.60929157e+00 -6.19288589e-02]\n [ 8.51799655e-01  2.49023005e+00  5.23645506e+00  1.32178956e-01\n   1.88152793e+00 -6.61497141e-02]\n [ 9.09677377e-01  2.72672068e+00  5.72507789e+00  1.35338447e-01\n   2.06752736e+00 -6.96672998e-02]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  7   5   5  10  22  57 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [10, 5], "maxprint": 50, "data": "[-0.50965218 -0.14778398 -0.79249401 -0.52978546  0.29484027 -0.30230275\n -0.80328386 -0.51203824  1.23271508 -1.60020786 -1.25279536  1.46552373\n  1.56914464 -1.56101351  2.38363567 -0.4380743  -0.01669425 -0.81753611\n -0.84862223  0.6476239  -1.42001794 -0.06642482  1.50037656  1.77341402\n -1.43411205  1.9507754  -0.04621249  1.27804656  1.48755048 -1.19536732\n -0.38732682 -0.7187573   0.50054121  2.14171734 -2.24080141  0.77749036\n  1.00732222  1.22140561 -0.91817318  1.51783379 -1.70627019 -0.0568887\n  0.99958558  1.20960511 -0.98740462 -1.04855297 -0.66261566  0.82768797\n  2.37124104 -2.3748206 ]", "indices": "[0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1\n 2 3 4 0 1 2 3 4 0 1 2 3 4]", "indptr": "[ 0  5 10 15 20 25 30 35 40 45 50]"}, "y": "[0 0 1 0 1 1 0 1 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[ 0.07733496  1.77798527  3.60301605 -0.05268578  1.45791498 -0.04418932]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": 14.297953063360481, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.13832984  2.00802945  4.09336535 -0.0333109   1.62614828 -0.06798573]]", "[21.5443469]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.59106196 0.59106196]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [50, 25], "maxprint": 50, "data": "[1.01227546 1.26791822 1.08137603 1.32646164 1.68192174 1.38585905\n 1.735879   1.01184243 1.12049186 1.19595682 1.31247037 1.27255325\n 1.79797132 1.41117206 1.07961859 1.15233156 1.13307988 1.6595508\n 1.0685094  1.06238655 1.00745522 2.2567235  1.22350722 1.4116954\n 1.73011739 1.64252894 2.59442459 1.12793525 1.99795608 1.54483432\n 2.25930895 1.35339573 1.48935596 1.01702099 1.40357103 1.66873628\n 1.07919473 1.18802979 1.64813493 1.76124918 1.65492163 1.3277827\n 1.02179059 1.15418403 1.32806016 1.8227236  1.32906285 1.14115334\n 1.03043827 1.08048271 2.01125668 1.29784579 1.31194333 2.13386825\n 1.92953205 1.71334272 1.12663592 2.38074535 1.12441918 2.11679102\n 1.4229835  1.55224318 1.82016301 2.25325619 1.02893549 1.07774381\n 1.16550583 1.12379522 1.14110187 1.46657872 1.84926373 1.3263859\n 1.73887268 1.02943883 1.3359988  1.27638401 1.12859406 1.31913688\n 1.13689136 1.65813068 1.24331938 2.49720039 2.13215341 1.26507784\n 1.09074973 1.09463837 1.08193522 2.41245368 1.41522589 1.43845611\n 2.02104356 1.30184623 2.3039167  1.02017271 2.06449286 1.21114529\n 1.53637705 1.5430146  1.10083721 1.84959125 1.11701629 2.38314477\n 1.69618157 1.75498615 1.49448454 1.36453185 1.24386492 1.43994634\n 1.36759724 1.03440989 1.35994854 1.0781973  1.1813786  1.08678051\n 1.51826117 1.20719779 1.75384676 1.70789413 1.04797216 1.30142807\n 1.37496407 1.09634685 1.37098901 1.1616032  2.22594433 1.0996596\n 1.33652795 2.16323595 1.22487056 1.35200433 1.32083783 1.74266878\n 1.41232771 1.26171292 1.20568398 1.43188362 1.4152163  1.29802197\n 2.69622405 1.10028434 1.51332808 1.71958931 1.51999486 1.73272119\n 1.95591231 1.28598401 1.67094303 1.19811586 1.3512674 ]", "indices": "[ 6 16 17 18  1  6 13 15 16  6  9 11 16 18 10 17  2  2  4  5  6 10 11 16\n  5  6  3 11 13 16  0  6 15  8 11 16 19  7  4  5  6  0 14 15 16  9 12 16\n 18 16 18 19 16 19  1 10 15  1  9 14 17  9 11 16 17 10  5  6 12 14 13 19\n  0  1  5  6 14 15 10 12 10 14  1  4 10 13 19  1  5  6 10  1  4  9 10 13\n 19 12 16 18  2 18  1 17 15 18 11 16  1  3 13  3  4 11 13 16  5  6  8 12\n 13 17 15 16 19  0 10 17  4  5  6 10 13  5  6  5  6 12 14 15 17  2  3 14\n 18  0  2 11 16]", "indptr": "[  0   4   9  14  16  17  22  24  26  30  31  33  37  38  41  43  45  49\n  52  54  57  61  65  66  70  72  78  80  82  87  91  97  98  98 100 102\n 104 105 106 108 111 116 122 125 128 133 135 141 144 145 149]"}, "y": "[1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0\n 1 0 0 0 1 1 0 1 1 1 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-10, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1000, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l1", "max_squared_sum": 16.508400572913548, "sample_weight": null}}, "return": ["[[-0.76408484 -0.29863011  0.          0.26929737  0.          0.\n   2.62920383  0.          0.          0.         -0.45036352 -0.61554028\n   0.         -0.26251182  0.16151433  0.          0.31476896  0.\n  -0.06687062  0.          0.          0.          0.          0.\n   0.        ]]", "[1.]", "[254]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.59709735  3.65343956  0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.01582196  0.          0.          0.          0.\n  -0.0781368   0.         -0.06695116]]", "[1.]", "[1693]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.38497371  2.57223762  0.          0.          0.17107205  0.\n   0.         -1.00887333  0.          0.          0.          0.\n   0.         -0.29446175  0.          0.          0.          0.\n   0.          0.          0.15271363]]", "[1.]", "[10000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.60850585  3.41557659  0.          0.          0.27070888  0.\n   0.         -0.29569664  0.          0.          0.          0.\n   0.         -0.07638204  0.          0.          0.          0.\n  -0.08580863  0.02531879 -0.12685105]]", "[1.]", "[10000]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[0.2943468  3.63486216 0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.27263929]]", "[1.]", "[2443]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n 1 0 1]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.          3.54620595  0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.32296543 -0.18802171  0.          0.          0.          0.\n   0.          0.          0.07151486]]", "[1.]", "[1486]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n 1 0 0 1 1 1 0 1 1 0 0 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[ 0.37698474  3.36446437  0.          0.          0.08835619  0.\n  0.         -0.26091399  0.          0.          0.          0.\n  0.06459309 -0.11493749  0.          0.          0.          0.\n -0.03278908  0.00506376  0.06061311]", "max_iter": 10000, "tol": 1e-12, "penalty": "l1", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.53483462  3.9952819   0.          0.          0.12038989  0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.16292726  0.          0.          0.          0.\n  -0.05259727  0.          0.05026074]]", "[1.]", "[1914]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n 1 0 0 1 1 1 0 1 1 0 0 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-12, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 10000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l1", "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.53483462  3.9952819   0.          0.          0.12038989  0.\n   0.          0.          0.          0.          0.          0.\n   0.         -0.16292726  0.          0.          0.          0.\n  -0.05259727  0.          0.05026074]]", "[1.]", "[2859]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 5.56339799e-01  1.35493789e+00 -5.98938544e-01 -1.23046095e-01\n  -2.78435081e-02 -4.10406800e-01 -3.82580407e-01 -1.17854598e+00\n   1.49895934e-01 -1.68194004e-01  2.85746909e-01  1.68352623e-01\n   1.80092989e-01 -2.12345995e-01 -1.08123382e-02  1.46254057e-01\n   3.60060088e-01  1.22497585e-01 -6.17166755e-01  2.48354543e-01\n   1.28695191e-03]]", "[1.]", "[607]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.45861237  1.39101296 -0.61621613  0.00371517  0.34822891 -0.25173299\n  -0.25385766 -1.26435508  0.21371178  0.1616667   0.07539134 -0.0755599\n   0.27320258 -0.58156365  0.0848172   0.29080778  0.07410883  0.09506672\n  -0.41831748  0.18951351  0.27500645]]", "[1.]", "[711]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.58423047  1.38375852 -0.61193227 -0.19659572  0.38990491 -0.10312059\n  -0.20205944 -1.21399493  0.40050115  0.14055233  0.07061769  0.12456274\n   0.28307461 -0.41100013 -0.28370827  0.2647566   0.26231662 -0.11872053\n  -0.51106155  0.39240759 -0.10443513]]", "[1.]", "[619]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0\n 0 1 0]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.45188937  1.42072574 -0.6288308  -0.16197751  0.19222443 -0.07009249\n  -0.06238509 -1.26894922  0.26678514 -0.17451154  0.08337773  0.0251092\n   0.25720714 -0.22904771 -0.23229034  0.23621773 -0.04372     0.13794489\n  -0.42720453  0.17213521  0.41412571]]", "[1.]", "[710]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n 1 0 1]"}, "kwargs": {"Cs": null, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 10000, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 1e-12, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.38511225  1.4615168  -0.64608806 -0.20070395  0.18148952 -0.28971516\n  -0.10421856 -1.27277268  0.09910173  0.06040045  0.18574239  0.17464622\n   0.48585063 -0.3424568  -0.12658286  0.28648415  0.25114906 -0.05975145\n  -0.31644848  0.06509436  0.10689091]]", "[1.]", "[608]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n 1 0 0 1 1 1 0 1 1 0 0 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[ 0.48723685  1.40239038 -0.62040116 -0.13572162  0.21680085 -0.22501361\n -0.20102023 -1.23972358  0.22599915  0.00398279  0.14017521  0.08342218\n  0.29588559 -0.35528286 -0.11371532  0.24490406  0.18078292  0.03540744\n -0.45803976  0.21350104  0.13857498]", "max_iter": 10000, "tol": 1e-12, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 57.206803193849325, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.53973417  1.53988537 -0.68108431 -0.18377762  0.23936608 -0.18721105\n  -0.18117111 -1.35542059  0.25158301  0.04560509  0.19724361  0.11829593\n   0.35732327 -0.38820979 -0.09516832  0.2694337   0.19816864  0.02858107\n  -0.54815509  0.22797138  0.13104621]]", "[1.]", "[502]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-0.92693047 -0.03666101  0.01742877  0.44381943 -1.24778318 -1.02438764\n   0.01023306  0.08190923 -0.05952536  1.16316375  1.44127329  0.22371669\n  -3.24126734  1.6324113  -0.25256815  0.13074058  0.77463405 -0.44004449\n  -1.43014138 -1.43586215]\n [-0.45006547  0.13044668 -0.062511    0.0052437   0.51443883 -0.14237949\n   0.11567463 -0.31174083  0.62284993  1.55115198  0.33231401 -0.88863141\n  -1.06762043  0.71161488  0.12029563  1.27767682  0.04698059 -1.53411417\n  -1.12464209 -0.74848654]\n [ 0.50091719  0.7290478  -0.32665202 -0.57677133  0.54336019  0.75138712\n  -0.90431663 -0.8133793  -0.97755524  0.2597225  -1.62754244 -0.727392\n   0.09933231 -0.66262376 -1.66940528 -1.8048821   0.75539123 -0.76325916\n   0.57059867  0.04808495]\n [-0.03471177 -1.23116192  0.53980966 -0.19236096 -0.90938745  0.75193303\n  -0.50347565  0.8903316  -1.16867804  0.09965137 -0.99053633 -0.97692815\n   1.14282281  1.40279431  0.79103195  2.19045563  0.30154734  0.58685709\n  -1.40185106 -0.56629773]\n [-0.63738713  1.58307723 -0.69470526 -0.62314053  0.47141556 -0.57074629\n  -0.38770156 -1.16921533  1.18901653 -0.61278869  1.5475052   1.14486264\n   1.42050425 -0.55222304 -0.83235557 -1.51574411 -0.55547712  0.20292302\n   0.63293182  1.79587767]\n [ 0.36867331  1.21524433 -0.53209848  1.20650897  0.04643655  1.27845186\n   1.57745328 -0.84888286 -0.39333881  0.24938368 -0.30777823  1.10091916\n   0.02874482 -1.35985614  0.19109907  2.16325472 -0.81693567  0.64548418\n   0.74625357  0.21915033]\n [-1.06230371 -1.85460906  0.80891312 -1.55066343 -0.32206152  1.54993441\n   0.78182287  1.16735935  0.47359243  0.25988279 -1.60748323 -2.26489668\n  -0.91942423  0.81351722 -0.78325329  1.30714275  0.06856297  0.22745993\n  -1.23086432  0.18463386]\n [-0.26987494 -1.35996395  0.60720389  1.03753994 -0.92216532  0.37730049\n   1.49604431  1.43008446 -0.97876372 -1.77872025 -0.7737892   0.95897538\n  -0.44429326  0.86960592  0.75698862  1.87679581 -0.5100164   0.4134349\n   1.35563786 -1.2446547 ]\n [ 0.62566735 -0.91528051  0.39804846 -0.26465683  0.71400049  0.48247242\n  -1.24573878  0.52852082 -0.85715756  0.21409374 -0.44651495 -1.33494489\n  -1.0708925   0.47323762 -0.22346279 -1.51484722  2.72016917 -0.84679372\n  -0.07282891  0.85639879]\n [ 0.1990597  -1.7412594   0.76513237 -0.98150865  0.66213067 -0.3853136\n  -0.62269952  1.32741912 -0.60021688  0.28099187 -0.1517851  -1.07044214\n   0.06980208  1.58601682  0.11351735 -1.9520878   0.46210347  2.13303337\n  -1.2378155   0.58831721]\n [ 0.54709738 -0.73346488  0.31938199  1.2776649   0.81350964  1.09877685\n   0.59515703  0.44004521 -0.20219265  0.09699596  0.32416635 -0.99441099\n  -0.2176812   1.30547881  0.82541635 -0.31026676 -0.59157139  0.68195297\n   0.02100384 -0.13014305]\n [-0.53050115  1.23051266 -0.5572771   0.6141667   1.36687427 -2.30192116\n  -0.95554044 -1.61587241 -0.57581824 -0.12791759  3.07888081 -2.33675611\n  -0.2750517   1.64496771 -1.51519106  0.31125015  0.75750771  0.57655696\n  -0.24903604  1.11957491]\n [-0.88385744 -0.59118479  0.25867096  0.17318093  0.56078453 -1.1429703\n   3.85273149  0.40555181  0.15372511  0.51504769  0.51503527 -0.56937358\n   0.05820872  1.08305124  0.35778736 -0.93782504  0.38531738 -1.37766937\n   1.05380205  0.51378595]\n [-1.20029641 -0.53914228  0.23294034  0.50498728  0.40498171 -0.65332923\n  -0.70766947  0.24881193 -0.33450124  1.26691115 -1.51936997 -1.07161518\n  -0.47494531 -1.26088395  1.76545424  1.03246526  0.86575519  2.1221562\n   0.91786195 -0.48423407]\n [ 0.4933179   0.75671589 -0.33046234 -0.94939889  0.12200981  0.70030988\n   1.81244856 -0.49308676  0.18483612 -0.62696706 -0.03498849  0.84753652\n  -0.85835778  2.56008454 -0.57563783 -0.70317643  2.63238206  1.14927333\n  -0.0960599   1.77080064]\n [ 0.96337613 -2.12694133  0.93173008  1.15859558 -0.75373616  1.89679298\n   1.45353408  1.50381595  0.41278093  0.01300189  0.2766908  -1.84430824\n   0.82206016 -0.88951443 -0.24538812  0.34115197 -0.82068232 -0.07710171\n  -0.81581028  0.82718325]\n [ 0.05572491 -0.90661532  0.41225669 -0.98960482 -0.42688107  1.52955032\n   1.66902153  1.25871068  1.09419152 -0.3357847  -1.2899609   2.03277013\n  -1.69246463 -1.01210438 -0.1580079   0.07331797 -0.12578692  0.82317058\n  -1.65485667 -1.29507877]\n [-1.08106333 -1.81054868  0.8147069  -0.36096617 -1.25111358 -0.30954644\n   0.60600995  2.1625167   0.61593561 -1.55662917 -0.70434369  2.45690167\n   0.59310126  0.92402702  0.32613302  1.04900923  1.1593298  -0.52272302\n  -0.18490214 -1.4084613 ]\n [-1.11057585 -1.42253587  0.64221854 -1.40751169 -1.12905177  1.27155509\n   0.44426331  1.78532015  1.75227044  0.71095997 -0.2403254   2.32395437\n   0.93567839 -0.52452027  0.72167206  0.71299843 -0.77781669 -1.22212781\n   0.48937456 -0.37482081]\n [-0.98572605  0.91863304 -0.41265292 -0.0626791  -1.03524232 -0.79287283\n  -0.2209696  -1.06810948  0.50404652 -0.11232805 -0.69972551 -1.11375934\n  -0.53025762 -0.55364931 -0.10703036  0.03526355  0.95514232  1.96472513\n  -1.19787789  0.21397991]\n [ 0.65854427  2.51170023 -1.10320346  0.28586539 -0.73093004 -0.79829724\n  -0.53086877 -1.89549787  2.01020454  2.52693243 -0.0164229   1.63193607\n  -0.17694723 -0.03312697 -1.37931923  0.22378795  0.33445679 -0.5176113\n   1.79455786  1.18839327]\n [ 0.27996863 -1.45005871  0.64299809  0.65436566  0.72576662  0.12922118\n  -0.51121568  1.34357713 -1.12548905  1.59318663  1.8820245   0.19537765\n   2.44575198  0.48100923  0.10939479  0.47146836 -0.05558467 -0.79047446\n   0.22388402  1.34542005]\n [ 0.33849641 -1.17172684  0.52844015 -1.47858625  0.24822059  2.27069286\n   0.33366211  1.448134   -0.41528791  0.47897983  0.07156624  1.81192736\n   0.63278187 -0.4593609   0.18186626 -0.85608383  1.14375404  0.83033582\n  -0.84984437 -0.47765745]\n [ 0.37114587 -0.48950622  0.22517433  0.57707213  0.25442084 -0.15567724\n   2.0754008   0.78536193 -0.60398519  0.28977486  0.39445214  1.58014031\n   0.08658979  0.33760266  1.16778206 -0.43255819 -0.20304539 -0.48760622\n  -0.41187697 -0.42098448]\n [-0.51728845  0.7355718  -0.3214526   0.08228399  1.45338448 -0.36283856\n  -0.76779757 -0.48847035  1.40934744 -1.00414077 -1.34445051  0.78204653\n   2.29889812  1.57957215 -0.44550252 -0.28178461  1.06548038 -0.42018682\n  -0.52286003 -0.91865195]\n [ 1.62861555  0.80846457 -0.35973157  1.50235705 -0.03269475 -0.0555477\n  -1.05921352 -0.79960192 -1.38010146 -0.51386692  0.36659825 -0.33941174\n  -1.70338244 -2.0674421   0.38406545  0.66967255  0.07409478 -1.3044695\n  -0.08912004 -0.93987979]\n [-0.43449623  0.33094931 -0.14194053  0.09612078 -0.8946073  -0.47874862\n   0.8896308  -0.10985044 -0.30917212  0.26705027  1.03184454  0.8534947\n   0.22213377 -0.18687164  1.25575613  0.19655478 -0.46227529  1.44697788\n  -0.43973106 -1.48556037]\n [ 0.52194157 -0.79382063  0.34723296 -1.23695071  0.2322537   0.34644821\n   0.7870846   0.54044388  0.29698467 -0.97468167 -1.1913035  -0.78331588\n   0.25049285  0.29307247 -0.68002472  0.47383292 -1.32045661  1.86577451\n  -0.71435142  0.65655361]\n [ 0.95400176 -0.51310348  0.22937621  0.57089051 -0.23681861  0.75896922\n   1.0889506   0.55113543  0.65139125 -0.47193187  0.68626019  0.41464132\n  -0.31526924 -0.48536355 -0.77282521 -1.86726519  1.13556564  2.31465857\n   0.08187414 -1.61271587]\n [ 2.06074792  1.54957192 -0.69762877  1.17929718  1.36863156  0.97157095\n   0.71754226 -1.86535146  1.75534084 -0.26940683 -1.18325851 -2.16913469\n  -0.24896415 -0.96492346  0.64537595 -1.75873949  0.06751848  1.05842449\n   0.68605146 -2.03923218]\n [-0.07016571  1.7867177  -0.78445379  0.83392215 -1.27674858  0.20768769\n  -0.51604473 -1.33534481 -1.66096093  0.93828381  0.02831838  1.22036473\n   0.42961822 -1.08105654  0.27157884  0.6815007   0.45918008 -0.03955515\n   1.05315285  0.02975614]\n [-1.00601738  1.55953222 -0.70116125 -0.81822068  0.62834551  0.79166269\n  -0.32138584 -1.83841898 -1.21418861 -0.8254972   0.97511973 -2.00545325\n   1.15811087 -0.01224677  0.62411982 -0.67716171  2.09238728  0.07580456\n  -0.89725437 -0.14705738]\n [-1.84087423  2.80439509 -1.23158752  1.66547444 -0.72574381  0.02609105\n   1.0536418  -2.10922529 -1.27957697 -0.97587325 -0.92323325  1.85478373\n  -0.62481858  0.18676676  0.51765902 -1.4066611   1.01437007 -0.6115178\n  -0.75538293 -1.35168461]\n [ 0.63240774  0.89147389 -0.38815236  0.70775194 -0.24751864 -1.57022472\n   1.08078073 -0.53347302  0.97255445  0.55979045  0.38019785  1.21488869\n   0.62180996 -0.07443343 -0.72713718 -1.33534436 -0.56246678  0.177701\n   0.6206721   0.61058575]\n [ 0.17086544  1.24228249 -0.54392235 -1.34818542 -0.77830473  0.34758171\n   0.98269098 -0.86716152 -0.18398334  0.25602973  1.02915564  1.12818953\n   0.01843393  0.19584526 -0.53975968 -1.7025836   0.74326409  0.40825276\n  -0.97837278  0.47259748]\n [ 1.20121392 -1.63835161  0.73036195  0.8711247  -0.35151348 -1.00808631\n   0.77086519  1.67628744 -0.40807537  0.23561456  0.82940558  0.9429\n  -2.03812454  0.01841838 -1.87079192 -0.21910053 -0.32602353  0.32692737\n   1.67643731 -2.21113531]\n [ 1.45114361  0.5753018  -0.26032526  0.02451017  0.18334201 -0.76734756\n   0.15039379 -0.74652914  0.95927083 -0.75913266 -2.12389572 -1.0517062\n   2.15318246  2.18980293  0.87232064 -0.59939265  0.49799829 -0.83972184\n  -0.80829829 -0.52575502]\n [ 1.55050049  0.06415523 -0.02528017 -0.03468489  0.67481949 -0.21398884\n  -0.53099696  0.07012303 -0.99835404 -0.63773998  0.28916864  0.58263943\n   0.9843224  -1.12272202 -0.04946371  0.49245126  0.23421473  0.16645221\n   0.38240975  2.45530014]\n [-0.71530371  0.14129631 -0.06409381  0.06428002 -0.65160035  0.21645859\n  -0.11473644 -0.18976836  0.67959775 -0.79252074 -0.66178646 -0.28759161\n  -0.73036663  2.14394409  0.04557184  0.18645431 -1.07774478 -2.02514259\n   0.63391902  0.85243333]\n [-0.0660798  -1.94237711  0.86928259  0.63859246 -0.38455554  0.04739867\n  -0.79689526  2.12594894 -1.2110162  -2.4716445   0.52980418  1.75036033\n  -0.65183611  1.00629281 -0.86041337 -1.12970685 -1.66152006  0.83569211\n  -0.57689187  1.44156862]\n [-0.01851314  1.96485511 -0.87769618 -0.01901621  1.53273891 -0.82723094\n  -0.77300978 -2.08322978 -0.28865864  0.0976761   0.22409248 -1.46339248\n   0.32271856 -0.10876015  0.51934651 -0.40122047 -1.00252936  0.69014399\n   0.40171172  0.0125924 ]\n [ 0.68189149  0.64027585 -0.27870724 -0.48943944  1.10870358 -0.35929209\n   0.14671369 -0.38019933  1.84670733 -0.16711808  1.38215899  0.88603341\n   0.58392819  0.82048218  0.59065483  1.16929559  1.04416088  1.06667469\n   0.50727403  0.64870989]\n [ 0.95042384  0.21344413 -0.09619309  0.34175598  1.83145877  0.49191917\n  -0.59937502 -0.26098803 -0.57690366 -1.59442766 -0.11453985 -0.31725458\n  -0.89841467  1.17944012 -1.32023321  1.35387237  1.87617084 -1.71313453\n  -0.46917565  1.23781631]\n [-0.58936476 -0.57481614  0.25486115 -0.20812225  0.30729952 -0.6929096\n   0.11732738  0.53142012  0.8496021  -0.02090159  0.74729361  0.07203808\n   0.35701549  0.81286212  0.89959988 -0.56018104 -0.49300093 -0.82899501\n   0.62962884  0.61037027]\n [-0.75635075  1.59211088 -0.71217024 -1.60644632  0.88163976 -1.081548\n  -0.19033868 -1.72802811 -1.42225371 -1.03724615  1.52312408 -1.3683148\n  -0.64657288 -0.00797264  1.68714164 -0.8612842   0.20346364  0.07736831\n   1.47994414  0.53891004]\n [ 0.92617755  0.16263743 -0.0760829  -0.87561825 -0.48712538  0.56296924\n  -0.90756366 -0.31284101  1.90941664 -0.23894805  0.27045683 -0.76187349\n  -1.39856757 -0.59239392 -0.65064257 -0.83095012 -1.38279973  0.04852163\n  -0.86399077 -0.05023811]\n [-0.57366201 -0.33851292  0.15149466  0.19808476  0.10643023 -0.54342477\n  -0.37144087  0.37042883 -0.54685894 -0.34268759  1.24608519  0.30469933\n  -0.03275327 -0.25497722 -0.71284578  1.09150685 -0.14436041 -2.65096981\n   1.50399299 -2.07339023]\n [-0.24574306 -1.56613543  0.70377565 -0.25959135  0.69620636 -0.05429487\n  -0.02412509  1.83170935 -0.27272357  0.01392929  2.5733598   1.94780225\n  -2.69688664  1.84895609 -0.23093453 -1.10652591 -1.50314295 -0.26888869\n   1.12656503  0.05921843]\n [-0.8222204   1.0939436  -0.49256414  0.41293145  0.23204994 -0.50694318\n  -0.15993853 -1.31943373  0.24368721  0.85765962  0.31090757 -1.54301962\n   0.24496657 -1.44808434 -0.47103831 -0.21344715 -0.56372455 -0.71844422\n  -1.40746377  1.47535622]\n [-2.08192941 -3.87991911  1.7309271  -1.28042935  0.39913611 -0.09671311\n  -1.71016839  4.02272665  1.69645637  0.30780177 -0.36361221  2.47468454\n   0.21101747 -0.0376347  -0.54491909  0.15030176  1.75479418  0.11422765\n   1.10330188 -0.05694562]]", "y": "[0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n 1 0 0 1 1 1 0 1 1 0 0 1 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-12, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 10000, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 57.206803193849325, "sample_weight": null}}, "return": ["[[ 0.53973417  1.53988537 -0.68108431 -0.18377762  0.23936608 -0.18721105\n  -0.18117111 -1.35542059  0.25158301  0.04560509  0.19724361  0.11829593\n   0.35732327 -0.38820979 -0.09516832  0.2694337   0.19816864  0.02858107\n  -0.54815509  0.22797138  0.13104621]]", "[1.]", "[561]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.2252548  -1.82700506  1.06138668  4.22923413  0.36846691 -1.81030697\n   0.69067096  0.6388735   0.20255518 -0.69601544 -0.09743004 -1.65604812\n  -6.87707967  0.18189257  3.62458594  1.4752086  -0.77358677 -0.41235644\n   1.45605312  1.80226235]\n [-2.73483056 -3.47240588  3.05732433 -1.37955446  1.48760981 -1.10931502\n  -1.71690454 -1.40026191  2.48309774  0.38512974 -0.58825482  0.75775133\n   7.63771052  0.76266143 -1.61705876 -2.03467156  0.32554003  0.34404156\n   0.75724063 -1.63210148]\n [-2.69707294  3.11637101 -0.93980543  0.21354402 -0.13434625  0.65663668\n   2.19224371  0.1633898   1.71004358 -1.46217032 -0.75724967  0.81977402\n  -1.57327335 -1.76194714  1.73644888 -0.81758029  0.55634416 -0.16425444\n  -0.09743421  1.08673104]\n [-3.98017014 -1.31841535  0.07323557 -1.45798276  0.41047029  0.15493378\n  -0.87742376 -1.91440763  1.74153649  0.0861383  -1.16893036  0.15337713\n   4.44647927  3.40706167  0.83319345  0.06024361  0.74968813 -1.73723493\n   4.93444826  2.9828522 ]\n [-1.91820896 -3.76343136  1.2421285  -2.46344697  0.75982372 -0.53000237\n   1.1677057  -0.65599418  0.91813312  0.84506705 -0.28299435 -2.11634948\n   2.40961198  0.71811196  0.58649561 -1.48175712 -1.46855646 -0.58419047\n   0.77843188 -1.27487938]\n [-0.75256923 -2.89262386  0.4991662  -1.24819037  0.34205751 -0.16357697\n   4.05570289  1.13274122  0.27881126 -0.04274332 -0.57688712  2.42202292\n  -2.75810241 -4.58234492 -0.58102531  0.09979763  0.86016198 -0.07517715\n   2.68918016 -1.72619939]\n [-0.37182498  1.68063016 -0.02075158 -2.29085326 -0.80120104 -0.47014724\n  -0.61738668 -0.57482904  1.15723898  1.75039066 -0.82758534  0.33119837\n   1.19572246 -1.24499331 -0.64005346  1.66075926 -1.14888952  1.18641832\n  -1.76465498  0.07821114]\n [ 0.00972975 -1.92921979 -0.42170588 -1.16732901 -0.30609984 -0.34258453\n  -0.4794942   0.83237877 -0.05115233 -1.68572411  0.90194082  0.48101741\n   1.08085001  1.41969911  1.76830867  0.9393332  -2.25102829  0.79570616\n   2.11833424  0.21112651]\n [-1.69849815  2.06841917  1.33844805 -0.48995687 -0.62697991 -1.25596928\n  -0.33265562 -0.11327544  2.29791244  0.56663693  1.6465058  -2.06859381\n   2.65406932  0.09699275  0.88921247  0.73813202  0.34579096 -1.75982722\n  -2.16328025 -2.24235448]\n [ 1.14059485 -0.26194808  0.06865298 -0.24880139  1.5308268  -0.84145667\n   2.97997089 -0.07198204  0.65445246 -0.24849596 -0.03325109 -3.54988475\n  -4.03711403  2.1595811  -1.62601079  3.51393225  1.1655696  -0.47948293\n   4.46370187 -0.50927666]]", "y": "[1 0 2 0 0 1 2 0 2 1]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.05324085 -0.32348012  0.002095   -0.10400518  0.03535652\n    0.0247465  -0.12778357 -0.0160828  -0.05808984 -0.09509424\n    0.021549    0.01497523  0.3214347   0.23994247  0.08546006\n   -0.13567241 -0.16719498  0.0378025   0.16770358  0.05046739\n   -0.05829518]\n  [ 0.13748096 -0.15276372  0.05462035  0.11209369  0.06288401\n   -0.05422144  0.17963003  0.04644298 -0.04994823  0.03346793\n   -0.02006474 -0.01944207 -0.37905102 -0.11726399 -0.08704975\n    0.1166166   0.11454636 -0.03063513  0.18501114 -0.05535639\n   -0.71748451]\n  [-0.08424011  0.47624384 -0.05671535 -0.00808852 -0.09824053\n    0.02947494 -0.05184646 -0.03036018  0.10803807  0.06162632\n   -0.00148426  0.00446684  0.05761632 -0.12267848  0.00158969\n    0.01905581  0.05264862 -0.00716736 -0.35271471  0.004889\n    0.77577969]]]", "[1.]", "[25]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.2252548  -1.82700506  1.06138668  4.22923413  0.36846691 -1.81030697\n   0.69067096  0.6388735   0.20255518 -0.69601544 -0.09743004 -1.65604812\n  -6.87707967  0.18189257  3.62458594  1.4752086  -0.77358677 -0.41235644\n   1.45605312  1.80226235]\n [-2.73483056 -3.47240588  3.05732433 -1.37955446  1.48760981 -1.10931502\n  -1.71690454 -1.40026191  2.48309774  0.38512974 -0.58825482  0.75775133\n   7.63771052  0.76266143 -1.61705876 -2.03467156  0.32554003  0.34404156\n   0.75724063 -1.63210148]\n [-2.69707294  3.11637101 -0.93980543  0.21354402 -0.13434625  0.65663668\n   2.19224371  0.1633898   1.71004358 -1.46217032 -0.75724967  0.81977402\n  -1.57327335 -1.76194714  1.73644888 -0.81758029  0.55634416 -0.16425444\n  -0.09743421  1.08673104]\n [-3.98017014 -1.31841535  0.07323557 -1.45798276  0.41047029  0.15493378\n  -0.87742376 -1.91440763  1.74153649  0.0861383  -1.16893036  0.15337713\n   4.44647927  3.40706167  0.83319345  0.06024361  0.74968813 -1.73723493\n   4.93444826  2.9828522 ]\n [-1.91820896 -3.76343136  1.2421285  -2.46344697  0.75982372 -0.53000237\n   1.1677057  -0.65599418  0.91813312  0.84506705 -0.28299435 -2.11634948\n   2.40961198  0.71811196  0.58649561 -1.48175712 -1.46855646 -0.58419047\n   0.77843188 -1.27487938]\n [-0.75256923 -2.89262386  0.4991662  -1.24819037  0.34205751 -0.16357697\n   4.05570289  1.13274122  0.27881126 -0.04274332 -0.57688712  2.42202292\n  -2.75810241 -4.58234492 -0.58102531  0.09979763  0.86016198 -0.07517715\n   2.68918016 -1.72619939]\n [-0.37182498  1.68063016 -0.02075158 -2.29085326 -0.80120104 -0.47014724\n  -0.61738668 -0.57482904  1.15723898  1.75039066 -0.82758534  0.33119837\n   1.19572246 -1.24499331 -0.64005346  1.66075926 -1.14888952  1.18641832\n  -1.76465498  0.07821114]\n [ 0.00972975 -1.92921979 -0.42170588 -1.16732901 -0.30609984 -0.34258453\n  -0.4794942   0.83237877 -0.05115233 -1.68572411  0.90194082  0.48101741\n   1.08085001  1.41969911  1.76830867  0.9393332  -2.25102829  0.79570616\n   2.11833424  0.21112651]\n [-1.69849815  2.06841917  1.33844805 -0.48995687 -0.62697991 -1.25596928\n  -0.33265562 -0.11327544  2.29791244  0.56663693  1.6465058  -2.06859381\n   2.65406932  0.09699275  0.88921247  0.73813202  0.34579096 -1.75982722\n  -2.16328025 -2.24235448]\n [ 1.14059485 -0.26194808  0.06865298 -0.24880139  1.5308268  -0.84145667\n   2.97997089 -0.07198204  0.65445246 -0.24849596 -0.03325109 -3.54988475\n  -4.03711403  2.1595811  -1.62601079  3.51393225  1.1655696  -0.47948293\n   4.46370187 -0.50927666]]", "y": "[1 0 2 0 0 1 2 0 2 1]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.08574649 -0.54274972 -0.02304988 -0.187531    0.05493733  0.05845739\n  -0.17751974 -0.01540109 -0.11471993 -0.16800958  0.02444157  0.03483024\n   0.48355166  0.37578836  0.15761428 -0.23610876 -0.2970498   0.07549742\n   0.28521073  0.09705017 -1.79185883]]", "[1.]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.2252548  -1.82700506  1.06138668  4.22923413  0.36846691 -1.81030697\n   0.69067096  0.6388735   0.20255518 -0.69601544 -0.09743004 -1.65604812\n  -6.87707967  0.18189257  3.62458594  1.4752086  -0.77358677 -0.41235644\n   1.45605312  1.80226235]\n [-2.73483056 -3.47240588  3.05732433 -1.37955446  1.48760981 -1.10931502\n  -1.71690454 -1.40026191  2.48309774  0.38512974 -0.58825482  0.75775133\n   7.63771052  0.76266143 -1.61705876 -2.03467156  0.32554003  0.34404156\n   0.75724063 -1.63210148]\n [-2.69707294  3.11637101 -0.93980543  0.21354402 -0.13434625  0.65663668\n   2.19224371  0.1633898   1.71004358 -1.46217032 -0.75724967  0.81977402\n  -1.57327335 -1.76194714  1.73644888 -0.81758029  0.55634416 -0.16425444\n  -0.09743421  1.08673104]\n [-3.98017014 -1.31841535  0.07323557 -1.45798276  0.41047029  0.15493378\n  -0.87742376 -1.91440763  1.74153649  0.0861383  -1.16893036  0.15337713\n   4.44647927  3.40706167  0.83319345  0.06024361  0.74968813 -1.73723493\n   4.93444826  2.9828522 ]\n [-1.91820896 -3.76343136  1.2421285  -2.46344697  0.75982372 -0.53000237\n   1.1677057  -0.65599418  0.91813312  0.84506705 -0.28299435 -2.11634948\n   2.40961198  0.71811196  0.58649561 -1.48175712 -1.46855646 -0.58419047\n   0.77843188 -1.27487938]\n [-0.75256923 -2.89262386  0.4991662  -1.24819037  0.34205751 -0.16357697\n   4.05570289  1.13274122  0.27881126 -0.04274332 -0.57688712  2.42202292\n  -2.75810241 -4.58234492 -0.58102531  0.09979763  0.86016198 -0.07517715\n   2.68918016 -1.72619939]\n [-0.37182498  1.68063016 -0.02075158 -2.29085326 -0.80120104 -0.47014724\n  -0.61738668 -0.57482904  1.15723898  1.75039066 -0.82758534  0.33119837\n   1.19572246 -1.24499331 -0.64005346  1.66075926 -1.14888952  1.18641832\n  -1.76465498  0.07821114]\n [ 0.00972975 -1.92921979 -0.42170588 -1.16732901 -0.30609984 -0.34258453\n  -0.4794942   0.83237877 -0.05115233 -1.68572411  0.90194082  0.48101741\n   1.08085001  1.41969911  1.76830867  0.9393332  -2.25102829  0.79570616\n   2.11833424  0.21112651]\n [-1.69849815  2.06841917  1.33844805 -0.48995687 -0.62697991 -1.25596928\n  -0.33265562 -0.11327544  2.29791244  0.56663693  1.6465058  -2.06859381\n   2.65406932  0.09699275  0.88921247  0.73813202  0.34579096 -1.75982722\n  -2.16328025 -2.24235448]\n [ 1.14059485 -0.26194808  0.06865298 -0.24880139  1.5308268  -0.84145667\n   2.97997089 -0.07198204  0.65445246 -0.24849596 -0.03325109 -3.54988475\n  -4.03711403  2.1595811  -1.62601079  3.51393225  1.1655696  -0.47948293\n   4.46370187 -0.50927666]]", "y": "[1 0 2 0 0 1 2 0 2 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.23597177 -0.26171371  0.09202306  0.17026985  0.09546464 -0.09371814\n   0.27210424  0.07828539 -0.08715185  0.05996951 -0.02343474 -0.02920358\n  -0.59278697 -0.18405701 -0.14289499  0.19840093  0.16967329 -0.04262684\n   0.29231191 -0.09880509 -2.54877596]]", "[1.]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.2252548  -1.82700506  1.06138668  4.22923413  0.36846691 -1.81030697\n   0.69067096  0.6388735   0.20255518 -0.69601544 -0.09743004 -1.65604812\n  -6.87707967  0.18189257  3.62458594  1.4752086  -0.77358677 -0.41235644\n   1.45605312  1.80226235]\n [-2.73483056 -3.47240588  3.05732433 -1.37955446  1.48760981 -1.10931502\n  -1.71690454 -1.40026191  2.48309774  0.38512974 -0.58825482  0.75775133\n   7.63771052  0.76266143 -1.61705876 -2.03467156  0.32554003  0.34404156\n   0.75724063 -1.63210148]\n [-2.69707294  3.11637101 -0.93980543  0.21354402 -0.13434625  0.65663668\n   2.19224371  0.1633898   1.71004358 -1.46217032 -0.75724967  0.81977402\n  -1.57327335 -1.76194714  1.73644888 -0.81758029  0.55634416 -0.16425444\n  -0.09743421  1.08673104]\n [-3.98017014 -1.31841535  0.07323557 -1.45798276  0.41047029  0.15493378\n  -0.87742376 -1.91440763  1.74153649  0.0861383  -1.16893036  0.15337713\n   4.44647927  3.40706167  0.83319345  0.06024361  0.74968813 -1.73723493\n   4.93444826  2.9828522 ]\n [-1.91820896 -3.76343136  1.2421285  -2.46344697  0.75982372 -0.53000237\n   1.1677057  -0.65599418  0.91813312  0.84506705 -0.28299435 -2.11634948\n   2.40961198  0.71811196  0.58649561 -1.48175712 -1.46855646 -0.58419047\n   0.77843188 -1.27487938]\n [-0.75256923 -2.89262386  0.4991662  -1.24819037  0.34205751 -0.16357697\n   4.05570289  1.13274122  0.27881126 -0.04274332 -0.57688712  2.42202292\n  -2.75810241 -4.58234492 -0.58102531  0.09979763  0.86016198 -0.07517715\n   2.68918016 -1.72619939]\n [-0.37182498  1.68063016 -0.02075158 -2.29085326 -0.80120104 -0.47014724\n  -0.61738668 -0.57482904  1.15723898  1.75039066 -0.82758534  0.33119837\n   1.19572246 -1.24499331 -0.64005346  1.66075926 -1.14888952  1.18641832\n  -1.76465498  0.07821114]\n [ 0.00972975 -1.92921979 -0.42170588 -1.16732901 -0.30609984 -0.34258453\n  -0.4794942   0.83237877 -0.05115233 -1.68572411  0.90194082  0.48101741\n   1.08085001  1.41969911  1.76830867  0.9393332  -2.25102829  0.79570616\n   2.11833424  0.21112651]\n [-1.69849815  2.06841917  1.33844805 -0.48995687 -0.62697991 -1.25596928\n  -0.33265562 -0.11327544  2.29791244  0.56663693  1.6465058  -2.06859381\n   2.65406932  0.09699275  0.88921247  0.73813202  0.34579096 -1.75982722\n  -2.16328025 -2.24235448]\n [ 1.14059485 -0.26194808  0.06865298 -0.24880139  1.5308268  -0.84145667\n   2.97997089 -0.07198204  0.65445246 -0.24849596 -0.03325109 -3.54988475\n  -4.03711403  2.1595811  -1.62601079  3.51393225  1.1655696  -0.47948293\n   4.46370187 -0.50927666]]", "y": "[1 0 2 0 0 1 2 0 2 1]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.06182209e-01  7.71823944e-01 -1.35972811e-01 -5.79318875e-02\n  -1.81783821e-01  6.45187628e-02 -4.57984191e-02 -1.80854898e-02\n   1.38652400e-01  8.76630115e-02  1.79495940e-02 -1.52585214e-03\n   3.71632175e-02 -2.13442857e-01  2.50804822e-02  5.08138946e-02\n   3.94617235e-02 -2.37257732e-04 -5.74054438e-01 -5.96409118e-03\n  -4.87073237e-01]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.06247755 -0.04010578 -0.0304106  -0.01044605 -0.01104234]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.03124555 -0.02005724 -0.0152086  -0.00522416 -0.00552237]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.26329386 -0.45276259  0.33723037  0.12188844 -0.04264697]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.13861092 -0.36722787  0.33039665  0.10873869  0.00359626]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.14821461 -0.31809358  0.2585925   0.0626183  -0.02094523]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.0817684  -0.21727884  0.15099144  0.00700791  0.0078425 ]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.09148702 -0.05872761 -0.0445308  -0.01529634 -0.0161695 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.05814786 -0.03732645 -0.02830315 -0.00972214 -0.01027711]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.13738872 -0.34353057  0.28977352  0.07380076 -0.04163175]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.06898051 -0.17288771  0.14605899  0.03720855 -0.0208852 ]]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.12804078 -0.55691078  0.40752431  0.00983975  0.00877084]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.01278788 -0.3518016   0.19288161 -0.09678265  0.08253705]]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.10211019 -0.44456444  0.36725286  0.00842467 -0.00558396]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.02652687 -0.31231861  0.23506066 -0.05422569  0.02937978]]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.06985254 -0.05330458 -0.02204964 -0.00837422 -0.01293383]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 2, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.03640585 -0.02776056 -0.01154844 -0.00439275 -0.00673134]]]", "[1.]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.14366563 -0.35036885  0.28554258  0.06998652 -0.0421933 ]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.07216745 -0.17634835  0.14391879  0.03528558 -0.02116712]]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.07834447 -0.68579986  0.30885572 -0.17128812  0.06262501]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.05983672 -0.41865019  0.08619744 -0.27648577  0.14740831]]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.08971985 -0.52191589  0.34138377 -0.07289934  0.0171568 ]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[-0.01472631 -0.3654014   0.18841421 -0.13500026  0.05695092]]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.06556058 -0.06452651 -0.00039718 -0.00232844 -0.01312895]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 3, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.03348453 -0.03195023 -0.00164743 -0.0015998  -0.00662554]]]", "[1.]", "[3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.10327942 -0.75669881  0.32211034 -0.33467023  0.09869862]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.05355931 -0.38276872  0.16205575 -0.17079746  0.05111158]]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.07315773 -0.72672885  0.30529367 -0.29930417  0.1348061 ]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.10358603 -0.55122951  0.18601944 -0.32548613  0.18403322]]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.002766   -0.556506    0.38487243 -0.12609704  0.04972279]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.06888699 -0.39484322  0.22902771 -0.18327042  0.09009183]]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.06866796 -0.12421073  0.07794349  0.01847019 -0.01748839]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 1e-15, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 4, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.03368671 -0.05437822  0.02909785  0.00659025 -0.00812288]]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.44482597  0.90006145 -2.32372851 -0.97246449  6.68902942]]", "[1.]", "[11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.17925752 -2.12843393  0.69667556 -1.27482924  5.58530916]]", "[1.]", "[13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ -0.39646178  -0.51509228   2.92942773   2.41764145 -14.40744037]]", "[1.]", "[16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.06119140e-03  8.03518412e-04 -5.58329665e-03 -2.34097778e-03\n  -6.60138539e-01]\n [-2.39924204e-01  1.68415116e-01 -7.74616234e-01 -3.16848060e-01\n   3.02195202e+00]\n [-1.02994692e-01  1.84995339e+00 -3.61653708e+00 -1.65393653e+00\n   5.68727931e+00]\n [ 2.51699295e-01  3.35565905e+00 -5.91669111e+00 -2.80619763e+00\n   5.87333084e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[8 7 9 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.09253298e-03  1.04170328e-03 -5.81787503e-03 -2.39273036e-03\n  -6.59049477e-01]\n [-2.26997001e-01  1.97381698e-01 -7.69612914e-01 -3.14351608e-01\n   2.90169319e+00]\n [-4.08317431e-01  1.57691734e+00 -3.52196465e+00 -1.50656468e+00\n   8.09993772e+00]\n [-8.27347260e-02  2.94476453e+00 -5.53623949e+00 -2.43574443e+00\n   8.21593656e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[8 8 9 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.10435519e-04 -7.22548559e-04  1.23280867e-03  3.00280692e-04\n  -6.96516622e-01]\n [-8.24410614e-02 -2.71084771e-01  1.93870246e-01 -1.79977511e-02\n  -1.03105585e-01]\n [-9.01113675e-01 -3.14945956e+00  1.77309216e+00 -2.98438255e+00\n   1.07160551e+01]\n [-9.87082030e-01 -3.27715881e+00  2.03506331e+00 -3.52578894e+00\n   1.12327198e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 8  4 12  3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.42990578e-04 -7.13951736e-04  1.25895790e-03  3.25701594e-04\n  -6.97809779e-01]\n [ 3.84504217e-03 -2.48801125e-01  1.56178416e-01 -1.96269976e-02\n  -5.44610103e-01]\n [ 4.71361515e-01 -2.65952327e+00  4.64972951e-01 -1.64992887e+00\n   4.69638937e+00]\n [ 4.91870292e-01 -2.76634954e+00  4.98173219e-01 -1.77667688e+00\n   4.91694967e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 9  5 10  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.94577391e-03 -8.35989866e-05  4.34733316e-03  2.03968881e-03\n  -7.22273999e-01]\n [ 2.76401193e-01  4.08482182e-02  6.13507068e-01  3.36105514e-01\n  -5.47676862e+00]\n [-1.11926304e+00 -6.46778294e-01  4.83608392e+00  5.85363175e+00\n  -2.44393612e+01]\n [-2.58558858e+00 -1.30313261e+00  6.89946722e+00  1.19447945e+01\n  -3.37562568e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 6  9 13  7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.74606901e-03 -3.29583358e-04  4.55669534e-03  2.06632216e-03\n  -7.22248155e-01]\n [ 1.69553082e-01 -1.79028100e-02  6.25703999e-01  3.42209605e-01\n  -4.80714125e+00]\n [-2.09895524e+00 -2.64034424e+00  5.69489806e+00  5.74891328e+00\n  -1.72354842e+01]\n [-8.52716176e+00 -1.57500474e+01  1.34784269e+01  3.34122617e+01\n  -2.68115150e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 8  7 12  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[-0.2334606   0.18289841 -0.77211457 -0.31559983  2.9618226 ]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.28545237  0.2656136  -1.00957707 -0.41094049  3.77567999]]", "[0.04641589]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[-0.21487608 -2.90449141  1.11903256 -2.31715571  7.70622222]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.22246911 -2.76022607  1.23120125 -2.59898141  7.24008918]]", "[21.5443469]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[ -1.60910914  -1.64356127   5.26549099   5.80127252 -20.83742269]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ -1.87929878  -2.43623049   5.90045567   7.32724983 -22.47912354]]", "[21.5443469]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.21025168e-03 -3.49052567e-04 -2.23589064e-03 -1.19491772e-03\n  -6.70908466e-01]\n [-2.44206424e-01 -6.07406312e-02 -5.94746261e-01 -3.56026602e-01\n   4.61737842e+00]\n [ 1.63986992e+00  2.16180379e+00 -5.00142163e+00 -6.70612087e+00\n   1.87373718e+01]\n [ 2.48425078e+00  4.77088796e+00 -6.82750749e+00 -1.41919610e+01\n   2.75741445e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 8  8 12  7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.66906083e-03 -1.08273201e-03  4.73025989e-03  1.82244198e-03\n  -7.11105436e-01]\n [ 2.47001544e-01 -2.16979327e-01  8.02465218e-01  3.12193433e-01\n  -3.66056434e+00]\n [ 1.33308518e-02 -1.89654046e+00  3.69599597e+00  1.57416757e+00\n  -5.96432312e+00]\n [-3.81326796e-01 -3.22135039e+00  5.78699735e+00  2.52899830e+00\n  -6.14264688e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[6 6 8 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[ 2.29404571e-04 -7.15892289e-04  1.24718462e-03  3.13762130e-04\n -6.91006951e-01]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 4.50590057e-04 -1.43273690e-03  2.47830464e-03  6.20171370e-04\n  -7.01461904e-01]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.41909762   0.96876767  -2.51476677  -1.07859093   9.80409065]\n  [  0.53730284  -0.31834605  -0.20234031  -0.94430534   2.19083184]\n  [ -0.11820522  -0.65042161   2.71710708   2.02289626 -11.99492249]]]", "[1.]", "[19]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.05339796e-03  8.02034186e-04 -5.56504525e-03 -2.33318192e-03\n    3.28719819e-02]\n  [ 1.07977537e-04 -7.22699007e-04  1.22856144e-03  2.98531239e-04\n   -3.22183272e-03]\n  [ 1.94542042e-03 -7.93351790e-05  4.33648381e-03  2.03465068e-03\n   -2.96501491e-02]]\n\n [[-1.95133078e-01  1.46531905e-01 -6.46530416e-01 -2.62613484e-01\n    3.14296784e+00]\n  [-4.84124059e-02 -1.96720579e-01  1.20782079e-01 -3.43399222e-02\n    8.85535289e-01]\n  [ 2.43545484e-01  5.01886735e-02  5.25748338e-01  2.96953406e-01\n   -4.02850313e+00]]\n\n [[-4.65929923e-01  1.81426195e+00 -4.21560607e+00 -2.10206367e+00\n    1.49291315e+01]\n  [ 8.92145409e-01 -6.80222710e-01 -3.59144971e-01 -2.30662240e+00\n    5.37210206e+00]\n  [-4.26215486e-01 -1.13403924e+00  4.57475104e+00  4.40868606e+00\n   -2.03012336e+01]]\n\n [[ 5.56814495e-01  3.90142958e+00 -7.30672695e+00 -3.85949236e+00\n    1.53059154e+01]\n  [ 1.01116449e+00 -1.32903748e+00  1.89036573e-01 -4.09886547e+00\n    9.49798933e+00]\n  [-1.56797899e+00 -2.57239211e+00  7.11769037e+00  7.95835783e+00\n   -2.48039048e+01]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 5 12 13  7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.08397411e-03  1.03921052e-03 -5.79708932e-03 -2.38420347e-03\n    3.39594807e-02]\n  [ 3.43890107e-04 -7.11986698e-04  1.25628808e-03  3.24446979e-04\n   -4.90397473e-03]\n  [ 1.74008401e-03 -3.27223824e-04  4.54080124e-03  2.05975649e-03\n   -2.90555060e-02]]\n\n [[-1.84755346e-01  1.71458489e-01 -6.41941738e-01 -2.62007563e-01\n    3.04310103e+00]\n  [ 3.79210074e-02 -1.66471810e-01  9.52063037e-02 -4.34402308e-02\n    4.05092926e-01]\n  [ 1.46834339e-01 -4.98667906e-03  5.46735435e-01  3.05447793e-01\n   -3.44819396e+00]]\n\n [[-6.67432328e-03  2.27090582e+00 -4.52405154e+00 -2.01479462e+00\n    1.29348121e+01]\n  [ 1.12619694e+00  3.53267586e-01 -6.55198481e-01 -2.45989189e+00\n    2.58350050e+00]\n  [-1.11952262e+00 -2.62417341e+00  5.17925002e+00  4.47468651e+00\n   -1.55183126e+01]]\n\n [[ 3.07531187e+00  8.75475999e+00 -1.16615550e+01 -6.40428600e+00\n    1.39534494e+01]\n  [ 2.84826285e+00  3.93926282e+00 -1.30535503e+00 -1.42064838e+01\n    7.58733337e+00]\n  [-5.92357471e+00 -1.26940228e+01  1.29669100e+01  2.06107698e+01\n   -2.15407827e+01]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 5  8 12  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[[ -0.23630212   2.04258389  -4.3698288   -2.05842914  13.9319718 ]\n [  1.00917117  -0.16347756  -0.50717173  -2.38325714   3.97780128]\n [ -0.77286905  -1.87910633   4.87700053   4.44168629 -17.90977308]]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ -0.36119783   2.51429212  -4.94558755  -2.45176537  15.7356016 ]\n  [  1.16060142   0.07063807  -0.51839501  -2.94473282   3.86269378]\n  [ -0.79940359  -2.58493019   5.46398256   5.39649819 -19.59829538]]]", "[21.5443469]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.20718264e-03 -3.48108738e-04 -2.23179695e-03 -1.19317476e-03\n   -3.24382827e-01]]\n\n [[-1.46774010e-01 -2.82121721e-02 -4.46381532e-01 -2.82658988e-01\n    3.36650669e+00]]\n\n [[ 9.32831507e-01  1.36918514e+00 -2.69855214e+00 -4.15116761e+00\n    1.01515192e+01]]\n\n [[ 1.23808616e+00  2.32330896e+00 -3.41285890e+00 -7.04774788e+00\n    1.39048786e+01]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 7 10 13  7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 1.66150341e-03 -1.07882477e-03  4.71064325e-03  1.81492931e-03\n   -3.64478554e-01]]\n\n [[ 1.53391437e-01 -1.53964772e-01  5.32778613e-01  2.08265717e-01\n   -2.24673229e+00]]\n\n [[-1.06210849e-01 -1.12924798e+00  2.03624866e+00  8.73490555e-01\n   -2.41563423e+00]]\n\n [[-3.19340246e-01 -1.78838368e+00  3.10444744e+00  1.36884000e+00\n   -2.51781757e+00]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[8 8 6 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[[ 2.27160386e-04 -7.13466754e-04  1.23942315e-03  3.10877277e-04\n  -3.44430691e-01]]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 0.00043819 -0.00142882  0.00244745  0.00060741 -0.35470105]]]", "[0.0001]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-8.25503194e-03 -2.46257251e-03 -9.50445739e-03 -3.58958789e-03\n  -1.06880101e-03]\n [ 1.01347575e-01  4.04903231e-01 -7.14965468e-01 -3.23243341e-01\n   7.88758761e-02]\n [ 6.91344214e-01  2.18874175e+00 -3.48980090e+00 -1.57928896e+00\n   4.12066109e-01]\n [ 8.28057139e-01  2.55638611e+00 -4.04426967e+00 -1.83725533e+00\n   4.82854488e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 3 6 6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-8.31859647e-03 -2.22062834e-03 -9.81516708e-03 -3.66174786e-03\n  -1.06427436e-03]\n [ 9.15560872e-02  4.23761292e-01 -7.06248029e-01 -3.16346527e-01\n   7.46173579e-02]\n [ 6.03964362e-01  2.18571108e+00 -3.26248238e+00 -1.49612337e+00\n   3.89943027e-01]\n [ 7.19217397e-01  2.52227367e+00 -3.73007997e+00 -1.71509883e+00\n   4.51123679e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 3 6 6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.44608343e-03 -4.17604506e-03 -2.92634546e-03 -1.02508557e-03\n  -1.13068868e-03]\n [-9.34614790e-02 -2.79567708e-01  1.92332101e-01 -1.71291879e-02\n  -3.48579334e-03]\n [-3.05773049e-01 -2.56973128e+00  1.59296772e+00 -3.06184896e+00\n   6.32930673e+00]\n [-8.92778086e-01 -3.21134344e+00  1.99993924e+00 -3.52970026e+00\n   1.06320727e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 2  2  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.27317092e-03 -4.17583721e-03 -2.99839277e-03 -1.02690237e-03\n  -1.13072900e-03]\n [-5.51210316e-02 -2.93242492e-01  1.49878141e-01 -1.73162177e-02\n  -1.65840774e-02]\n [ 6.82486774e-01 -2.43805524e+00  4.21559061e-01 -1.68196649e+00\n   2.99696077e+00]\n [ 5.69037534e-01 -2.76661802e+00  4.88696449e-01 -1.83295813e+00\n   4.57080631e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 2 7 8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-4.85486992e-03 -3.66275275e-03  2.45221487e-05  6.60145648e-04\n  -1.17261169e-03]\n [-2.80866919e-01 -3.30637010e-01  4.67186686e-01  3.32048002e-01\n  -1.35749558e-01]\n [-2.32088032e+00 -3.39290861e+00  4.00752729e+00  5.86605536e+00\n  -4.79260510e+00]\n [-2.02387343e+00 -3.93834888e+00  5.55862213e+00  1.17704378e+01\n  -2.26523760e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 3 6 8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-5.10073283e-03 -3.90864374e-03  1.40387217e-04  6.61166240e-04\n  -1.16855960e-03]\n [-3.08789748e-01 -3.38143572e-01  4.93301682e-01  3.23767847e-01\n  -1.20111647e-01]\n [-3.56799770e+00 -3.40198089e+00  4.90332995e+00  6.19198557e+00\n  -2.88351421e+00]\n [-8.35348780e+00 -1.44181847e+01  1.13271803e+01  2.95217930e+01\n  -1.42152508e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 3 7 9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[ 0.09645183  0.41433226 -0.71060675 -0.31979493  0.07674662]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.15185128  0.57709086 -0.94907807 -0.42700989  0.10755768]]", "[0.04641589]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[-0.16187028 -2.98898073  1.24431784 -2.6813292   7.6014395 ]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.16985907 -2.79520056  1.26257971 -2.73080971  7.07284885]]", "[10000.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[ -5.18868061  -9.1782668    8.44290121  20.64611542 -18.43381338]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ -3.10872293  -4.97670051   6.07209962  10.65615682 -14.0216457 ]]", "[10000.]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-7.87845108e-03 -3.40259619e-03 -7.59418598e-03 -3.06968649e-03\n  -1.05280744e-03]\n [ 1.59672121e-01  1.51352864e-01 -3.65039921e-01 -2.93567170e-01\n   9.73461016e-02]\n [ 2.55845736e+00  3.75736952e+00 -4.29503581e+00 -6.63589717e+00\n   4.75397948e+00]\n [ 3.32326463e+00  6.35518984e+00 -5.89433079e+00 -1.05049288e+01\n   6.76585842e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 4 9 9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-4.62849709e-03 -4.87006248e-03  1.89091637e-03  1.10287422e-03\n  -1.17994374e-03]\n [-1.66812037e-01 -5.13970357e-01  7.23942651e-01  3.11862197e-01\n  -9.70623506e-02]\n [-7.16835643e-01 -2.38566739e+00  3.62441422e+00  1.59873427e+00\n  -4.65990387e-01]\n [-8.37782825e-01 -2.83390285e+00  4.34309845e+00  1.91572242e+00\n  -5.52771114e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[2 3 6 6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[-0.00625347 -0.00413633 -0.00285163 -0.00098341 -0.00111638]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.0115586  -0.00775674 -0.00514648 -0.00179817 -0.00206703]]", "[0.0001]", "[2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.41143954  1.4252253  -2.23627946 -1.04603857  0.33043943]]", "[1.]", "[7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.43784298 -1.56425861  0.49805637 -1.2220019   0.97258287]]", "[1.]", "[24]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.62076559 -1.42954698  2.43350194  2.2528806  -1.38498844]]", "[1.]", "[20]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-2.56413408e-03  5.38585290e-04 -5.90120687e-03 -2.44205590e-03\n  -6.08836058e-01]\n [ 1.28936380e-01  4.27499648e-01 -7.02664630e-01 -3.19204136e-01\n  -1.45755210e-01]\n [ 5.27737553e-01  1.58421688e+00 -2.53388883e+00 -1.15800321e+00\n   9.34618570e-02]\n [ 5.43332006e-01  1.63442874e+00 -2.61259208e+00 -1.19320441e+00\n   1.02683469e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[25  6 20  3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-2.60083019e-03  7.75020787e-04 -6.14345328e-03 -2.49618066e-03\n  -6.07551187e-01]\n [ 1.21510218e-01  4.42916414e-01 -6.91618350e-01 -3.12888345e-01\n  -1.47481449e-01]\n [ 4.60301303e-01  1.59336388e+00 -2.39381652e+00 -1.08923758e+00\n   7.74564296e-02]\n [ 4.72477350e-01  1.64496609e+00 -2.47173893e+00 -1.12519745e+00\n   8.66018110e-02]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[25  6 18  3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 5.59121933e-06 -7.77719537e-04  1.16628990e-03  2.79023469e-04\n  -6.85918064e-01]\n [-2.19675707e-02 -2.27776298e-01  2.00745096e-01 -2.09828239e-02\n  -6.24771286e-01]\n [ 5.29641976e-01 -1.83587778e+00  8.65430556e-01 -2.03072906e+00\n   8.12823590e-01]\n [ 5.35735315e-01 -1.90921777e+00  9.13640296e-01 -2.16183461e+00\n   9.63172255e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[39  8 51  6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 2.40308355e-04 -7.67754929e-04  1.19284638e-03  3.04663581e-04\n  -6.87512779e-01]\n [ 2.01492092e-02 -2.36995099e-01  1.58243777e-01 -2.02661437e-02\n  -6.90213590e-01]\n [ 8.66651926e-01 -1.75395803e+00  2.30583723e-01 -1.17318590e+00\n  -3.33462993e-02]\n [ 8.85505845e-01 -1.79075534e+00  2.32833299e-01 -1.20284449e+00\n   4.74689906e-04]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[39  8 36  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 1.58768502e-03 -2.72908181e-04  4.12146081e-03  1.96787397e-03\n  -6.85883413e-01]\n [-1.51867281e-01 -2.42354350e-01  4.96273657e-01  3.30439153e-01\n  -1.36933135e+00]\n [-1.79127051e+00 -1.83946235e+00  2.93491553e+00  2.93578227e+00\n  -2.53010609e+00]\n [-1.88403100e+00 -1.95058015e+00  3.07815243e+00  3.12709239e+00\n  -2.62666159e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[29  8 43  6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 1.37703732e-03 -5.23592703e-04  4.32021994e-03  1.99126395e-03\n  -6.84932336e-01]\n [-1.87266756e-01 -2.56960789e-01  5.20314104e-01  3.24435878e-01\n  -1.28303085e+00]\n [-2.05639575e+00 -1.64043049e+00  3.09040358e+00  2.57999165e+00\n  -2.09485300e+00]\n [-2.15142181e+00 -1.71330350e+00  3.21700491e+00  2.71066331e+00\n  -2.14462908e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[29  8 36  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[ 0.1252233   0.43520803 -0.69714149 -0.31604624 -0.14661833]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.13093594  0.56167757 -0.95422108 -0.4268447   0.31964321]]", "[0.04641589]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[ 0.71062058 -1.84998655  0.5732368  -1.68233955  0.48182347]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.77525297 -2.07834408  0.66272964 -2.02647474  0.89747283]]", "[10000.]", "[9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[-1.92383313 -1.73994642  3.01265956  2.75788696 -2.31247955]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.4098958  -2.20002741  3.6808122   3.70435193 -2.80448869]]", "[21.5443469]", "[17]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.44784371e-03 -4.57946988e-04 -2.42650448e-03 -1.26151998e-03\n  -6.47480533e-01]\n [ 1.75830562e-01  1.62028879e-01 -3.56853616e-01 -2.93241453e-01\n  -4.13591153e-02]\n [ 2.19087464e+00  2.14952036e+00 -3.30152707e+00 -3.35381244e+00\n   1.33410536e+00]\n [ 2.27791899e+00  2.26410773e+00 -3.43717165e+00 -3.53538693e+00\n   1.42464439e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[34  8 42  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 1.28256038e-03 -1.31514138e-03  4.55651688e-03  1.77859310e-03\n  -6.69445106e-01]\n [-4.80716382e-02 -4.27068933e-01  7.45016664e-01  3.12004513e-01\n  -1.14765654e+00]\n [-3.80810595e-01 -1.64499199e+00  2.61552108e+00  1.11922207e+00\n  -1.37433897e+00]\n [-3.92801576e-01 -1.68077733e+00  2.66833887e+00  1.14300020e+00\n  -1.38117844e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[27  8 19  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[-8.26416640e-05 -8.86544185e-04  1.06500620e-03  2.58536560e-04\n -6.58462819e-01]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 5.18518086e-04 -1.39841593e-03  2.52394629e-03  6.34770889e-04\n  -7.04461137e-01]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.37335016  1.28832986 -2.03482026 -0.93469215  0.29827235]]", "[1.]", "[16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.41592971 -1.42779059  0.45047505 -1.05292535  0.65481214]]", "[1.]", "[34]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.47907809 -1.28149037  2.19391217  1.9861213  -1.05790115]]", "[1.]", "[29]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-6.94436330e-03 -1.76565568e-03 -8.68907078e-03 -3.33231558e-03\n  -1.39082841e-01]\n [ 1.00432230e-01  4.01581226e-01 -7.07642714e-01 -3.18405236e-01\n   6.90363763e-02]\n [ 4.26456284e-01  1.34805800e+00 -2.18409420e+00 -9.83876597e-01\n   2.57479230e-01]\n [ 4.34590953e-01  1.37578682e+00 -2.22840224e+00 -1.00350412e+00\n   2.62536688e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 7  9 26  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-7.28656788e-03 -1.66271060e-03 -9.30080405e-03 -3.50922757e-03\n  -8.37968384e-02]\n [ 8.55925751e-02  4.17490138e-01 -7.00712379e-01 -3.12876779e-01\n   1.11349127e-01]\n [ 3.69491989e-01  1.37802728e+00 -2.10499756e+00 -9.52330128e-01\n   2.92212184e-01]\n [ 3.76393004e-01  1.40560406e+00 -2.14617165e+00 -9.71180558e-01\n   2.97085806e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 4  9 26  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-2.88903292e-03 -2.30317807e-03 -6.72586335e-04 -3.06684787e-04\n  -3.75898020e-01]\n [-5.48127770e-02 -2.41851904e-01  1.94791521e-01 -1.20997217e-02\n  -3.78080899e-01]\n [ 4.30850581e-01 -1.56404347e+00  7.16219744e-01 -1.53185204e+00\n   5.42430747e-01]\n [ 4.43273412e-01 -1.60629502e+00  7.35770790e-01 -1.59643059e+00\n   5.95521095e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[22 11 65  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-3.27424171e-03 -2.59696526e-03 -1.09365655e-03 -4.24254787e-04\n  -3.08552455e-01]\n [-2.40960680e-02 -2.57812564e-01  1.53902946e-01 -1.22761926e-02\n  -3.47022797e-01]\n [ 6.23195104e-01 -1.43093612e+00  2.41182737e-01 -8.63444336e-01\n   2.16959319e-02]\n [ 6.67953088e-01 -1.50663803e+00  2.40690679e-01 -9.26628693e-01\n   6.39659470e-02]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[16 11 43  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.31826115e-03 -1.80311226e-03  2.27255477e-03  1.37857319e-03\n  -3.74453254e-01]\n [-2.14882586e-01 -2.91584317e-01  4.77361872e-01  3.21723075e-01\n  -7.00955506e-01]\n [-1.45687723e+00 -1.45610034e+00  2.32503432e+00  2.19594372e+00\n  -1.51785019e+00]\n [-1.49812223e+00 -1.49837673e+00  2.38570941e+00  2.26845869e+00\n  -1.55221756e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[22 10 47  3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.55574326e-03 -2.05445885e-03  2.42929596e-03  1.39124698e-03\n  -3.73267037e-01]\n [-2.44433710e-01 -3.02210966e-01  5.02213096e-01  3.15443882e-01\n  -6.65247535e-01]\n [-1.64133951e+00 -1.32712576e+00  2.43713339e+00  1.95868654e+00\n  -1.26206316e+00]\n [-1.67961762e+00 -1.35402569e+00  2.48720391e+00  2.00666935e+00\n  -1.28037502e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[22 10 41  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[ 0.0930124   0.40953568 -0.70417755 -0.31564101  0.09019275]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.14427219  0.57579353 -0.96439769 -0.43567739  0.24156627]]", "[0.04641589]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[ 0.55561325 -1.55646653  0.48823073 -1.26152964  0.32974352]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.67586532 -1.83869334  0.55759249 -1.63368507  0.64890008]]", "[10000.]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[-1.54910837 -1.39161305  2.38108385  2.07731513 -1.38995668]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.04648065 -1.8056698   3.06184871  2.88339634 -1.77462659]]", "[21.5443469]", "[20]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-6.49837099e-03 -2.77227256e-03 -6.48768174e-03 -2.68412364e-03\n  -1.37949535e-01]\n [ 1.46219948e-01  1.44157607e-01 -3.61938960e-01 -2.89612482e-01\n   1.84236269e-01]\n [ 1.74230410e+00  1.62796419e+00 -2.65409588e+00 -2.57044266e+00\n   1.14900981e+00]\n [ 1.78922064e+00  1.67982070e+00 -2.72338422e+00 -2.65121492e+00\n   1.18542389e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 7 14 49  3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.90367837e-03 -3.22486298e-03  3.10237798e-03  1.40714001e-03\n  -2.99829802e-01]\n [-1.15943240e-01 -4.71100998e-01  7.23042260e-01  3.07695099e-01\n  -5.24815829e-01]\n [-3.94816636e-01 -1.47780061e+00  2.25602712e+00  9.73352982e-01\n  -7.17209573e-01]\n [-4.03959383e-01 -1.50781858e+00  2.30154972e+00  9.93659968e-01\n  -7.23055810e-01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[16  9 25  2]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[-0.00420102 -0.00299857 -0.00169265 -0.00063849 -0.21888967]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": 123.46000000000001, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 1.36717607e-04 -1.59795732e-03  2.28070153e-03  5.57471615e-04\n  -6.82613762e-01]]", "[0.0001]", "[33]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.44565052  0.90054581 -2.32023343 -0.98112874  6.68931554]]", "[1.]", "[24]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.17917535 -2.12878487  0.69671839 -1.27500517  5.58592907]]", "[1.]", "[27]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ -0.39270716  -0.51442952   2.93064063   2.41608802 -14.43598319]]", "[1.]", "[26]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.06144258e-03  8.03261482e-04 -5.58317548e-03 -2.34090266e-03\n  -6.60136995e-01]\n [-2.40190503e-01  1.68720099e-01 -7.74388856e-01 -3.17042138e-01\n   3.02195752e+00]\n [ 2.35812477e-01  2.05902971e+00 -3.64523930e+00 -1.66206147e+00\n   3.42786786e+00]\n [ 6.85548155e-01  3.78620712e+00 -6.31114529e+00 -2.93878579e+00\n   3.67603279e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[13 18 11  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.09255060e-03  1.04166358e-03 -5.81792958e-03 -2.39276701e-03\n  -6.59049760e-01]\n [-2.27865429e-01  1.96802012e-01 -7.69644673e-01 -3.14465343e-01\n   2.90890164e+00]\n [ 2.26472551e-01  1.99287060e+00 -3.42320417e+00 -1.53749088e+00\n   3.28332391e+00]\n [ 6.39682657e-01  3.57574853e+00 -5.72151043e+00 -2.62199653e+00\n   3.50509248e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[13 18 10  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.11279154e-04 -7.23869011e-04  1.23261295e-03  2.98122509e-04\n  -6.96506911e-01]\n [-8.23143631e-02 -2.70990096e-01  1.93724397e-01 -1.77483788e-02\n  -1.03848508e-01]\n [-9.01330726e-01 -3.14955801e+00  1.77360023e+00 -2.98524552e+00\n   1.07166534e+01]\n [-9.87988732e-01 -3.28001313e+00  2.03357798e+00 -3.51979043e+00\n   1.12443561e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[12 18 26 24]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 3.46523322e-04 -7.12194861e-04  1.26100711e-03  3.26229701e-04\n  -6.98191947e-01]\n [ 3.81896466e-03 -2.48950773e-01  1.56109495e-01 -1.96127578e-02\n  -5.43768283e-01]\n [ 4.69668588e-01 -2.67166830e+00  4.59866561e-01 -1.63883879e+00\n   4.74887915e+00]\n [ 4.88241328e-01 -2.74965850e+00  5.10179996e-01 -1.79737255e+00\n   4.86690029e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[12 15 27 16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.95069542e-03 -8.11500831e-05  4.35052646e-03  2.04061452e-03\n  -7.22823689e-01]\n [ 2.77340325e-01  4.14558538e-02  6.13838447e-01  3.36114481e-01\n  -5.48620558e+00]\n [-1.04644409e+00 -5.86838060e-01  4.86000127e+00  5.88004238e+00\n  -2.52285792e+01]\n [-2.79200181e+00 -1.04102902e-01  8.06646347e+00  1.30024615e+01\n  -4.35074770e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[12 16 33 39]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.74607407e-03 -3.29575346e-04  4.55669529e-03  2.06632396e-03\n  -7.22249932e-01]\n [ 1.69465441e-01 -1.78000278e-02  6.25924173e-01  3.41944414e-01\n  -4.80755485e+00]\n [-2.12158039e+00 -2.63725752e+00  5.80464406e+00  5.78164176e+00\n  -1.76963347e+01]\n [-1.14448972e+01 -2.15699930e+01  1.57112702e+01  4.71540547e+01\n  -2.72346565e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[13 16 35 21]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[-0.23402797  0.18276106 -0.77201676 -0.31575374  2.96542958]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.28559888  0.26554579 -1.009655   -0.41121691  3.77722117]]", "[0.04641589]", "[14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[-0.21583107 -2.91061316  1.1167334  -2.31204215  7.73276626]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.22262472 -2.76027299  1.23125649 -2.59894292  7.24081749]]", "[21.5443469]", "[12]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[ -1.58401224  -1.61204779   5.33232266   5.83084207 -21.46245694]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ -1.91688007  -2.49413296   5.80260481   7.30883838 -21.57235312]]", "[21.5443469]", "[20]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.21027598e-03 -3.49043940e-04 -2.23591226e-03 -1.19491192e-03\n  -6.70908437e-01]\n [-2.44817975e-01 -6.08299381e-02 -5.95526033e-01 -3.56174985e-01\n   4.62580670e+00]\n [ 1.64816573e+00  2.14827266e+00 -5.03133931e+00 -6.71940748e+00\n   1.88940395e+01]\n [ 2.49305902e+00  4.65252787e+00 -6.98127225e+00 -1.42853372e+01\n   2.87819682e+01]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[14 23 45 37]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 1.66929775e-03 -1.08291527e-03  4.73014281e-03  1.82215897e-03\n  -7.11123538e-01]\n [ 2.47666610e-01 -2.16362767e-01  8.02699257e-01  3.12090887e-01\n  -3.66701491e+00]\n [ 4.70801647e-01 -1.54188063e+00  3.82278612e+00  1.55961454e+00\n  -9.70259149e+00]\n [ 2.44216871e-02 -3.41123563e+00  6.69975363e+00  2.82416228e+00\n  -9.86233322e+00]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[11 18 25  7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[ 2.29510886e-04 -7.15979605e-04  1.24711528e-03  3.13623524e-04\n -6.91015987e-01]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 4.50995281e-04 -1.43267771e-03  2.47857394e-03  6.20158260e-04\n  -7.01470304e-01]]", "[0.0001]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.01, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.41796398   0.96618786  -2.52148566  -1.08399394   9.83857507]\n  [  0.53085183  -0.31438328  -0.19906402  -0.94910998   2.2145103 ]\n  [ -0.11288784  -0.65180458   2.72054969   2.03310393 -12.05308537]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.05260572e-03  8.02375595e-04 -5.56438053e-03 -2.33295287e-03\n    3.28026876e-02]\n  [ 1.05954515e-04 -7.23706965e-04  1.22721730e-03  2.98123572e-04\n   -3.08566349e-03]\n  [ 1.94665121e-03 -7.86686305e-05  4.33716323e-03  2.03482930e-03\n   -2.97170241e-02]]\n\n [[-1.94781132e-01  1.46858204e-01 -6.46622132e-01 -2.62615440e-01\n    3.14032394e+00]\n  [-4.88018559e-02 -1.96959568e-01  1.20925654e-01 -3.43669638e-02\n    8.88025765e-01]\n  [ 2.43582987e-01  5.01013644e-02  5.25696478e-01  2.96982404e-01\n   -4.02834971e+00]]\n\n [[-4.94059764e-01  1.97966912e+00 -4.24981670e+00 -1.94658116e+00\n    1.44119426e+01]\n  [ 9.01088606e-01 -6.37241139e-01 -2.83094975e-01 -2.30905316e+00\n    4.88379336e+00]\n  [-4.07028842e-01 -1.34242798e+00  4.53291167e+00  4.25563432e+00\n   -1.92957360e+01]]\n\n [[ 2.05806109e+00  7.73320214e+00 -1.25665507e+01 -6.56733082e+00\n    1.53196015e+01]\n  [ 3.61276375e-01 -3.74450992e+00  2.31349531e+00 -3.13016120e+00\n    1.34663921e+01]\n  [-2.41933746e+00 -3.98869223e+00  1.02530554e+01  9.69749202e+00\n   -2.87859936e+01]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[ 11  40 100  38]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.08271169e-03  1.03981232e-03 -5.79641815e-03 -2.38402098e-03\n    3.38752545e-02]\n  [ 3.41667949e-04 -7.12567168e-04  1.25509024e-03  3.24432678e-04\n   -4.77171157e-03]\n  [ 1.74104374e-03 -3.27245153e-04  4.54132791e-03  2.05958830e-03\n   -2.91035430e-02]]\n\n [[-1.84633247e-01  1.71475730e-01 -6.41991417e-01 -2.62140681e-01\n    3.04268963e+00]\n  [ 3.76623276e-02 -1.66689039e-01  9.52743692e-02 -4.34012083e-02\n    4.07065208e-01]\n  [ 1.46970919e-01 -4.78669099e-03  5.46717047e-01  3.05541890e-01\n   -3.44975484e+00]]\n\n [[-1.26759156e-01  2.15143590e+00 -4.58493580e+00 -2.00921967e+00\n    1.40410077e+01]\n  [ 1.19352932e+00  4.44089646e-01 -5.89319776e-01 -2.50534912e+00\n    1.80006985e+00]\n  [-1.06677017e+00 -2.59552555e+00  5.17425557e+00  4.51456879e+00\n   -1.58410776e+01]]\n\n [[ 5.76248187e+00  1.59124125e+01 -2.06963611e+01 -1.01851625e+01\n    1.55252243e+01]\n  [ 2.94256069e+00  3.43662698e+00  2.62231565e+00 -2.02123746e+01\n    5.89065762e+00]\n  [-8.70504256e+00 -1.93490395e+01  1.80740454e+01  3.03975371e+01\n   -2.14158819e+01]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[11 45 96 32]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[ -0.31040946   2.06555251  -4.41737625  -1.97790042  14.22647516]\n [  1.04730896  -0.09657575  -0.43620738  -2.40720114   3.34193161]\n [ -0.7368995   -1.96897676   4.85358362   4.38510156 -17.56840677]]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ -0.19884612   2.58614539  -4.82751362  -2.61506197  14.45553605]\n  [  1.09299228   0.04229422  -0.55141881  -2.84497114   4.23937304]\n  [ -0.89414616  -2.62843961   5.37893243   5.46003311 -18.6949091 ]]]", "[21.5443469]", "[64]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.20740979e-03 -3.48189484e-04 -2.23212168e-03 -1.19332887e-03\n   -3.24385578e-01]]\n\n [[-1.48084493e-01 -2.90801358e-02 -4.46989391e-01 -2.82988644e-01\n    3.38090691e+00]]\n\n [[ 9.48060727e-01  1.33794174e+00 -2.71856276e+00 -4.13558173e+00\n    1.02191079e+01]]\n\n [[ 1.25195704e+00  2.34105437e+00 -3.50708301e+00 -7.18768369e+00\n    1.44723260e+01]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[13 13 34 37]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1]"}, "kwargs": {"Cs": 4, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.01, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 1.66005329e-03 -1.07847104e-03  4.70944390e-03  1.81497781e-03\n   -3.64523894e-01]]\n\n [[ 1.53467655e-01 -1.54101106e-01  5.32754521e-01  2.08423617e-01\n   -2.24674216e+00]]\n\n [[-1.09254695e-01 -1.12543981e+00  2.04803580e+00  8.81741965e-01\n   -2.44320635e+00]]\n\n [[-4.15764920e-01 -2.05099943e+00  3.46286767e+00  1.53298430e+00\n   -2.58339800e+00]]]", "[1.00000000e-04 4.64158883e-02 2.15443469e+01 1.00000000e+04]", "[12 19 11  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[ 2.26321752e-04 -7.13330263e-04  1.23866111e-03  3.10824472e-04\n  -3.44454736e-01]]", "max_iter": 100, "tol": 0.01, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 42, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 0.00043819 -0.00142874  0.00244761  0.0006076  -0.3547021 ]]]", "[0.0001]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.44485016  0.90011112 -2.32351065 -0.97345779  6.68910147]]", "[1.]", "[12]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.17926572 -2.12862225  0.69666723 -1.27482663  5.58591994]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ -0.39442668  -0.51333158   2.9308642    2.41706395 -14.43125791]]", "[1.]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-0.44485016  0.90011112 -2.32351065 -0.97345779  6.68910147]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.44485016  0.90011112 -2.32351065 -0.97345779  6.68910147]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-0.17926572 -2.12862225  0.69666723 -1.27482663  5.58591994]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.17926572 -2.12862225  0.69666723 -1.27482663  5.58591994]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ -0.39442668  -0.51333158   2.9308642    2.41706395 -14.43125791]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ -0.39442668  -0.51333158   2.9308642    2.41706395 -14.43125791]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.30731082  1.39140391 -2.2632964  -1.01527991  1.04536933]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.16871699 -1.82040556  0.62500047 -1.34772006  2.98582892]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.38895827 -1.30766327  2.50855327  2.50291457 -3.98211517]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.30731082  1.39140391 -2.2632964  -1.01527991  1.04536933]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.27058837  1.36718292 -2.27354136 -1.01827884  1.04520381]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.16871699 -1.82040556  0.62500047 -1.34772006  2.98582892]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.19182081 -1.8613209   0.57363328 -1.44168445  3.04847415]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-1.38895827 -1.30766327  2.50855327  2.50291457 -3.98211517]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.42723703 -1.30574391  2.48903411  2.5086867  -4.03662475]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.36440014  1.42430582 -2.26343687 -1.02209989  0.64424364]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.35159204 -1.68611061  0.56973355 -1.34851044  1.71955724]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.58168472 -1.42568756  2.50415929  2.48191775 -2.36700749]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.36440014  1.42430582 -2.26343687 -1.02209989  0.64424364]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.34395202  1.42157667 -2.28869314 -1.03254157  0.64503812]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.35159204 -1.68611061  0.56973355 -1.34851044  1.71955724]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.41890057 -1.7017472   0.58034894 -1.38647373  1.75862789]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-1.58168472 -1.42568756  2.50415929  2.48191775 -2.36700749]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.61861238 -1.4370057   2.51431305  2.51618163 -2.4046841 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.44501376  0.89999242 -2.32353827 -0.97345836  6.69040651]]", "[1.]", "[29]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.1792787  -2.12866718  0.69665417 -1.27480129  5.58615272]]", "[1.]", "[28]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ -0.39444787  -0.5133412    2.93087523   2.41709879 -14.43121671]]", "[1.]", "[28]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-0.44501376  0.89999242 -2.32353827 -0.97345836  6.69040651]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.44501376  0.89999242 -2.32353827 -0.97345836  6.69040651]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-0.1792787  -2.12866718  0.69665417 -1.27480129  5.58615272]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.17927905 -2.12866732  0.69665412 -1.2748013   5.58615267]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ -0.39444787  -0.5133412    2.93087523   2.41709879 -14.43121671]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ -0.39444734  -0.51334096   2.93087555   2.41709883 -14.43121664]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.08815763 -0.0271579  -0.09791383 -0.0364216  -0.01172621]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.06247755 -0.04010578 -0.0304106  -0.01044605 -0.01104234]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.32557883 -0.47955028  0.64875925  0.37235757 -0.14015766]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.33003919  0.86658179 -1.30729664 -0.6351545   0.1930348 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.08010577 -0.40031452  0.2000473  -0.08555917  0.03179489]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.68643432 -0.79101954  1.14691742  0.81338884 -0.33546778]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.17081546  0.58194104 -0.9594021  -0.4591795   0.12294386]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.03963056 -0.31951631  0.20945045 -0.01728984  0.00082945]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.45048068 -0.48595591  0.66155384  0.47173856 -0.19359446]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.13950708 -0.04297664 -0.15494601 -0.0576362  -0.01855641]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.09148702 -0.05872761 -0.0445308  -0.01529634 -0.0161695 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.08629701 -0.06390022 -0.00336943  0.00899836 -0.01982017]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44615938  1.48869097 -2.26041625 -1.02459007]]", "[1.]", "[11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.58075112 -1.4977408   0.54745227 -1.44439488]]", "[1.]", "[11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.86394078 -1.64712227  2.47847783  2.59360392]]", "[1.]", "[10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.44615938  1.48869097 -2.26041625 -1.02459007]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44615938  1.48869097 -2.26041625 -1.02459007]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.58075112 -1.4977408   0.54745227 -1.44439488]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.58075112 -1.4977408   0.54745227 -1.44439488]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-1.86394078 -1.64712227  2.47847783  2.59360392]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.86394078 -1.64712227  2.47847783  2.59360392]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.44814393  1.48563465 -2.25915138 -1.03101542]]", "[1.]", "[56]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.58172755 -1.49870076  0.54593876 -1.44195964]]", "[1.]", "[94]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.86585495 -1.64525175  2.48156373  2.58848202]]", "[1.]", "[94]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.44814393  1.48563465 -2.25915138 -1.03101542]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.41084983  1.46156589 -2.26985484 -1.03399615]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.58172755 -1.49870076  0.54593876 -1.44195964]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.61092606 -1.53723474  0.50025605 -1.5403408 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-1.86585495 -1.64525175  2.48156373  2.58848202]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.92416349 -1.65123282  2.46415639  2.60326215]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.45035132  1.48091915 -2.25884758 -1.02906019]]", "[1.]", "[78]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.58928531 -1.50389083  0.52637434 -1.40374548]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.86581567 -1.62044189  2.48626662  2.53179186]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.45035132  1.48091915 -2.25884758 -1.02906019]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.42999128  1.47866276 -2.28472198 -1.03976831]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.58928531 -1.50389083  0.52637434 -1.40374548]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.66051876 -1.51618091  0.54133082 -1.44099066]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-1.86581567 -1.62044189  2.48626662  2.53179186]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-1.91157947 -1.63505475  2.4986343   2.5690278 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44621207  1.48862057 -2.26042693 -1.02464735]]", "[1.]", "[21]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.58075142 -1.49774187  0.5474528  -1.44439548]]", "[1.]", "[23]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.86393852 -1.64711993  2.47847356  2.59360394]]", "[1.]", "[17]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.44621207  1.48862057 -2.26042693 -1.02464735]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.44621084  1.48862642 -2.26042492 -1.02464344]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[ 0.58075142 -1.49774187  0.5474528  -1.44439548]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[ 0.58075142 -1.49774187  0.5474528  -1.44439548]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[-1.86393852 -1.64711993  2.47847356  2.59360394]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.86393852 -1.64711993  2.47847356  2.59360394]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.08945397 -0.02755725 -0.09935364 -0.03695717]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.06349482 -0.04075878 -0.03090575 -0.01061614]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.34315121 -0.4931679   0.64970963  0.37501295]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.35343681  0.88422335 -1.30417413 -0.63599967]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.07760353 -0.40178144  0.20308026 -0.08575723]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.72163685 -0.81371709  1.13932291  0.81517107]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[ 0.18556256  0.59396496 -0.9595151  -0.4606204 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.03982728 -0.32180425  0.2110642  -0.01747869]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[-0.47210378 -0.50081945  0.65877298  0.4736944 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.14121173 -0.04350178 -0.15683932 -0.05834047]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.09256618 -0.05942036 -0.04505607 -0.01547678]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.08767746 -0.0649224  -0.00342333  0.0091423 ]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.42350116   0.96735147  -2.5171831   -1.07925538   9.84954282]\n  [  0.53445991  -0.32158906  -0.20637894  -0.94433346   2.23720484]\n  [ -0.11095875  -0.64576242   2.72356204   2.02358884 -12.08674766]]]", "[1.]", "[21]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ -0.42350116   0.96735147  -2.5171831   -1.07925538   9.84954282]\n [  0.53445991  -0.32158906  -0.20637894  -0.94433346   2.23720484]\n [ -0.11095875  -0.64576242   2.72356204   2.02358884 -12.08674766]]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.42350116   0.96735147  -2.5171831   -1.07925538   9.84954282]\n  [  0.53445991  -0.32158906  -0.20637894  -0.94433346   2.23720484]\n  [ -0.11095875  -0.64576242   2.72356204   2.02358884 -12.08674766]]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.61912347  1.62010927 -2.36756329 -1.10659032  1.40804833]\n  [ 0.3731735  -0.28962886 -0.03418889 -0.95430458  1.99387572]\n  [-0.99229697 -1.33048041  2.40175218  2.0608949  -3.40192405]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ 0.61912347  1.62010927 -2.36756329 -1.10659032  1.40804833]\n [ 0.3731735  -0.28962886 -0.03418889 -0.95430458  1.99387572]\n [-0.99229697 -1.33048041  2.40175218  2.0608949  -3.40192405]]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.57405622  1.59535393 -2.38535637 -1.11242448  1.40914279]\n  [ 0.43497792 -0.28696481 -0.03354807 -0.97690306  2.03904773]\n  [-1.00903414 -1.30838912  2.41890445  2.08932753 -3.44819052]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.67884244  1.66706386 -2.35168005 -1.10140195  0.82690382]\n  [ 0.46931822 -0.22610237 -0.04159989 -0.95978658  1.2404627 ]\n  [-1.14816066 -1.44096149  2.39327995  2.06118852 -2.06736652]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ 0.67884244  1.66706386 -2.35168005 -1.10140195  0.82690382]\n [ 0.46931822 -0.22610237 -0.04159989 -0.95978658  1.2404627 ]\n [-1.14816066 -1.44096149  2.39327995  2.06118852 -2.06736652]]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.66965108  1.67442218 -2.37818558 -1.11408547  0.83150412]\n  [ 0.50955627 -0.22103223 -0.03808366 -0.9769183   1.26902655]\n  [-1.17920735 -1.45338995  2.41626924  2.09100377 -2.10053066]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.41796398   0.96618786  -2.52148566  -1.08399394   9.83857507]\n  [  0.53085183  -0.31438328  -0.19906402  -0.94910998   2.2145103 ]\n  [ -0.11288784  -0.65180458   2.72054969   2.03310393 -12.05308537]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ -0.41796398   0.96618786  -2.52148566  -1.08399394   9.83857507]\n [  0.53085183  -0.31438328  -0.19906402  -0.94910998   2.2145103 ]\n [ -0.11288784  -0.65180458   2.72054969   2.03310393 -12.05308537]]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ -0.41799548   0.96616805  -2.5214867   -1.08399069   9.83856919]\n  [  0.53094736  -0.31433865  -0.19901393  -0.94908855   2.2145276 ]\n  [ -0.11295188  -0.65182941   2.72050064   2.03307924 -12.05309678]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.21768999  0.48184672 -0.65719172 -0.30927265  0.10139775]\n  [-0.03553245 -0.17605322  0.18022892  0.03991536 -0.01274986]\n  [-0.18215754 -0.3057935   0.4769628   0.26935729 -0.08864789]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.32066049  0.80434924 -1.20554385 -0.59603127  0.18350415]\n  [ 0.28673104 -0.12026485  0.25136529 -0.09881258  0.10500167]\n  [-0.60739154 -0.68408439  0.95417857  0.69484385 -0.28850582]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.21325129  0.54593048 -0.79777153 -0.39291639  0.12198091]\n  [ 0.08745938 -0.19817881  0.18695226 -0.02609636  0.02759793]\n  [-0.30071068 -0.34775167  0.61081927  0.41901275 -0.14957885]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-3.83888641e-02  1.69937965e-02 -1.05263732e-01 -4.37070666e-02\n    4.83549253e-17]\n  [ 4.24844913e-03 -1.31732487e-02  2.30149798e-02  5.80723263e-03\n   -2.43301624e-17]\n  [ 3.41404150e-02 -3.82054778e-03  8.22487526e-02  3.78998340e-02\n    5.70079119e-17]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.77441431  1.74692796 -2.34855535 -1.11245332]\n  [ 0.62339316 -0.09419464 -0.04478341 -1.02176229]\n  [-1.39780748 -1.65273332  2.39333876  2.1342156 ]]]", "[1.]", "[12]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ 0.77441431  1.74692796 -2.34855535 -1.11245332]\n [ 0.62339316 -0.09419464 -0.04478341 -1.02176229]\n [-1.39780748 -1.65273332  2.39333876  2.1342156 ]]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.77441431  1.74692796 -2.34855535 -1.11245332]\n  [ 0.62339316 -0.09419464 -0.04478341 -1.02176229]\n  [-1.39780748 -1.65273332  2.39333876  2.1342156 ]]]", "[1.]", "[0]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.77429206  1.74664909 -2.34812926 -1.11257462]\n  [ 0.62482433 -0.09581602 -0.04693045 -1.0180353 ]\n  [-1.39911639 -1.65083307  2.39505972  2.13060992]]]", "[1.]", "[72]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ 0.77429206  1.74664909 -2.34812926 -1.11257462]\n [ 0.62482433 -0.09581602 -0.04693045 -1.0180353 ]\n [-1.39911639 -1.65083307  2.39505972  2.13060992]]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.73019048  1.72275282 -2.36605422 -1.11837441]\n  [ 0.73830365 -0.08279701 -0.03131068 -1.05149947]\n  [-1.46849413 -1.63995581  2.3973649   2.16987388]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.77052248  1.73991401 -2.34007576 -1.10464907]\n  [ 0.62932203 -0.10704744 -0.05243252 -1.00236115]\n  [-1.39984452 -1.63286657  2.39250828  2.10701023]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ 0.77052248  1.73991401 -2.34007576 -1.10464907]\n [ 0.62932203 -0.10704744 -0.05243252 -1.00236115]\n [-1.39984452 -1.63286657  2.39250828  2.10701023]]", "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.76506552  1.75017979 -2.36618261 -1.11751454]\n  [ 0.67667141 -0.10228272 -0.05505984 -1.02355973]\n  [-1.44173693 -1.64789708  2.42124245  2.14107427]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.77433982  1.74702228 -2.34860274 -1.11227851]\n  [ 0.6234361  -0.09428645 -0.04476242 -1.02178783]\n  [-1.39777592 -1.65273583  2.39336516  2.13406633]]]", "[1.]", "[50]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": "[[ 0.77433982  1.74702228 -2.34860274 -1.11227851]\n [ 0.6234361  -0.09428645 -0.04476242 -1.02178783]\n [-1.39777592 -1.65273583  2.39336516  2.13406633]]", "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.7743422   1.74702321 -2.34860123 -1.11227836]\n  [ 0.6234348  -0.0942868  -0.04476321 -1.02178809]\n  [-1.397777   -1.65273641  2.39336445  2.13406645]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[ 0.23064018  0.49349722 -0.65938489 -0.31127752]\n  [-0.03730959 -0.17914793  0.18180696  0.04014637]\n  [-0.19333059 -0.31434929  0.47757793  0.27113115]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.34496585  0.82331684 -1.20320466 -0.59733442]\n  [ 0.29336698 -0.118419    0.25534945 -0.09927891]\n  [-0.63833283 -0.70489784  0.94785521  0.69661334]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 123.46000000000001, "sample_weight": null}}, "return": ["[[[ 0.22799211  0.55764608 -0.79753491 -0.39426398]\n  [ 0.09010987 -0.19797915  0.18874589 -0.02644066]\n  [-0.31810198 -0.35966693  0.60878902  0.42070464]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]", "y": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 1, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.03838886  0.0169938  -0.10526373 -0.04370707]\n  [ 0.00424845 -0.01317325  0.02301498  0.00580723]\n  [ 0.03414041 -0.00382055  0.08224875  0.03789983]]]", "[1.]", "[1]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [50, 20], "maxprint": 50, "data": "[ 6.99380484e-01 -9.64606424e-01 -2.12523045e-01  5.98946831e-02\n -7.62114512e-01  4.57627354e-01  1.01227546e+00 -2.41337791e-01\n -8.87780137e-01 -8.78190343e-01 -6.31375988e-01  8.75732584e-01\n -8.58919908e-01 -1.79422927e+00  5.09542770e-02 -2.22477010e-01\n  1.26791822e+00  1.08137603e+00  1.32646164e+00 -1.06122229e+00\n -5.32489919e-01  1.68192174e+00  2.29597556e-02 -8.52585847e-01\n -1.11456118e-02  7.89509362e-01  1.38585905e+00 -1.68823003e+00\n  1.14988999e-02 -1.12465983e-01 -2.61922373e-02  7.10890117e-01\n -6.57951045e-01  1.73587900e+00  4.68385234e-01  1.01184243e+00\n  1.12049186e+00  4.98052405e-01 -6.67712721e-01  6.45055273e-01\n -8.58972388e-01  7.85803827e-01 -3.91217052e-01 -5.74695185e-02\n  9.40917615e-01  4.61206902e-01  1.19595682e+00 -8.97400927e-01\n  4.05204080e-01  1.31247037e+00 -5.00840943e-02  1.27255325e+00\n -1.07709907e+00 -8.29964598e-01 -4.24663302e-01  7.45864065e-02\n  1.79797132e+00 -7.57870860e-01  1.41117206e+00 -8.98942156e-01\n  5.21064876e-01 -1.38336396e+00  6.10379379e-01 -1.58293840e+00\n -1.18885926e+00 -1.97938995e-01 -6.00663118e-01 -8.13364259e-01\n -5.06816354e-01 -1.46642433e+00  1.07961859e+00 -7.40037255e-01\n -3.19328417e-01  6.94749144e-01  6.91538751e-01  1.41953163e-01\n -1.03025018e+00  1.15233156e+00 -7.25597378e-01 -5.75787970e-01\n  4.53781913e-01 -1.11831192e+00  1.13307988e+00 -1.31054012e-01\n -1.95180410e+00 -1.02503327e+00 -9.71862486e-01  8.62789892e-03\n -6.59891730e-01  5.27004208e-01  6.16886554e-01  9.12861017e-01\n  7.67902408e-01 -3.63858810e-01  5.89879821e-01  3.70057219e-02\n  9.93830333e-01  3.54757693e-01 -8.05626508e-01 -1.82974041e+00\n  7.47188334e-01  4.50934462e-01  1.65955080e+00 -6.84010898e-01\n  1.06850940e+00  1.06238655e+00  1.00745522e+00 -7.04700276e-01\n -4.53385804e-01  9.43260725e-01  2.25672350e+00 -9.45733763e-01\n -1.18388064e+00  6.06319524e-01 -2.65917224e+00  7.73252977e-01\n -1.02952256e+00 -1.57667016e-01 -1.75589058e+00 -1.18894496e+00\n -2.16949570e-01 -1.08403662e+00  3.79235534e-01  3.51780111e-01\n -4.70032883e-01 -1.00885504e+00 -8.10018628e-01 -5.54309627e-01\n -2.16731471e-01 -4.70637658e-01  7.84957521e-01  1.22350722e+00\n -3.04614305e+00  4.39042958e-01  5.43311891e-01 -3.92388998e-01\n  1.41169540e+00 -1.13980246e+00 -2.19541028e-01  4.45393251e-01\n -8.59307670e-02 -1.10389299e-01  8.20247837e-01 -1.05462846e+00\n  4.63130329e-01  1.73011739e+00  1.64252894e+00 -3.95228983e-01\n  2.79095764e-01 -1.15942052e+00  7.82601752e-02 -1.53600082e+00\n -1.15107468e-01 -9.64612014e-01  4.57415606e-01  8.75832762e-01\n -1.67106893e+00  8.00564803e-01 -7.82629156e-01  1.94292938e-01\n -6.47181432e-01 -1.54158740e+00 -4.04032294e-01  2.59442459e+00\n -1.46173269e+00  1.85170955e-01  7.58261638e-01  2.71170185e-01\n -6.83439767e-01 -8.01496885e-01 -5.25640593e-01  1.12793525e+00\n -1.75316402e-01  1.99795608e+00 -1.42191987e+00  9.30408496e-01\n  1.54483432e+00  9.36398544e-01 -8.56549308e-01  4.72247150e-01\n  2.25930895e+00  6.32619942e-02  2.32181036e-01  1.56506538e-01\n -5.97316069e-01 -3.68194521e-01 -8.86348276e-01 -1.70204139e-02\n -2.37921730e-01  3.79151736e-01 -4.10049693e-01 -8.64114721e-01\n -3.45981776e-01  4.81481474e-01 -4.63595975e-01 -9.55945000e-01\n -1.23290271e+00 -9.44446256e-01 -1.54079701e+00 -4.22571517e-02\n -1.63242330e+00  1.48449581e-01  4.22628622e-01  5.29045238e-01\n -1.35978073e+00  9.01429587e-01  1.35339573e+00 -5.85865511e-02\n -4.14008116e-02 -3.17543094e-01 -1.79132755e+00  3.03751081e-01\n  5.21303748e-01 -1.34149673e+00  6.11927193e-01  1.48935596e+00\n  6.01885577e-01 -3.65055217e-01  4.76898369e-01 -6.71341546e-02\n -2.34231050e-02 -9.12783494e-01  3.93062934e-01  2.19509556e-01\n -9.38981573e-01 -9.31538865e-01 -6.24522925e-01 -4.48165363e-01\n  1.01702099e+00 -6.49337928e-01  9.78961454e-02  1.40357103e+00\n  3.76876521e-01 -1.88458584e+00 -5.45711974e-01 -2.00421572e+00\n  1.66873628e+00  4.52489093e-01 -1.94570308e+00  1.07919473e+00\n  9.20858824e-01 -6.89549778e-01  1.74791590e-02 -4.55532504e-01\n -3.53993911e-01 -3.13648031e-01 -7.37767915e-01  1.18802979e+00\n -1.37495129e+00  3.16942612e-01 -1.54477110e+00 -6.97778897e-01\n -6.51025593e-01  6.81594518e-01 -1.03424284e+00  8.56830612e-01\n -9.99141722e-01 -1.00021535e+00 -8.03409664e-01  3.18727653e-01\n -2.06903676e-01 -1.65671510e+00 -1.47183501e+00 -9.85510738e-01\n  1.64813493e+00  1.76124918e+00  1.65492163e+00  6.43314465e-01\n  1.64227755e-01 -1.57062341e+00  4.93836776e-01 -1.60171974e+00\n  3.87280475e-01 -1.02250684e+00 -2.25556423e+00 -1.69810582e+00\n -1.75192866e+00  4.94949817e-02  3.86305518e-02  8.80178912e-01\n  1.32778270e+00 -5.10292740e-01 -3.85489760e-01  1.83925494e-01\n -1.60183605e+00 -1.17043707e+00 -1.28678001e+00 -6.96326654e-01\n -8.87180942e-01 -2.90397101e-01  6.79974844e-01  6.49513839e-01\n -4.64337691e-01 -5.52540673e-01  1.02179059e+00 -8.03141387e-01\n  6.10846720e-01 -7.04921353e-01 -3.86870847e-01 -1.01281486e-01\n -5.35270165e-01 -1.01673865e+00  3.08751242e-01 -1.14775325e-01\n -1.37075998e+00  3.77093686e-01  9.29856929e-01 -1.64296529e+00\n  8.65652923e-01 -4.06071796e-01 -4.36748337e-01  9.34002585e-01\n  1.72504416e-01  9.94544570e-02  2.10620213e-02  1.15418403e+00\n  1.32806016e+00 -1.03264310e+00  2.27392775e-01  2.54052084e-02\n -5.21579678e-01 -2.04732361e+00  9.67446150e-01 -1.22662166e+00\n -5.53525480e-02  4.68843169e-01  9.83747954e-01 -8.51729197e-01\n -2.63937349e-01  1.82272360e+00  1.90311558e-01  7.78855447e-01\n  1.32906285e+00 -1.40134729e+00 -8.17493098e-01  9.60693398e-01\n  1.14115334e+00  3.67544896e-01  1.03043827e+00 -1.18468659e+00\n -6.78025782e-01 -4.45954265e-02 -1.78156286e+00  1.95069697e-01\n -7.29044659e-01 -1.00010839e+00 -9.10782893e-01  9.42468119e-01\n  1.96557401e-01 -2.67594746e-01  9.63213559e-02  9.73749738e-01\n  2.03341817e-02 -7.61573388e-01 -1.34792542e+00 -2.36417382e+00\n  1.08048271e+00  1.63928572e-01  2.01125668e+00  1.29784579e+00\n  9.72535789e-01  3.28087476e-02 -1.15395036e+00 -2.58279663e+00\n -3.47961856e-01  2.08081267e-01  7.08791531e-01  2.39582760e-01\n -1.35338886e+00 -3.69801166e-01  3.11447072e-01  9.49576528e-01\n -1.93176702e-01 -5.39132637e-01  7.55740289e-01  4.06415494e-01\n  1.31194333e+00  4.70433145e-01 -7.49690345e-01  2.13386825e+00\n -9.84525244e-02  1.92953205e+00  8.75512414e-02  9.49420807e-01\n -1.22543552e+00 -7.70627173e-02 -2.14775921e-01 -7.44754822e-01\n  8.44362976e-01 -8.26438539e-01  1.71334272e+00 -2.45787470e-01\n -1.07993151e+00 -4.37820045e-01 -1.14746865e+00  1.12663592e+00\n -3.44646521e-01 -6.82416053e-02 -4.98032451e-01 -6.63478286e-01\n  7.55395696e-01  2.38074535e+00  9.49246474e-01  3.30576756e-01\n -1.50239657e+00 -1.12489639e+00 -1.27069884e+00 -5.91402668e-01\n -1.77766695e+00  1.12441918e+00  3.96086585e-01  5.48835515e-01\n -2.83455451e+00 -1.61087840e+00  2.11679102e+00 -6.56463675e-01\n  4.86503717e-01  1.42298350e+00 -3.57680719e-02  8.67407411e-01\n  2.86904488e-01 -1.31839587e+00 -9.45615796e-01 -3.70704003e-01\n -9.32740911e-01 -7.99232512e-01 -2.58211760e-01 -6.00657558e-01\n -1.26306835e+00  1.55224318e+00 -7.22870076e-02  1.82016301e+00\n  5.20040615e-01  4.49712100e-01  2.25608654e-01  3.17160626e-01\n  2.25325619e+00  1.02893549e+00 -6.72756089e-02 -2.32059428e+00\n -3.84879809e-01 -8.12992989e-01 -8.90915083e-01  2.74516358e-01\n -1.15735526e+00  3.31334994e-02  6.01385307e-02 -1.12682581e+00\n -3.12292251e-01 -7.30677753e-01  1.07774381e+00  3.42224942e-02\n -2.86887192e-01 -1.07305276e-01 -6.16264021e-02 -4.21714513e-02\n  5.28771057e-02 -1.33701560e-01 -7.19604389e-01  9.43515893e-02\n -2.91837363e-01 -1.11589699e+00  3.56292817e-01  7.66663182e-01\n -1.76853845e+00  1.16550583e+00  1.12379522e+00 -3.53431749e-01\n  3.55481793e-01 -1.61647419e+00 -2.22675101e-01 -9.96367240e-01\n  1.14110187e+00  8.52551939e-01  1.46657872e+00  8.57923924e-01\n -1.07454946e+00  5.67290278e-01 -5.98653937e-01 -7.61492212e-01\n  2.98238174e-01  4.07461836e-01  5.39249191e-01 -7.69916074e-01\n -6.74332661e-01 -1.76135782e-01 -7.83436137e-01  3.76425531e-01\n  3.18305583e-02 -1.09940079e+00  9.22206672e-01 -1.21084369e+00\n -1.49634540e-01  1.84926373e+00 -4.35153552e-01 -6.94567860e-01\n -1.65344398e+00  6.14079370e-01  6.72294757e-01  1.32638590e+00\n  1.73887268e+00  1.02943883e+00 -4.24317621e-01 -9.08763246e-01\n  8.62596011e-01  1.33599880e+00  1.27638401e+00 -2.75670535e-01\n -2.65561909e+00 -7.09727966e-01 -5.39454633e-01 -1.16830507e+00\n -8.82418819e-01  4.96000946e-01  1.12859406e+00  1.31913688e+00\n -1.26666464e+00 -2.01640663e+00  7.71405949e-01  9.94394391e-01\n -3.99449029e-01 -4.60719787e-01 -1.34671751e+00 -1.33425847e+00\n  6.93773153e-01 -2.98090508e-01 -5.21531248e-01  9.77249677e-02\n -1.59573438e-01  5.82953680e-01  1.13689136e+00 -2.64591418e-01\n  1.65813068e+00 -6.80178204e-01 -1.18164045e-01 -1.30652685e+00\n -4.17968925e-01 -1.35949701e-01  6.66383082e-01  3.70055888e-01\n -5.05358317e-01 -1.28455230e+00 -9.88001942e-01 -1.04343491e-01\n -1.17762896e+00  4.52993153e-01  8.12583157e-01  8.12674042e-01\n -1.14019630e+00  5.87259379e-01  1.24331938e+00  4.46545869e-01\n -1.05188010e+00 -2.24532165e+00  2.49720039e+00 -5.07517602e-01\n  6.94465717e-01 -9.32789042e-01  5.64008535e-01 -8.15791542e-01\n  1.97967290e-01  2.13215341e+00 -3.50951769e-02  9.36445726e-01\n  1.26507784e+00 -1.31915570e+00 -1.68409858e+00 -3.46249448e-01\n  2.11497013e-01 -7.94636321e-01  1.09074973e+00  2.13266624e-01\n -1.21054299e+00  1.09463837e+00 -7.88669255e-01 -1.44494020e+00\n -3.47115802e-03 -5.32702792e-01  2.34821526e-01  1.08193522e+00\n  1.99300197e-01  2.41245368e+00 -7.93117363e-01 -9.60504382e-01\n -2.28862004e+00  1.41522589e+00  1.43845611e+00 -4.68864188e-01\n  2.51484415e-01 -2.20144129e+00  2.02104356e+00 -1.04593349e+00\n -9.78829859e-01  1.81338429e-01 -4.39189522e-01 -5.17519043e-01\n -1.08615547e+00  3.38904125e-01 -5.02816701e-01 -5.06035410e-02\n -6.92049848e-01  1.30184623e+00 -4.81027118e-01 -6.28087560e-01\n  2.30391670e+00 -1.08460978e+00 -1.80263036e+00 -1.10540657e-01\n -1.06001582e+00  1.02017271e+00  2.06449286e+00 -7.52000898e-01\n  6.08843834e-01  1.21114529e+00 -1.04525337e+00  2.86343689e-01\n -1.23973396e+00 -2.03068447e+00  6.89818165e-01  1.53637705e+00\n -1.10438334e+00 -1.16809350e+00 -1.71546331e-01  5.23276661e-01\n  7.71790551e-01 -5.63492003e-01 -1.18490974e+00  6.25231451e-01\n  8.23504154e-01 -1.60205766e+00 -2.22340315e+00 -9.41780481e-01\n  1.54301460e+00  2.67050869e-01 -1.29285691e+00 -7.39562996e-01\n -1.37911792e+00 -6.43618403e-01 -3.92828182e-02  5.21650793e-02\n  9.31848374e-01 -1.12801133e+00 -9.93123611e-01  2.80441705e-01\n  8.41631264e-01  9.18711757e-01  8.81072116e-01  6.98457149e-01\n -2.49458580e-01  3.77088909e-03  6.20358298e-01 -7.95951782e-01\n  1.60928168e-01 -3.94849514e-01 -1.90653494e-01 -1.56821116e-02\n -8.61105021e-01 -4.79655814e-01 -2.67733537e-01  3.39964984e-01\n  7.23100494e-01 -2.14166656e-01  2.13512238e-02 -4.99016638e-01\n -9.19113445e-01  1.15572557e-01  5.19435999e-01 -4.51303037e-01\n  1.92753849e-01  2.65687975e-01 -1.56699471e+00  8.06438359e-01\n -1.10290621e+00  1.92793845e-02 -1.01697275e-01  7.19983730e-01\n  1.10083721e+00  3.97667346e-02  1.84959125e+00  2.46121252e-02\n  3.96006713e-01  9.44479487e-01  1.11701629e+00 -9.12822225e-01\n -1.31590741e+00 -4.42544047e-01 -1.68103713e+00  5.76590817e-01\n -4.61584605e-01 -2.08298756e-01  6.76433295e-01 -2.40469377e+00\n  4.39391701e-01  6.35031437e-01  1.66673495e-01 -1.49125759e+00\n -3.30392530e+00 -6.35846078e-01  2.38314477e+00 -1.09306151e+00\n  1.03493146e-02  1.69618157e+00  8.21405937e-01 -1.48577034e-02\n  6.70570450e-01  4.45847098e-01  8.96835979e-01 -7.65702194e-01\n -7.07505698e-01  5.55786964e-01 -1.32988422e-01  6.54876509e-01\n  3.03603904e-01 -1.66159829e+00  7.72694837e-01 -1.82425666e+00\n  9.70773425e-01  1.75498615e+00  4.48195284e-01  7.20033759e-01\n -1.15618243e+00 -3.97271814e-01 -2.97790879e-01 -1.32880578e-01\n -3.09012969e-01 -4.45839392e-01 -1.03797071e+00 -5.42861476e-01\n -1.67600381e+00  4.16050046e-01 -4.93319883e-01 -9.68038832e-01\n -2.06998503e+00  6.76908035e-01  4.26258731e-01  1.49448454e+00\n -1.38846166e+00 -1.42406091e+00 -6.37437026e-01  7.81198102e-01\n -3.64693544e-01 -6.89449185e-01 -5.21189312e-01 -6.52293600e-01\n -1.84306955e+00  1.58290316e-01  1.47141971e-01 -4.40922632e-01\n -4.77974004e-01 -2.80355495e-01 -1.21407740e+00 -1.47485603e-01\n  3.49654457e-01 -1.43779147e+00 -7.64143924e-01  5.78521498e-01\n -1.62164651e-01 -6.87837611e-01  1.36453185e+00  1.56703855e-01\n -9.44368491e-01 -3.79147563e-01 -1.30324275e+00 -1.74235620e+00\n  6.05120084e-01 -1.00382332e+00 -7.94052862e-01 -1.55042935e+00\n  8.95555986e-01  4.17318821e-01 -1.78589092e-01  1.24386492e+00\n -5.90057646e-01 -1.66069981e+00 -1.10489405e-01 -1.40596292e+00\n  1.43994634e+00 -9.30156503e-01  1.15147873e-01  2.38103148e-01\n -4.53804041e-01  1.36759724e+00 -9.96212640e-01  1.03440989e+00\n -1.21793851e+00 -1.11291452e+00 -1.14460186e+00  4.66166426e-01\n -3.04963638e-01 -3.70242441e-01 -1.17474546e-01  7.92733971e-01\n  2.52496627e-01  1.35994854e+00  8.20321797e-01 -9.18004770e-01\n  8.14426004e-01 -6.87299037e-01 -9.03820073e-02  4.03264540e-01\n -2.02896841e-01 -4.43836093e-01 -2.55918467e+00  1.07819730e+00\n  1.18137860e+00 -1.11026569e+00 -1.00849776e+00 -2.61645446e-01\n -6.31903758e-01 -1.82244784e-01 -5.85431204e-01  1.08678051e+00\n -1.20857365e+00  1.51826117e+00 -2.42019830e-01  2.13480049e-01\n  1.20719779e+00 -1.27968917e+00 -3.84645423e-01 -1.09882779e-01\n -1.63263453e+00 -1.96862469e+00  1.75818953e-01 -6.60056320e-01\n  4.98690275e-01  1.75384676e+00  1.70789413e+00 -3.47450652e-01\n  1.04797216e+00 -5.81268477e-01 -2.34215801e-01 -1.46202392e+00\n  1.30142807e+00  1.37496407e+00  8.95260273e-01 -1.17915793e+00\n -1.56722073e+00  1.09634685e+00 -1.33221165e+00 -1.56776772e+00\n  3.30035115e-01 -6.96415784e-02  8.67276629e-01  5.15749428e-02\n -8.48320523e-01  1.05631651e-01  5.27287743e-01 -6.67720286e-01\n -3.25669469e-01  3.26962595e-01 -5.91183104e-01  8.53624313e-01\n -5.09843242e-01  9.97117981e-01  3.24869616e-01  1.37098901e+00\n  1.16160320e+00 -8.37678042e-01  3.06018243e-02  2.22594433e+00\n  1.09965960e+00 -9.81503896e-02  3.17218215e-01  9.10178908e-01\n  7.86327962e-01 -5.71099374e-01 -1.54647846e+00 -3.69181838e-01\n -4.66419097e-01 -2.39379178e-01  1.33652795e+00 -1.72122429e+00\n -1.61695604e+00 -7.38030909e-01 -2.43261244e-02  6.40131526e-01\n -2.42038557e+00  2.16323595e+00  2.79924599e-01  6.55263731e-01\n -1.68121822e+00  8.64052300e-01  4.01499055e-01 -2.23960406e+00\n  1.22487056e+00  1.35200433e+00  1.32083783e+00 -2.22605681e-01\n  6.48561063e-02 -9.13079218e-01  1.74266878e+00 -1.11759804e+00\n -8.88720257e-01  1.41232771e+00  9.36742464e-01  2.42117961e-01\n -1.19553917e+00  2.84279671e-01 -2.36958691e+00 -8.88971358e-01\n  9.43046087e-01  2.76871906e-01  3.14817205e-01 -9.71104570e-01\n  8.21585712e-01  1.26171292e+00  1.20568398e+00 -1.30106954e-01\n  5.29264630e-03  9.39532294e-02  1.23721914e-01 -1.10274208e+00\n  2.69904355e-01 -1.41690611e+00 -4.66845546e-01 -5.69312053e-01\n -1.19543179e+00 -2.09460307e+00  8.68963487e-01 -2.73967717e+00\n -1.02993528e+00 -5.14233966e-01 -7.78547559e-02 -1.01804188e+00\n  3.82732430e-01  1.43188362e+00  1.41521630e+00 -4.57039607e-02\n -3.42422805e-02  2.20507656e-01  5.53132064e-01 -1.14737286e+00\n  1.29802197e+00 -7.39246663e-02  2.69622405e+00  1.10028434e+00\n -1.21781761e+00  1.51332808e+00 -6.58552967e-01 -3.49943365e-01\n -1.44653470e+00  1.42061805e-01  1.71958931e+00  1.51999486e+00\n  9.29505111e-01  3.30008796e-01  3.12174716e-01 -1.85053671e-01\n  5.82224591e-01 -8.07648488e-01  5.89255892e-02 -2.95483129e-01\n -2.33466662e-01  6.84501107e-01  1.73272119e+00 -3.09114445e-01\n -3.22081232e-01  8.14519822e-01  3.70825001e-01  8.00297949e-01\n  5.23891024e-01  3.90093323e-01 -3.90953375e-01 -6.52408582e-01\n  4.93741777e-01 -4.05986867e-01 -5.94435235e-01 -1.93627981e+00\n -1.16103939e-01  1.88778597e-01 -5.25672963e-02 -1.03281805e-01\n  9.74001663e-02 -2.77259276e+00  3.99046346e-01 -3.10886172e-01\n -2.26366968e-01 -5.96314038e-01  1.95591231e+00  8.84220870e-02\n  1.28598401e+00 -1.22619619e+00  1.67094303e+00  1.83339199e-01\n -5.61330204e-02 -1.13055023e+00 -9.85692180e-01  2.23843563e-01\n -1.38504274e-03  3.29622982e-01  4.04761812e-01  1.19811586e+00\n -3.82008956e-01 -3.02249730e-01 -2.24258934e-01  6.76460732e-01\n  1.35126740e+00 -1.31908640e-01 -3.75147117e-01 -1.50699840e+00]", "indices": "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]", "indptr": "[   0   20   40   60   80  100  120  140  160  180  200  220  240  260\n  280  300  320  340  360  380  400  420  440  460  480  500  520  540\n  560  580  600  620  640  660  680  700  720  740  760  780  800  820\n  840  860  880  900  920  940  960  980 1000]"}, "y": "[1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0\n 1 0 0 0 1 1 0 1 1 1 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-24, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 200, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l1", "max_squared_sum": 36.175084373264106, "sample_weight": null}}, "return": ["[[0.         0.         0.         0.         0.         0.\n  1.89768273 0.         0.         0.         0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.        ]]", "[0.2]", "[132]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [50, 20], "maxprint": 50, "data": "[ 6.99380484e-01 -9.64606424e-01 -2.12523045e-01  5.98946831e-02\n -7.62114512e-01  4.57627354e-01  1.01227546e+00 -2.41337791e-01\n -8.87780137e-01 -8.78190343e-01 -6.31375988e-01  8.75732584e-01\n -8.58919908e-01 -1.79422927e+00  5.09542770e-02 -2.22477010e-01\n  1.26791822e+00  1.08137603e+00  1.32646164e+00 -1.06122229e+00\n -5.32489919e-01  1.68192174e+00  2.29597556e-02 -8.52585847e-01\n -1.11456118e-02  7.89509362e-01  1.38585905e+00 -1.68823003e+00\n  1.14988999e-02 -1.12465983e-01 -2.61922373e-02  7.10890117e-01\n -6.57951045e-01  1.73587900e+00  4.68385234e-01  1.01184243e+00\n  1.12049186e+00  4.98052405e-01 -6.67712721e-01  6.45055273e-01\n -8.58972388e-01  7.85803827e-01 -3.91217052e-01 -5.74695185e-02\n  9.40917615e-01  4.61206902e-01  1.19595682e+00 -8.97400927e-01\n  4.05204080e-01  1.31247037e+00 -5.00840943e-02  1.27255325e+00\n -1.07709907e+00 -8.29964598e-01 -4.24663302e-01  7.45864065e-02\n  1.79797132e+00 -7.57870860e-01  1.41117206e+00 -8.98942156e-01\n  5.21064876e-01 -1.38336396e+00  6.10379379e-01 -1.58293840e+00\n -1.18885926e+00 -1.97938995e-01 -6.00663118e-01 -8.13364259e-01\n -5.06816354e-01 -1.46642433e+00  1.07961859e+00 -7.40037255e-01\n -3.19328417e-01  6.94749144e-01  6.91538751e-01  1.41953163e-01\n -1.03025018e+00  1.15233156e+00 -7.25597378e-01 -5.75787970e-01\n  4.53781913e-01 -1.11831192e+00  1.13307988e+00 -1.31054012e-01\n -1.95180410e+00 -1.02503327e+00 -9.71862486e-01  8.62789892e-03\n -6.59891730e-01  5.27004208e-01  6.16886554e-01  9.12861017e-01\n  7.67902408e-01 -3.63858810e-01  5.89879821e-01  3.70057219e-02\n  9.93830333e-01  3.54757693e-01 -8.05626508e-01 -1.82974041e+00\n  7.47188334e-01  4.50934462e-01  1.65955080e+00 -6.84010898e-01\n  1.06850940e+00  1.06238655e+00  1.00745522e+00 -7.04700276e-01\n -4.53385804e-01  9.43260725e-01  2.25672350e+00 -9.45733763e-01\n -1.18388064e+00  6.06319524e-01 -2.65917224e+00  7.73252977e-01\n -1.02952256e+00 -1.57667016e-01 -1.75589058e+00 -1.18894496e+00\n -2.16949570e-01 -1.08403662e+00  3.79235534e-01  3.51780111e-01\n -4.70032883e-01 -1.00885504e+00 -8.10018628e-01 -5.54309627e-01\n -2.16731471e-01 -4.70637658e-01  7.84957521e-01  1.22350722e+00\n -3.04614305e+00  4.39042958e-01  5.43311891e-01 -3.92388998e-01\n  1.41169540e+00 -1.13980246e+00 -2.19541028e-01  4.45393251e-01\n -8.59307670e-02 -1.10389299e-01  8.20247837e-01 -1.05462846e+00\n  4.63130329e-01  1.73011739e+00  1.64252894e+00 -3.95228983e-01\n  2.79095764e-01 -1.15942052e+00  7.82601752e-02 -1.53600082e+00\n -1.15107468e-01 -9.64612014e-01  4.57415606e-01  8.75832762e-01\n -1.67106893e+00  8.00564803e-01 -7.82629156e-01  1.94292938e-01\n -6.47181432e-01 -1.54158740e+00 -4.04032294e-01  2.59442459e+00\n -1.46173269e+00  1.85170955e-01  7.58261638e-01  2.71170185e-01\n -6.83439767e-01 -8.01496885e-01 -5.25640593e-01  1.12793525e+00\n -1.75316402e-01  1.99795608e+00 -1.42191987e+00  9.30408496e-01\n  1.54483432e+00  9.36398544e-01 -8.56549308e-01  4.72247150e-01\n  2.25930895e+00  6.32619942e-02  2.32181036e-01  1.56506538e-01\n -5.97316069e-01 -3.68194521e-01 -8.86348276e-01 -1.70204139e-02\n -2.37921730e-01  3.79151736e-01 -4.10049693e-01 -8.64114721e-01\n -3.45981776e-01  4.81481474e-01 -4.63595975e-01 -9.55945000e-01\n -1.23290271e+00 -9.44446256e-01 -1.54079701e+00 -4.22571517e-02\n -1.63242330e+00  1.48449581e-01  4.22628622e-01  5.29045238e-01\n -1.35978073e+00  9.01429587e-01  1.35339573e+00 -5.85865511e-02\n -4.14008116e-02 -3.17543094e-01 -1.79132755e+00  3.03751081e-01\n  5.21303748e-01 -1.34149673e+00  6.11927193e-01  1.48935596e+00\n  6.01885577e-01 -3.65055217e-01  4.76898369e-01 -6.71341546e-02\n -2.34231050e-02 -9.12783494e-01  3.93062934e-01  2.19509556e-01\n -9.38981573e-01 -9.31538865e-01 -6.24522925e-01 -4.48165363e-01\n  1.01702099e+00 -6.49337928e-01  9.78961454e-02  1.40357103e+00\n  3.76876521e-01 -1.88458584e+00 -5.45711974e-01 -2.00421572e+00\n  1.66873628e+00  4.52489093e-01 -1.94570308e+00  1.07919473e+00\n  9.20858824e-01 -6.89549778e-01  1.74791590e-02 -4.55532504e-01\n -3.53993911e-01 -3.13648031e-01 -7.37767915e-01  1.18802979e+00\n -1.37495129e+00  3.16942612e-01 -1.54477110e+00 -6.97778897e-01\n -6.51025593e-01  6.81594518e-01 -1.03424284e+00  8.56830612e-01\n -9.99141722e-01 -1.00021535e+00 -8.03409664e-01  3.18727653e-01\n -2.06903676e-01 -1.65671510e+00 -1.47183501e+00 -9.85510738e-01\n  1.64813493e+00  1.76124918e+00  1.65492163e+00  6.43314465e-01\n  1.64227755e-01 -1.57062341e+00  4.93836776e-01 -1.60171974e+00\n  3.87280475e-01 -1.02250684e+00 -2.25556423e+00 -1.69810582e+00\n -1.75192866e+00  4.94949817e-02  3.86305518e-02  8.80178912e-01\n  1.32778270e+00 -5.10292740e-01 -3.85489760e-01  1.83925494e-01\n -1.60183605e+00 -1.17043707e+00 -1.28678001e+00 -6.96326654e-01\n -8.87180942e-01 -2.90397101e-01  6.79974844e-01  6.49513839e-01\n -4.64337691e-01 -5.52540673e-01  1.02179059e+00 -8.03141387e-01\n  6.10846720e-01 -7.04921353e-01 -3.86870847e-01 -1.01281486e-01\n -5.35270165e-01 -1.01673865e+00  3.08751242e-01 -1.14775325e-01\n -1.37075998e+00  3.77093686e-01  9.29856929e-01 -1.64296529e+00\n  8.65652923e-01 -4.06071796e-01 -4.36748337e-01  9.34002585e-01\n  1.72504416e-01  9.94544570e-02  2.10620213e-02  1.15418403e+00\n  1.32806016e+00 -1.03264310e+00  2.27392775e-01  2.54052084e-02\n -5.21579678e-01 -2.04732361e+00  9.67446150e-01 -1.22662166e+00\n -5.53525480e-02  4.68843169e-01  9.83747954e-01 -8.51729197e-01\n -2.63937349e-01  1.82272360e+00  1.90311558e-01  7.78855447e-01\n  1.32906285e+00 -1.40134729e+00 -8.17493098e-01  9.60693398e-01\n  1.14115334e+00  3.67544896e-01  1.03043827e+00 -1.18468659e+00\n -6.78025782e-01 -4.45954265e-02 -1.78156286e+00  1.95069697e-01\n -7.29044659e-01 -1.00010839e+00 -9.10782893e-01  9.42468119e-01\n  1.96557401e-01 -2.67594746e-01  9.63213559e-02  9.73749738e-01\n  2.03341817e-02 -7.61573388e-01 -1.34792542e+00 -2.36417382e+00\n  1.08048271e+00  1.63928572e-01  2.01125668e+00  1.29784579e+00\n  9.72535789e-01  3.28087476e-02 -1.15395036e+00 -2.58279663e+00\n -3.47961856e-01  2.08081267e-01  7.08791531e-01  2.39582760e-01\n -1.35338886e+00 -3.69801166e-01  3.11447072e-01  9.49576528e-01\n -1.93176702e-01 -5.39132637e-01  7.55740289e-01  4.06415494e-01\n  1.31194333e+00  4.70433145e-01 -7.49690345e-01  2.13386825e+00\n -9.84525244e-02  1.92953205e+00  8.75512414e-02  9.49420807e-01\n -1.22543552e+00 -7.70627173e-02 -2.14775921e-01 -7.44754822e-01\n  8.44362976e-01 -8.26438539e-01  1.71334272e+00 -2.45787470e-01\n -1.07993151e+00 -4.37820045e-01 -1.14746865e+00  1.12663592e+00\n -3.44646521e-01 -6.82416053e-02 -4.98032451e-01 -6.63478286e-01\n  7.55395696e-01  2.38074535e+00  9.49246474e-01  3.30576756e-01\n -1.50239657e+00 -1.12489639e+00 -1.27069884e+00 -5.91402668e-01\n -1.77766695e+00  1.12441918e+00  3.96086585e-01  5.48835515e-01\n -2.83455451e+00 -1.61087840e+00  2.11679102e+00 -6.56463675e-01\n  4.86503717e-01  1.42298350e+00 -3.57680719e-02  8.67407411e-01\n  2.86904488e-01 -1.31839587e+00 -9.45615796e-01 -3.70704003e-01\n -9.32740911e-01 -7.99232512e-01 -2.58211760e-01 -6.00657558e-01\n -1.26306835e+00  1.55224318e+00 -7.22870076e-02  1.82016301e+00\n  5.20040615e-01  4.49712100e-01  2.25608654e-01  3.17160626e-01\n  2.25325619e+00  1.02893549e+00 -6.72756089e-02 -2.32059428e+00\n -3.84879809e-01 -8.12992989e-01 -8.90915083e-01  2.74516358e-01\n -1.15735526e+00  3.31334994e-02  6.01385307e-02 -1.12682581e+00\n -3.12292251e-01 -7.30677753e-01  1.07774381e+00  3.42224942e-02\n -2.86887192e-01 -1.07305276e-01 -6.16264021e-02 -4.21714513e-02\n  5.28771057e-02 -1.33701560e-01 -7.19604389e-01  9.43515893e-02\n -2.91837363e-01 -1.11589699e+00  3.56292817e-01  7.66663182e-01\n -1.76853845e+00  1.16550583e+00  1.12379522e+00 -3.53431749e-01\n  3.55481793e-01 -1.61647419e+00 -2.22675101e-01 -9.96367240e-01\n  1.14110187e+00  8.52551939e-01  1.46657872e+00  8.57923924e-01\n -1.07454946e+00  5.67290278e-01 -5.98653937e-01 -7.61492212e-01\n  2.98238174e-01  4.07461836e-01  5.39249191e-01 -7.69916074e-01\n -6.74332661e-01 -1.76135782e-01 -7.83436137e-01  3.76425531e-01\n  3.18305583e-02 -1.09940079e+00  9.22206672e-01 -1.21084369e+00\n -1.49634540e-01  1.84926373e+00 -4.35153552e-01 -6.94567860e-01\n -1.65344398e+00  6.14079370e-01  6.72294757e-01  1.32638590e+00\n  1.73887268e+00  1.02943883e+00 -4.24317621e-01 -9.08763246e-01\n  8.62596011e-01  1.33599880e+00  1.27638401e+00 -2.75670535e-01\n -2.65561909e+00 -7.09727966e-01 -5.39454633e-01 -1.16830507e+00\n -8.82418819e-01  4.96000946e-01  1.12859406e+00  1.31913688e+00\n -1.26666464e+00 -2.01640663e+00  7.71405949e-01  9.94394391e-01\n -3.99449029e-01 -4.60719787e-01 -1.34671751e+00 -1.33425847e+00\n  6.93773153e-01 -2.98090508e-01 -5.21531248e-01  9.77249677e-02\n -1.59573438e-01  5.82953680e-01  1.13689136e+00 -2.64591418e-01\n  1.65813068e+00 -6.80178204e-01 -1.18164045e-01 -1.30652685e+00\n -4.17968925e-01 -1.35949701e-01  6.66383082e-01  3.70055888e-01\n -5.05358317e-01 -1.28455230e+00 -9.88001942e-01 -1.04343491e-01\n -1.17762896e+00  4.52993153e-01  8.12583157e-01  8.12674042e-01\n -1.14019630e+00  5.87259379e-01  1.24331938e+00  4.46545869e-01\n -1.05188010e+00 -2.24532165e+00  2.49720039e+00 -5.07517602e-01\n  6.94465717e-01 -9.32789042e-01  5.64008535e-01 -8.15791542e-01\n  1.97967290e-01  2.13215341e+00 -3.50951769e-02  9.36445726e-01\n  1.26507784e+00 -1.31915570e+00 -1.68409858e+00 -3.46249448e-01\n  2.11497013e-01 -7.94636321e-01  1.09074973e+00  2.13266624e-01\n -1.21054299e+00  1.09463837e+00 -7.88669255e-01 -1.44494020e+00\n -3.47115802e-03 -5.32702792e-01  2.34821526e-01  1.08193522e+00\n  1.99300197e-01  2.41245368e+00 -7.93117363e-01 -9.60504382e-01\n -2.28862004e+00  1.41522589e+00  1.43845611e+00 -4.68864188e-01\n  2.51484415e-01 -2.20144129e+00  2.02104356e+00 -1.04593349e+00\n -9.78829859e-01  1.81338429e-01 -4.39189522e-01 -5.17519043e-01\n -1.08615547e+00  3.38904125e-01 -5.02816701e-01 -5.06035410e-02\n -6.92049848e-01  1.30184623e+00 -4.81027118e-01 -6.28087560e-01\n  2.30391670e+00 -1.08460978e+00 -1.80263036e+00 -1.10540657e-01\n -1.06001582e+00  1.02017271e+00  2.06449286e+00 -7.52000898e-01\n  6.08843834e-01  1.21114529e+00 -1.04525337e+00  2.86343689e-01\n -1.23973396e+00 -2.03068447e+00  6.89818165e-01  1.53637705e+00\n -1.10438334e+00 -1.16809350e+00 -1.71546331e-01  5.23276661e-01\n  7.71790551e-01 -5.63492003e-01 -1.18490974e+00  6.25231451e-01\n  8.23504154e-01 -1.60205766e+00 -2.22340315e+00 -9.41780481e-01\n  1.54301460e+00  2.67050869e-01 -1.29285691e+00 -7.39562996e-01\n -1.37911792e+00 -6.43618403e-01 -3.92828182e-02  5.21650793e-02\n  9.31848374e-01 -1.12801133e+00 -9.93123611e-01  2.80441705e-01\n  8.41631264e-01  9.18711757e-01  8.81072116e-01  6.98457149e-01\n -2.49458580e-01  3.77088909e-03  6.20358298e-01 -7.95951782e-01\n  1.60928168e-01 -3.94849514e-01 -1.90653494e-01 -1.56821116e-02\n -8.61105021e-01 -4.79655814e-01 -2.67733537e-01  3.39964984e-01\n  7.23100494e-01 -2.14166656e-01  2.13512238e-02 -4.99016638e-01\n -9.19113445e-01  1.15572557e-01  5.19435999e-01 -4.51303037e-01\n  1.92753849e-01  2.65687975e-01 -1.56699471e+00  8.06438359e-01\n -1.10290621e+00  1.92793845e-02 -1.01697275e-01  7.19983730e-01\n  1.10083721e+00  3.97667346e-02  1.84959125e+00  2.46121252e-02\n  3.96006713e-01  9.44479487e-01  1.11701629e+00 -9.12822225e-01\n -1.31590741e+00 -4.42544047e-01 -1.68103713e+00  5.76590817e-01\n -4.61584605e-01 -2.08298756e-01  6.76433295e-01 -2.40469377e+00\n  4.39391701e-01  6.35031437e-01  1.66673495e-01 -1.49125759e+00\n -3.30392530e+00 -6.35846078e-01  2.38314477e+00 -1.09306151e+00\n  1.03493146e-02  1.69618157e+00  8.21405937e-01 -1.48577034e-02\n  6.70570450e-01  4.45847098e-01  8.96835979e-01 -7.65702194e-01\n -7.07505698e-01  5.55786964e-01 -1.32988422e-01  6.54876509e-01\n  3.03603904e-01 -1.66159829e+00  7.72694837e-01 -1.82425666e+00\n  9.70773425e-01  1.75498615e+00  4.48195284e-01  7.20033759e-01\n -1.15618243e+00 -3.97271814e-01 -2.97790879e-01 -1.32880578e-01\n -3.09012969e-01 -4.45839392e-01 -1.03797071e+00 -5.42861476e-01\n -1.67600381e+00  4.16050046e-01 -4.93319883e-01 -9.68038832e-01\n -2.06998503e+00  6.76908035e-01  4.26258731e-01  1.49448454e+00\n -1.38846166e+00 -1.42406091e+00 -6.37437026e-01  7.81198102e-01\n -3.64693544e-01 -6.89449185e-01 -5.21189312e-01 -6.52293600e-01\n -1.84306955e+00  1.58290316e-01  1.47141971e-01 -4.40922632e-01\n -4.77974004e-01 -2.80355495e-01 -1.21407740e+00 -1.47485603e-01\n  3.49654457e-01 -1.43779147e+00 -7.64143924e-01  5.78521498e-01\n -1.62164651e-01 -6.87837611e-01  1.36453185e+00  1.56703855e-01\n -9.44368491e-01 -3.79147563e-01 -1.30324275e+00 -1.74235620e+00\n  6.05120084e-01 -1.00382332e+00 -7.94052862e-01 -1.55042935e+00\n  8.95555986e-01  4.17318821e-01 -1.78589092e-01  1.24386492e+00\n -5.90057646e-01 -1.66069981e+00 -1.10489405e-01 -1.40596292e+00\n  1.43994634e+00 -9.30156503e-01  1.15147873e-01  2.38103148e-01\n -4.53804041e-01  1.36759724e+00 -9.96212640e-01  1.03440989e+00\n -1.21793851e+00 -1.11291452e+00 -1.14460186e+00  4.66166426e-01\n -3.04963638e-01 -3.70242441e-01 -1.17474546e-01  7.92733971e-01\n  2.52496627e-01  1.35994854e+00  8.20321797e-01 -9.18004770e-01\n  8.14426004e-01 -6.87299037e-01 -9.03820073e-02  4.03264540e-01\n -2.02896841e-01 -4.43836093e-01 -2.55918467e+00  1.07819730e+00\n  1.18137860e+00 -1.11026569e+00 -1.00849776e+00 -2.61645446e-01\n -6.31903758e-01 -1.82244784e-01 -5.85431204e-01  1.08678051e+00\n -1.20857365e+00  1.51826117e+00 -2.42019830e-01  2.13480049e-01\n  1.20719779e+00 -1.27968917e+00 -3.84645423e-01 -1.09882779e-01\n -1.63263453e+00 -1.96862469e+00  1.75818953e-01 -6.60056320e-01\n  4.98690275e-01  1.75384676e+00  1.70789413e+00 -3.47450652e-01\n  1.04797216e+00 -5.81268477e-01 -2.34215801e-01 -1.46202392e+00\n  1.30142807e+00  1.37496407e+00  8.95260273e-01 -1.17915793e+00\n -1.56722073e+00  1.09634685e+00 -1.33221165e+00 -1.56776772e+00\n  3.30035115e-01 -6.96415784e-02  8.67276629e-01  5.15749428e-02\n -8.48320523e-01  1.05631651e-01  5.27287743e-01 -6.67720286e-01\n -3.25669469e-01  3.26962595e-01 -5.91183104e-01  8.53624313e-01\n -5.09843242e-01  9.97117981e-01  3.24869616e-01  1.37098901e+00\n  1.16160320e+00 -8.37678042e-01  3.06018243e-02  2.22594433e+00\n  1.09965960e+00 -9.81503896e-02  3.17218215e-01  9.10178908e-01\n  7.86327962e-01 -5.71099374e-01 -1.54647846e+00 -3.69181838e-01\n -4.66419097e-01 -2.39379178e-01  1.33652795e+00 -1.72122429e+00\n -1.61695604e+00 -7.38030909e-01 -2.43261244e-02  6.40131526e-01\n -2.42038557e+00  2.16323595e+00  2.79924599e-01  6.55263731e-01\n -1.68121822e+00  8.64052300e-01  4.01499055e-01 -2.23960406e+00\n  1.22487056e+00  1.35200433e+00  1.32083783e+00 -2.22605681e-01\n  6.48561063e-02 -9.13079218e-01  1.74266878e+00 -1.11759804e+00\n -8.88720257e-01  1.41232771e+00  9.36742464e-01  2.42117961e-01\n -1.19553917e+00  2.84279671e-01 -2.36958691e+00 -8.88971358e-01\n  9.43046087e-01  2.76871906e-01  3.14817205e-01 -9.71104570e-01\n  8.21585712e-01  1.26171292e+00  1.20568398e+00 -1.30106954e-01\n  5.29264630e-03  9.39532294e-02  1.23721914e-01 -1.10274208e+00\n  2.69904355e-01 -1.41690611e+00 -4.66845546e-01 -5.69312053e-01\n -1.19543179e+00 -2.09460307e+00  8.68963487e-01 -2.73967717e+00\n -1.02993528e+00 -5.14233966e-01 -7.78547559e-02 -1.01804188e+00\n  3.82732430e-01  1.43188362e+00  1.41521630e+00 -4.57039607e-02\n -3.42422805e-02  2.20507656e-01  5.53132064e-01 -1.14737286e+00\n  1.29802197e+00 -7.39246663e-02  2.69622405e+00  1.10028434e+00\n -1.21781761e+00  1.51332808e+00 -6.58552967e-01 -3.49943365e-01\n -1.44653470e+00  1.42061805e-01  1.71958931e+00  1.51999486e+00\n  9.29505111e-01  3.30008796e-01  3.12174716e-01 -1.85053671e-01\n  5.82224591e-01 -8.07648488e-01  5.89255892e-02 -2.95483129e-01\n -2.33466662e-01  6.84501107e-01  1.73272119e+00 -3.09114445e-01\n -3.22081232e-01  8.14519822e-01  3.70825001e-01  8.00297949e-01\n  5.23891024e-01  3.90093323e-01 -3.90953375e-01 -6.52408582e-01\n  4.93741777e-01 -4.05986867e-01 -5.94435235e-01 -1.93627981e+00\n -1.16103939e-01  1.88778597e-01 -5.25672963e-02 -1.03281805e-01\n  9.74001663e-02 -2.77259276e+00  3.99046346e-01 -3.10886172e-01\n -2.26366968e-01 -5.96314038e-01  1.95591231e+00  8.84220870e-02\n  1.28598401e+00 -1.22619619e+00  1.67094303e+00  1.83339199e-01\n -5.61330204e-02 -1.13055023e+00 -9.85692180e-01  2.23843563e-01\n -1.38504274e-03  3.29622982e-01  4.04761812e-01  1.19811586e+00\n -3.82008956e-01 -3.02249730e-01 -2.24258934e-01  6.76460732e-01\n  1.35126740e+00 -1.31908640e-01 -3.75147117e-01 -1.50699840e+00]", "indices": "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7\n  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11\n 12 13 14 15 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n 16 17 18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19\n  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19  0  1  2  3\n  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]", "indptr": "[   0   20   40   60   80  100  120  140  160  180  200  220  240  260\n  280  300  320  340  360  380  400  420  440  460  480  500  520  540\n  560  580  600  620  640  660  680  700  720  740  760  780  800  820\n  840  860  880  900  920  940  960  980 1000]"}, "y": "[1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0\n 1 0 0 0 1 1 0 1 1 1 1 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": null, "fit_intercept": false, "tol": 1e-24, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 200, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 36.175084373264106, "sample_weight": null}}, "return": ["[[-0.09756681 -0.0506935   0.24884963 -0.04294292  0.0341221   0.79956976\n   1.10437278  0.06516143  0.08701596 -0.09382016 -0.17883694  0.05622643\n   0.08038283 -0.21478978  0.05205292  0.13141357  0.24950976  0.07151282\n  -0.06272591  0.19057438]]", "[0.2]", "[200]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": "1.0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.6324396  0.4584476  0.46553645]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "data": "[-1.  1.  1.  1.]", "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]"}, "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": "1.0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.6324396  0.4584476  0.46553645]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "float", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": 1.0, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[0.63243961 0.45844759 0.46553642]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[0.47517297 0.3618571  0.19141586]]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "data": "[-1.  1.  1.  1.]", "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]"}, "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[0.47517297 0.3618571  0.19141586]]]", "[1.]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "str", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": "1.0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": "2.0", "sample_weight": null}}, "return": ["[[0.6315525  0.4603072  0.46063083]]", "[1.]", "[33]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "data": "[-1.  1.  1.  1.]", "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]"}, "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": "1.0", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[0.60094935 0.5551392  0.11965632]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "float", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": 1.0, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[0.63155241 0.46030718 0.46063085]]", "[1.]", "[33]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "str", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": "2.0", "sample_weight": null}}, "return": ["[[[0.4745235  0.3630401  0.18960543]]]", "[1.]", "[24]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": {"_shape": "list of 2 int", "maxprint": "int", "data": "np.ndarray[float64]", "indices": "np.ndarray[int64]", "indptr": "np.ndarray[int64]"}, "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": {"_shape": [3, 2], "maxprint": 50, "data": "[-1.  1.  1.  1.]", "indices": "[0 1 0 1]", "indptr": "[0 1 2 4]"}, "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[[0.45694768 0.39967644 0.09630726]]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[float64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0. 1. 1.]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0005, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 42, "coef": null, "penalty": "l2", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[[0.47452346 0.36304013 0.18960572]]]", "[1.]", "[24]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[[ 0.61928939  0.69371799 -0.60199313]]]", "[1.]", "[26]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": "[[ 0.61928939  0.69371799 -0.60199313]]", "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[[ 0.61930367  0.6937014  -0.60198137]]]", "[1.]", "[27]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "np.ndarray[float64]", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 2.76405235e+00  1.40015721e+00]\n [ 1.97873798e+00  3.24089320e+00]\n [ 2.86755799e+00  2.27221201e-02]\n [ 1.95008842e+00  8.48642792e-01]\n [ 8.96781148e-01  1.41059850e+00]\n [ 1.14404357e+00  2.45427351e+00]\n [ 1.76103773e+00  1.12167502e+00]\n [ 1.44386323e+00  1.33367433e+00]\n [ 2.49407907e+00  7.94841736e-01]\n [ 1.31306770e+00  1.45904261e-01]\n [-1.55298982e+00  1.65361860e+00]\n [ 1.86443620e+00  2.57834980e-01]\n [ 3.26975462e+00 -4.54365675e-01]\n [ 1.04575852e+00  8.12816150e-01]\n [ 2.53277921e+00  2.46935877e+00]\n [ 1.15494743e+00  1.37816252e+00]\n [ 1.12214252e-01 -9.80796468e-01]\n [ 6.52087851e-01  1.15634897e+00]\n [ 2.23029068e+00  2.20237985e+00]\n [ 6.12673183e-01  6.97697249e-01]\n [-4.85529651e-02 -4.20017937e-01]\n [-7.06270191e-01  2.95077540e+00]\n [ 4.90347818e-01  5.61925698e-01]\n [-2.52795360e-01  1.77749036e+00]\n [-6.13897848e-01  7.87259720e-01]\n [ 1.04533439e-01  1.38690250e+00]\n [ 4.89194862e-01 -1.80632184e-01]\n [ 9.71817772e-01  1.42833187e+00]\n [ 1.06651722e+00  1.30247190e+00]\n [ 3.65677906e-01  6.37258834e-01]\n [ 3.27539552e-01  6.40446838e-01]\n [ 1.86853718e-01 -7.26282602e-01]\n [ 1.17742614e+00  5.98219064e-01]\n [-6.30198347e-01  1.46278226e+00]\n [ 9.27016356e-02  1.05194540e+00]\n [ 1.72909056e+00  1.12898291e+00]\n [ 2.13940068e+00 -2.34825820e-01]\n [ 1.40234164e+00  3.15189909e-01]\n [ 1.29202851e-01  4.21150335e-01]\n [ 6.88447468e-01  1.05616534e+00]\n [-1.65149841e-01  1.90082649e+00]\n [ 1.46566244e+00 -5.36243686e-01]\n [ 2.48825219e+00  2.89588918e+00]\n [ 2.17877957e+00  8.20075164e-01]\n [-7.07526215e-02  2.05445173e+00]\n [ 5.96823053e-01  2.22244507e+00]\n [ 1.20827498e+00  1.97663904e+00]\n [ 1.35636640e+00  1.70657317e+00]\n [ 1.01050002e+00  2.78587049e+00]\n [ 1.12691209e+00  1.40198936e+00]\n [ 2.88315070e+00 -3.47759061e-01]\n [-2.70484998e-01  1.96939671e+00]\n [-1.73123405e-01  2.94362119e+00]\n [ 5.86381019e-01  2.52545189e-01]\n [ 2.92294203e+00  2.48051479e+00]\n [ 2.86755896e+00  1.90604466e+00]\n [ 1.38774315e-01  2.91006495e+00]\n [ 7.31996629e-01  1.80245640e+00]\n [ 1.94725197e+00  8.44989907e-01]\n [ 1.61407937e+00  1.92220667e+00]\n [ 1.37642553e+00 -9.94007906e-02]\n [ 1.29823817e+00  2.32638590e+00]\n [ 3.05432140e-01  8.50365460e-01]\n [ 5.64846448e-01  2.84926373e+00]\n [ 1.67229476e+00  1.40746184e+00]\n [ 2.30083926e-01  1.53924919e+00]\n [ 3.25667339e-01  1.03183056e+00]\n [ 3.64153922e-01  1.67643329e+00]\n [ 1.57659082e+00  7.91701244e-01]\n [ 1.39600671e+00 -9.30615087e-02]\n [-4.91257593e-01  1.43939170e+00]\n [ 1.16667350e+00  1.63503144e+00]\n [ 3.38314477e+00  1.94447949e+00]\n [ 8.71777746e-02  2.11701629e+00]\n [-3.15907411e-01  5.38415395e-01]\n [ 9.31758395e-01  2.71334272e+00]\n [ 2.55245178e-01  1.73561461e-01]\n [ 9.01547476e-01  3.36521714e-01]\n [ 2.12663592e+00 -7.99315084e-02]\n [-1.47468652e-01  5.62179955e-01]\n [ 5.01967549e-01  2.92953205e+00]\n [ 1.94942081e+00  1.08755124e+00]\n [-2.25435519e-01  1.84436298e+00]\n [-2.15347390e-04 -5.44771097e-01]\n [ 2.18802979e+00  1.31694261e+00]\n [ 1.92085882e+00  1.31872765e+00]\n [ 1.85683061e+00  3.48974407e-01]\n [-3.42428418e-02  1.68159452e+00]\n [ 1.96590336e-01  3.10450222e-01]\n [ 5.44467496e-01  1.01747916e+00]\n [ 6.46006089e-01 -3.74951293e-01]\n [ 3.56381597e-01 -1.22340315e+00]\n [ 1.62523145e+00 -6.02057656e-01]\n [-1.04383339e-01  1.05216508e+00]\n [ 2.60437004e-01  2.54301460e+00]\n [-2.92856910e-01  1.26705087e+00]\n [ 9.60717182e-01 -1.68093498e-01]\n [ 1.52327666e+00  8.28453669e-01]\n [ 1.77179055e+00  1.82350415e+00]\n [ 3.16323595e+00  2.33652795e+00]\n [-3.69181838e-01 -2.39379178e-01]\n [ 1.09965960e+00  6.55263731e-01]\n [ 6.40131526e-01 -1.61695604e+00]\n [-2.43261244e-02 -7.38030909e-01]\n [ 2.79924599e-01 -9.81503896e-02]\n [ 9.10178908e-01  3.17218215e-01]\n [ 7.86327962e-01 -4.66419097e-01]\n [-9.44446256e-01 -4.10049693e-01]\n [-1.70204139e-02  3.79151736e-01]\n [ 2.25930895e+00 -4.22571517e-02]\n [-9.55945000e-01 -3.45981776e-01]\n [-4.63595975e-01  4.81481474e-01]\n [-1.54079701e+00  6.32619942e-02]\n [ 1.56506538e-01  2.32181036e-01]\n [-5.97316069e-01 -2.37921730e-01]\n [-1.42406091e+00 -4.93319883e-01]\n [-5.42861476e-01  4.16050046e-01]\n [-1.15618243e+00  7.81198102e-01]\n [ 1.49448454e+00 -2.06998503e+00]\n [ 4.26258731e-01  6.76908035e-01]\n [-6.37437026e-01 -3.97271814e-01]\n [-1.32880578e-01 -2.97790879e-01]\n [-3.09012969e-01 -1.67600381e+00]\n [ 1.15233156e+00  1.07961859e+00]\n [-8.13364259e-01 -1.46642433e+00]\n [ 5.21064876e-01 -5.75787970e-01]\n [ 1.41953163e-01 -3.19328417e-01]\n [ 6.91538751e-01  6.94749144e-01]\n [-7.25597378e-01 -1.38336396e+00]\n [-1.58293840e+00  6.10379379e-01]\n [-1.18885926e+00 -5.06816354e-01]\n [-5.96314038e-01 -5.25672963e-02]\n [-1.93627981e+00  1.88778597e-01]\n [ 5.23891024e-01  8.84220870e-02]\n [-3.10886172e-01  9.74001663e-02]\n [ 3.99046346e-01 -2.77259276e+00]\n [ 1.95591231e+00  3.90093323e-01]\n [-6.52408582e-01 -3.90953375e-01]\n [ 4.93741777e-01 -1.16103939e-01]\n [-2.03068447e+00  2.06449286e+00]\n [-1.10540657e-01  1.02017271e+00]\n [-6.92049848e-01  1.53637705e+00]\n [ 2.86343689e-01  6.08843834e-01]\n [-1.04525337e+00  1.21114529e+00]\n [ 6.89818165e-01  1.30184623e+00]\n [-6.28087560e-01 -4.81027118e-01]\n [ 2.30391670e+00 -1.06001582e+00]\n [-1.35949701e-01  1.13689136e+00]\n [ 9.77249677e-02  5.82953680e-01]\n [-3.99449029e-01  3.70055888e-01]\n [-1.30652685e+00  1.65813068e+00]\n [-1.18164045e-01 -6.80178204e-01]\n [ 6.66383082e-01 -4.60719787e-01]\n [-1.33425847e+00 -1.34671751e+00]\n [ 6.93773153e-01 -1.59573438e-01]\n [-1.33701560e-01  1.07774381e+00]\n [-1.12682581e+00 -7.30677753e-01]\n [-3.84879809e-01  9.43515893e-02]\n [-4.21714513e-02 -2.86887192e-01]\n [-6.16264021e-02 -1.07305276e-01]\n [-7.19604389e-01 -8.12992989e-01]\n [ 2.74516358e-01 -8.90915083e-01]\n [-1.15735526e+00 -3.12292251e-01]\n [-1.57667016e-01  2.25672350e+00]\n [-7.04700276e-01  9.43260725e-01]\n [ 7.47188334e-01 -1.18894496e+00]\n [ 7.73252977e-01 -1.18388064e+00]\n [-2.65917224e+00  6.06319524e-01]\n [-1.75589058e+00  4.50934462e-01]\n [-6.84010898e-01  1.65955080e+00]\n [ 1.06850940e+00 -4.53385804e-01]\n [-6.87837611e-01 -1.21407740e+00]\n [-4.40922632e-01 -2.80355495e-01]\n [-3.64693544e-01  1.56703855e-01]\n [ 5.78521498e-01  3.49654457e-01]\n [-7.64143924e-01 -1.43779147e+00]\n [ 1.36453185e+00 -6.89449185e-01]\n [-6.52293600e-01 -5.21189312e-01]\n [-1.84306955e+00 -4.77974004e-01]\n [-4.79655814e-01  6.20358298e-01]\n [ 6.98457149e-01  3.77088909e-03]\n [ 9.31848374e-01  3.39964984e-01]\n [-1.56821116e-02  1.60928168e-01]\n [-1.90653494e-01 -3.94849514e-01]\n [-2.67733537e-01 -1.12801133e+00]\n [ 2.80441705e-01 -9.93123611e-01]\n [ 8.41631264e-01 -2.49458580e-01]\n [ 4.94949817e-02  4.93836776e-01]\n [ 6.43314465e-01 -1.57062341e+00]\n [-2.06903676e-01  8.80178912e-01]\n [-1.69810582e+00  3.87280475e-01]\n [-2.25556423e+00 -1.02250684e+00]\n [ 3.86305518e-02 -1.65671510e+00]\n [-9.85510738e-01 -1.47183501e+00]\n [ 1.64813493e+00  1.64227755e-01]\n [ 5.67290278e-01 -2.22675101e-01]\n [-3.53431749e-01 -1.61647419e+00]\n [-2.91837363e-01 -7.61492212e-01]\n [ 8.57923924e-01  1.14110187e+00]\n [ 1.46657872e+00  8.52551939e-01]]", "y": "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n -1 -1 -1 -1 -1 -1 -1 -1]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": "[[ 0.61930367  0.6937014  -0.60198137]]", "penalty": "l2", "max_squared_sum": 15.465424529319137, "sample_weight": null}}, "return": ["[[[ 0.61930367  0.6937014  -0.60198137]]]", "[1.]", "[27]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "int", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": -1, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l1", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[2.97817326e-14 0.00000000e+00 6.93147181e-01]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "int", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": 2, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l1", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[5.33184608e-14 0.00000000e+00 6.93147181e-01]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "str", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "null value in the ground truth", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "l1_ratio": "something_wrong", "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": null, "coef": null, "penalty": "l1", "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[3.10862447e-14 0.00000000e+00 6.93147181e-01]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "list of 1 int"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[1. 1.]]", "y": "[1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[0.         0.         0.33333333]\n [0.         0.         0.61161986]\n [0.         0.         0.84607971]\n [0.         0.         1.04625029]\n [0.         0.         1.21954749]\n [0.         0.         1.37155822]\n [0.         0.         3.4606232 ]\n [0.38669782 0.38669782 4.24697718]\n [0.62554618 0.62554618 4.53744312]\n [0.778978   0.778978   4.69754161]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  1   1   1   1   1   1  68 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]]", "y": "[0 1]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l1", "intercept_scaling": 1.0, "random_state": null, "check_input": false, "max_squared_sum": 2.0, "sample_weight": null}}, "return": ["[[ 0.          0.         -0.61161986]\n [ 0.          0.         -1.04625029]\n [ 0.          0.         -1.37155822]\n [ 0.          0.         -1.02823475]\n [ 0.          0.         -0.75527054]\n [ 0.32587407  0.82939326 -0.25175135]\n [ 2.71813655  3.22124687 -0.25216023]\n [ 3.95204857  4.4548076  -0.25251152]\n [ 4.5997564   5.10321839 -0.25180856]\n [ 5.01182431  5.51557063 -0.25152423]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  1   1   1   1   1  43 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[0.16293704 0.41469663 0.55990344]", "max_iter": 100, "tol": 0.0001, "penalty": "l1", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": 2.0, "sample_weight": null, "l1_ratio": null}}, "return": ["[[1.86476995 0.         1.05804858]]", "[2.7825594]", "[83]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[0.27488231 0.30281768 0.67180431]", "max_iter": 100, "tol": 0.0001, "penalty": "l1", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": 2.0, "sample_weight": null, "l1_ratio": null}}, "return": ["[[1.86497022 0.         1.05801727]]", "[2.7825594]", "[77]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[-1.  0.]\n [ 0.  1.]\n [ 1.  1.]]", "y": "[0 1 1]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[0.27495517 0.30280001 0.67185777]", "max_iter": 100, "tol": 0.0001, "penalty": "l1", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": null, "check_input": false, "max_squared_sum": 2.0, "sample_weight": null, "l1_ratio": null}}, "return": ["[[1.86472086 0.         1.05802058]]", "[2.7825594]", "[75]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"penalty": "str", "Cs": "null value in the ground truth", "solver": "str", "random_state": "int", "multi_class": "str"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[ 1.20120424  2.68585849]\n [-0.47565612  1.27888341]\n [ 1.85445232  0.02177088]\n [ 0.12692666  0.02418069]\n [-0.98887301  0.78891079]\n [-1.84733219  0.7181598 ]\n [-2.27039869  0.7146886 ]\n [ 1.56968042 -2.34787726]\n [ 1.00671517  0.62443754]\n [-0.87432656  0.71681344]\n [ 0.52276605 -0.7188685 ]\n [ 0.96815935 -0.91566499]\n [ 0.02271892  1.73743499]\n [ 1.35360805  1.67300665]\n [-0.21360694  1.32166991]\n [-2.13163526  0.41254111]\n [ 0.76253223  1.61199303]\n [-0.66716811  1.27256807]\n [ 0.13738716  2.63339007]\n [-1.10271319 -2.81899406]\n [ 1.98734896 -0.56250671]\n [ 2.28166504 -0.35061669]\n [ 0.68050218 -0.79675418]\n [-0.18493983  1.80714016]\n [-2.28810495  0.626327  ]\n [-1.2607126   0.8950888 ]\n [ 1.0069467  -0.06671705]\n [ 0.84121147  1.57291492]\n [ 1.7574514  -0.74378964]\n [-0.56719078 -1.47746213]\n [-0.02773616  1.39978454]\n [ 1.29574025 -0.67809401]\n [ 0.97283912 -1.47264283]\n [ 1.12753296  1.74551547]\n [-1.04682679  1.08765144]\n [-1.17815468  0.50635361]\n [ 1.30211125 -0.16735617]\n [-2.13374202  1.0081594 ]\n [-1.26647778  1.15872918]\n [ 1.30621965 -0.1788759 ]\n [ 0.39135878  1.30085465]\n [ 1.01836578 -0.76703808]\n [ 1.50962026 -1.88445987]\n [-3.22042807  0.15720705]\n [ 0.33571813  2.38535976]\n [ 0.40085686  1.29375203]\n [ 1.29541821  3.79304254]\n [ 0.8093097   1.79536619]\n [ 0.59316278 -1.32821604]\n [-1.1623946   0.83706513]\n [ 1.52080806 -0.78253438]\n [-0.39721718  1.08199704]\n [ 0.17867137  1.8864625 ]\n [ 0.68596056  2.23866478]\n [ 1.36581799  1.07715301]\n [-1.52529436  0.76508847]\n [-2.483329    0.86328673]\n [ 1.12720503 -1.48237915]\n [ 0.26077969  1.96861719]\n [-1.03678414  1.18733728]\n [ 0.80391855  1.41078267]\n [ 0.64769832 -0.0452385 ]\n [-2.27523047  0.6679949 ]\n [-0.46604731 -0.72014255]\n [-1.76817662  1.15970779]\n [ 0.98616946 -0.09024206]\n [-1.23155081  1.54074613]\n [ 0.52655498  2.82348832]\n [ 1.52622444  0.83574246]\n [-0.88394333  0.99977754]\n [ 1.9611922  -1.08109654]\n [ 2.57784346 -1.20081465]\n [ 0.70451998 -0.12039885]\n [ 0.659752   -1.73527301]\n [ 0.84441622  1.19622238]\n [ 0.56024267 -0.64343158]\n [ 0.52213161  1.98625818]\n [-1.5520205   0.97563231]\n [-0.39135708  1.03574118]\n [-0.23669235  1.03664497]\n [ 0.65732666 -1.10097   ]\n [ 0.11035533 -2.40428488]\n [ 1.14103034  1.180924  ]\n [-1.40890463  0.64249104]\n [ 0.2694814   1.32028391]\n [-2.43758126  0.46580645]\n [-0.80835836  1.18560361]\n [-1.46177728  0.74210378]\n [-1.52277562  1.17781287]\n [ 1.58894417 -0.96043807]\n [ 0.68438592 -1.89300517]\n [ 1.29559815  0.66329019]\n [ 0.66568872  1.10054468]\n [ 2.36049953 -1.03417388]\n [ 0.83300907  1.98989843]\n [ 1.11497332 -0.53563895]\n [ 1.20983945 -1.14524442]\n [ 1.11399992 -0.33351524]\n [-1.35899217 -1.66020237]\n [-1.20752869  1.02748359]\n [ 3.14442454  0.01099495]\n [ 0.62536284  0.13377283]\n [ 1.00570843  0.3055573 ]\n [ 1.01993066  1.41794047]\n [ 1.43866906 -0.8745224 ]\n [ 0.31469877  1.31738748]\n [ 0.56397118  2.69064005]\n [ 0.95648774 -1.13308156]\n [ 0.22237537  1.50871858]\n [-1.35024367  1.22099238]\n [ 0.29596922  0.17615722]\n [-1.77624826  0.8349644 ]\n [ 0.89714711  2.5131262 ]\n [-0.86650305  0.56257683]\n [ 1.1777002   1.7492486 ]\n [-1.3537787   0.73155864]\n [-0.11026188 -2.05820175]\n [ 0.38812682  1.95183723]\n [ 1.68103117  1.9900371 ]\n [-1.25673475  0.99948519]\n [ 0.71476889 -1.84432413]\n [-0.50643326 -1.42167234]\n [ 0.47836464 -1.53861564]\n [-1.0784459   1.07985083]\n [ 1.0312521   3.20748115]\n [ 0.08168113 -0.81428947]\n [ 1.1427501   0.83360532]\n [ 1.29678711  2.93990303]\n [ 1.72273512 -1.22220285]\n [ 0.90565088  1.58246182]\n [-0.71184979 -0.29826802]\n [ 1.04702267  3.04327092]\n [ 2.15579512  1.63323278]\n [-0.50306309  1.26826091]\n [ 0.53500378 -0.62221138]\n [ 1.42357712 -0.16750686]\n [ 1.85845135  1.30070043]\n [ 0.89687259 -0.39263039]\n [ 0.18615953 -0.46892584]\n [-0.58941713  1.53869419]\n [-0.69516082  1.69020402]\n [ 1.34426635  0.36254051]\n [-0.41491976 -2.44113876]\n [ 1.01404945  1.54604732]\n [ 0.22763405 -1.81746651]\n [ 1.19787119  0.42076111]\n [ 0.68237205  0.96167271]\n [ 1.28092025  2.18658212]\n [ 1.74894182  1.00439526]\n [ 0.83761496  2.43350388]\n [ 1.87550402  0.01920491]\n [ 1.61571741 -0.82661667]\n [ 1.67096934  1.9893727 ]\n [-1.83707291  0.96467423]\n [ 0.44236955 -2.86242403]\n [-3.14196229  0.56897756]\n [ 0.62877748  2.50899704]\n [ 0.67136142 -1.94170326]\n [-0.47601802  1.66863909]\n [-0.93503117  1.29701413]\n [-0.21417075  1.320351  ]\n [-1.08100321  1.04986909]\n [ 1.76202222 -2.16862152]\n [-1.32346641  0.74472334]\n [ 1.33746304 -2.02669971]\n [ 0.91332321 -0.68746829]\n [ 1.8385592   0.32878902]\n [ 0.97259914  3.46014464]\n [ 0.89629206  0.64281799]\n [ 1.26381158  0.6772075 ]\n [-2.38492464  0.63685586]\n [ 0.62893489  2.61579309]\n [ 0.94888652 -1.4024225 ]\n [ 0.5473625  -0.61193635]\n [-1.19616825  0.7820868 ]\n [ 0.90840956  0.21838721]\n [ 1.37710211  0.02182044]\n [ 1.44955729  0.7202862 ]\n [-0.02180605  1.23986812]\n [ 1.42262574 -1.25173725]\n [ 0.12673954 -2.30364887]\n [-2.73447748  0.75627882]\n [-0.81250291  0.5140342 ]\n [ 0.44488401  0.14820309]\n [ 0.29915124 -0.43119062]\n [-0.6908134   1.02744203]\n [-1.81831596  0.77572287]\n [ 1.02819517 -0.44878308]\n [ 0.54542994 -0.37647331]\n [ 1.44492881  1.70376591]\n [ 1.64924434 -0.58104506]\n [ 1.39934781 -0.25178307]\n [ 1.41906598 -0.42813401]\n [ 0.70711216  2.29091905]\n [ 0.33156063  0.75822045]\n [ 0.02084335  1.02993874]\n [ 0.66263895 -1.15092902]\n [ 2.07774126 -1.61038399]\n [-1.71073367  0.68472872]\n [-1.33183013  0.89102424]]", "y": "[1 0 2 2 0 0 0 1 1 0 2 2 0 0 0 0 1 0 1 2 2 2 2 0 0 0 1 0 2 2 0 1 2 1 0 0 1\n 0 0 1 1 2 2 0 1 0 1 1 2 0 2 0 1 1 1 0 0 2 1 0 1 2 0 2 0 2 0 1 1 0 1 2 2 2\n 1 2 1 0 0 0 2 2 1 0 1 0 0 0 0 2 2 1 1 2 1 1 1 1 2 0 2 2 2 1 2 1 1 2 0 0 1\n 0 1 0 1 0 2 1 1 0 2 2 2 0 1 2 1 1 2 1 2 1 1 0 1 2 2 2 2 0 0 2 2 0 2 1 1 1\n 1 1 2 2 1 0 2 0 1 2 0 0 0 0 1 0 2 2 2 1 1 1 0 1 2 2 0 1 1 1 1 2 2 0 0 2 1\n 0 0 2 2 1 2 2 1 1 1 0 2 2 0 0]"}, "kwargs": {"penalty": "l1", "Cs": null, "solver": "saga", "random_state": 0, "multi_class": "multinomial"}}, "return": ["[[[ 0.          0.         -0.0355599 ]\n  [ 0.          0.          0.11706391]\n  [ 0.          0.         -0.08150401]]\n\n [[-2.9154774   0.35490446 -0.30303219]\n  [ 0.31263684  0.         -0.05975485]\n  [ 0.         -1.85737477  0.36278704]]\n\n [[-3.20175751  0.51358493 -0.45479447]\n  [ 0.45951926 -0.0486827   0.02130467]\n  [ 0.1391633  -1.96716685  0.4334898 ]]]", "[1.e-05 1.e+00 1.e+04]", "[ 1 40 20]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.18349067e-03 -3.99347519e-04 -1.39893975e-03 -5.74211702e-04\n  -1.46572364e-04]\n [-8.16538337e-03 -2.59821722e-03 -1.00850722e-02 -4.17671018e-03\n  -9.75934257e-04]\n [-3.25268048e-02 -5.03184243e-03 -5.48350173e-02 -2.39117009e-02\n  -2.69190533e-03]\n [-1.37038028e-02  6.78953089e-02 -2.15734052e-01 -1.05452581e-01\n   1.45317423e-02]\n [ 1.50455921e-01  3.61541978e-01 -6.76516094e-01 -3.45811335e-01\n   8.64544640e-02]\n [ 3.82458287e-01  7.86735925e-01 -1.36589226e+00 -6.82971271e-01\n   1.82932224e-01]\n [ 6.39095003e-01  1.27115888e+00 -2.18264014e+00 -1.04218815e+00\n   2.80651482e-01]\n [ 9.16483665e-01  1.80755886e+00 -3.10208659e+00 -1.41417526e+00\n   3.80953132e-01]\n [ 1.20158937e+00  2.37239579e+00 -4.04611947e+00 -1.90990968e+00\n   5.20831000e-01]\n [ 1.49917382e+00  2.94780240e+00 -5.01321064e+00 -2.33864470e+00\n   6.40837069e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  3  3  4  5  6  7  8  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.41948546e-03 -4.47508748e-04 -1.48239068e-03 -5.54026824e-04\n  -1.95882231e-04]\n [-9.81108509e-03 -2.88809223e-03 -1.06621975e-02 -4.01285787e-03\n  -1.32639853e-03]\n [-4.02806080e-02 -5.04903373e-03 -5.75903368e-02 -2.25615303e-02\n  -4.53435490e-03]\n [-3.88129240e-02  8.01840972e-02 -2.26787256e-01 -9.67044615e-02\n   6.74228987e-03]\n [ 7.01617108e-02  4.27927982e-01 -7.15316803e-01 -3.07462255e-01\n   5.61087314e-02]\n [ 1.94629342e-01  9.69780587e-01 -1.45622581e+00 -5.95633898e-01\n   1.10115453e-01]\n [ 3.05385301e-01  1.61085930e+00 -2.31667323e+00 -9.12010336e-01\n   1.57078562e-01]\n [ 4.14614550e-01  2.30982341e+00 -3.24805929e+00 -1.25226811e+00\n   1.99867400e-01]\n [ 5.25938623e-01  3.04696204e+00 -4.22881777e+00 -1.61067224e+00\n   2.38464558e-01]\n [ 7.30945088e-01  3.63404266e+00 -5.18113942e+00 -2.06367086e+00\n   3.50828154e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  3  3  3  5  6  7  8 10 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.03083701e-03 -2.99974142e-04 -1.29215867e-03 -5.05840087e-04\n  -1.46702306e-04]\n [-7.09309339e-03 -1.85807616e-03 -9.40847240e-03 -3.72318111e-03\n  -9.83047155e-04]\n [-2.75609477e-02 -2.31804078e-04 -5.40344693e-02 -2.26518926e-02\n  -2.92676933e-03]\n [-5.79275202e-03  9.23665954e-02 -2.37376544e-01 -1.09848324e-01\n   1.09645469e-02]\n [ 1.30171626e-01  4.51554907e-01 -7.77498737e-01 -3.63399989e-01\n   6.69137331e-02]\n [ 2.94771094e-01  1.01865871e+00 -1.58625065e+00 -7.25520332e-01\n   1.43856962e-01]\n [ 4.56444884e-01  1.69744106e+00 -2.51746772e+00 -1.13963000e+00\n   2.29429922e-01]\n [ 6.19286453e-01  2.45584632e+00 -3.53080131e+00 -1.59550416e+00\n   3.22734545e-01]\n [ 8.94092135e-01  3.13679533e+00 -4.65912382e+00 -2.13954031e+00\n   4.31074588e-01]\n [ 1.10541688e+00  3.91370998e+00 -5.75162778e+00 -2.64067713e+00\n   5.33844058e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  4  3  3  4  6  7  8  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[ 0.11692975  0.41367496 -0.72311054 -0.33889119  0.06982564]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.14776017  0.50838485 -0.85739387 -0.39831934  0.08321472]]", "[0.35938137]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.11654658e-03 -3.55925162e-04 -1.27684279e-03 -4.95530028e-04\n  -1.46981040e-04]\n [-7.78100587e-03 -2.33130409e-03 -9.26912118e-03 -3.62694525e-03\n  -9.96758548e-04]\n [-3.25589859e-02 -4.54426967e-03 -5.17564826e-02 -2.12458950e-02\n  -3.21072480e-03]\n [-2.17773816e-02  6.74541545e-02 -2.10191434e-01 -9.61053570e-02\n   1.06216383e-02]\n [ 1.26861735e-01  3.76316121e-01 -6.89557427e-01 -3.26918668e-01\n   7.23207913e-02]\n [ 3.31811427e-01  8.67826450e-01 -1.44523612e+00 -6.67259232e-01\n   1.49740192e-01]\n [ 5.25455581e-01  1.49072103e+00 -2.34981186e+00 -1.06010267e+00\n   2.29071630e-01]\n [ 7.04877762e-01  2.22307395e+00 -3.35450235e+00 -1.50607869e+00\n   3.20895885e-01]\n [ 9.83339705e-01  2.88902839e+00 -4.47664896e+00 -2.04461420e+00\n   4.57446416e-01]\n [ 1.21374084e+00  3.64144853e+00 -5.57791652e+00 -2.54822705e+00\n   5.71053403e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  3  3  4  5  5  7  8  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.05800129e-03 -3.26225459e-04 -1.24318427e-03 -4.85866284e-04\n  -1.47169264e-04]\n [-7.39357119e-03 -2.11426966e-03 -9.06953990e-03 -3.56719851e-03\n  -1.00663466e-03]\n [-3.13053983e-02 -3.10816924e-03 -5.18447096e-02 -2.11434899e-02\n  -3.49335568e-03]\n [-2.36317391e-02  7.65259234e-02 -2.17150953e-01 -9.50882734e-02\n   7.54041908e-03]\n [ 8.91931276e-02  4.08602307e-01 -6.99022143e-01 -3.01527094e-01\n   5.71499931e-02]\n [ 2.16022006e-01  9.36531489e-01 -1.42664012e+00 -5.76825549e-01\n   1.17263329e-01]\n [ 3.28360503e-01  1.56272053e+00 -2.26426637e+00 -8.77408154e-01\n   1.70696581e-01]\n [ 4.35361969e-01  2.25185854e+00 -3.16839573e+00 -1.20292851e+00\n   2.15489602e-01]\n [ 6.38431945e-01  2.85145353e+00 -4.15297414e+00 -1.65125460e+00\n   3.07669598e-01]\n [ 7.80146158e-01  3.53090483e+00 -5.09141558e+00 -2.01447661e+00\n   3.64786166e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  3  3  3  4  6  7  8  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "0", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.45795896e-03 -4.63955969e-04 -1.65263357e-03 -6.52456471e-04\n  -1.94773777e-04]\n [-9.83840972e-03 -2.86672471e-03 -1.17818425e-02 -4.70947048e-03\n  -1.27167486e-03]\n [-3.58798056e-02 -2.23777505e-03 -6.25092264e-02 -2.66831108e-02\n  -3.31340405e-03]\n [-1.24986098e-02  9.72811548e-02 -2.51202585e-01 -1.20359352e-01\n   1.42640894e-02]\n [ 1.27171749e-01  4.57587829e-01 -7.74806156e-01 -3.79140052e-01\n   7.60412279e-02]\n [ 2.85748633e-01  1.01891232e+00 -1.55388022e+00 -7.36832686e-01\n   1.51859866e-01]\n [ 4.39018522e-01  1.70366619e+00 -2.47508894e+00 -1.14524135e+00\n   2.33383234e-01]\n [ 5.98535117e-01  2.46791874e+00 -3.49085332e+00 -1.59825096e+00\n   3.23652582e-01]\n [ 7.66056618e-01  3.29032068e+00 -4.57687423e+00 -2.08838233e+00\n   4.22828801e-01]\n [ 1.06629530e+00  3.92227050e+00 -5.66401657e+00 -2.65178102e+00\n   5.46539133e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  4  4  4  4  6  7  8 10 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-9.52321679e-04 -5.38661276e-04 -4.41215054e-04 -1.57051961e-04\n  -1.47903309e-04]\n [-6.77868729e-03 -3.87309082e-03 -3.00448336e-03 -1.07791895e-03\n  -1.04675040e-03]\n [-3.31765053e-02 -2.02751072e-02 -1.00260084e-02 -3.92653787e-03\n  -4.89754877e-03]\n [-8.60788627e-02 -6.66844599e-02  2.87797187e-02  3.52337309e-03\n  -8.58397658e-03]\n [-2.10854823e-01 -1.69281681e-01  2.48722110e-01 -5.18691167e-03\n   3.47373837e-02]\n [-6.39142245e-01 -9.08620941e-02  8.40161845e-01 -5.21954846e-01\n   5.51230802e-01]\n [-2.40497900e+00  8.72516159e-01  2.66363454e+00 -2.57462929e+00\n   3.44787846e+00]\n [-5.88952657e+00  1.76263505e+00  5.69638276e+00 -5.46134967e+00\n   1.29233337e+01]\n [-1.10650356e+01  1.94066129e+00  9.87062574e+00 -8.67108519e+00\n   3.00925869e+01]\n [-1.71923853e+01  2.07530973e+00  1.48034989e+01 -1.23281040e+01\n   5.03716570e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  3  3  3  3  5  8 10 12 14]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-8.63112118e-04 -6.18746809e-04 -4.07048549e-04 -1.97260147e-04\n  -1.48002078e-04]\n [-6.12335386e-03 -4.49630164e-03 -2.77796199e-03 -1.39864364e-03\n  -1.05187833e-03]\n [-2.89842917e-02 -2.50632020e-02 -9.34011276e-03 -6.65964303e-03\n  -5.03772415e-03]\n [-5.73653886e-02 -1.01151659e-01  2.64147561e-02 -1.92838600e-02\n  -1.01567126e-02]\n [ 1.00808911e-03 -4.21625251e-01  2.10689305e-01 -1.76558109e-01\n   1.19884514e-02]\n [ 5.54401401e-01 -1.58547080e+00  6.16126526e-01 -1.33863614e+00\n   2.03259467e-01]\n [ 1.65799538e+00 -3.79327931e+00  1.55685205e+00 -4.32977706e+00\n   5.26085794e-01]\n [ 2.99784264e+00 -6.50624555e+00  2.90499665e+00 -8.46429852e+00\n   7.18215940e-01]\n [ 4.56790554e+00 -9.62358273e+00  4.40120916e+00 -1.31685859e+01\n   8.42557536e-01]\n [ 6.30071422e+00 -1.30354664e+01  5.98038578e+00 -1.82424902e+01\n   1.00772305e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[2 3 3 4 4 4 5 7 8 9]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.19777974e-03 -7.58696584e-04 -5.99954377e-04 -2.05001387e-04\n  -1.96341406e-04]\n [-8.26562878e-03 -5.36097969e-03 -3.96348327e-03 -1.36092640e-03\n  -1.35409580e-03]\n [-3.55167543e-02 -2.69183346e-02 -1.16722476e-02 -4.26593611e-03\n  -5.77306873e-03]\n [-7.11074375e-02 -9.74242723e-02  2.90539530e-02  3.58557960e-03\n  -9.70263864e-03]\n [-6.52080803e-02 -3.49482478e-01  1.90123776e-01 -3.68005682e-02\n   3.28875076e-02]\n [ 1.44782405e-01 -1.01266789e+00  4.19347153e-01 -5.45553626e-01\n   4.86831641e-01]\n [-1.73496565e-01 -1.52278048e+00  1.14819026e+00 -1.87348199e+00\n   2.74578372e+00]\n [-1.76773331e+00 -1.11714606e+00  3.01865524e+00 -4.53197280e+00\n   7.04919049e+00]\n [-2.95286083e+00 -5.85350781e-01  4.54411192e+00 -6.77684064e+00\n   9.31982702e+00]\n [-3.26278963e+00 -4.10282710e-01  4.97078538e+00 -7.42104733e+00\n   9.76015872e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 2  3  4  3  3  5  7 10 11 11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-5.48735212e-04 -4.51809151e-04 -5.80217786e-06  9.13862159e-05\n  -1.48950635e-04]\n [-3.95423564e-03 -3.34784404e-03  1.51401573e-04  7.72248258e-04\n  -1.10386619e-03]\n [-2.09581724e-02 -2.08876716e-02  7.36421280e-03  7.97954215e-03\n  -6.90355585e-03]\n [-7.16174060e-02 -1.05470560e-01  9.31165671e-02  6.97623785e-02\n  -3.60031923e-02]\n [-1.96212292e-01 -4.00884113e-01  3.91548146e-01  3.35468543e-01\n  -1.63876704e-01]\n [-3.16819238e-01 -1.20682577e+00  8.32842624e-01  1.16292517e+00\n  -6.58147350e-01]\n [-4.78050079e-01 -3.61757016e+00  1.89166740e+00  3.28811371e+00\n  -1.89348886e+00]\n [-4.86622767e-01 -7.02619506e+00  3.11095246e+00  6.24112311e+00\n  -3.47183916e+00]\n [-3.49169909e-01 -1.09332524e+01  4.33090083e+00  9.61519620e+00\n  -5.22279358e+00]\n [-1.05365233e-01 -1.52206252e+01  5.58444816e+00  1.32405177e+01\n  -7.10325547e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 3  4  2  4  4  5  7  8  9 10]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-6.68020179e-04 -4.41269060e-04 -5.09124651e-07  1.31517844e-04\n  -1.48816141e-04]\n [-4.84317747e-03 -3.24028686e-03  2.06612911e-04  1.08926779e-03\n  -1.09634667e-03]\n [-2.65501985e-02 -1.91157738e-02  8.30092723e-03  1.06428168e-02\n  -6.61091378e-03]\n [-9.99265368e-02 -8.12382834e-02  1.02424498e-01  9.03696730e-02\n  -3.14763682e-02]\n [-3.46788718e-01 -1.97043212e-01  4.18299725e-01  4.53378297e-01\n  -1.32176284e-01]\n [-9.57452120e-01 -6.40919480e-02  7.97568249e-01  1.61732926e+00\n  -4.80359412e-01]\n [-1.86682268e+00  5.28604476e-01  8.53675978e-01  4.30560767e+00\n  -1.35647364e+00]\n [-2.85160814e+00  1.48554148e+00  3.89466527e-01  8.44571360e+00\n  -2.63513968e+00]\n [-3.85310690e+00  2.47866407e+00 -3.19512634e-01  1.34338015e+01\n  -4.09829847e+00]\n [-4.85398610e+00  3.66758313e+00 -1.29963054e+00  1.88532429e+01\n  -5.54240621e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 3  4  2  3  4  5  7  8 10 11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "liblinear", "max_iter": 100, "class_weight": null, "pos_class": "2", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-8.37697404e-04 -5.93640502e-04  3.04333658e-06  1.32620439e-04\n  -1.97952925e-04]\n [-5.92637677e-03 -4.30618798e-03  3.86993169e-04  1.14478537e-03\n  -1.43937880e-03]\n [-2.98732299e-02 -2.48387923e-02  1.28436619e-02  1.19584254e-02\n  -8.43393971e-03]\n [-1.06761395e-01 -1.11655024e-01  1.35400573e-01  9.59331254e-02\n  -4.11941598e-02]\n [-3.37991821e-01 -3.31532516e-01  5.23414361e-01  4.06820884e-01\n  -1.73757027e-01]\n [-7.94039610e-01 -8.16224359e-01  1.23102918e+00  1.21491550e+00\n  -6.86018438e-01]\n [-1.05198286e+00 -2.67314070e+00  2.24385154e+00  3.31940827e+00\n  -2.30832442e+00]\n [ 2.52045305e-01 -6.45282539e+00  1.78912682e+00  8.49513004e+00\n  -5.99176349e+00]\n [ 2.91436087e+00 -1.25079682e+01  4.55143861e-01  1.66248667e+01\n  -1.19620796e+01]\n [ 5.90917977e+00 -1.96075894e+01 -4.51491952e-01  2.53328820e+01\n  -1.98564134e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 3  4  2  4  4  6  7 10 11 12]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": "0", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[ 0.11440887  0.41416875 -0.72112858 -0.33586194  0.068504  ]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.14776017  0.50838485 -0.85739387 -0.39831934  0.08321472]]", "[0.35938137]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[-1.55313908 -1.95358552  3.87334488 -6.15254033  6.89691337]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-2.49204027 -0.52390734  4.20813814 -6.40480925  7.20628109]]", "[166.81005372]", "[8]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": "2", "Cs": null, "solver": "liblinear", "fit_intercept": true, "coef": "[-0.29366428 -0.30981995  0.44442074  0.39855591 -0.15660334]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.35879931 -0.3635509   0.53633383  0.51612734 -0.20683873]]", "[0.35938137]", "[4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": "True", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.21984359  0.48220944 -1.3038955  -0.53027307  3.73368486]]", "[1.]", "[28]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.22143201  0.40542176 -1.1694829  -0.47269144  4.8631459 ]\n  [-0.22950015 -0.48657317  0.15448225 -0.25484222  3.6040843 ]\n  [ 0.45093216  0.08115142  1.01500066  0.72753366 -8.4672302 ]]]", "[1.]", "[71]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.11433422  0.32415561 -0.79521445 -0.32080684  2.08456963]]]", "[1.]", "[27]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.96337673e-04  5.99562770e-05 -7.89200413e-04 -3.62957166e-04\n  -6.87728653e-01]\n [-2.27742089e-03  4.61903252e-04 -6.06889818e-03 -2.79071786e-03\n  -6.51530333e-01]\n [-1.66632675e-02  3.44703833e-03 -4.46257066e-02 -2.04989282e-02\n  -3.89761670e-01]\n [-9.01750804e-02  2.12356463e-02 -2.49806435e-01 -1.13893332e-01\n   9.27691651e-01]\n [-2.31159851e-01  8.59850752e-02 -7.35246037e-01 -3.22768469e-01\n   3.52646268e+00]\n [-3.37144958e-01  2.48073437e-01 -1.42268893e+00 -5.74578534e-01\n   6.09188346e+00]\n [-4.03146066e-01  4.99195442e-01 -2.28106120e+00 -8.57535234e-01\n   8.56490721e+00]\n [-4.74623529e-01  7.78707458e-01 -3.25395969e+00 -1.18537276e+00\n   1.13091334e+01]\n [-1.94372288e-01  1.33703577e+00 -4.24460507e+00 -1.57838397e+00\n   1.14132358e+01]\n [ 1.00691537e-01  1.92507842e+00 -5.28878208e+00 -1.99267228e+00\n   1.15248176e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 12 13 15 18 19 18 22  8  7]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.46687377e-04  1.51887268e-04 -7.31348361e-04 -3.07779360e-04\n  -8.43089239e-01]\n [-1.89572871e-03  1.17296621e-03 -5.62889026e-03 -2.36784579e-03\n  -8.14969362e-01]\n [-1.38532377e-02  8.88231080e-03 -4.16595389e-02 -1.74954905e-02\n  -6.11441165e-01]\n [-7.38779061e-02  5.92597696e-02 -2.42055466e-01 -1.00544646e-01\n   4.07471963e-01]\n [-1.68489272e-01  2.68367306e-01 -7.64536487e-01 -3.05217393e-01\n   2.15116328e+00]\n [-1.99740320e-01  7.22774201e-01 -1.52646156e+00 -5.82146210e-01\n   3.26757077e+00]\n [-1.94455450e-01  1.31897243e+00 -2.41646481e+00 -9.01930608e-01\n   4.02459977e+00]\n [-1.74538192e-01  1.97827687e+00 -3.37934040e+00 -1.24910958e+00\n   4.69820162e+00]\n [-5.65852708e-02  2.70947394e+00 -4.37601223e+00 -1.62676690e+00\n   4.73319523e+00]\n [ 5.91215728e-02  3.43800101e+00 -5.36140668e+00 -1.99786262e+00\n   4.76568686e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 10 13 15 17 24 18 22  7  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.98956327e-04  1.47686415e-04 -7.79109243e-04 -3.48824081e-04\n  -5.55844764e-01]\n [-1.52939956e-03  1.14411695e-03 -5.99984077e-03 -2.68416162e-03\n  -5.30571590e-01]\n [-1.12407046e-02  8.69811099e-03 -4.44974789e-02 -1.98541050e-02\n  -3.46547489e-01]\n [-6.22914588e-02  5.92691089e-02 -2.62211193e-01 -1.15091435e-01\n   6.15059155e-01]\n [-1.57021962e-01  2.71130283e-01 -8.45717192e-01 -3.56565080e-01\n   2.50711255e+00]\n [-2.07547623e-01  7.16313539e-01 -1.68035507e+00 -6.92675417e-01\n   4.07198537e+00]\n [-2.23195905e-01  1.30741186e+00 -2.64517360e+00 -1.09165906e+00\n   5.34981097e+00]\n [-2.29071763e-01  1.97091690e+00 -3.69925621e+00 -1.54380510e+00\n   6.62893010e+00]\n [-4.73004469e-02  2.75883541e+00 -4.78408217e+00 -2.01805876e+00\n   6.68109867e+00]\n [ 1.30473051e-01  3.58059665e+00 -5.89574195e+00 -2.51171530e+00\n   6.75387659e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[11  8  9 14 19 19 25 23  7  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[-0.18555703  0.20849422 -0.78183324 -0.32818365  2.72824617]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.19486119  0.28148491 -0.91893503 -0.38134415  2.97785252]]", "[0.35938137]", "[18]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.49605329e-04  8.99132625e-05 -7.05704158e-04 -3.09563395e-04\n    4.33394254e-03]\n  [-8.00519404e-05 -8.99875551e-05  1.33196144e-04  2.99442480e-05\n    1.95450839e-04]\n  [ 3.29657270e-04  7.42925973e-08  5.72508014e-04  2.79619147e-04\n   -4.52939338e-03]]\n\n [[-1.91082828e-03  6.93245403e-04 -5.41584558e-03 -2.37480436e-03\n    3.31075747e-02]\n  [-6.24548786e-04 -6.96582670e-04  1.02480764e-03  2.27342063e-04\n    1.75073234e-03]\n  [ 2.53537706e-03  3.33726677e-06  4.39103794e-03  2.14746229e-03\n   -3.48583071e-02]]\n\n [[-1.36565697e-02  5.17031676e-03 -3.92824595e-02 -1.71913070e-02\n    2.37620695e-01]\n  [-4.93823979e-03 -5.34399057e-03  7.58963887e-03  1.62277932e-03\n    1.64001602e-02]\n  [ 1.85948095e-02  1.73673816e-04  3.16928206e-02  1.55685277e-02\n   -2.54020855e-01]]\n\n [[-6.61497723e-02  3.23439167e-02 -2.09222008e-01 -9.03472121e-02\n    1.17580608e+00]\n  [-4.13791712e-02 -3.83195180e-02  4.41671331e-02  6.55095280e-03\n    2.49159093e-01]\n  [ 1.07528943e-01  5.97560133e-03  1.65054875e-01  8.37962593e-02\n   -1.42496518e+00]]\n\n [[-1.54480263e-01  1.39678180e-01 -6.34426835e-01 -2.62381885e-01\n    3.06257671e+00]\n  [-2.62182828e-01 -1.92360587e-01  1.52962002e-01 -6.22119056e-03\n    1.98590234e+00]\n  [ 4.16663090e-01  5.26824064e-02  4.81464833e-01  2.68603076e-01\n   -5.04847905e+00]]\n\n [[-2.93779969e-01  3.76373807e-01 -1.37843454e+00 -5.55161164e-01\n    6.32859596e+00]\n  [-7.92589210e-01 -4.23914423e-01  3.06539828e-01 -8.49410180e-02\n    6.09787493e+00]\n  [ 1.08636918e+00  4.75406158e-02  1.07189471e+00  6.40102182e-01\n   -1.24264709e+01]]\n\n [[-5.33454686e-01  7.08292831e-01 -2.37463805e+00 -9.61720231e-01\n    1.12742248e+01]\n  [-1.49820314e+00 -5.89503058e-01  4.21752752e-01 -2.85992841e-01\n    1.17021566e+01]\n  [ 2.03165782e+00 -1.18789772e-01  1.95288530e+00  1.24771307e+00\n   -2.29763813e+01]]\n\n [[-8.64389460e-01  1.10267928e+00 -3.53057500e+00 -1.44440831e+00\n    1.74769835e+01]\n  [-2.27825129e+00 -8.21349439e-01  4.93333446e-01 -6.21878144e-01\n    1.85482981e+01]\n  [ 3.14264075e+00 -2.81329838e-01  3.03724156e+00  2.06628646e+00\n   -3.60252816e+01]]\n\n [[-8.28084156e-01  1.78093163e+00 -4.76976668e+00 -1.96316506e+00\n    2.13841753e+01]\n  [-3.36632169e+00 -1.28096807e+00  6.18005173e-01 -1.04015574e+00\n    2.77353542e+01]\n  [ 4.19440585e+00 -4.99963557e-01  4.15176151e+00  3.00332080e+00\n   -4.91195295e+01]]\n\n [[-4.13063541e-01  2.90534059e+00 -6.16727015e+00 -2.64267225e+00\n    2.16638801e+01]\n  [-4.05555848e+00 -1.88162448e-02  1.16326569e+00 -1.92754007e+00\n    2.82280687e+01]\n  [ 4.46862202e+00 -2.88652434e+00  5.00400446e+00  4.57021232e+00\n   -4.98919488e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 12 19 24 43 70 64 88 58 13]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.99714858e-04  1.33258310e-04 -6.95790366e-04 -3.02910799e-04\n    3.71247045e-03]\n  [-4.06169257e-08 -1.56674139e-04  1.43180166e-04 -1.34310909e-05\n   -2.19366562e-05]\n  [ 1.99755475e-04  2.34158288e-05  5.52610201e-04  3.16341890e-04\n   -3.69053379e-03]]\n\n [[-1.53016617e-03  1.02828621e-03 -5.34209311e-03 -2.32412880e-03\n    2.83963949e-02]\n  [-4.11221058e-06 -1.21248511e-03  1.10016430e-03 -1.07434554e-04\n    1.63316973e-05]\n  [ 1.53427839e-03  1.84198900e-04  4.24192881e-03  2.43156336e-03\n   -2.84127266e-02]]\n\n [[-1.10055656e-02  7.73052363e-03 -3.88652201e-02 -1.68177823e-02\n    2.03945269e-01]\n  [-1.35388313e-04 -9.29931483e-03  8.09878393e-03 -1.01747078e-03\n    3.18062468e-03]\n  [ 1.11409539e-02  1.56879121e-03  3.07664362e-02  1.78352531e-02\n   -2.07125894e-01]]\n\n [[-5.46831612e-02  4.99157775e-02 -2.08990613e-01 -8.75804177e-02\n    1.00658381e+00]\n  [-4.79245370e-03 -6.64954034e-02  4.52664332e-02 -1.46163184e-02\n    1.45603789e-01]\n  [ 5.94756149e-02  1.65796259e-02  1.63724179e-01  1.02196736e-01\n   -1.15218760e+00]]\n\n [[-1.24423875e-01  2.12882923e-01 -6.19502378e-01 -2.39887382e-01\n    2.44262893e+00]\n  [-2.19952523e-02 -3.29334862e-01  1.34534965e-01 -1.49566234e-01\n    1.22837954e+00]\n  [ 1.46419127e-01  1.16451938e-01  4.84967413e-01  3.89453616e-01\n   -3.67100847e+00]]\n\n [[-1.98529603e-01  5.49528464e-01 -1.29329467e+00 -4.72856400e-01\n    4.55829721e+00]\n  [ 1.46673205e-01 -8.35547932e-01  2.04144273e-01 -6.88725041e-01\n    2.87943177e+00]\n  [ 5.18563981e-02  2.86019468e-01  1.08915040e+00  1.16158144e+00\n   -7.43772898e+00]]\n\n [[-2.62015135e-01  1.01753598e+00 -2.17177155e+00 -7.83289509e-01\n    7.27079872e+00]\n  [ 6.05838227e-01 -1.54716117e+00  1.92357654e-01 -1.73179923e+00\n    4.51181104e+00]\n  [-3.43823092e-01  5.29625187e-01  1.97941390e+00  2.51508874e+00\n   -1.17826098e+01]]\n\n [[-3.15259609e-01  1.58111043e+00 -3.19085843e+00 -1.14796020e+00\n    1.04286952e+01]\n  [ 1.23046551e+00 -2.47766017e+00  5.53238212e-02 -3.11159068e+00\n    6.81676610e+00]\n  [-9.15205903e-01  8.96549738e-01  3.13553461e+00  4.25955088e+00\n   -1.72454613e+01]]\n\n [[-3.92628135e-01  2.28221693e+00 -4.29356188e+00 -1.53939978e+00\n    1.38243135e+01]\n  [ 1.90309547e+00 -3.48031344e+00 -1.80804251e-01 -4.63986128e+00\n    9.71641847e+00]\n  [-1.51046733e+00  1.19809651e+00  4.47436613e+00  6.17926107e+00\n   -2.35407320e+01]]\n\n [[-1.33454085e-01  2.90492040e+00 -5.13051651e+00 -1.86866079e+00\n    1.39364362e+01]\n  [ 2.54224397e+00 -4.45697201e+00  3.27914874e-01 -6.83969820e+00\n    1.02139039e+01]\n  [-2.40878989e+00  1.55205161e+00  4.80260164e+00  8.70835899e+00\n   -2.41503402e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 11 20 25 50 60 59 80 62 23]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-3.02705028e-04  1.36594835e-04 -9.08431351e-04 -4.12599593e-04\n    5.35301989e-03]\n  [-3.34512386e-05 -1.53372415e-04  1.49747371e-04  3.65262854e-05\n    6.31856133e-05]\n  [ 3.36156267e-04  1.67775803e-05  7.58683980e-04  3.76073307e-04\n   -5.41620550e-03]]\n\n [[-2.30984256e-03  1.05392287e-03 -6.95314298e-03 -3.15757982e-03\n    4.07747066e-02]\n  [-2.66349689e-04 -1.18771346e-03  1.14655656e-03  2.77494648e-04\n    8.15400075e-04]\n  [ 2.57619225e-03  1.33790597e-04  5.80658642e-03  2.88008517e-03\n   -4.15901066e-02]]\n\n [[-1.61540096e-02  7.90182066e-03 -4.95164026e-02 -2.24492134e-02\n    2.85618896e-01]\n  [-2.26470616e-03 -9.10992401e-03  8.27217076e-03  1.87305175e-03\n    1.18589918e-02]\n  [ 1.84187157e-02  1.20810335e-03  4.12442318e-02  2.05761616e-02\n   -2.97477888e-01]]\n\n [[-7.20369468e-02  5.06927403e-02 -2.46056607e-01 -1.10357642e-01\n    1.28881334e+00]\n  [-2.17382539e-02 -6.39095391e-02  4.27376441e-02  5.07425489e-03\n    2.46075578e-01]\n  [ 9.37752007e-02  1.32167988e-02  2.03318963e-01  1.05283387e-01\n   -1.53488892e+00]]\n\n [[-1.52911229e-01  2.23681821e-01 -7.02085757e-01 -3.05033759e-01\n    3.02776074e+00]\n  [-1.14393800e-01 -2.88503330e-01  1.09473369e-01 -4.11812501e-02\n    1.71214691e+00]\n  [ 2.67305030e-01  6.48215086e-02  5.92612389e-01  3.46215010e-01\n   -4.73990765e+00]]\n\n [[-2.83643154e-01  6.00028374e-01 -1.56246292e+00 -6.63069525e-01\n    6.46784429e+00]\n  [-2.15239956e-01 -5.75482106e-01  7.99103343e-02 -3.66505946e-01\n    4.71210735e+00]\n  [ 4.98883110e-01 -2.45462671e-02  1.48255258e+00  1.02957547e+00\n   -1.11799516e+01]]\n\n [[-5.45415187e-01  1.06089760e+00 -2.82271081e+00 -1.19819344e+00\n    1.27660935e+01]\n  [-4.79794139e-01 -9.66033509e-01  1.52578246e-02 -1.41806877e+00\n    1.05764940e+01]\n  [ 1.02520933e+00 -9.48640891e-02  2.80745299e+00  2.61626222e+00\n   -2.33425875e+01]]\n\n [[-1.13844145e+00  1.54641833e+00 -4.57312593e+00 -1.88393501e+00\n    2.39077879e+01]\n  [-1.06624287e+00 -1.54956956e+00 -1.96378550e-01 -3.49022699e+00\n    2.15087268e+01]\n  [ 2.20468431e+00  3.15122701e-03  4.76950448e+00  5.37416200e+00\n   -4.54165147e+01]]\n\n [[-1.66562148e+00  1.98606088e+00 -6.80608614e+00 -2.94960866e+00\n    3.77607166e+01]\n  [-1.82968912e+00 -2.17181110e+00 -9.90037811e-01 -5.30213406e+00\n    3.61481927e+01]\n  [ 3.49531061e+00  1.85750215e-01  7.79612395e+00  8.25174272e+00\n   -7.39089093e+01]]\n\n [[-1.23232380e+00  3.40440763e+00 -9.17144541e+00 -4.49550206e+00\n    4.37586420e+01]\n  [-3.14946970e+00 -2.41811274e+00 -1.34835044e+00 -7.18909447e+00\n    5.11835908e+01]\n  [ 4.38179350e+00 -9.86294892e-01  1.05197958e+01  1.16845965e+01\n   -9.49422327e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 12  12  13  28  53  61  98 100 100  55]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[-5.92947143e-01  3.07155620e+00 -6.82307736e+00 -3.00227837e+00\n   2.64529861e+01]\n [-1.55426140e+00 -2.29796700e+00  4.76100432e-02 -5.31877758e+00\n   2.98751878e+01]\n [ 2.14720855e+00 -7.73589207e-01  6.77546732e+00  8.32105595e+00\n  -5.63281739e+01]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[  -1.95400839    2.74284065   -9.18392797   -4.02124065   49.86152024]\n  [  -2.86325056   -2.87572228   -1.49597024   -7.48335106   51.99862711]\n  [   4.81725895    0.13288163   10.67989822   11.50459171 -101.86014735]]]", "[10000.]", "[93]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.96013400e-04  5.99194112e-05 -7.88395304e-04 -3.62588522e-04\n   -3.41161525e-01]]\n\n [[-2.25804712e-03  4.59339915e-04 -6.02184451e-03 -2.76869008e-03\n   -3.05332202e-01]]\n\n [[-1.56598832e-02  3.31242685e-03 -4.21756136e-02 -1.93503640e-02\n   -6.24081093e-02]]\n\n [[-6.77852157e-02  1.78203214e-02 -1.93588682e-01 -8.76049305e-02\n    8.69351078e-01]]\n\n [[-1.37000571e-01  6.40051279e-02 -4.73396128e-01 -2.02698479e-01\n    2.21487486e+00]]\n\n [[-1.80441088e-01  1.63127582e-01 -8.48434626e-01 -3.32988698e-01\n    3.45724303e+00]]\n\n [[-2.12011678e-01  2.95530030e-01 -1.30058763e+00 -4.81657083e-01\n    4.72787645e+00]]\n\n [[-2.51028950e-01  4.39490255e-01 -1.80069894e+00 -6.49516354e-01\n    6.14517385e+00]]\n\n [[-1.11018006e-01  7.15962662e-01 -2.29113504e+00 -8.44183152e-01\n    6.19253791e+00]]\n\n [[ 3.87885399e-02  1.01447179e+00 -2.82304326e+00 -1.05516368e+00\n    6.24554743e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[14 12 14 17 18 18 22 20  6  6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.46445341e-04  1.51867429e-04 -7.30708797e-04 -3.07436706e-04\n   -4.19445365e-01]]\n\n [[-1.87930719e-03  1.16903137e-03 -5.59077115e-03 -2.35126960e-03\n   -3.91607787e-01]]\n\n [[-1.29979352e-02  8.66578832e-03 -3.96491476e-02 -1.66213127e-02\n   -2.02633606e-01]]\n\n [[-5.43337499e-02  5.21752645e-02 -1.92076472e-01 -7.90114789e-02\n    5.04176915e-01]]\n\n [[-9.32030630e-02  1.98824989e-01 -5.01026720e-01 -1.96501333e-01\n    1.30322982e+00]]\n\n [[-9.99658551e-02  4.57280532e-01 -9.08822750e-01 -3.43174767e-01\n    1.77034993e+00]]\n\n [[-9.42867938e-02  7.68290071e-01 -1.36831689e+00 -5.08097039e-01\n    2.12920621e+00]]\n\n [[-3.71373129e-02  1.12121125e+00 -1.84936981e+00 -6.90354717e-01\n    2.14993130e+00]]\n\n [[ 2.03957983e-02  1.49413275e+00 -2.35329686e+00 -8.79198851e-01\n    2.17282235e+00]]\n\n [[ 9.28128610e-02  1.92880599e+00 -2.93647258e+00 -1.09873594e+00\n    2.19393432e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[13 10 12 17 18 26 24  6  5  3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "lbfgs", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.98688237e-04  1.48073762e-04 -7.78690219e-04 -3.48470374e-04\n   -2.76034468e-01]]\n\n [[-1.51738579e-03  1.14106052e-03 -5.96092856e-03 -2.66567269e-03\n   -2.51005169e-01]]\n\n [[-1.06175442e-02  8.52047986e-03 -4.24531393e-02 -1.88872599e-02\n   -7.88686055e-02]]\n\n [[-4.71462822e-02  5.27070801e-02 -2.09971610e-01 -9.10367036e-02\n    6.11243394e-01]]\n\n [[-9.03014729e-02  1.99289274e-01 -5.54317420e-01 -2.31103716e-01\n    1.54803296e+00]]\n\n [[-1.07399250e-01  4.52420993e-01 -9.97823558e-01 -4.10710028e-01\n    2.25855850e+00]]\n\n [[-1.13086917e-01  7.63207876e-01 -1.49642409e+00 -6.19672652e-01\n    2.88828718e+00]]\n\n [[-1.19189637e-01  1.10373636e+00 -2.03786828e+00 -8.48970283e-01\n    3.55896410e+00]]\n\n [[-2.64027014e-02  1.50993713e+00 -2.59310718e+00 -1.09261399e+00\n    3.58564128e+00]]\n\n [[ 6.80868274e-02  1.92462751e+00 -3.15148955e+00 -1.34031634e+00\n    3.61600520e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[12 11 13 16 20 24 23 21  7  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "lbfgs", "fit_intercept": true, "coef": "[[-0.05642175  0.04090089 -0.19854559 -0.08588437  0.66159046]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.06705919  0.05680417 -0.24924089 -0.10688265  0.85541625]]]", "[0.04641589]", "[16]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": "True", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-0.21982053  0.48221749 -1.30388666 -0.53030162  3.73351646]]", "[1.]", "[11]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.2214357   0.40542377 -1.16946527 -0.47267731  4.86306278]\n  [-0.2295256  -0.4865705   0.15449168 -0.25481542  3.60413206]\n  [ 0.45096131  0.08114673  1.01497359  0.72749273 -8.46719485]]]", "[1.]", "[15]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "newton-cg", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-0.11433177  0.32417066 -0.79521101 -0.32080152  2.08449724]]]", "[1.]", "[12]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.96337130e-04  5.99568716e-05 -7.89199476e-04 -3.62957590e-04\n  -6.87728678e-01]\n [-2.27734586e-03  4.61984429e-04 -6.06896845e-03 -2.79076312e-03\n  -6.51523103e-01]\n [-1.66620606e-02  3.44816052e-03 -4.46259375e-02 -2.04989613e-02\n  -3.89766862e-01]\n [-9.01752206e-02  2.12338112e-02 -2.49805919e-01 -1.13892977e-01\n   9.27693489e-01]\n [-2.31154582e-01  8.59809810e-02 -7.35249881e-01 -3.22769657e-01\n   3.52645748e+00]\n [-3.37054314e-01  2.48136812e-01 -1.42266292e+00 -5.74509309e-01\n   6.09103491e+00]\n [-4.03383379e-01  4.99430366e-01 -2.28100109e+00 -8.57489495e-01\n   8.56529038e+00]\n [-4.74969269e-01  7.80957685e-01 -3.25281448e+00 -1.18535508e+00\n   1.13005668e+01]\n [-5.51986975e-01  1.07311306e+00 -4.28916027e+00 -1.54698361e+00\n   1.42336105e+01]\n [-2.61514515e-01  1.64264407e+00 -5.30061619e+00 -1.94697634e+00\n   1.43302999e+01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[8 5 9 4 7 7 6 5 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-2.46719419e-04  1.51934856e-04 -7.31351166e-04 -3.07717127e-04\n  -8.43089343e-01]\n [-1.89571234e-03  1.17298387e-03 -5.62892537e-03 -2.36787077e-03\n  -8.14969382e-01]\n [-1.38518710e-02  8.88308683e-03 -4.16594420e-02 -1.74958037e-02\n  -6.11451476e-01]\n [-7.38804572e-02  5.92625658e-02 -2.42055344e-01 -1.00547444e-01\n   4.07485919e-01]\n [-1.68457293e-01  2.68332273e-01 -7.64576625e-01 -3.05171311e-01\n   2.15117205e+00]\n [-1.99736610e-01  7.22790147e-01 -1.52644629e+00 -5.82126342e-01\n   3.26746033e+00]\n [-1.91972124e-01  1.31996719e+00 -2.41628203e+00 -9.01590303e-01\n   4.00768154e+00]\n [-1.72105726e-01  1.97989654e+00 -3.37750342e+00 -1.24851787e+00\n   4.67570238e+00]\n [-1.44323928e-01  2.67730696e+00 -4.38637122e+00 -1.61687240e+00\n   5.31675228e+00]\n [-2.91273586e-02  3.41457128e+00 -5.38152757e+00 -1.99109490e+00\n   5.34760290e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[8 5 7 4 8 7 5 4 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[-1.98887212e-04  1.48129419e-04 -7.79338751e-04 -3.48776649e-04\n  -5.55837536e-01]\n [-1.52934990e-03  1.14418260e-03 -5.99983982e-03 -2.68415567e-03\n  -5.30577711e-01]\n [-1.12406532e-02  8.69821320e-03 -4.44974767e-02 -1.98540831e-02\n  -3.46548533e-01]\n [-6.22851678e-02  5.92700759e-02 -2.62208272e-01 -1.15091624e-01\n   6.14943987e-01]\n [-1.57022106e-01  2.71130459e-01 -8.45715758e-01 -3.56565344e-01\n   2.50710846e+00]\n [-2.06952167e-01  7.16611220e-01 -1.68029201e+00 -6.92584762e-01\n   4.06762502e+00]\n [-2.16941399e-01  1.31055554e+00 -2.64428485e+00 -1.09037655e+00\n   5.30429827e+00]\n [-2.32500775e-01  1.97295394e+00 -3.70023961e+00 -1.53717640e+00\n   6.63896716e+00]\n [-2.41160092e-01  2.68452678e+00 -4.82068731e+00 -2.01939565e+00\n   7.99201536e+00]\n [-6.09031283e-02  3.50097399e+00 -5.92583492e+00 -2.50804934e+00\n   8.04753223e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[7 5 6 5 8 7 5 5 4 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[-0.18554466  0.20848124 -0.78184742 -0.32816877  2.728246  ]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.19486285  0.28148605 -0.91893321 -0.38134553  2.97784847]]", "[0.35938137]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.49597267e-04  8.99348447e-05 -7.05742315e-04 -3.09581998e-04\n    4.33539375e-03]\n  [-8.00469586e-05 -8.99887413e-05  1.33215603e-04  2.99486698e-05\n    1.90929955e-04]\n  [ 3.29644225e-04  5.38965901e-08  5.72526712e-04  2.79633329e-04\n   -4.52632370e-03]]\n\n [[-1.91178502e-03  6.92927563e-04 -5.41654754e-03 -2.37538057e-03\n    3.32122324e-02]\n  [-6.22087701e-04 -6.96091184e-04  1.02539056e-03  2.29229258e-04\n    1.55967207e-03]\n  [ 2.53387272e-03  3.16362015e-06  4.39115698e-03  2.14615131e-03\n   -3.47719045e-02]]\n\n [[-1.36559908e-02  5.17044452e-03 -3.92816527e-02 -1.71909864e-02\n    2.37610738e-01]\n  [-4.93846991e-03 -5.34409354e-03  7.58936927e-03  1.62272777e-03\n    1.64068649e-02]\n  [ 1.85944607e-02  1.73649017e-04  3.16922835e-02  1.55682586e-02\n   -2.54017603e-01]]\n\n [[-6.61510011e-02  3.23447829e-02 -2.09218151e-01 -9.03454996e-02\n    1.17579440e+00]\n  [-4.13821489e-02 -3.83195687e-02  4.41690416e-02  6.54806617e-03\n    2.49170725e-01]\n  [ 1.07533150e-01  5.97478582e-03  1.65049110e-01  8.37974334e-02\n   -1.42496512e+00]]\n\n [[-1.54474191e-01  1.39677882e-01 -6.34424016e-01 -2.62383169e-01\n    3.06254158e+00]\n  [-2.62185070e-01 -1.92358957e-01  1.52948914e-01 -6.21790434e-03\n    1.98595975e+00]\n  [ 4.16659260e-01  5.26810743e-02  4.81475102e-01  2.68601074e-01\n   -5.04850133e+00]]\n\n [[-2.93620711e-01  3.76492981e-01 -1.37851331e+00 -5.54991166e-01\n    6.32758375e+00]\n  [-7.92725145e-01 -4.24013118e-01  3.06563777e-01 -8.50614316e-02\n    6.09900708e+00]\n  [ 1.08634586e+00  4.75201368e-02  1.07194954e+00  6.40052597e-01\n   -1.24265908e+01]]\n\n [[-5.32296260e-01  7.07423790e-01 -2.37485545e+00 -9.61552867e-01\n    1.12706195e+01]\n  [-1.49909566e+00 -5.89187425e-01  4.22563923e-01 -2.86715914e-01\n    1.17039260e+01]\n  [ 2.03139192e+00 -1.18236365e-01  1.95229152e+00  1.24826878e+00\n   -2.29745455e+01]]\n\n [[-8.59191770e-01  1.10635911e+00 -3.53356121e+00 -1.44285748e+00\n    1.74462601e+01]\n  [-2.28030806e+00 -8.22881045e-01  4.95343140e-01 -6.23452479e-01\n    1.85582107e+01]\n  [ 3.13949983e+00 -2.83478065e-01  3.03821807e+00  2.06630996e+00\n   -3.60044708e+01]]\n\n [[-7.99729377e-01  1.87859106e+00 -4.73557250e+00 -2.02111734e+00\n    2.07305973e+01]\n  [-3.31098310e+00 -1.06810345e+00  6.39582925e-01 -1.01186146e+00\n    2.65947182e+01]\n  [ 4.11071248e+00 -8.10487608e-01  4.09598958e+00  3.03297880e+00\n   -4.73253155e+01]]\n\n [[-1.05016443e+00  2.44542920e+00 -6.06971461e+00 -2.59149533e+00\n    2.69887477e+01]\n  [-4.25908250e+00 -1.49943257e+00  7.22356311e-01 -1.46860157e+00\n    3.53095863e+01]\n  [ 5.30924693e+00 -9.45996626e-01  5.34735830e+00  4.06009690e+00\n   -6.22983340e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 5  6  8  9 10  9 10  7  4  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.99705162e-04  1.33257786e-04 -6.95802224e-04 -3.02924726e-04\n    3.71514219e-03]\n  [-4.11212186e-08 -1.56643222e-04  1.43190005e-04 -1.33979504e-05\n   -2.60849384e-05]\n  [ 1.99746283e-04  2.33854361e-05  5.52612219e-04  3.16322676e-04\n   -3.68905725e-03]]\n\n [[-1.53098618e-03  1.02784876e-03 -5.34260877e-03 -2.32429747e-03\n    2.84648493e-02]\n  [-2.47412958e-06 -1.21161670e-03  1.10120033e-03 -1.07099199e-04\n   -1.19939355e-04]\n  [ 1.53346031e-03  1.83767945e-04  4.24140845e-03  2.43139667e-03\n   -2.83449100e-02]]\n\n [[-1.10058357e-02  7.73031039e-03 -3.88652278e-02 -1.68177642e-02\n    2.03948153e-01]\n  [-1.35135435e-04 -9.29912901e-03  8.09886597e-03 -1.01743065e-03\n    3.18537710e-03]\n  [ 1.11409711e-02  1.56881863e-03  3.07663618e-02  1.78351948e-02\n   -2.07133531e-01]]\n\n [[-5.46844148e-02  4.99173341e-02 -2.08990898e-01 -8.75787421e-02\n    1.00658883e+00]\n  [-4.78829514e-03 -6.64930399e-02  4.52687336e-02 -1.46179925e-02\n    1.45554031e-01]\n  [ 5.94727099e-02  1.65757058e-02  1.63722165e-01  1.02196735e-01\n   -1.15214286e+00]]\n\n [[-1.24436048e-01  2.12901248e-01 -6.19510925e-01 -2.39860553e-01\n    2.44263210e+00]\n  [-2.19901009e-02 -3.29359162e-01  1.34536854e-01 -1.49570215e-01\n    1.22841297e+00]\n  [ 1.46426149e-01  1.16457914e-01  4.84974071e-01  3.89430768e-01\n   -3.67104507e+00]]\n\n [[-1.98393359e-01  5.49104225e-01 -1.29345990e+00 -4.73094072e-01\n    4.55967680e+00]\n  [ 1.46480058e-01 -8.35249007e-01  2.04101670e-01 -6.88461971e-01\n    2.87964930e+00]\n  [ 5.19133013e-02  2.86144782e-01  1.08935823e+00  1.16155604e+00\n   -7.43932610e+00]]\n\n [[-2.63071164e-01  1.01850834e+00 -2.17138164e+00 -7.82904812e-01\n    7.27298362e+00]\n  [ 6.05923760e-01 -1.54801542e+00  1.91887672e-01 -1.73203949e+00\n    4.51620592e+00]\n  [-3.42852597e-01  5.29507078e-01  1.97949397e+00  2.51494431e+00\n   -1.17891895e+01]]\n\n [[-3.08755154e-01  1.57707904e+00 -3.19104100e+00 -1.14793591e+00\n    1.04034225e+01]\n  [ 1.22817729e+00 -2.47943417e+00  5.47426247e-02 -3.10708641e+00\n    6.83048438e+00]\n  [-9.19422138e-01  9.02355134e-01  3.13629837e+00  4.25502232e+00\n   -1.72339069e+01]]\n\n [[-3.50564556e-01  2.19634411e+00 -4.31878051e+00 -1.55560183e+00\n    1.39173586e+01]\n  [ 1.89998048e+00 -3.48432136e+00 -1.64897008e-01 -4.61864672e+00\n    9.66099202e+00]\n  [-1.54941592e+00  1.28797724e+00  4.48367752e+00  6.17424855e+00\n   -2.35783506e+01]]\n\n [[-3.45089426e-01  2.87084640e+00 -5.49886299e+00 -1.99484545e+00\n    1.72725475e+01]\n  [ 2.57766214e+00 -4.52345789e+00 -4.00995796e-01 -6.21018399e+00\n    1.27625512e+01]\n  [-2.23257271e+00  1.65261149e+00  5.89985878e+00  8.20502944e+00\n   -3.00350986e+01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 5  6  8  7 10 14 14  9  8  5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-3.02714295e-04  1.36578109e-04 -9.08460671e-04 -4.12620534e-04\n    5.35778255e-03]\n  [-3.34038375e-05 -1.53307449e-04  1.49795050e-04  3.65729475e-05\n    5.41777984e-05]\n  [ 3.36118133e-04  1.67293401e-05  7.58665622e-04  3.76047587e-04\n   -5.41196035e-03]]\n\n [[-2.31192185e-03  1.05287574e-03 -6.95452800e-03 -3.15802847e-03\n    4.09105527e-02]\n  [-2.62259532e-04 -1.18562093e-03  1.14917917e-03  2.78314217e-04\n    5.52137627e-04]\n  [ 2.57418138e-03  1.32745193e-04  5.80534883e-03  2.87971425e-03\n   -4.14626904e-02]]\n\n [[-1.61750190e-02  7.88969631e-03 -4.95286566e-02 -2.24531801e-02\n    2.85973453e-01]\n  [-2.22356547e-03 -9.08613304e-03  8.29680856e-03  1.88166595e-03\n    1.11395829e-02]\n  [ 1.83985845e-02  1.19643674e-03  4.12318481e-02  2.05715141e-02\n   -2.97113036e-01]]\n\n [[-7.20441409e-02  5.06883032e-02 -2.46063640e-01 -1.10357882e-01\n    1.28888476e+00]\n  [-2.17373297e-02 -6.39057648e-02  4.27324503e-02  5.07695475e-03\n    2.46095644e-01]\n  [ 9.37814706e-02  1.32174615e-02  2.03331189e-01  1.05280927e-01\n   -1.53498040e+00]]\n\n [[-1.52931494e-01  2.23704112e-01 -7.02102647e-01 -3.05029777e-01\n    3.02788217e+00]\n  [-1.14363651e-01 -2.88507287e-01  1.09456502e-01 -4.11816517e-02\n    1.71204840e+00]\n  [ 2.67295145e-01  6.48031748e-02  5.92646144e-01  3.46211429e-01\n   -4.73993057e+00]]\n\n [[-2.83859697e-01  6.00180673e-01 -1.56240667e+00 -6.63007385e-01\n    6.46844359e+00]\n  [-2.15204395e-01 -5.75598745e-01  7.98668940e-02 -3.66475981e-01\n    4.71239878e+00]\n  [ 4.99064092e-01 -2.45819280e-02  1.48253977e+00  1.02948337e+00\n   -1.11808424e+01]]\n\n [[-5.43876380e-01  1.06113423e+00 -2.82210742e+00 -1.19911607e+00\n    1.27546443e+01]\n  [-4.80156107e-01 -9.65689862e-01  1.54473315e-02 -1.41716892e+00\n    1.05748563e+01]\n  [ 1.02403249e+00 -9.54443682e-02  2.80666009e+00  2.61628499e+00\n   -2.33295005e+01]]\n\n [[-1.06363243e+00  1.53442008e+00 -4.64867480e+00 -1.99374545e+00\n    2.40055681e+01]\n  [-1.10106524e+00 -1.52664254e+00 -3.30357775e-01 -3.29943313e+00\n    2.19957254e+01]\n  [ 2.16469767e+00 -7.77754074e-03  4.97903257e+00  5.29317857e+00\n   -4.60012935e+01]]\n\n [[-1.68647285e+00  2.07945173e+00 -6.81964625e+00 -2.94857780e+00\n    3.75617535e+01]\n  [-1.84163044e+00 -2.02779673e+00 -9.26332396e-01 -5.32053463e+00\n    3.55317314e+01]\n  [ 3.52810330e+00 -5.16549969e-02  7.74597865e+00  8.26911243e+00\n   -7.30934849e+01]]\n\n [[-2.28831428e+00  2.68483727e+00 -9.13331606e+00 -3.89332877e+00\n    5.14305411e+01]\n  [-2.64715520e+00 -2.46613719e+00 -1.47711741e+00 -7.51371063e+00\n    4.94023543e+01]\n  [ 4.93546949e+00 -2.18700077e-01  1.06104335e+01  1.14070394e+01\n   -1.00832895e+02]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 5  6  8  7 10 13 12 12  5  4]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[[-6.42931856e-02  4.43168067e-02 -2.21424230e-01 -9.60940411e-02\n   1.15708933e+00]\n [-2.26359246e-02 -5.62394578e-02  4.40567418e-02 -9.97657197e-04\n   2.13606800e-01]\n [ 8.69291102e-02  1.19226510e-02  1.77367488e-01  9.70916983e-02\n  -1.37069613e+00]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.07985713  0.06149491 -0.2862516  -0.1234032   1.45018192]\n  [-0.03469172 -0.0805526   0.05726901 -0.00467225  0.35620911]\n  [ 0.11454886  0.01905769  0.22898258  0.12807545 -1.80639102]]]", "[0.04641589]", "[5]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.96008180e-04  5.99138002e-05 -7.88400313e-04 -3.62582492e-04\n   -3.41161538e-01]]\n\n [[-2.25841611e-03  4.59212917e-04 -6.02218421e-03 -2.76877146e-03\n   -3.05305413e-01]]\n\n [[-1.56598871e-02  3.31240122e-03 -4.21756446e-02 -1.93503670e-02\n   -6.24078420e-02]]\n\n [[-6.77852486e-02  1.78203349e-02 -1.93588463e-01 -8.76053195e-02\n    8.69350814e-01]]\n\n [[-1.36999569e-01  6.40016062e-02 -4.73397358e-01 -2.02696964e-01\n    2.21488285e+00]]\n\n [[-1.80590091e-01  1.63268310e-01 -8.48394771e-01 -3.32941636e-01\n    3.45748408e+00]]\n\n [[-2.13052112e-01  2.96761998e-01 -1.30012997e+00 -4.81673101e-01\n    4.72843422e+00]]\n\n [[-2.32384326e-01  4.50583868e-01 -1.79520521e+00 -6.51435231e-01\n    5.99543265e+00]]\n\n [[-9.13491718e-02  7.29803612e-01 -2.28994096e+00 -8.47562449e-01\n    6.04504280e+00]]\n\n [[-2.94279740e-01  7.52747463e-01 -2.84730175e+00 -1.02433575e+00\n    8.86643133e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[8 7 7 6 8 8 6 4 3 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-2.46439354e-04  1.51869762e-04 -7.30703374e-04 -3.07434712e-04\n   -4.19445428e-01]]\n\n [[-1.87969566e-03  1.16887870e-03 -5.59101476e-03 -2.35130681e-03\n   -3.91581927e-01]]\n\n [[-1.29979593e-02  8.66578633e-03 -3.96492103e-02 -1.66213673e-02\n   -2.02632486e-01]]\n\n [[-5.43331511e-02  5.21745905e-02 -1.92076936e-01 -7.90110962e-02\n    5.04176711e-01]]\n\n [[-9.32024083e-02  1.98826775e-01 -5.01028241e-01 -1.96500944e-01\n    1.30322102e+00]]\n\n [[-9.99713633e-02  4.57264621e-01 -9.08807508e-01 -3.43182022e-01\n    1.77038877e+00]]\n\n [[-9.32388311e-02  7.69024787e-01 -1.36776867e+00 -5.08446390e-01\n    2.12008435e+00]]\n\n [[-8.17051654e-02  1.10638692e+00 -1.85737449e+00 -6.85643673e-01\n    2.44723536e+00]]\n\n [[-2.43974230e-02  1.46788387e+00 -2.34697765e+00 -8.70211285e-01\n    2.46377761e+00]]\n\n [[ 3.40830156e-02  1.84642119e+00 -2.85736554e+00 -1.06160630e+00\n    2.48145422e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[8 8 7 8 9 6 5 4 3 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "newton-cg", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null}}, "return": ["[[[-1.98683877e-04  1.48077034e-04 -7.78678594e-04 -3.48462971e-04\n   -2.76033291e-01]]\n\n [[-1.51737829e-03  1.14106229e-03 -5.96093386e-03 -2.66567797e-03\n   -2.51004958e-01]]\n\n [[-1.06172683e-02  8.52069029e-03 -4.24533913e-02 -1.88874493e-02\n   -7.88704521e-02]]\n\n [[-4.71435915e-02  5.27095712e-02 -2.09969964e-01 -9.10356683e-02\n    6.11211297e-01]]\n\n [[-9.03015096e-02  1.99290614e-01 -5.54314937e-01 -2.31104312e-01\n    1.54802127e+00]]\n\n [[-1.06720547e-01  4.52868961e-01 -9.97693818e-01 -4.10625068e-01\n    2.25315995e+00]]\n\n [[-1.09697305e-01  7.65031536e-01 -1.49613699e+00 -6.18306704e-01\n    2.86346564e+00]]\n\n [[-1.18534677e-01  1.10440061e+00 -2.03718281e+00 -8.48747021e-01\n    3.55176192e+00]]\n\n [[-3.00921595e-02  1.49976735e+00 -2.57607235e+00 -1.08610446e+00\n    3.57947096e+00]]\n\n [[-1.02883774e-01  1.84521516e+00 -3.17161792e+00 -1.34934048e+00\n    4.74965900e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[7 6 8 7 8 6 5 5 3 3]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "newton-cg", "fit_intercept": true, "coef": "[[-0.05642066  0.0409015  -0.19854512 -0.08588403  0.66157961]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.06706017  0.05680471 -0.2492414  -0.10688139  0.85542003]]]", "[0.04641589]", "[6]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": "True", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[ 0.18044398  0.736564   -1.23959907 -0.56000054  0.5292692 ]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[ 0.23371556  0.68047946 -1.01889623 -0.46638789  0.53546477]\n  [ 0.02524077 -0.3105117   0.2747574  -0.34344874  0.83648256]\n  [-0.25895633 -0.36996777  0.74413883  0.80983663 -1.37194734]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "sag", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[ 0.11100804  0.46249051 -0.75857496 -0.33884611  0.32350259]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[-1.02474157e-03 -3.17163888e-04 -1.28983325e-03 -5.36389906e-04\n  -1.19854561e-01]\n [-3.79221421e-03 -3.24771953e-04 -7.10269095e-03 -3.14689823e-03\n  -4.78914426e-01]\n [-1.63695406e-02  3.60420794e-03 -4.44369697e-02 -2.04356392e-02\n  -3.96910999e-01]\n [-5.65999407e-02  4.17658349e-02 -2.34960891e-01 -1.10256357e-01\n   5.29255441e-01]\n [ 2.18401222e-02  2.67858133e-01 -6.94732960e-01 -3.37713656e-01\n   1.24328904e+00]\n [ 2.18827541e-01  6.60219786e-01 -1.36784085e+00 -6.60988348e-01\n   1.51338750e+00]\n [ 3.97109019e-01  1.00803472e+00 -1.95949265e+00 -9.40534832e-01\n   1.62239075e+00]\n [ 5.01581424e-01  1.21205043e+00 -2.30749480e+00 -1.10131346e+00\n   1.67074183e+00]\n [ 5.69427440e-01  1.34466497e+00 -2.53406773e+00 -1.20466167e+00\n   1.69900836e+00]\n [ 6.18143493e-01  1.43959290e+00 -2.69605231e+00 -1.27789379e+00\n   1.71860447e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[-1.18007799e-03 -3.25128606e-04 -1.32900060e-03 -5.03681250e-04\n  -1.64619262e-01]\n [-3.51298160e-03  3.44961673e-04 -6.66003711e-03 -2.70510618e-03\n  -6.39792912e-01]\n [-1.36510084e-02  8.98884093e-03 -4.15378783e-02 -1.74571614e-02\n  -6.16078158e-01]\n [-4.86837812e-02  7.43440047e-02 -2.31183450e-01 -9.78253096e-02\n   1.21132606e-01]\n [ 4.38277111e-03  3.83242930e-01 -7.28459320e-01 -3.06821765e-01\n   6.39165130e-01]\n [ 1.13448302e-01  9.03513902e-01 -1.46687423e+00 -5.98825535e-01\n   8.10937407e-01]\n [ 2.05899832e-01  1.35867483e+00 -2.11232987e+00 -8.53495577e-01\n   8.74621489e-01]\n [ 2.57131521e-01  1.62404998e+00 -2.48596886e+00 -9.99218607e-01\n   9.01172455e-01]\n [ 2.89712586e-01  1.79557270e+00 -2.72629164e+00 -1.09248775e+00\n   9.16210480e-01]\n [ 3.12572092e-01  1.91765297e+00 -2.89678346e+00 -1.15840813e+00\n   9.26379155e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100  68 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[-8.29352086e-04 -1.91425808e-04 -1.16800663e-03 -4.67806669e-04\n  -1.32295971e-01]\n [-2.31188283e-03  7.21871916e-04 -6.47959688e-03 -2.83055442e-03\n  -4.54611548e-01]\n [-1.10722290e-02  8.79031565e-03 -4.43990521e-02 -1.98252144e-02\n  -3.50082412e-01]\n [-3.95082456e-02  7.26161681e-02 -2.52247067e-01 -1.13011649e-01\n   3.72640945e-01]\n [ 2.97453736e-02  3.87583804e-01 -8.00613373e-01 -3.60791127e-01\n   9.25255230e-01]\n [ 1.76296633e-01  9.27820056e-01 -1.60494444e+00 -7.19284111e-01\n   1.13125948e+00]\n [ 3.08363253e-01  1.40398644e+00 -2.30348766e+00 -1.03273192e+00\n   1.21540567e+00]\n [ 3.83690766e-01  1.68347037e+00 -2.70788459e+00 -1.21403940e+00\n   1.25320901e+00]\n [ 4.32092250e-01  1.86512023e+00 -2.96852220e+00 -1.33096416e+00\n   1.27553004e+00]\n [ 4.66293950e-01  1.99493242e+00 -3.15373217e+00 -1.41407109e+00\n   1.29104702e+00]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[ 0.01865609  0.34622829 -0.74126855 -0.33510885  0.93590313]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null, "l1_ratio": null}}, "return": ["[[-0.01546187  0.39849288 -0.88471655 -0.38952347  1.46749882]]", "[0.35938137]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-2.36970370e-04  9.64313145e-05 -6.97430641e-04 -3.06876784e-04\n   -2.92965221e-03]\n  [-8.28543147e-05 -9.14339237e-05  1.31369836e-04  2.93481265e-05\n    1.81733133e-03]\n  [ 3.19824685e-04 -4.99739082e-06  5.66060805e-04  2.77528658e-04\n    1.11232089e-03]]\n\n [[-1.81905141e-03  7.40869922e-04 -5.35596929e-03 -2.35576114e-03\n    2.55818087e-02]\n  [-6.23027968e-04 -6.96643526e-04  1.02493550e-03  2.29111589e-04\n    1.65722351e-03]\n  [ 2.44207938e-03 -4.42263966e-05  4.33103379e-03  2.12664955e-03\n   -2.72390322e-02]]\n\n [[-1.32623540e-02  5.38054850e-03 -3.90412485e-02 -1.71163801e-02\n    2.29929794e-01]\n  [-4.90388460e-03 -5.32792220e-03  7.61614065e-03  1.63209398e-03\n    1.57064041e-02]\n  [ 1.81662386e-02 -5.26262985e-05  3.14251079e-02  1.54842861e-02\n   -2.45636198e-01]]\n\n [[-4.40858338e-02  4.58258020e-02 -1.99913064e-01 -8.83871785e-02\n    9.34453298e-01]\n  [-3.51396841e-02 -3.50595514e-02  4.84359974e-02  7.83799693e-03\n    1.66057392e-01]\n  [ 7.92255179e-02 -1.07662506e-02  1.51477067e-01  8.05491815e-02\n   -1.10051069e+00]]\n\n [[ 1.82053728e-02  2.49058010e-01 -5.77760798e-01 -2.59318633e-01\n    1.40401929e+00]\n  [-1.38179130e-01 -1.01683821e-01  1.97909661e-01 -1.75944615e-02\n    6.52372069e-01]\n  [ 1.19973758e-01 -1.47374189e-01  3.79851138e-01  2.76913094e-01\n   -2.05639136e+00]]\n\n [[ 2.14288006e-01  6.95072035e-01 -1.23312192e+00 -5.53954672e-01\n    1.60664098e+00]\n  [-2.96679731e-01  5.96363805e-02  4.18777362e-01 -3.28327052e-01\n    1.21385631e+00]\n  [ 8.23917254e-02 -7.54708415e-01  8.14344562e-01  8.82281725e-01\n   -2.82049729e+00]]\n\n [[ 4.45654156e-01  1.18295120e+00 -1.89528576e+00 -8.56817649e-01\n    1.71496890e+00]\n  [-4.49272440e-01  3.96651639e-01  5.76841618e-01 -7.48691971e-01\n    1.64419030e+00]\n  [ 3.61828322e-03 -1.57960284e+00  1.31844414e+00  1.60550962e+00\n   -3.35915921e+00]]\n\n [[ 6.16160103e-01  1.53959928e+00 -2.35739530e+00 -1.06988414e+00\n    1.77879941e+00]\n  [-5.64530736e-01  7.11018204e-01  6.61406806e-01 -1.08921480e+00\n    1.93114485e+00]\n  [-5.16293679e-02 -2.25061748e+00  1.69598849e+00  2.15909894e+00\n   -3.70994425e+00]]\n\n [[ 7.38660380e-01  1.79806392e+00 -2.68464275e+00 -1.22150869e+00\n    1.82206983e+00]\n  [-6.51501886e-01  9.58664936e-01  7.16619583e-01 -1.34549570e+00\n    2.13281996e+00]\n  [-8.71584933e-02 -2.75672886e+00  1.96802317e+00  2.56700439e+00\n   -3.95488979e+00]]\n\n [[ 8.31021116e-01  1.99560503e+00 -2.93160424e+00 -1.33625371e+00\n    1.85452269e+00]\n  [-7.19735508e-01  1.15278225e+00  7.59000853e-01 -1.54416720e+00\n    2.28513975e+00]\n  [-1.11285609e-01 -3.14838728e+00  2.17260339e+00  2.88042091e+00\n   -4.13966244e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  7 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-1.88271350e-04  1.39380576e-04 -6.88516167e-04 -3.00490675e-04\n   -2.93355420e-03]\n  [-3.18364734e-06 -1.58326730e-04  1.41189171e-04 -1.40661799e-05\n    1.80819187e-03]\n  [ 1.91454997e-04  1.89461537e-05  5.47326996e-04  3.14556855e-04\n    1.12536232e-03]]\n\n [[-1.45130758e-03  1.07062783e-03 -5.29227648e-03 -2.30758835e-03\n    2.18669652e-02]\n  [-7.54661073e-06 -1.21437980e-03  1.09812587e-03 -1.08092418e-04\n    3.13004805e-04]\n  [ 1.45885419e-03  1.43751971e-04  4.19415060e-03  2.41568076e-03\n   -2.21799700e-02]]\n\n [[-1.06769049e-02  7.91111245e-03 -3.86703799e-02 -1.67555824e-02\n    1.97565087e-01]\n  [-1.25434415e-04 -9.29536841e-03  8.10902449e-03 -1.01339329e-03\n    2.97691321e-03]\n  [ 1.08023393e-02  1.38425596e-03  3.05613554e-02  1.77689757e-02\n   -2.00542000e-01]]\n\n [[-3.55495218e-02  6.15219622e-02 -2.01097018e-01 -8.58418745e-02\n    8.00210556e-01]\n  [-7.47188041e-04 -6.46500562e-02  4.82552425e-02 -1.37246892e-02\n    9.20450354e-02]\n  [ 3.62967098e-02  3.12809400e-03  1.52841775e-01  9.95665637e-02\n   -8.92255592e-01]]\n\n [[ 8.16781867e-03  2.94985204e-01 -5.77741923e-01 -2.37268889e-01\n    1.18274438e+00]\n  [ 6.11686180e-02 -2.95528308e-01  1.71603571e-01 -1.59836079e-01\n    4.02653349e-01]\n  [-6.93364366e-02  5.43104060e-04  4.06138352e-01  3.97104968e-01\n   -1.58539773e+00]]\n\n [[ 1.25057525e-01  7.14160153e-01 -1.14535669e+00 -4.56670478e-01\n    1.33241801e+00]\n  [ 3.55670370e-01 -7.83186690e-01  3.61659583e-01 -7.79369186e-01\n    6.99125180e-01]\n  [-4.80727894e-01  6.90265367e-02  7.83697102e-01  1.23603966e+00\n   -2.03154319e+00]]\n\n [[ 2.46474982e-01  1.09643172e+00 -1.64650613e+00 -6.53660680e-01\n    1.40035817e+00]\n  [ 6.49719494e-01 -1.23209666e+00  5.44620026e-01 -1.47870681e+00\n    9.00824317e-01]\n  [-8.96194477e-01  1.35664940e-01  1.10188610e+00  2.13236749e+00\n   -2.30118249e+00]]\n\n [[ 3.22916222e-01  1.32756857e+00 -1.94350874e+00 -7.70617336e-01\n    1.43372321e+00]\n  [ 8.41846177e-01 -1.52514039e+00  6.75390176e-01 -2.00651131e+00\n    1.03665558e+00]\n  [-1.16476240e+00  1.97571813e-01  1.26811856e+00  2.77712864e+00\n   -2.47037879e+00]]\n\n [[ 3.73762006e-01  1.47772549e+00 -2.13426685e+00 -8.45888246e-01\n    1.45411883e+00]\n  [ 9.73037304e-01 -1.72754602e+00  7.73108098e-01 -2.40204126e+00\n    1.13718716e+00]\n  [-1.34679931e+00  2.49820533e-01  1.36115875e+00  3.24792951e+00\n   -2.59130598e+00]]\n\n [[ 4.10424839e-01  1.58460406e+00 -2.26908088e+00 -8.99150087e-01\n    1.46854619e+00]\n  [ 1.06856868e+00 -1.87867082e+00  8.50914772e-01 -2.71155643e+00\n    1.21682129e+00]\n  [-1.47899352e+00  2.94066762e-01  1.41816611e+00  3.61070652e+00\n   -2.68536748e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  7 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-2.94308962e-04  1.40949000e-04 -9.03050117e-04 -4.10877617e-04\n    1.76440547e-03]\n  [-1.77780418e-05 -1.45183688e-04  1.59858518e-04  3.98156597e-05\n   -6.65756628e-03]\n  [ 3.12087004e-04  4.23468854e-06  7.43191599e-04  3.71061958e-04\n    4.89316081e-03]]\n\n [[-2.26456018e-03  1.07760613e-03 -6.92438841e-03 -3.14839285e-03\n    3.78830721e-02]\n  [-2.53979144e-04 -1.18134342e-03  1.15457694e-03  2.80064662e-04\n    2.78391269e-05]\n  [ 2.51853933e-03  1.03737295e-04  5.76981148e-03  2.86832818e-03\n   -3.79109112e-02]]\n\n [[-1.59679282e-02  8.00197527e-03 -4.94086698e-02 -2.24171780e-02\n    2.82445629e-01]\n  [-2.20544396e-03 -9.07766559e-03  8.31099528e-03  1.88671368e-03\n    1.08026779e-02]\n  [ 1.81733721e-02  1.07569032e-03  4.10976745e-02  2.05304644e-02\n   -2.93248307e-01]]\n\n [[-5.01575350e-02  6.39475597e-02 -2.37673826e-01 -1.08844910e-01\n    1.06018432e+00]\n  [-1.56725182e-02 -6.08183159e-02  4.66446759e-02  6.29351879e-03\n    1.67214111e-01]\n  [ 6.58300532e-02 -3.12924386e-03  1.91029150e-01  1.02551391e-01\n   -1.22739843e+00]]\n\n [[ 4.85461301e-03  3.17454925e-01 -6.50470962e-01 -3.01282014e-01\n    1.52077000e+00]\n  [-9.95581417e-03 -2.27953063e-01  1.42330383e-01 -4.26723347e-02\n    6.34733226e-01]\n  [ 5.10120116e-03 -8.95018621e-02  5.08140579e-01  3.43954349e-01\n   -2.15550322e+00]]\n\n [[ 1.99356781e-01  8.77941857e-01 -1.38604020e+00 -6.43717198e-01\n    1.73408044e+00]\n  [ 1.02060072e-01 -2.94193432e-01  1.69404680e-01 -3.35232178e-01\n    1.11805076e+00]\n  [-3.01416853e-01 -5.83748426e-01  1.21663552e+00  9.78949375e-01\n   -2.85213119e+00]]\n\n [[ 4.20072689e-01  1.44844221e+00 -2.10332597e+00 -9.82683578e-01\n    1.84966570e+00]\n  [ 1.41168722e-01 -1.45074441e-01  1.76841247e-01 -6.75628397e-01\n    1.49009161e+00]\n  [-5.61241411e-01 -1.30336777e+00  1.92648473e+00  1.65831197e+00\n   -3.33975731e+00]]\n\n [[ 5.72886004e-01  1.83513190e+00 -2.57940674e+00 -1.20831335e+00\n    1.91534087e+00]\n  [ 9.44208553e-02  7.52002543e-02  2.10802339e-01 -9.62706176e-01\n    1.76720154e+00]\n  [-6.67306859e-01 -1.91033216e+00  2.36860440e+00  2.17101952e+00\n   -3.68254241e+00]]\n\n [[ 6.80120862e-01  2.10463318e+00 -2.90733541e+00 -1.36394439e+00\n    1.95904807e+00]\n  [ 1.88456214e-02  2.82251284e-01  2.63160523e-01 -1.21218677e+00\n    1.98903776e+00]\n  [-6.98966483e-01 -2.38688446e+00  2.64417488e+00  2.57613116e+00\n   -3.94808583e+00]]\n\n [[ 7.60158747e-01  2.30671996e+00 -3.15204857e+00 -1.48009201e+00\n    1.99175234e+00]\n  [-6.36446644e-02  4.65410409e-01  3.25013502e-01 -1.43487010e+00\n    2.17751505e+00]\n  [-6.96514082e-01 -2.77213037e+00  2.82703507e+00  2.91496211e+00\n   -4.16926739e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  9 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[[-4.32642968e-02  5.70984413e-02 -2.12894636e-01 -9.43579876e-02\n   9.31616058e-01]\n [-1.71864634e-02 -5.35093078e-02  4.77786386e-02  1.35608855e-04\n   1.41772179e-01]\n [ 6.04507603e-02 -3.58913350e-03  1.65115997e-01  9.42223787e-02\n  -1.07338824e+00]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.06917517  0.06806087 -0.28223204 -0.12271944  1.34023653]\n  [-0.02954616 -0.07773945  0.06012723 -0.00396265  0.29480487]\n  [ 0.09872132  0.00967858  0.22210481  0.12668209 -1.6350414 ]]]", "[0.04641589]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-8.84024491e-04 -2.44704182e-04 -1.19208436e-03 -5.02330821e-04\n   -1.07038151e-01]]\n\n [[-2.66785351e-03  2.45769537e-04 -6.29927198e-03 -2.86366472e-03\n   -2.79544114e-01]]\n\n [[-1.53428940e-02  3.48640604e-03 -4.19836231e-02 -1.92884781e-02\n   -6.79577724e-02]]\n\n [[-4.70197102e-02  3.13890771e-02 -1.86690813e-01 -8.66204227e-02\n    6.51188879e-01]]\n\n [[-2.84166280e-03  1.62133957e-01 -4.56903879e-01 -2.15415311e-01\n    1.05377066e+00]]\n\n [[ 9.84376023e-02  3.68532324e-01 -8.18325808e-01 -3.80176536e-01\n    1.19248838e+00]]\n\n [[ 1.92877118e-01  5.55093166e-01 -1.13981533e+00 -5.26049880e-01\n    1.24793476e+00]]\n\n [[ 2.47392181e-01  6.62638134e-01 -1.32517466e+00 -6.08610482e-01\n    1.27219419e+00]]\n\n [[ 2.82511000e-01  7.31847148e-01 -1.44442527e+00 -6.61214555e-01\n    1.28627958e+00]]\n\n [[ 3.07617063e-01  7.81073569e-01 -1.52899664e+00 -6.98269596e-01\n    1.29601196e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-9.80199237e-04 -2.23377351e-04 -1.19999572e-03 -4.61202793e-04\n   -1.45479084e-01]]\n\n [[-2.26744411e-03  9.69869639e-04 -5.83683640e-03 -2.43144905e-03\n   -3.68409519e-01]]\n\n [[-1.28266499e-02  8.75833345e-03 -3.95513441e-02 -1.65912205e-02\n   -2.05493030e-01]]\n\n [[-3.93479866e-02  6.16739962e-02 -1.87023329e-01 -7.81049746e-02\n    3.53022331e-01]]\n\n [[-1.17764257e-02  2.51702472e-01 -4.85292182e-01 -1.98401701e-01\n    6.21431676e-01]]\n\n [[ 3.98344478e-02  5.33449949e-01 -8.80686808e-01 -3.50627398e-01\n    6.98229828e-01]]\n\n [[ 8.63190206e-02  7.81377104e-01 -1.22876497e+00 -4.85707325e-01\n    7.27999723e-01]]\n\n [[ 1.11857495e-01  9.22196122e-01 -1.42532817e+00 -5.61453318e-01\n    7.40257977e-01]]\n\n [[ 1.28037526e-01  1.01190742e+00 -1.55000169e+00 -6.09356624e-01\n    7.47152026e-01]]\n\n [[ 1.39359848e-01  1.07518212e+00 -1.63767441e+00 -6.42957812e-01\n    7.51790504e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100 100 100 100  94 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "sag", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-6.70017556e-04 -1.05831247e-04 -1.06899967e-03 -4.37303187e-04\n   -1.14389495e-01]]\n\n [[-1.64280723e-03  1.07321970e-03 -6.03733009e-03 -2.68888205e-03\n   -2.44333320e-01]]\n\n [[-1.05250879e-02  8.57183989e-03 -4.24021199e-02 -1.88731039e-02\n   -8.02660517e-02]]\n\n [[-3.28821562e-02  6.13355312e-02 -2.04862485e-01 -9.03669225e-02\n    4.74737676e-01]]\n\n [[ 3.74727933e-03  2.56977259e-01 -5.33594530e-01 -2.34799248e-01\n    7.80573292e-01]]\n\n [[ 7.55655017e-02  5.49770298e-01 -9.61730855e-01 -4.23223761e-01\n    8.83639738e-01]]\n\n [[ 1.43535536e-01  8.09660371e-01 -1.33739245e+00 -5.90537157e-01\n    9.25431757e-01]]\n\n [[ 1.81768612e-01  9.58612699e-01 -1.55015533e+00 -6.85420382e-01\n    9.43889395e-01]]\n\n [[ 2.06178296e-01  1.05415520e+00 -1.68557791e+00 -7.45909398e-01\n    9.54686227e-01]]\n\n [[ 2.23341974e-01  1.12185193e+00 -1.78104890e+00 -7.88590044e-01\n    9.62147408e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100  99 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "sag", "fit_intercept": true, "coef": "[[-0.03974995  0.0514662  -0.19285888 -0.08503077  0.49298296]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[-0.0604191   0.06107385 -0.24732286 -0.10675877  0.79284083]]]", "[0.04641589]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": "True", "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "ovr", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[ 0.20954008  0.74889339 -1.23421094 -0.56609125  0.31418841]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[ 0.25696572  0.68565939 -1.00408083 -0.46655376  0.31129423]\n  [ 0.07690516 -0.28793328  0.26851426 -0.33176988  0.4428705 ]\n  [-0.33387087 -0.39772611  0.73556657  0.79832365 -0.75416473]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[bool_]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "tol": "float", "verbose": "int", "solver": "str", "multi_class": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "check_input": "bool", "random_state": "int", "coef": "null value in the ground truth", "penalty": "str", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[ True  True  True  True  True False False False False False False False\n False False False]"}, "kwargs": {"pos_class": null, "Cs": null, "l1_ratio": null, "fit_intercept": true, "tol": 0.0001, "verbose": 0, "solver": "saga", "multi_class": "multinomial", "max_iter": 100, "class_weight": null, "check_input": false, "random_state": 0, "coef": null, "penalty": "l2", "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[ 0.12887361  0.4707176  -0.75632675 -0.34281339  0.19452105]]]", "[1.]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[-1.17834968e-03 -3.96657544e-04 -1.39546272e-03 -5.73009396e-04\n  -4.17546608e-03]\n [-6.23040448e-03 -1.59240626e-03 -8.76441738e-03 -3.71984105e-03\n  -2.08024602e-01]\n [-1.97714341e-02  1.78844816e-03 -4.66324515e-02 -2.11708082e-02\n  -3.13128562e-01]\n [-2.00690935e-02  6.40747235e-02 -2.18733553e-01 -1.06244902e-01\n   9.35596295e-02]\n [ 1.03902220e-01  3.27943075e-01 -6.83833437e-01 -3.43469377e-01\n   5.09828670e-01]\n [ 3.06077794e-01  7.14630818e-01 -1.32591945e+00 -6.64165062e-01\n   6.97485812e-01]\n [ 4.45929729e-01  9.83886708e-01 -1.77757005e+00 -8.84192863e-01\n   7.75988721e-01]\n [ 5.32269431e-01  1.15035091e+00 -2.05780182e+00 -1.01816240e+00\n   8.15477016e-01]\n [ 5.90585735e-01  1.26317112e+00 -2.24846214e+00 -1.10811328e+00\n   8.40372442e-01]\n [ 6.33727536e-01  1.34662970e+00 -2.38966760e+00 -1.17409656e+00\n   8.58359016e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  7 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[-1.39325410e-03 -4.34103971e-04 -1.46554908e-03 -5.48473644e-04\n  -1.85671452e-02]\n [-6.74268035e-03 -1.31104880e-03 -8.71588949e-03 -3.37735142e-03\n  -3.04991858e-01]\n [-1.88782308e-02  6.23647986e-03 -4.46960435e-02 -1.84621978e-02\n  -4.93366036e-01]\n [-2.21164467e-02  9.02142769e-02 -2.19606227e-01 -9.48966024e-02\n  -1.82886227e-01]\n [ 6.32916544e-02  4.23283833e-01 -7.17480338e-01 -3.07938063e-01\n   1.22290985e-01]\n [ 1.82080038e-01  9.13567111e-01 -1.41776506e+00 -5.94211299e-01\n   2.47011103e-01]\n [ 2.56884676e-01  1.25812545e+00 -1.90944313e+00 -7.90877190e-01\n   2.95230886e-01]\n [ 3.00997399e-01  1.47158719e+00 -2.21222253e+00 -9.10572585e-01\n   3.18350827e-01]\n [ 3.30108673e-01  1.61632941e+00 -2.41664880e+00 -9.90838231e-01\n   3.32559130e-01]\n [ 3.51179439e-01  1.72325830e+00 -2.56720849e+00 -1.04966482e+00\n   3.42624945e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 32 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "str", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": "1", "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[ 0.0879267   0.39369142 -0.72902869 -0.33814351  0.33036715]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "ovr", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null, "l1_ratio": null}}, "return": ["[[ 0.07866109  0.46148313 -0.86912261 -0.39493753  0.67391279]]", "[0.35938137]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "str", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": "1", "multi_class": "ovr", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[-1.02464184e-03 -2.96605407e-04 -1.28838042e-03 -5.04680396e-04\n  -4.50860052e-03]\n [-4.66642783e-03 -5.47341066e-04 -7.92571122e-03 -3.27196851e-03\n  -2.27923892e-01]\n [-1.30231712e-02  7.72320017e-03 -4.55389051e-02 -2.01596106e-02\n  -3.08709255e-01]\n [-7.54492649e-03  9.13638097e-02 -2.38251515e-01 -1.10070962e-01\n   3.15533032e-02]\n [ 9.65862303e-02  4.29847355e-01 -7.85772297e-01 -3.63023100e-01\n   3.58981786e-01]\n [ 2.53352260e-01  9.38558817e-01 -1.55112218e+00 -7.11625509e-01\n   5.05515928e-01]\n [ 3.58668028e-01  1.29905355e+00 -2.08474917e+00 -9.53263854e-01\n   5.67712184e-01]\n [ 4.22442001e-01  1.52358069e+00 -2.41314840e+00 -1.10168123e+00\n   5.99498710e-01]\n [ 4.65051241e-01  1.67644137e+00 -2.63502744e+00 -1.20187458e+00\n   6.19770107e-01]\n [ 4.96158880e-01  1.78971391e+00 -2.79854823e+00 -1.27566922e+00\n   6.34495602e-01]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 11 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-2.40612592e-04  9.45580384e-05 -6.99829575e-04 -3.07657789e-04\n   -8.39554930e-04]\n  [-8.05258391e-05 -9.02360105e-05  1.32902659e-04  2.98470499e-05\n    4.75506905e-04]\n  [ 3.21138431e-04 -4.32202782e-06  5.66926916e-04  2.77810739e-04\n    3.64048025e-04]]\n\n [[-1.51582262e-03  8.97867906e-04 -5.15868228e-03 -2.29197789e-03\n    1.32760305e-04]\n  [-6.06005461e-04 -6.88081376e-04  1.03662844e-03  2.33005125e-04\n    5.15732553e-04]\n  [ 2.12182808e-03 -2.09786530e-04  4.12205384e-03  2.05897277e-03\n   -6.48492858e-04]]\n\n [[-9.61747906e-03  7.32786557e-03 -3.68164016e-02 -1.64258412e-02\n    1.57456715e-01]\n  [-4.66384228e-03 -5.21866069e-03  7.80968492e-03  1.70085718e-03\n    1.11944351e-02]\n  [ 1.42813213e-02 -2.10920488e-03  2.90067167e-02  1.47249840e-02\n   -1.68651150e-01]]\n\n [[-6.79453655e-03  6.88086663e-02 -1.84652098e-01 -8.52774783e-02\n    5.30215159e-01]\n  [-2.89109126e-02 -3.19449882e-02  5.31128845e-02  9.28328016e-03\n    7.93920663e-02]\n  [ 3.57054492e-02 -3.68636781e-02  1.31539213e-01  7.59941981e-02\n   -6.09607225e-01]]\n\n [[ 8.35064445e-02  2.92974927e-01 -5.63031910e-01 -2.61614245e-01\n    8.20064218e-01]\n  [-1.07494025e-01 -7.85417426e-02  2.06419362e-01 -2.18115503e-02\n    3.30245413e-01]\n  [ 2.39875800e-02 -2.14433184e-01  3.56612549e-01  2.83425795e-01\n   -1.15030963e+00]]\n\n [[ 2.62253505e-01  6.81381989e-01 -1.14174445e+00 -5.27854844e-01\n    9.55472275e-01]\n  [-2.11986307e-01  3.54886580e-02  3.98163533e-01 -2.63543861e-01\n    6.59519644e-01]\n  [-5.02671978e-02 -7.16870647e-01  7.43580919e-01  7.91398705e-01\n   -1.61499192e+00]]\n\n [[ 4.31885351e-01  1.03019012e+00 -1.62351464e+00 -7.49624387e-01\n    1.02839993e+00]\n  [-3.04389650e-01  2.56807331e-01  5.10871420e-01 -5.66106578e-01\n    9.43040176e-01]\n  [-1.27495701e-01 -1.28699746e+00  1.11264322e+00  1.31573096e+00\n   -1.97144011e+00]]\n\n [[ 5.64984773e-01  1.29819873e+00 -1.97612427e+00 -9.12669145e-01\n    1.07612408e+00]\n  [-3.78179117e-01  4.85153652e-01  5.65999490e-01 -8.29333312e-01\n    1.16077659e+00]\n  [-1.86805656e-01 -1.78335238e+00  1.41012478e+00  1.74200246e+00\n   -2.23690066e+00]]\n\n [[ 6.67532177e-01  1.50563661e+00 -2.24283369e+00 -1.03631942e+00\n    1.11138414e+00]\n  [-4.39366694e-01  6.80411839e-01  6.02533895e-01 -1.03905549e+00\n    1.32880029e+00]\n  [-2.28165483e-01 -2.18604845e+00  1.64029979e+00  2.07537491e+00\n   -2.44018442e+00]]\n\n [[ 7.48943504e-01  1.67227780e+00 -2.45444688e+00 -1.13458099e+00\n    1.13928435e+00]\n  [-4.91425763e-01  8.42974529e-01  6.31521066e-01 -1.20868688e+00\n    1.46315171e+00]\n  [-2.57517741e-01 -2.51525233e+00  1.82292582e+00  2.34326786e+00\n   -2.60243606e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  9   6 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 1 1 1 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-1.91874949e-04  1.37451847e-04 -6.90813623e-04 -3.01258324e-04\n   -8.42936789e-04]\n  [-8.87732811e-07 -1.57097538e-04  1.42652532e-04 -1.35772292e-05\n    4.71914652e-04]\n  [ 1.92762682e-04  1.96456909e-05  5.48161091e-04  3.14835553e-04\n    3.71022137e-04]]\n\n [[-1.22238085e-03  1.19363105e-03 -5.14765305e-03 -2.25951884e-03\n    2.52466996e-03]\n  [-6.80115949e-06 -1.21411666e-03  1.09899011e-03 -1.07735738e-04\n    4.25232506e-04]\n  [ 1.22918201e-03  2.04856064e-05  4.04866294e-03  2.36725458e-03\n   -2.94990246e-03]]\n\n [[-7.59869667e-03  9.60413074e-03 -3.68482334e-02 -1.61746932e-02\n    1.36681346e-01]\n  [-8.72383151e-05 -9.28806793e-03  8.16961586e-03 -9.87305783e-04\n    2.37038441e-03]\n  [ 7.68593498e-03 -3.16062813e-04  2.86786175e-02  1.71619990e-02\n   -1.39051730e-01]]\n\n [[-3.39515192e-03  8.11521920e-02 -1.88077577e-01 -8.30127557e-02\n    4.54896073e-01]\n  [ 2.81177153e-03 -6.33388585e-02  5.14708337e-02 -1.27357770e-02\n    4.10706760e-02]\n  [ 5.83380391e-04 -1.78133335e-02  1.36606743e-01  9.57485328e-02\n   -4.95966749e-01]]\n\n [[ 6.22867207e-02  3.29907866e-01 -5.64718562e-01 -2.38103180e-01\n    6.94090341e-01]\n  [ 8.14605074e-02 -2.88378152e-01  1.80542393e-01 -1.63066438e-01\n    2.03097485e-01]\n  [-1.43747228e-01 -4.15297149e-02  3.84176169e-01  4.01169617e-01\n   -8.97187826e-01]]\n\n [[ 1.78127183e-01  7.15536055e-01 -1.09453693e+00 -4.49645806e-01\n    7.99171759e-01]\n  [ 3.40356487e-01 -7.02552356e-01  3.46310859e-01 -6.60943273e-01\n    3.90725371e-01]\n  [-5.18483670e-01 -1.29836984e-02  7.48226072e-01  1.11058908e+00\n   -1.18989713e+00]]\n\n [[ 2.70216905e-01  1.00461289e+00 -1.47717057e+00 -6.01416655e-01\n    8.47535099e-01]\n  [ 5.62532175e-01 -1.04011754e+00  4.79775874e-01 -1.15740858e+00\n    5.32861144e-01]\n  [-8.32749080e-01  3.55046510e-02  9.97394693e-01  1.75882524e+00\n   -1.38039624e+00]]\n\n [[ 3.32156256e-01  1.19042611e+00 -1.71737024e+00 -6.96684093e-01\n    8.74124362e-01]\n  [ 7.17494316e-01 -1.27095262e+00  5.73750932e-01 -1.55164492e+00\n    6.38541480e-01]\n  [-1.04965057e+00  8.05265159e-02  1.14361931e+00  2.24832902e+00\n   -1.51266584e+00]]\n\n [[ 3.75574761e-01  1.31817449e+00 -1.88067754e+00 -7.61458137e-01\n    8.91704114e-01]\n  [ 8.28439254e-01 -1.43825042e+00  6.47457280e-01 -1.86094936e+00\n    7.21596841e-01]\n  [-1.20401402e+00  1.20075934e-01  1.23322026e+00  2.62240750e+00\n   -1.61330096e+00]]\n\n [[ 4.08104818e-01  1.41298760e+00 -2.00111493e+00 -8.09224646e-01\n    9.04711383e-01]\n  [ 9.12337457e-01 -1.56807197e+00  7.08556088e-01 -2.11258270e+00\n    7.90006217e-01]\n  [-1.32044228e+00  1.55084364e-01  1.29255884e+00  2.92180734e+00\n   -1.69471760e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  9  24 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]]", "y": "[0 0 0 0 1 1 1 1 2 2 2 2]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-2.91847466e-04  1.42227477e-04 -9.01462527e-04 -4.10365735e-04\n    6.65559062e-04]\n  [-2.84944298e-05 -1.50755645e-04  1.52958247e-04  3.75925097e-05\n   -2.05126439e-03]\n  [ 3.20341895e-04  8.52816827e-06  7.48504280e-04  3.72773226e-04\n    1.38570533e-03]]\n\n [[-1.87628905e-03  1.28073214e-03 -6.67702072e-03 -3.06910398e-03\n    1.28132813e-02]\n  [-2.31824254e-04 -1.17006377e-03  1.16959780e-03  2.85057763e-04\n   -1.18526608e-03]\n  [ 2.10811330e-03 -1.10668372e-04  5.50742293e-03  2.78404622e-03\n   -1.16280152e-02]]\n\n [[-1.22331687e-02  1.00251267e-02 -4.72392433e-02 -2.17649922e-02\n    2.17789284e-01]\n  [-2.03236913e-03 -9.00570816e-03  8.47126458e-03  1.94739378e-03\n    7.62345943e-03]\n  [ 1.42655378e-02 -1.01941853e-03  3.87679788e-02  1.98175984e-02\n   -2.25412744e-01]]\n\n [[-9.33039841e-03  8.88995945e-02 -2.22560217e-01 -1.06287915e-01\n    6.37408761e-01]\n  [-9.26383511e-03 -5.78558756e-02  5.13935938e-02  7.85808050e-03\n    7.89554337e-02]\n  [ 1.85942335e-02 -3.10437188e-02  1.71166623e-01  9.84298345e-02\n   -7.16364195e-01]]\n\n [[ 7.10032568e-02  3.58211345e-01 -6.34473038e-01 -3.02909740e-01\n    9.29765004e-01]\n  [ 2.09535585e-02 -2.10851115e-01  1.49502964e-01 -4.48020249e-02\n    3.30206190e-01]\n  [-9.19568154e-02 -1.47360230e-01  4.84970075e-01  3.47711765e-01\n   -1.25997119e+00]]\n\n [[ 2.47909340e-01  8.42617324e-01 -1.28231298e+00 -6.10290548e-01\n    1.07364029e+00]\n  [ 1.52470258e-01 -3.12734328e-01  1.79318571e-01 -2.83920715e-01\n    6.32960949e-01]\n  [-4.00379597e-01 -5.29882996e-01  1.10299441e+00  8.94211263e-01\n   -1.70660124e+00]]\n\n [[ 4.11775297e-01  1.25930707e+00 -1.81121703e+00 -8.61851429e-01\n    1.15314266e+00]\n  [ 2.20009166e-01 -2.53687550e-01  1.67326545e-01 -5.19077681e-01\n    8.87512736e-01]\n  [-6.31784463e-01 -1.00561952e+00  1.64389049e+00  1.38092911e+00\n   -2.04065540e+00]]\n\n [[ 5.33161547e-01  1.55854604e+00 -2.18126388e+00 -1.03826709e+00\n    1.20354370e+00]\n  [ 2.26375558e-01 -1.24069710e-01  1.56152165e-01 -7.10999081e-01\n    1.09184589e+00]\n  [-7.59537105e-01 -1.43447633e+00  2.02511171e+00  1.74926618e+00\n   -2.29538959e+00]]\n\n [[ 6.23592767e-01  1.77982650e+00 -2.45176565e+00 -1.16731371e+00\n    1.23985478e+00]\n  [ 2.03194707e-01  1.07096055e-02  1.60342978e-01 -8.72528471e-01\n    1.26107197e+00]\n  [-8.26787473e-01 -1.79053611e+00  2.29142267e+00  2.03984218e+00\n   -2.50092675e+00]]\n\n [[ 6.93985762e-01  1.95272632e+00 -2.66216042e+00 -1.26764876e+00\n    1.26823155e+00]\n  [ 1.67942263e-01  1.35290107e-01  1.76293983e-01 -1.01595045e+00\n    1.40686060e+00]\n  [-8.61928025e-01 -2.08801643e+00  2.48586644e+00  2.28359921e+00\n   -2.67509214e+00]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[  9  43 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[0 0 0 0 0 1 1 1 1 1 2 2 2 2 2]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[[ 0.07226547  0.32703138 -0.58740784 -0.26754239  0.81463985]\n [-0.00169332 -0.19259034  0.17882157 -0.07656     0.2878497 ]\n [-0.07057215 -0.13444104  0.40858626  0.34410239 -1.10248955]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 0.07109017  0.38611786 -0.70172143 -0.31530835  1.09154044]\n  [-0.01351698 -0.24542311  0.19987289 -0.12388254  0.60620609]\n  [-0.05757318 -0.14069474  0.50184854  0.43919089 -1.69774653]]]", "[0.35938137]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-1.08183173e-03 -3.47219043e-04 -1.32783085e-03 -5.49378680e-04\n   -3.10888790e-02]]\n\n [[-4.46956256e-03 -6.94885395e-04 -7.51642208e-03 -3.28096700e-03\n   -1.66511877e-01]]\n\n [[-1.38871327e-02  4.28528289e-03 -4.11011163e-02 -1.90038640e-02\n   -9.38691021e-02]]\n\n [[-1.11761334e-02  5.48555785e-02 -1.74879545e-01 -8.49324671e-02\n    2.75499917e-01]]\n\n [[ 5.79716490e-02  2.07640024e-01 -4.51419039e-01 -2.22040703e-01\n    5.32212412e-01]]\n\n [[ 1.63129966e-01  4.13186719e-01 -7.99929201e-01 -3.89869493e-01\n    6.33346731e-01]]\n\n [[ 2.37328622e-01  5.57889582e-01 -1.04604347e+00 -5.05723045e-01\n    6.74244335e-01]]\n\n [[ 2.82396501e-01  6.45657199e-01 -1.19543397e+00 -5.74831321e-01\n    6.94281014e-01]]\n\n [[ 3.12585885e-01  7.04560925e-01 -1.29591039e+00 -6.20770929e-01\n    7.06773211e-01]]\n\n [[ 3.34816339e-01  7.47869390e-01 -1.36976348e+00 -6.54255483e-01\n    7.15753500e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 75 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-1.23272870e-03 -3.52502894e-04 -1.36167636e-03 -5.14234251e-04\n   -5.63820673e-02]]\n\n [[-4.43313934e-03 -1.44057260e-04 -7.20649842e-03 -2.87779707e-03\n   -2.40289985e-01]]\n\n [[-1.23951795e-02  8.99159260e-03 -3.93049988e-02 -1.65152408e-02\n   -2.12821787e-01]]\n\n [[-1.19372100e-02  7.90831178e-02 -1.77747735e-01 -7.64140768e-02\n    7.57254755e-02]]\n\n [[ 3.18455490e-02  2.80866887e-01 -4.78127669e-01 -1.99947562e-01\n    2.54824626e-01]]\n\n [[ 8.87070490e-02  5.49446714e-01 -8.59368032e-01 -3.51249174e-01\n    3.17775736e-01]]\n\n [[ 1.26285692e-01  7.37770171e-01 -1.12587957e+00 -4.55902676e-01\n    3.41412899e-01]]\n\n [[ 1.48238968e-01  8.51248295e-01 -1.28552266e+00 -5.18121551e-01\n    3.52441369e-01]]\n\n [[ 1.62671269e-01  9.27091638e-01 -1.39178619e+00 -5.59348234e-01\n    3.59137164e-01]]\n\n [[ 1.73086264e-01  9.82612208e-01 -1.46935799e+00 -5.89338012e-01\n    3.63849313e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"Cs": "int", "l1_ratio": "null value in the ground truth", "fit_intercept": "bool", "solver": "str", "max_iter": "int", "class_weight": "null value in the ground truth", "pos_class": "null value in the ground truth", "multi_class": "str", "tol": "float", "verbose": "int", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]]", "y": "[1 1 1 1 0 0 0 0 0 0 0]"}, "kwargs": {"Cs": 10, "l1_ratio": null, "fit_intercept": true, "solver": "saga", "max_iter": 100, "class_weight": null, "pos_class": null, "multi_class": "multinomial", "tol": 0.0001, "verbose": 0, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null}}, "return": ["[[[-8.74204199e-04 -2.15758634e-04 -1.19487036e-03 -4.75836249e-04\n   -4.56160855e-02]]\n\n [[-2.92933532e-03  3.78589476e-04 -6.82314317e-03 -2.92768743e-03\n   -1.74982325e-01]]\n\n [[-9.32350666e-03  9.23839084e-03 -4.17351884e-02 -1.86860477e-02\n   -9.87985977e-02]]\n\n [[-4.07046444e-03  7.88252635e-02 -1.94605895e-01 -8.90259458e-02\n    1.98413794e-01]]\n\n [[ 5.07064668e-02  2.86424368e-01 -5.24437955e-01 -2.37327498e-01\n    3.96907265e-01]]\n\n [[ 1.29141391e-01  5.65923126e-01 -9.38854417e-01 -4.23463388e-01\n    4.74877757e-01]]\n\n [[ 1.83469089e-01  7.63517007e-01 -1.22730763e+00 -5.53037723e-01\n    5.06962583e-01]]\n\n [[ 2.15840981e-01  8.83363794e-01 -1.40033132e+00 -6.30776061e-01\n    5.22890942e-01]]\n\n [[ 2.37318827e-01  9.63874805e-01 -1.51574081e+00 -6.82646143e-01\n    5.32916097e-01]]\n\n [[ 2.52917671e-01  1.02302924e+00 -1.60012128e+00 -7.20573930e-01\n    5.40145726e-01]]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[100 100 100 100 100 100 100 100 100 100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "np.ndarray[float64]", "y": "np.ndarray[int64]"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "null value in the ground truth", "solver": "str", "fit_intercept": "bool", "coef": "np.ndarray[float64]", "max_iter": "int", "tol": "float", "penalty": "str", "class_weight": "null value in the ground truth", "multi_class": "str", "verbose": "int", "random_state": "int", "check_input": "bool", "max_squared_sum": "float", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'list of 1 float', 'list of 1 int']"}, "values": {"inputs": {"self": {}, "args": {"X": "[[5.1 3.5 1.4 0.2]\n [5.4 3.7 1.5 0.2]\n [5.4 3.4 1.7 0.2]\n [4.8 3.1 1.6 0.2]\n [5.  3.5 1.3 0.3]\n [7.  3.2 4.7 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.2 4.8 1.8]\n [5.5 2.4 3.8 1.1]\n [5.5 2.6 4.4 1.2]\n [6.3 3.3 6.  2.5]\n [6.5 3.2 5.1 2. ]\n [6.9 3.2 5.7 2.3]\n [7.4 2.8 6.1 1.9]\n [6.7 3.1 5.6 2.4]]", "y": "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]"}, "kwargs": {"pos_class": null, "Cs": null, "solver": "saga", "fit_intercept": true, "coef": "[[ 0.04684122  0.25831043 -0.48466155 -0.21977192  0.3946481 ]]", "max_iter": 100, "tol": 0.0001, "penalty": "l2", "class_weight": null, "multi_class": "multinomial", "verbose": 0, "random_state": 0, "check_input": false, "max_squared_sum": 103.41999999999999, "sample_weight": null, "l1_ratio": null}}, "return": ["[[[ 0.03692373  0.29748725 -0.56247308 -0.24920568  0.58688504]]]", "[0.35938137]", "[100]"]}, "name": "_logistic_regression_path"}
{"types": {"inputs": {"self": "in ground truth values, it is an empty dict", "args": {"X": "null value in the ground truth", "y": "null value in the ground truth"}, "kwargs": {"pos_class": "null value in the ground truth", "Cs": "int", "fit_intercept": "bool", "max_iter": "int", "tol": "float", "verbose": "int", "solver": "str", "coef": "null value in the ground truth", "class_weight": "null value in the ground truth", "dual": "bool", "penalty": "str", "intercept_scaling": "float", "multi_class": "str", "random_state": "null value in the ground truth", "check_input": "bool", "max_squared_sum": "null value in the ground truth", "sample_weight": "null value in the ground truth", "l1_ratio": "null value in the ground truth"}}, "return": "list of different types containing 3 elements ['np.ndarray[float64]', 'np.ndarray[int64]']"}, "values": {"inputs": {"self": {}, "args": {"X": null, "y": null}, "kwargs": {"pos_class": null, "Cs": 10, "fit_intercept": true, "max_iter": 100, "tol": 0.0001, "verbose": 0, "solver": "lbfgs", "coef": null, "class_weight": null, "dual": false, "penalty": "l2", "intercept_scaling": 1.0, "multi_class": "auto", "random_state": null, "check_input": true, "max_squared_sum": null, "sample_weight": null, "l1_ratio": null}}, "return": ["[[9.99940743e-05 6.66634570e-05 6.93095286e-01]\n [7.73908644e-04 5.15883043e-04 6.93095140e-01]\n [5.97356532e-03 3.98504644e-03 6.90498049e-01]\n [4.51671773e-02 3.02687696e-02 6.73424246e-01]\n [2.95983771e-01 2.04524184e-01 5.74225205e-01]\n [1.12097980e+00 8.77074031e-01 3.44806594e-01]\n [2.35347574e+00 2.15233402e+00 1.55483664e-01]\n [3.82525110e+00 3.74456710e+00 5.19154080e-02]\n [5.50292505e+00 5.42808873e+00 3.97553292e-02]\n [7.20636667e+00 7.15038386e+00 4.25598847e-02]]", "[1.00000000e-04 7.74263683e-04 5.99484250e-03 4.64158883e-02\n 3.59381366e-01 2.78255940e+00 2.15443469e+01 1.66810054e+02\n 1.29154967e+03 1.00000000e+04]", "[ 6  2  7  6  5  6  8 10  6  4]"]}, "name": "_logistic_regression_path"}

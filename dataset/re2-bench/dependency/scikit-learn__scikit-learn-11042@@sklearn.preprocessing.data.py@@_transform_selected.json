{
    ".sklearn.utils.validation.py@@check_array": "def check_array(array, accept_sparse=False, dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None):\n    if accept_sparse is None:\n        warnings.warn(\"Passing 'None' to parameter 'accept_sparse' in methods check_array and check_X_y is deprecated in version 0.19 and will be removed in 0.21. Use 'accept_sparse=False'  instead.\", DeprecationWarning)\n        accept_sparse = False\n    array_orig = array\n    dtype_numeric = isinstance(dtype, six.string_types) and dtype == 'numeric'\n    dtype_orig = getattr(array, 'dtype', None)\n    if not hasattr(dtype_orig, 'kind'):\n        dtype_orig = None\n    if dtype_numeric:\n        if dtype_orig is not None and dtype_orig.kind == 'O':\n            dtype = np.float64\n        else:\n            dtype = None\n    if isinstance(dtype, (list, tuple)):\n        if dtype_orig is not None and dtype_orig in dtype:\n            dtype = None\n        else:\n            dtype = dtype[0]\n    if force_all_finite not in (True, False, 'allow-nan'):\n        raise ValueError('force_all_finite should be a bool or \"allow-nan\". Got {!r} instead'.format(force_all_finite))\n    if estimator is not None:\n        if isinstance(estimator, six.string_types):\n            estimator_name = estimator\n        else:\n            estimator_name = estimator.__class__.__name__\n    else:\n        estimator_name = 'Estimator'\n    context = ' by %s' % estimator_name if estimator is not None else ''\n    if sp.issparse(array):\n        _ensure_no_complex_data(array)\n        array = _ensure_sparse_format(array, accept_sparse, dtype, copy, force_all_finite)\n    else:\n        with warnings.catch_warnings():\n            try:\n                warnings.simplefilter('error', ComplexWarning)\n                array = np.asarray(array, dtype=dtype, order=order)\n            except ComplexWarning:\n                raise ValueError('Complex data not supported\\n{}\\n'.format(array))\n        _ensure_no_complex_data(array)\n        if ensure_2d:\n            if array.ndim == 0:\n                raise ValueError('Expected 2D array, got scalar array instead:\\narray={}.\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'.format(array))\n            if array.ndim == 1:\n                raise ValueError('Expected 2D array, got 1D array instead:\\narray={}.\\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.'.format(array))\n        if dtype_numeric and np.issubdtype(array.dtype, np.flexible):\n            warnings.warn(\"Beginning in version 0.22, arrays of strings will be interpreted as decimal numbers if parameter 'dtype' is 'numeric'. It is recommended that you convert the array to type np.float64 before passing it to check_array.\", FutureWarning)\n        if dtype_numeric and array.dtype.kind == 'O':\n            array = array.astype(np.float64)\n        if not allow_nd and array.ndim >= 3:\n            raise ValueError('Found array with dim %d. %s expected <= 2.' % (array.ndim, estimator_name))\n        if force_all_finite:\n            _assert_all_finite(array, allow_nan=force_all_finite == 'allow-nan')\n    shape_repr = _shape_repr(array.shape)\n    if ensure_min_samples > 0:\n        n_samples = _num_samples(array)\n        if n_samples < ensure_min_samples:\n            raise ValueError('Found array with %d sample(s) (shape=%s) while a minimum of %d is required%s.' % (n_samples, shape_repr, ensure_min_samples, context))\n    if ensure_min_features > 0 and array.ndim == 2:\n        n_features = array.shape[1]\n        if n_features < ensure_min_features:\n            raise ValueError('Found array with %d feature(s) (shape=%s) while a minimum of %d is required%s.' % (n_features, shape_repr, ensure_min_features, context))\n    if warn_on_dtype and dtype_orig is not None and (array.dtype != dtype_orig):\n        msg = 'Data with input dtype %s was converted to %s%s.' % (dtype_orig, array.dtype, context)\n        warnings.warn(msg, DataConversionWarning)\n    if copy and np.may_share_memory(array, array_orig):\n        array = np.array(array, dtype=dtype, order=order)\n    return array",
    ".sklearn.utils.validation.py@@_ensure_no_complex_data": "def _ensure_no_complex_data(array):\n    if hasattr(array, 'dtype') and array.dtype is not None and hasattr(array.dtype, 'kind') and (array.dtype.kind == 'c'):\n        raise ValueError('Complex data not supported\\n{}\\n'.format(array))",
    ".sklearn.utils.validation.py@@_assert_all_finite": "def _assert_all_finite(X, allow_nan=False):\n    if _get_config()['assume_finite']:\n        return\n    X = np.asanyarray(X)\n    is_float = X.dtype.kind in 'fc'\n    if is_float and np.isfinite(X.sum()):\n        pass\n    elif is_float:\n        msg_err = 'Input contains {} or a value too large for {!r}.'\n        if allow_nan and np.isinf(X).any() or (not allow_nan and (not np.isfinite(X).all())):\n            type_err = 'infinity' if allow_nan else 'NaN, infinity'\n            raise ValueError(msg_err.format(type_err, X.dtype))",
    ".sklearn._config.py@@get_config": "def get_config():\n    return _global_config.copy()",
    ".sklearn.utils.validation.py@@_shape_repr": "def _shape_repr(shape):\n    if len(shape) == 0:\n        return '()'\n    joined = ', '.join(('%d' % e for e in shape))\n    if len(shape) == 1:\n        joined += ','\n    return '(%s)' % joined",
    ".sklearn.utils.validation.py@@_num_samples": "def _num_samples(x):\n    if hasattr(x, 'fit') and callable(x.fit):\n        raise TypeError('Expected sequence or array-like, got estimator %s' % x)\n    if not hasattr(x, '__len__') and (not hasattr(x, 'shape')):\n        if hasattr(x, '__array__'):\n            x = np.asarray(x)\n        else:\n            raise TypeError('Expected sequence or array-like, got %s' % type(x))\n    if hasattr(x, 'shape'):\n        if len(x.shape) == 0:\n            raise TypeError('Singleton array %r cannot be considered a valid collection.' % x)\n        return x.shape[0]\n    else:\n        return len(x)",
    ".sklearn.preprocessing.data.py@@Binarizer.transform": "def transform(self, X, y='deprecated', copy=None):\n    if not isinstance(y, string_types) or y != 'deprecated':\n        warnings.warn('The parameter y on transform() is deprecated since 0.19 and will be removed in 0.21', DeprecationWarning)\n    copy = copy if copy is not None else self.copy\n    return binarize(X, threshold=self.threshold, copy=copy)",
    ".sklearn.preprocessing.data.py@@binarize": "def binarize(X, threshold=0.0, copy=True):\n    X = check_array(X, accept_sparse=['csr', 'csc'], copy=copy)\n    if sparse.issparse(X):\n        if threshold < 0:\n            raise ValueError('Cannot binarize a sparse matrix with threshold < 0')\n        cond = X.data > threshold\n        not_cond = np.logical_not(cond)\n        X.data[cond] = 1\n        X.data[not_cond] = 0\n        X.eliminate_zeros()\n    else:\n        cond = X > threshold\n        not_cond = np.logical_not(cond)\n        X[cond] = 1\n        X[not_cond] = 0\n    return X",
    ".sklearn.utils.validation.py@@_ensure_sparse_format": "def _ensure_sparse_format(spmatrix, accept_sparse, dtype, copy, force_all_finite):\n    if dtype is None:\n        dtype = spmatrix.dtype\n    changed_format = False\n    if isinstance(accept_sparse, six.string_types):\n        accept_sparse = [accept_sparse]\n    if accept_sparse is False:\n        raise TypeError('A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.')\n    elif isinstance(accept_sparse, (list, tuple)):\n        if len(accept_sparse) == 0:\n            raise ValueError(\"When providing 'accept_sparse' as a tuple or list, it must contain at least one string value.\")\n        if spmatrix.format not in accept_sparse:\n            spmatrix = spmatrix.asformat(accept_sparse[0])\n            changed_format = True\n    elif accept_sparse is not True:\n        raise ValueError(\"Parameter 'accept_sparse' should be a string, boolean or list of strings. You provided 'accept_sparse={}'.\".format(accept_sparse))\n    if dtype != spmatrix.dtype:\n        spmatrix = spmatrix.astype(dtype)\n    elif copy and (not changed_format):\n        spmatrix = spmatrix.copy()\n    if force_all_finite:\n        if not hasattr(spmatrix, 'data'):\n            warnings.warn(\"Can't check %s sparse matrix for nan or inf.\" % spmatrix.format)\n        else:\n            _assert_all_finite(spmatrix.data, allow_nan=force_all_finite == 'allow-nan')\n    return spmatrix",
    ".sklearn.preprocessing.data.py@@OneHotEncoder._fit_transform": "def _fit_transform(self, X):\n    X = check_array(X, dtype=np.int)\n    if np.any(X < 0):\n        raise ValueError('X needs to contain only non-negative integers.')\n    n_samples, n_features = X.shape\n    if isinstance(self.n_values, six.string_types) and self.n_values == 'auto':\n        n_values = np.max(X, axis=0) + 1\n    elif isinstance(self.n_values, numbers.Integral):\n        if (np.max(X, axis=0) >= self.n_values).any():\n            raise ValueError('Feature out of bounds for n_values=%d' % self.n_values)\n        n_values = np.empty(n_features, dtype=np.int)\n        n_values.fill(self.n_values)\n    else:\n        try:\n            n_values = np.asarray(self.n_values, dtype=int)\n        except (ValueError, TypeError):\n            raise TypeError(\"Wrong type for parameter `n_values`. Expected 'auto', int or array of ints, got %r\" % type(X))\n        if n_values.ndim < 1 or n_values.shape[0] != X.shape[1]:\n            raise ValueError('Shape mismatch: if n_values is an array, it has to be of shape (n_features,).')\n    self.n_values_ = n_values\n    n_values = np.hstack([[0], n_values])\n    indices = np.cumsum(n_values)\n    self.feature_indices_ = indices\n    column_indices = (X + indices[:-1]).ravel()\n    row_indices = np.repeat(np.arange(n_samples, dtype=np.int32), n_features)\n    data = np.ones(n_samples * n_features)\n    out = sparse.coo_matrix((data, (row_indices, column_indices)), shape=(n_samples, indices[-1]), dtype=self.dtype).tocsr()\n    if isinstance(self.n_values, six.string_types) and self.n_values == 'auto':\n        mask = np.array(out.sum(axis=0)).ravel() != 0\n        active_features = np.where(mask)[0]\n        out = out[:, active_features]\n        self.active_features_ = active_features\n    return out if self.sparse else out.toarray()",
    ".sklearn.preprocessing.data.py@@OneHotEncoder._transform": "def _transform(self, X):\n    X = check_array(X, dtype=np.int)\n    if np.any(X < 0):\n        raise ValueError('X needs to contain only non-negative integers.')\n    n_samples, n_features = X.shape\n    indices = self.feature_indices_\n    if n_features != indices.shape[0] - 1:\n        raise ValueError('X has different shape than during fitting. Expected %d, got %d.' % (indices.shape[0] - 1, n_features))\n    mask = (X < self.n_values_).ravel()\n    if np.any(~mask):\n        if self.handle_unknown not in ['error', 'ignore']:\n            raise ValueError('handle_unknown should be either error or unknown got %s' % self.handle_unknown)\n        if self.handle_unknown == 'error':\n            raise ValueError('unknown categorical feature present %s during transform.' % X.ravel()[~mask])\n    column_indices = (X + indices[:-1]).ravel()[mask]\n    row_indices = np.repeat(np.arange(n_samples, dtype=np.int32), n_features)[mask]\n    data = np.ones(np.sum(mask))\n    out = sparse.coo_matrix((data, (row_indices, column_indices)), shape=(n_samples, indices[-1]), dtype=self.dtype).tocsr()\n    if isinstance(self.n_values, six.string_types) and self.n_values == 'auto':\n        out = out[:, self.active_features_]\n    return out if self.sparse else out.toarray()"
}
{
    ".xarray.core.merge.py@@_assert_compat_valid": "def _assert_compat_valid(compat):\n    if compat not in _VALID_COMPAT:\n        raise ValueError('compat=%r invalid: must be %s' % (compat, set(_VALID_COMPAT)))",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.merge.py@@OrderedDefaultDict.__init__": "def __init__(self, default_factory):\n    self.default_factory = default_factory\n    super().__init__()",
    ".xarray.core.merge.py@@OrderedDefaultDict.__missing__": "def __missing__(self, key):\n    self[key] = default = self.default_factory()\n    return default",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self):\n    return self._dims",
    ".xarray.core.merge.py@@unique_variable": "def unique_variable(name, variables, compat='broadcast_equals', equals=None):\n    out = variables[0]\n    if len(variables) == 1 or compat == 'override':\n        return out\n    combine_method = None\n    if compat == 'minimal':\n        compat = 'broadcast_equals'\n    if compat == 'broadcast_equals':\n        dim_lengths = broadcast_dimension_size(variables)\n        out = out.set_dims(dim_lengths)\n    if compat == 'no_conflicts':\n        combine_method = 'fillna'\n    if equals is None:\n        out = out.compute()\n        for var in variables[1:]:\n            equals = getattr(out, compat)(var)\n            if not equals:\n                break\n    if not equals:\n        raise MergeError(\"conflicting values for variable %r on objects to be combined. You can skip this check by specifying compat='override'.\" % name)\n    if combine_method:\n        for var in variables[1:]:\n            out = getattr(out, combine_method)(var)\n    return out",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.variable.py@@Variable.compute": "def compute(self, **kwargs):\n    new = self.copy(deep=False)\n    return new.load(**kwargs)",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data\n        if isinstance(data, indexing.MemoryCachedArray):\n            data = indexing.MemoryCachedArray(data.array)\n        if deep:\n            if hasattr(data, '__array_function__') or isinstance(data, dask_array_type):\n                data = data.copy()\n            elif not isinstance(data, PandasIndexAdapter):\n                data = np.array(data)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, Variable):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    data = getattr(data, 'values', data)\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, '__array_function__'):\n            if IS_NEP18_ACTIVE:\n                return data\n            else:\n                raise TypeError('Got an NumPy-like array type providing the __array_function__ protocol but NEP18 is not enabled. Check that numpy >= v1.16 and that the environment variable \"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\" is set to \"1\"')\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == 'O':\n            data = _possibly_convert_objects(data)\n        elif data.dtype.kind == 'M':\n            data = np.asarray(data, 'datetime64[ns]')\n        elif data.dtype.kind == 'm':\n            data = np.asarray(data, 'timedelta64[ns]')\n    return _maybe_wrap_data(data)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims):\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError('dimensions %s must have the same length as the number of data dimensions, ndim=%s' % (dims, self.ndim))\n    return dims",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.variable.py@@Variable.load": "def load(self, **kwargs):\n    if isinstance(self._data, dask_array_type):\n        self._data = as_compatible_data(self._data.compute(**kwargs))\n    elif not hasattr(self._data, '__array_function__'):\n        self._data = np.asarray(self._data)\n    return self",
    ".xarray.core.variable.py@@Variable.no_conflicts": "def no_conflicts(self, other):\n    return self.broadcast_equals(other, equiv=duck_array_ops.array_notnull_equiv)",
    ".xarray.core.variable.py@@Variable.broadcast_equals": "def broadcast_equals(self, other, equiv=duck_array_ops.array_equiv):\n    try:\n        self, other = broadcast_variables(self, other)\n    except (ValueError, AttributeError):\n        return False\n    return self.equals(other, equiv=equiv)",
    ".xarray.core.variable.py@@broadcast_variables": "def broadcast_variables(*variables):\n    dims_map = _unified_dims(variables)\n    dims_tuple = tuple(dims_map)\n    return tuple((var.set_dims(dims_map) if var.dims != dims_tuple else var for var in variables))",
    ".xarray.core.variable.py@@_unified_dims": "def _unified_dims(variables):\n    all_dims = OrderedDict()\n    for var in variables:\n        var_dims = var.dims\n        if len(set(var_dims)) < len(var_dims):\n            raise ValueError('broadcasting cannot handle duplicate dimensions: %r' % list(var_dims))\n        for d, s in zip(var_dims, var.shape):\n            if d not in all_dims:\n                all_dims[d] = s\n            elif all_dims[d] != s:\n                raise ValueError('operands cannot be broadcast together with mismatched lengths for dimension %r: %s' % (d, (all_dims[d], s)))\n    return all_dims",
    ".xarray.core.variable.py@@Variable.equals": "def equals(self, other, equiv=duck_array_ops.array_equiv):\n    other = getattr(other, 'variable', other)\n    try:\n        return self.dims == other.dims and (self._data is other._data or equiv(self.data, other.data))\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.variable.py@@Variable.fillna": "def fillna(self, value):\n    return ops.fillna(self, value)",
    ".xarray.core.ops.py@@fillna": "def fillna(data, other, join='left', dataset_join='left'):\n    from .computation import apply_ufunc\n    return apply_ufunc(duck_array_ops.fillna, data, other, join=join, dask='allowed', dataset_join=dataset_join, dataset_fill_value=np.nan, keep_attrs=True)",
    ".xarray.core.computation.py@@apply_ufunc": "def apply_ufunc(func: Callable, *args: Any, input_core_dims: Sequence[Sequence]=None, output_core_dims: Optional[Sequence[Sequence]]=((),), exclude_dims: AbstractSet=frozenset(), vectorize: bool=False, join: str='exact', dataset_join: str='exact', dataset_fill_value: object=_NO_FILL_VALUE, keep_attrs: bool=False, kwargs: Mapping=None, dask: str='forbidden', output_dtypes: Sequence=None, output_sizes: Mapping[Any, int]=None) -> Any:\n    from .groupby import GroupBy\n    from .dataarray import DataArray\n    from .variable import Variable\n    if input_core_dims is None:\n        input_core_dims = ((),) * len(args)\n    elif len(input_core_dims) != len(args):\n        raise ValueError('input_core_dims must be None or a tuple with the length same to the number of arguments. Given input_core_dims: {}, number of args: {}.'.format(input_core_dims, len(args)))\n    if kwargs is None:\n        kwargs = {}\n    signature = _UFuncSignature(input_core_dims, output_core_dims)\n    if exclude_dims and (not exclude_dims <= signature.all_core_dims):\n        raise ValueError('each dimension in `exclude_dims` must also be a core dimension in the function signature')\n    if kwargs:\n        func = functools.partial(func, **kwargs)\n    if vectorize:\n        if signature.all_core_dims:\n            if LooseVersion(np.__version__) < '1.12':\n                raise NotImplementedError('numpy 1.12 or newer required when using vectorize=True in xarray.apply_ufunc with non-scalar output core dimensions.')\n            func = np.vectorize(func, otypes=output_dtypes, signature=signature.to_gufunc_string())\n        else:\n            func = np.vectorize(func, otypes=output_dtypes)\n    variables_vfunc = functools.partial(apply_variable_ufunc, func, signature=signature, exclude_dims=exclude_dims, keep_attrs=keep_attrs, dask=dask, output_dtypes=output_dtypes, output_sizes=output_sizes)\n    if any((isinstance(a, GroupBy) for a in args)):\n        this_apply = functools.partial(apply_ufunc, func, input_core_dims=input_core_dims, output_core_dims=output_core_dims, exclude_dims=exclude_dims, join=join, dataset_join=dataset_join, dataset_fill_value=dataset_fill_value, keep_attrs=keep_attrs, dask=dask)\n        return apply_groupby_func(this_apply, *args)\n    elif any((is_dict_like(a) for a in args)):\n        return apply_dataset_vfunc(variables_vfunc, *args, signature=signature, join=join, exclude_dims=exclude_dims, dataset_join=dataset_join, fill_value=dataset_fill_value, keep_attrs=keep_attrs)\n    elif any((isinstance(a, DataArray) for a in args)):\n        return apply_dataarray_vfunc(variables_vfunc, *args, signature=signature, join=join, exclude_dims=exclude_dims, keep_attrs=keep_attrs)\n    elif any((isinstance(a, Variable) for a in args)):\n        return variables_vfunc(*args)\n    else:\n        return apply_array_ufunc(func, *args, dask=dask)",
    ".xarray.core.computation.py@@_UFuncSignature.__init__": "def __init__(self, input_core_dims, output_core_dims=((),)):\n    self.input_core_dims = tuple((tuple(a) for a in input_core_dims))\n    self.output_core_dims = tuple((tuple(a) for a in output_core_dims))\n    self._all_input_core_dims = None\n    self._all_output_core_dims = None\n    self._all_core_dims = None",
    ".xarray.core.utils.py@@is_dict_like": "def is_dict_like(value: Any) -> bool:\n    return hasattr(value, 'keys') and hasattr(value, '__getitem__')",
    ".xarray.core.computation.py@@apply_variable_ufunc": "def apply_variable_ufunc(func, *args, signature, exclude_dims=frozenset(), dask='forbidden', output_dtypes=None, output_sizes=None, keep_attrs=False):\n    from .variable import Variable, as_compatible_data\n    dim_sizes = unified_dim_sizes((a for a in args if hasattr(a, 'dims')), exclude_dims=exclude_dims)\n    broadcast_dims = tuple((dim for dim in dim_sizes if dim not in signature.all_core_dims))\n    output_dims = [broadcast_dims + out for out in signature.output_core_dims]\n    input_data = [broadcast_compat_data(arg, broadcast_dims, core_dims) if isinstance(arg, Variable) else arg for arg, core_dims in zip(args, signature.input_core_dims)]\n    if any((isinstance(array, dask_array_type) for array in input_data)):\n        if dask == 'forbidden':\n            raise ValueError('apply_ufunc encountered a dask array on an argument, but handling for dask arrays has not been enabled. Either set the ``dask`` argument or load your data into memory first with ``.load()`` or ``.compute()``')\n        elif dask == 'parallelized':\n            input_dims = [broadcast_dims + dims for dims in signature.input_core_dims]\n            numpy_func = func\n\n            def func(*arrays):\n                return _apply_blockwise(numpy_func, arrays, input_dims, output_dims, signature, output_dtypes, output_sizes)\n        elif dask == 'allowed':\n            pass\n        else:\n            raise ValueError('unknown setting for dask array handling in apply_ufunc: {}'.format(dask))\n    result_data = func(*input_data)\n    if signature.num_outputs == 1:\n        result_data = (result_data,)\n    elif not isinstance(result_data, tuple) or len(result_data) != signature.num_outputs:\n        raise ValueError('applied function does not have the number of outputs specified in the ufunc signature. Result is not a tuple of {} elements: {!r}'.format(signature.num_outputs, result_data))\n    output = []\n    for dims, data in zip(output_dims, result_data):\n        data = as_compatible_data(data)\n        if data.ndim != len(dims):\n            raise ValueError('applied function returned data with unexpected number of dimensions: {} vs {}, for dimensions {}'.format(data.ndim, len(dims), dims))\n        var = Variable(dims, data, fastpath=True)\n        for dim, new_size in var.sizes.items():\n            if dim in dim_sizes and new_size != dim_sizes[dim]:\n                raise ValueError('size of dimension {!r} on inputs was unexpectedly changed by applied function from {} to {}. Only dimensions specified in ``exclude_dims`` with xarray.apply_ufunc are allowed to change size.'.format(dim, dim_sizes[dim], new_size))\n        if keep_attrs and isinstance(args[0], Variable):\n            var.attrs.update(args[0].attrs)\n        output.append(var)\n    if signature.num_outputs == 1:\n        return output[0]\n    else:\n        return tuple(output)",
    ".xarray.core.computation.py@@unified_dim_sizes": "def unified_dim_sizes(variables: Iterable[Variable], exclude_dims: AbstractSet=frozenset()) -> 'OrderedDict[Any, int]':\n    dim_sizes = OrderedDict()\n    for var in variables:\n        if len(set(var.dims)) < len(var.dims):\n            raise ValueError('broadcasting cannot handle duplicate dimensions on a variable: %r' % list(var.dims))\n        for dim, size in zip(var.dims, var.shape):\n            if dim not in exclude_dims:\n                if dim not in dim_sizes:\n                    dim_sizes[dim] = size\n                elif dim_sizes[dim] != size:\n                    raise ValueError('operands cannot be broadcast together with mismatched lengths for dimension %r: %s vs %s' % (dim, dim_sizes[dim], size))\n    return dim_sizes",
    ".xarray.core.computation.py@@broadcast_compat_data": "def broadcast_compat_data(variable, broadcast_dims, core_dims):\n    data = variable.data\n    old_dims = variable.dims\n    new_dims = broadcast_dims + core_dims\n    if new_dims == old_dims:\n        return data\n    set_old_dims = set(old_dims)\n    missing_core_dims = [d for d in core_dims if d not in set_old_dims]\n    if missing_core_dims:\n        raise ValueError('operand to apply_ufunc has required core dimensions {}, but some of these dimensions are absent on an input variable: {}'.format(list(core_dims), missing_core_dims))\n    set_new_dims = set(new_dims)\n    unexpected_dims = [d for d in old_dims if d not in set_new_dims]\n    if unexpected_dims:\n        raise ValueError('operand to apply_ufunc encountered unexpected dimensions %r on an input variable: these are core dimensions on other input or output variables' % unexpected_dims)\n    old_broadcast_dims = tuple((d for d in broadcast_dims if d in set_old_dims))\n    reordered_dims = old_broadcast_dims + core_dims\n    if reordered_dims != old_dims:\n        order = tuple((old_dims.index(d) for d in reordered_dims))\n        data = duck_array_ops.transpose(data, order)\n    if new_dims != reordered_dims:\n        key_parts = []\n        for dim in new_dims:\n            if dim in set_old_dims:\n                key_parts.append(SLICE_NONE)\n            elif key_parts:\n                key_parts.append(np.newaxis)\n        data = data[tuple(key_parts)]\n    return data",
    ".xarray.core.variable.py@@Variable.data": "def data(self):\n    if hasattr(self._data, '__array_function__') or isinstance(self._data, dask_array_type):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.duck_array_ops.py@@fillna": "def fillna(data, other):\n    return where(isnull(data), other, data)",
    ".xarray.core.duck_array_ops.py@@isnull": "def isnull(data):\n    data = asarray(data)\n    scalar_type = data.dtype.type\n    if issubclass(scalar_type, (np.datetime64, np.timedelta64)):\n        return isnat(data)\n    elif issubclass(scalar_type, np.inexact):\n        return isnan(data)\n    elif issubclass(scalar_type, (np.bool_, np.integer, np.character, np.void)):\n        return zeros_like(data, dtype=bool)\n    elif isinstance(data, (np.ndarray, dask_array_type)):\n        return pandas_isnull(data)\n    else:\n        return data != data",
    ".xarray.core.duck_array_ops.py@@asarray": "def asarray(data):\n    return data if isinstance(data, dask_array_type) or hasattr(data, '__array_function__') else np.asarray(data)",
    ".xarray.core.duck_array_ops.py@@f": "def f(values, axis=None, skipna=None, **kwargs):\n    if kwargs.pop('out', None) is not None:\n        raise TypeError('`out` is not valid for {}'.format(name))\n    values = asarray(values)\n    if coerce_strings and values.dtype.kind in 'SU':\n        values = values.astype(object)\n    func = None\n    if skipna or (skipna is None and values.dtype.kind in 'cfO'):\n        nanname = 'nan' + name\n        func = getattr(nanops, nanname)\n    else:\n        func = _dask_or_eager_func(name)\n    try:\n        return func(values, axis=axis, **kwargs)\n    except AttributeError:\n        if isinstance(values, dask_array_type):\n            try:\n                return func(values, axis=axis, dtype=values.dtype, **kwargs)\n            except (AttributeError, TypeError):\n                msg = '%s is not yet implemented on dask arrays' % name\n        else:\n            msg = '%s is not available with skipna=False with the installed version of numpy; upgrade to numpy 1.12 or newer to use skipna=True or skipna=None' % name\n        raise NotImplementedError(msg)",
    ".xarray.core.duck_array_ops.py@@where": "def where(condition, x, y):\n    return _where(condition, *as_shared_dtype([x, y]))",
    ".xarray.core.duck_array_ops.py@@as_shared_dtype": "def as_shared_dtype(scalars_or_arrays):\n    arrays = [asarray(x) for x in scalars_or_arrays]\n    out_type = dtypes.result_type(*arrays)\n    return [x.astype(out_type, copy=False) for x in arrays]",
    ".xarray.core.dtypes.py@@result_type": "def result_type(*arrays_and_dtypes):\n    types = {np.result_type(t).type for t in arrays_and_dtypes}\n    for left, right in PROMOTE_TO_OBJECT:\n        if any((issubclass(t, left) for t in types)) and any((issubclass(t, right) for t in types)):\n            return np.dtype(object)\n    return np.result_type(*arrays_and_dtypes)",
    ".xarray.core.computation.py@@_UFuncSignature.num_outputs": "def num_outputs(self):\n    return len(self.output_core_dims)",
    ".xarray.core.common.py@@AbstractArray.sizes": "def sizes(self: Any) -> Mapping[Hashable, int]:\n    return Frozen(OrderedDict(zip(self.dims, self.shape)))",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> 'OrderedDict[Any, Any]':\n    if self._attrs is None:\n        self._attrs = OrderedDict()\n    return self._attrs",
    ".xarray.core.variable.py@@IndexVariable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data.copy(deep=deep)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.copy": "def copy(self, deep: bool=True) -> 'PandasIndexAdapter':\n    array = self.array.copy(deep=True) if deep else self.array\n    return PandasIndexAdapter(array, self._dtype)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__init__": "def __init__(self, array: Any, dtype: DTypeLike=None):\n    self.array = utils.safe_cast_to_index(array)\n    if dtype is None:\n        if isinstance(array, pd.PeriodIndex):\n            dtype = np.dtype('O')\n        elif hasattr(array, 'categories'):\n            dtype = array.categories.dtype\n        elif not utils.is_valid_numpy_dtype(array.dtype):\n            dtype = np.dtype('O')\n        else:\n            dtype = array.dtype\n    else:\n        dtype = np.dtype(dtype)\n    self._dtype = dtype",
    ".xarray.core.utils.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    if isinstance(array, pd.Index):\n        index = array\n    elif hasattr(array, 'to_index'):\n        index = array.to_index()\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.utils.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError('%s objects must be 1-dimensional' % type(self).__name__)\n    if not isinstance(self._data, PandasIndexAdapter):\n        self._data = PandasIndexAdapter(self._data)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.shape": "def shape(self) -> Tuple[int]:\n    return (len(self.array),)",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self):\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.core.variable.py@@IndexVariable.load": "def load(self):\n    return self",
    ".xarray.core.variable.py@@IndexVariable.equals": "def equals(self, other, equiv=None):\n    if equiv is not None:\n        return super().equals(other, equiv)\n    other = getattr(other, 'variable', other)\n    try:\n        return self.dims == other.dims and self._data_equals(other)\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.variable.py@@IndexVariable._data_equals": "def _data_equals(self, other):\n    return self.to_index().equals(other.to_index())",
    ".xarray.core.variable.py@@IndexVariable.to_index": "def to_index(self):\n    assert self.ndim == 1\n    index = self._data.array\n    if isinstance(index, pd.MultiIndex):\n        valid_level_names = [name or '{}_level_{}'.format(self.dims[0], i) for i, name in enumerate(index.names)]\n        index = index.set_names(valid_level_names)\n    else:\n        index = index.set_names(self.name)\n    return index",
    ".xarray.core.variable.py@@IndexVariable.name": "def name(self):\n    return self.dims[0]",
    ".xarray.core.duck_array_ops.py@@array_notnull_equiv": "def array_notnull_equiv(arr1, arr2):\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', \"In the future, 'NAT == x'\")\n        flag_array = (arr1 == arr2) | isnull(arr1) | isnull(arr2)\n        return bool(flag_array.all())",
    ".xarray.core.computation.py@@_UFuncSignature.all_core_dims": "def all_core_dims(self):\n    if self._all_core_dims is None:\n        self._all_core_dims = self.all_input_core_dims | self.all_output_core_dims\n    return self._all_core_dims",
    ".xarray.core.computation.py@@_UFuncSignature.all_input_core_dims": "def all_input_core_dims(self):\n    if self._all_input_core_dims is None:\n        self._all_input_core_dims = frozenset((dim for dims in self.input_core_dims for dim in dims))\n    return self._all_input_core_dims",
    ".xarray.core.computation.py@@_UFuncSignature.all_output_core_dims": "def all_output_core_dims(self):\n    if self._all_output_core_dims is None:\n        self._all_output_core_dims = frozenset((dim for dims in self.output_core_dims for dim in dims))\n    return self._all_output_core_dims",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((ReprObject, self._value))",
    ".xarray.core.utils.py@@ReprObject.__eq__": "def __eq__(self, other) -> bool:\n    if isinstance(other, ReprObject):\n        return self._value == other._value\n    return False",
    ".xarray.coding.cftimeindex.py@@CFTimeIndex.__new__": "def __new__(cls, data, name=None):\n    assert_all_valid_date_type(data)\n    if name is None and hasattr(data, 'name'):\n        name = data.name\n    result = object.__new__(cls)\n    result._data = np.array(data, dtype='O')\n    result.name = name\n    return result",
    ".xarray.coding.cftimeindex.py@@assert_all_valid_date_type": "def assert_all_valid_date_type(data):\n    import cftime\n    if len(data) > 0:\n        sample = data[0]\n        date_type = type(sample)\n        if not isinstance(sample, cftime.datetime):\n            raise TypeError('CFTimeIndex requires cftime.datetime objects. Got object of {}.'.format(date_type))\n        if not all((isinstance(value, date_type) for value in data)):\n            raise TypeError('CFTimeIndex requires using datetime objects of all the same type.  Got\\n{}.'.format(data))",
    ".xarray.core.variable.py@@Variable.set_dims": "def set_dims(self, dims, shape=None):\n    if isinstance(dims, str):\n        dims = [dims]\n    if shape is None and utils.is_dict_like(dims):\n        shape = dims.values()\n    missing_dims = set(self.dims) - set(dims)\n    if missing_dims:\n        raise ValueError('new dimensions %r must be a superset of existing dimensions %r' % (dims, self.dims))\n    self_dims = set(self.dims)\n    expanded_dims = tuple((d for d in dims if d not in self_dims)) + self.dims\n    if self.dims == expanded_dims:\n        expanded_data = self.data\n    elif shape is not None:\n        dims_map = dict(zip(dims, shape))\n        tmp_shape = tuple((dims_map[d] for d in expanded_dims))\n        expanded_data = duck_array_ops.broadcast_to(self.data, tmp_shape)\n    else:\n        expanded_data = self.data[(None,) * (len(expanded_dims) - self.ndim)]\n    expanded_var = Variable(expanded_dims, expanded_data, self._attrs, self._encoding, fastpath=True)\n    return expanded_var.transpose(*dims)",
    ".xarray.core.variable.py@@Variable.transpose": "def transpose(self, *dims) -> 'Variable':\n    if len(dims) == 0:\n        dims = self.dims[::-1]\n    axes = self.get_axis_num(dims)\n    if len(dims) < 2:\n        return self.copy(deep=False)\n    data = as_indexable(self._data).transpose(axes)\n    return type(self)(dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.common.py@@AbstractArray.get_axis_num": "def get_axis_num(self, dim: Union[Hashable, Iterable[Hashable]]) -> Union[int, Tuple[int, ...]]:\n    if isinstance(dim, Iterable) and (not isinstance(dim, str)):\n        return tuple((self._get_axis_num(d) for d in dim))\n    else:\n        return self._get_axis_num(dim)",
    ".xarray.core.common.py@@AbstractArray._get_axis_num": "def _get_axis_num(self: Any, dim: Hashable) -> int:\n    try:\n        return self.dims.index(dim)\n    except ValueError:\n        raise ValueError('%r not found in array dimensions %r' % (dim, self.dims))"
}
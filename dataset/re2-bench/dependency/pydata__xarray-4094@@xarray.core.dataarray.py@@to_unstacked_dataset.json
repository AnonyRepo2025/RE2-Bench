{
    ".xarray.core.indexes.py@@Indexes.__init__": "def __init__(self, indexes):\n    self._indexes = indexes",
    ".xarray.core.indexes.py@@Indexes.__getitem__": "def __getitem__(self, key):\n    return self._indexes[key]",
    ".xarray.core.coordinates.py@@DataArrayCoordinates.__init__": "def __init__(self, dataarray: 'DataArray'):\n    self._data = dataarray",
    ".xarray.core.coordinates.py@@Coordinates.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._names",
    ".xarray.core.coordinates.py@@DataArrayCoordinates._names": "def _names(self) -> Set[Hashable]:\n    return set(self._data._coords)",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((type(self), self._value))",
    ".xarray.core.dataset.py@@Dataset._construct_direct": "def _construct_direct(cls, variables, coord_names, dims=None, attrs=None, indexes=None, encoding=None, file_obj=None):\n    if dims is None:\n        dims = calculate_dimensions(variables)\n    obj = object.__new__(cls)\n    obj._variables = variables\n    obj._coord_names = coord_names\n    obj._dims = dims\n    obj._indexes = indexes\n    obj._attrs = attrs\n    obj._file_obj = file_obj\n    obj._encoding = encoding\n    return obj",
    ".xarray.core.dataset.py@@calculate_dimensions": "def calculate_dimensions(variables: Mapping[Hashable, Variable]) -> Dict[Hashable, int]:\n    dims: Dict[Hashable, int] = {}\n    last_used = {}\n    scalar_vars = {k for k, v in variables.items() if not v.dims}\n    for k, var in variables.items():\n        for dim, size in zip(var.dims, var.shape):\n            if dim in scalar_vars:\n                raise ValueError('dimension %r already exists as a scalar variable' % dim)\n            if dim not in dims:\n                dims[dim] = size\n                last_used[dim] = k\n            elif dims[dim] != size:\n                raise ValueError('conflicting sizes for dimension %r: length %s on %r and length %s on %r' % (dim, size, k, dims[dim], last_used[dim]))\n    return dims",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self):\n    return self._dims",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.indexing.py@@PandasIndexAdapter.shape": "def shape(self) -> Tuple[int]:\n    return (len(self.array),)",
    ".xarray.core.common.py@@AttrAccessMixin.__setattr__": "def __setattr__(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '{!r} object has no attribute {!r}'.format(type(self).__name__, name):\n            raise\n        raise AttributeError(\"cannot set attribute %r on a %r object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\" % (name, type(self).__name__)) from e",
    ".xarray.core.dataset.py@@Dataset.sel": "def sel(self, indexers: Mapping[Hashable, Any]=None, method: str=None, tolerance: Number=None, drop: bool=False, **indexers_kwargs: Any) -> 'Dataset':\n    indexers = either_dict_or_kwargs(indexers, indexers_kwargs, 'sel')\n    pos_indexers, new_indexes = remap_label_indexers(self, indexers=indexers, method=method, tolerance=tolerance)\n    result = self.isel(indexers=pos_indexers, drop=drop)\n    return result._overwrite_indexes(new_indexes)",
    ".xarray.core.utils.py@@either_dict_or_kwargs": "def either_dict_or_kwargs(pos_kwargs: Optional[Mapping[Hashable, T]], kw_kwargs: Mapping[str, T], func_name: str) -> Mapping[Hashable, T]:\n    if pos_kwargs is not None:\n        if not is_dict_like(pos_kwargs):\n            raise ValueError('the first argument to .%s must be a dictionary' % func_name)\n        if kw_kwargs:\n            raise ValueError('cannot specify both keyword and positional arguments to .%s' % func_name)\n        return pos_kwargs\n    else:\n        return cast(Mapping[Hashable, T], kw_kwargs)",
    ".xarray.core.utils.py@@is_dict_like": "def is_dict_like(value: Any) -> bool:\n    return hasattr(value, 'keys') and hasattr(value, '__getitem__')",
    ".xarray.core.coordinates.py@@remap_label_indexers": "def remap_label_indexers(obj: Union['DataArray', 'Dataset'], indexers: Mapping[Hashable, Any]=None, method: str=None, tolerance=None, **indexers_kwargs: Any) -> Tuple[dict, dict]:\n    from .dataarray import DataArray\n    indexers = either_dict_or_kwargs(indexers, indexers_kwargs, 'remap_label_indexers')\n    v_indexers = {k: v.variable.data if isinstance(v, DataArray) else v for k, v in indexers.items()}\n    pos_indexers, new_indexes = indexing.remap_label_indexers(obj, v_indexers, method=method, tolerance=tolerance)\n    for k, v in indexers.items():\n        if isinstance(v, Variable):\n            pos_indexers[k] = Variable(v.dims, pos_indexers[k])\n        elif isinstance(v, DataArray):\n            coords = {k: var for k, var in v._coords.items() if k not in indexers}\n            pos_indexers[k] = DataArray(pos_indexers[k], coords=coords, dims=v.dims)\n    return (pos_indexers, new_indexes)",
    ".xarray.core.indexing.py@@remap_label_indexers": "def remap_label_indexers(data_obj, indexers, method=None, tolerance=None):\n    if method is not None and (not isinstance(method, str)):\n        raise TypeError('``method`` must be a string')\n    pos_indexers = {}\n    new_indexes = {}\n    dim_indexers = get_dim_indexers(data_obj, indexers)\n    for dim, label in dim_indexers.items():\n        try:\n            index = data_obj.indexes[dim]\n        except KeyError:\n            if method is not None or tolerance is not None:\n                raise ValueError('cannot supply ``method`` or ``tolerance`` when the indexed dimension does not have an associated coordinate.')\n            pos_indexers[dim] = label\n        else:\n            coords_dtype = data_obj.coords[dim].dtype\n            label = maybe_cast_to_coords_dtype(label, coords_dtype)\n            idxr, new_idx = convert_label_indexer(index, label, dim, method, tolerance)\n            pos_indexers[dim] = idxr\n            if new_idx is not None:\n                new_indexes[dim] = new_idx\n    return (pos_indexers, new_indexes)",
    ".xarray.core.indexing.py@@get_dim_indexers": "def get_dim_indexers(data_obj, indexers):\n    invalid = [k for k in indexers if k not in data_obj.dims and k not in data_obj._level_coords]\n    if invalid:\n        raise ValueError(f'dimensions or multi-index levels {invalid!r} do not exist')\n    level_indexers = defaultdict(dict)\n    dim_indexers = {}\n    for key, label in indexers.items():\n        dim, = data_obj[key].dims\n        if key != dim:\n            level_indexers[dim][key] = label\n        else:\n            dim_indexers[key] = label\n    for dim, level_labels in level_indexers.items():\n        if dim_indexers.get(dim, False):\n            raise ValueError(f'cannot combine multi-index level indexers with an indexer for dimension {dim}')\n        dim_indexers[dim] = level_labels\n    return dim_indexers",
    ".xarray.core.dataset.py@@Dataset.dims": "def dims(self) -> Mapping[Hashable, int]:\n    return Frozen(SortedKeysDict(self._dims))",
    ".xarray.core.utils.py@@SortedKeysDict.__init__": "def __init__(self, mapping: MutableMapping[K, V]=None):\n    self.mapping = {} if mapping is None else mapping",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.utils.py@@SortedKeysDict.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.dataset.py@@Dataset._level_coords": "def _level_coords(self) -> Dict[str, Hashable]:\n    level_coords: Dict[str, Hashable] = {}\n    for name, index in self.indexes.items():\n        if isinstance(index, pd.MultiIndex):\n            level_names = index.names\n            dim, = self.variables[name].dims\n            level_coords.update({lname: dim for lname in level_names})\n    return level_coords",
    ".xarray.core.dataset.py@@Dataset.indexes": "def indexes(self) -> Indexes:\n    if self._indexes is None:\n        self._indexes = default_indexes(self._variables, self._dims)\n    return Indexes(self._indexes)",
    ".xarray.core.indexes.py@@Indexes.__iter__": "def __iter__(self):\n    return iter(self._indexes)",
    ".xarray.core.dataset.py@@Dataset.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen(self._variables)",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.dataset.py@@Dataset.__getitem__": "def __getitem__(self, key: Mapping) -> 'Dataset':\n    ...",
    ".xarray.core.utils.py@@hashable": "def hashable(v: Any) -> bool:\n    try:\n        hash(v)\n    except TypeError:\n        return False\n    return True",
    ".xarray.core.dataset.py@@Dataset._construct_dataarray": "def _construct_dataarray(self, name: Hashable) -> 'DataArray':\n    from .dataarray import DataArray\n    try:\n        variable = self._variables[name]\n    except KeyError:\n        _, name, variable = _get_virtual_variable(self._variables, name, self._level_coords, self.dims)\n    needed_dims = set(variable.dims)\n    coords: Dict[Hashable, Variable] = {}\n    for k in self.coords:\n        if set(self.variables[k].dims) <= needed_dims:\n            coords[k] = self.variables[k]\n    if self._indexes is None:\n        indexes = None\n    else:\n        indexes = {k: v for k, v in self._indexes.items() if k in coords}\n    return DataArray(variable, coords, name=name, indexes=indexes, fastpath=True)",
    ".xarray.core.dataset.py@@_get_virtual_variable": "def _get_virtual_variable(variables, key: Hashable, level_vars: Mapping=None, dim_sizes: Mapping=None) -> Tuple[Hashable, Hashable, Variable]:\n    if level_vars is None:\n        level_vars = {}\n    if dim_sizes is None:\n        dim_sizes = {}\n    if key in dim_sizes:\n        data = pd.Index(range(dim_sizes[key]), name=key)\n        variable = IndexVariable((key,), data)\n        return (key, key, variable)\n    if not isinstance(key, str):\n        raise KeyError(key)\n    split_key = key.split('.', 1)\n    var_name: Optional[str]\n    if len(split_key) == 2:\n        ref_name, var_name = split_key\n    elif len(split_key) == 1:\n        ref_name, var_name = (key, None)\n    else:\n        raise KeyError(key)\n    if ref_name in level_vars:\n        dim_var = variables[level_vars[ref_name]]\n        ref_var = dim_var.to_index_variable().get_level_variable(ref_name)\n    else:\n        ref_var = variables[ref_name]\n    if var_name is None:\n        virtual_var = ref_var\n        var_name = key\n    else:\n        if _contains_datetime_like_objects(ref_var):\n            ref_var = xr.DataArray(ref_var)\n            data = getattr(ref_var.dt, var_name).data\n        else:\n            data = getattr(ref_var, var_name).data\n        virtual_var = Variable(ref_var.dims, data)\n    return (ref_name, var_name, virtual_var)",
    ".xarray.core.variable.py@@IndexVariable.to_index_variable": "def to_index_variable(self):\n    return self",
    ".xarray.core.variable.py@@IndexVariable.get_level_variable": "def get_level_variable(self, level):\n    if self.level_names is None:\n        raise ValueError('IndexVariable %r has no MultiIndex' % self.name)\n    index = self.to_index()\n    return type(self)(self.dims, index.get_level_values(level))",
    ".xarray.core.variable.py@@IndexVariable.level_names": "def level_names(self):\n    index = self.to_index()\n    if isinstance(index, pd.MultiIndex):\n        return index.names\n    else:\n        return None",
    ".xarray.core.variable.py@@IndexVariable.to_index": "def to_index(self):\n    assert self.ndim == 1\n    index = self._data.array\n    if isinstance(index, pd.MultiIndex):\n        valid_level_names = [name or '{}_level_{}'.format(self.dims[0], i) for i, name in enumerate(index.names)]\n        index = index.set_names(valid_level_names)\n    else:\n        index = index.set_names(self.name)\n    return index",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError('%s objects must be 1-dimensional' % type(self).__name__)\n    if not isinstance(self._data, PandasIndexAdapter):\n        self._data = PandasIndexAdapter(self._data)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, Variable):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    data = getattr(data, 'values', data)\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, '__array_function__'):\n            if IS_NEP18_ACTIVE:\n                return data\n            else:\n                raise TypeError('Got an NumPy-like array type providing the __array_function__ protocol but NEP18 is not enabled. Check that numpy >= v1.16 and that the environment variable \"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\" is set to \"1\"')\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == 'O':\n            data = _possibly_convert_objects(data)\n        elif data.dtype.kind == 'M':\n            data = np.asarray(data, 'datetime64[ns]')\n        elif data.dtype.kind == 'm':\n            data = np.asarray(data, 'timedelta64[ns]')\n    return _maybe_wrap_data(data)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexAdapter(data)\n    return data",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__init__": "def __init__(self, array: Any, dtype: DTypeLike=None):\n    self.array = utils.safe_cast_to_index(array)\n    if dtype is None:\n        if isinstance(array, pd.PeriodIndex):\n            dtype = np.dtype('O')\n        elif hasattr(array, 'categories'):\n            dtype = array.categories.dtype\n        elif not utils.is_valid_numpy_dtype(array.dtype):\n            dtype = np.dtype('O')\n        else:\n            dtype = array.dtype\n    else:\n        dtype = np.dtype(dtype)\n    self._dtype = dtype",
    ".xarray.core.utils.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    if isinstance(array, pd.Index):\n        index = array\n    elif hasattr(array, 'to_index'):\n        index = array.to_index()\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.utils.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.coding.cftimeindex.py@@CFTimeIndex.__new__": "def __new__(cls, data, name=None):\n    assert_all_valid_date_type(data)\n    if name is None and hasattr(data, 'name'):\n        name = data.name\n    result = object.__new__(cls)\n    result._data = np.array(data, dtype='O')\n    result.name = name\n    result._cache = {}\n    return result",
    ".xarray.coding.cftimeindex.py@@assert_all_valid_date_type": "def assert_all_valid_date_type(data):\n    import cftime\n    if len(data) > 0:\n        sample = data[0]\n        date_type = type(sample)\n        if not isinstance(sample, cftime.datetime):\n            raise TypeError('CFTimeIndex requires cftime.datetime objects. Got object of {}.'.format(date_type))\n        if not all((isinstance(value, date_type) for value in data)):\n            raise TypeError('CFTimeIndex requires using datetime objects of all the same type.  Got\\n{}.'.format(data))",
    ".xarray.core.utils.py@@is_valid_numpy_dtype": "def is_valid_numpy_dtype(dtype: Any) -> bool:\n    try:\n        np.dtype(dtype)\n    except (TypeError, ValueError):\n        return False\n    else:\n        return True",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims):\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError('dimensions %s must have the same length as the number of data dimensions, ndim=%s' % (dims, self.ndim))\n    return dims",
    ".xarray.core.dataset.py@@Dataset.coords": "def coords(self) -> DatasetCoordinates:\n    return DatasetCoordinates(self)",
    ".xarray.core.coordinates.py@@DatasetCoordinates.__init__": "def __init__(self, dataset: 'Dataset'):\n    self._data = dataset",
    ".xarray.core.coordinates.py@@Coordinates.__iter__": "def __iter__(self) -> Iterator['Hashable']:\n    for k in self.variables:\n        if k in self._names:\n            yield k",
    ".xarray.core.coordinates.py@@DatasetCoordinates.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen({k: v for k, v in self._data.variables.items() if k in self._names})",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.coordinates.py@@DatasetCoordinates._names": "def _names(self) -> Set[Hashable]:\n    return self._data._coord_names",
    ".xarray.core.dataarray.py@@DataArray.dims": "def dims(self) -> Tuple[Hashable, ...]:\n    return self.variable.dims",
    ".xarray.core.coordinates.py@@DatasetCoordinates.__getitem__": "def __getitem__(self, key: Hashable) -> 'DataArray':\n    if key in self._data.data_vars:\n        raise KeyError(key)\n    return cast('DataArray', self._data[key])",
    ".xarray.core.dataset.py@@Dataset.data_vars": "def data_vars(self) -> DataVariables:\n    return DataVariables(self)",
    ".xarray.core.dataset.py@@DataVariables.__init__": "def __init__(self, dataset: 'Dataset'):\n    self._dataset = dataset",
    ".xarray.core.dataset.py@@DataVariables.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._dataset._variables and key not in self._dataset._coord_names",
    ".xarray.core.variable.py@@Variable.dtype": "def dtype(self):\n    return self._data.dtype",
    ".xarray.core.indexing.py@@PandasIndexAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.utils.py@@maybe_cast_to_coords_dtype": "def maybe_cast_to_coords_dtype(label, coords_dtype):\n    if coords_dtype.kind == 'f' and (not isinstance(label, slice)):\n        label = np.asarray(label, dtype=coords_dtype)\n    return label",
    ".xarray.core.indexing.py@@convert_label_indexer": "def convert_label_indexer(index, label, index_name='', method=None, tolerance=None):\n    new_index = None\n    if isinstance(label, slice):\n        if method is not None or tolerance is not None:\n            raise NotImplementedError('cannot use ``method`` argument if any indexers are slice objects')\n        indexer = index.slice_indexer(_sanitize_slice_element(label.start), _sanitize_slice_element(label.stop), _sanitize_slice_element(label.step))\n        if not isinstance(indexer, slice):\n            raise KeyError(f'cannot represent labeled-based slice indexer for dimension {index_name!r} with a slice over integer positions; the index is unsorted or non-unique')\n    elif is_dict_like(label):\n        is_nested_vals = _is_nested_tuple(tuple(label.values()))\n        if not isinstance(index, pd.MultiIndex):\n            raise ValueError('cannot use a dict-like object for selection on a dimension that does not have a MultiIndex')\n        elif len(label) == index.nlevels and (not is_nested_vals):\n            indexer = index.get_loc(tuple((label[k] for k in index.names)))\n        else:\n            for k, v in label.items():\n                if isinstance(v, Sequence) and (not isinstance(v, str)):\n                    raise ValueError('Vectorized selection is not available along level variable: ' + k)\n            indexer, new_index = index.get_loc_level(tuple(label.values()), level=tuple(label.keys()))\n            if indexer.dtype.kind == 'b' and indexer.sum() == 0:\n                raise KeyError(f'{label} not found')\n    elif isinstance(label, tuple) and isinstance(index, pd.MultiIndex):\n        if _is_nested_tuple(label):\n            indexer = index.get_locs(label)\n        elif len(label) == index.nlevels:\n            indexer = index.get_loc(label)\n        else:\n            indexer, new_index = index.get_loc_level(label, level=list(range(len(label))))\n    else:\n        label = label if getattr(label, 'ndim', 1) > 1 else _asarray_tuplesafe(label)\n        if label.ndim == 0:\n            if isinstance(index, pd.MultiIndex):\n                indexer, new_index = index.get_loc_level(label.item(), level=0)\n            elif isinstance(index, pd.CategoricalIndex):\n                if method is not None:\n                    raise ValueError(\"'method' is not a valid kwarg when indexing using a CategoricalIndex.\")\n                if tolerance is not None:\n                    raise ValueError(\"'tolerance' is not a valid kwarg when indexing using a CategoricalIndex.\")\n                indexer = index.get_loc(label.item())\n            else:\n                indexer = index.get_loc(label.item(), method=method, tolerance=tolerance)\n        elif label.dtype.kind == 'b':\n            indexer = label\n        else:\n            if isinstance(index, pd.MultiIndex) and label.ndim > 1:\n                raise ValueError('Vectorized selection is not available along MultiIndex variable: ' + index_name)\n            indexer = get_indexer_nd(index, label, method, tolerance)\n            if np.any(indexer < 0):\n                raise KeyError(f'not all values found in index {index_name!r}')\n    return (indexer, new_index)",
    ".xarray.core.indexing.py@@_is_nested_tuple": "def _is_nested_tuple(possible_tuple):\n    return isinstance(possible_tuple, tuple) and any((isinstance(value, (tuple, list, slice)) for value in possible_tuple))",
    ".xarray.core.dataset.py@@Dataset.isel": "def isel(self, indexers: Mapping[Hashable, Any]=None, drop: bool=False, missing_dims: str='raise', **indexers_kwargs: Any) -> 'Dataset':\n    indexers = either_dict_or_kwargs(indexers, indexers_kwargs, 'isel')\n    if any((is_fancy_indexer(idx) for idx in indexers.values())):\n        return self._isel_fancy(indexers, drop=drop, missing_dims=missing_dims)\n    indexers = drop_dims_from_indexers(indexers, self.dims, missing_dims)\n    variables = {}\n    dims: Dict[Hashable, Tuple[int, ...]] = {}\n    coord_names = self._coord_names.copy()\n    indexes = self._indexes.copy() if self._indexes is not None else None\n    for var_name, var_value in self._variables.items():\n        var_indexers = {k: v for k, v in indexers.items() if k in var_value.dims}\n        if var_indexers:\n            var_value = var_value.isel(var_indexers)\n            if drop and var_value.ndim == 0 and (var_name in coord_names):\n                coord_names.remove(var_name)\n                if indexes:\n                    indexes.pop(var_name, None)\n                continue\n            if indexes and var_name in indexes:\n                if var_value.ndim == 1:\n                    indexes[var_name] = var_value.to_index()\n                else:\n                    del indexes[var_name]\n        variables[var_name] = var_value\n        dims.update(zip(var_value.dims, var_value.shape))\n    return self._construct_direct(variables=variables, coord_names=coord_names, dims=dims, attrs=self._attrs, indexes=indexes, encoding=self._encoding, file_obj=self._file_obj)",
    ".xarray.core.indexing.py@@is_fancy_indexer": "def is_fancy_indexer(indexer: Any) -> bool:\n    if isinstance(indexer, (int, slice)):\n        return False\n    if isinstance(indexer, np.ndarray):\n        return indexer.ndim > 1\n    if isinstance(indexer, list):\n        return bool(indexer) and (not isinstance(indexer[0], int))\n    return True",
    ".xarray.core.utils.py@@drop_dims_from_indexers": "def drop_dims_from_indexers(indexers: Mapping[Hashable, Any], dims: Union[list, Mapping[Hashable, int]], missing_dims: str) -> Mapping[Hashable, Any]:\n    if missing_dims == 'raise':\n        invalid = indexers.keys() - set(dims)\n        if invalid:\n            raise ValueError(f'dimensions {invalid} do not exist. Expected one or more of {dims}')\n        return indexers\n    elif missing_dims == 'warn':\n        indexers = dict(indexers)\n        invalid = indexers.keys() - set(dims)\n        if invalid:\n            warnings.warn(f'dimensions {invalid} do not exist. Expected one or more of {dims}')\n        for key in invalid:\n            indexers.pop(key)\n        return indexers\n    elif missing_dims == 'ignore':\n        return {key: val for key, val in indexers.items() if key in dims}\n    else:\n        raise ValueError(f'Unrecognised option {missing_dims} for missing_dims argument')",
    ".xarray.core.utils.py@@SortedKeysDict.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(sorted(self.mapping))",
    ".xarray.core.variable.py@@Variable.isel": "def isel(self: VariableType, indexers: Mapping[Hashable, Any]=None, missing_dims: str='raise', **indexers_kwargs: Any) -> VariableType:\n    indexers = either_dict_or_kwargs(indexers, indexers_kwargs, 'isel')\n    indexers = drop_dims_from_indexers(indexers, self.dims, missing_dims)\n    key = tuple((indexers.get(dim, slice(None)) for dim in self.dims))\n    return self[key]",
    ".xarray.core.variable.py@@Variable.__getitem__": "def __getitem__(self: VariableType, key) -> VariableType:\n    dims, indexer, new_order = self._broadcast_indexes(key)\n    data = as_indexable(self._data)[indexer]\n    if new_order:\n        data = duck_array_ops.moveaxis(data, range(len(new_order)), new_order)\n    return self._finalize_indexing_result(dims, data)",
    ".xarray.core.variable.py@@Variable._broadcast_indexes": "def _broadcast_indexes(self, key):\n    key = self._item_key_to_tuple(key)\n    key = indexing.expanded_indexer(key, self.ndim)\n    key = tuple((k.data.item() if isinstance(k, Variable) and k.ndim == 0 else k for k in key))\n    key = tuple((k.item() if isinstance(k, np.ndarray) and k.ndim == 0 else k for k in key))\n    if all((isinstance(k, BASIC_INDEXING_TYPES) for k in key)):\n        return self._broadcast_indexes_basic(key)\n    self._validate_indexers(key)\n    if all((not isinstance(k, Variable) for k in key)):\n        return self._broadcast_indexes_outer(key)\n    dims = []\n    for k, d in zip(key, self.dims):\n        if isinstance(k, Variable):\n            if len(k.dims) > 1:\n                return self._broadcast_indexes_vectorized(key)\n            dims.append(k.dims[0])\n        elif not isinstance(k, integer_types):\n            dims.append(d)\n    if len(set(dims)) == len(dims):\n        return self._broadcast_indexes_outer(key)\n    return self._broadcast_indexes_vectorized(key)",
    ".xarray.core.variable.py@@Variable._item_key_to_tuple": "def _item_key_to_tuple(self, key):\n    if utils.is_dict_like(key):\n        return tuple((key.get(dim, slice(None)) for dim in self.dims))\n    else:\n        return key",
    ".xarray.core.indexing.py@@expanded_indexer": "def expanded_indexer(key, ndim):\n    if not isinstance(key, tuple):\n        key = (key,)\n    new_key = []\n    found_ellipsis = False\n    for k in key:\n        if k is Ellipsis:\n            if not found_ellipsis:\n                new_key.extend((ndim + 1 - len(key)) * [slice(None)])\n                found_ellipsis = True\n            else:\n                new_key.append(slice(None))\n        else:\n            new_key.append(k)\n    if len(new_key) > ndim:\n        raise IndexError('too many indices')\n    new_key.extend((ndim - len(new_key)) * [slice(None)])\n    return tuple(new_key)",
    ".xarray.core.variable.py@@Variable._broadcast_indexes_basic": "def _broadcast_indexes_basic(self, key):\n    dims = tuple((dim for k, dim in zip(key, self.dims) if not isinstance(k, integer_types)))\n    return (dims, BasicIndexer(key), None)",
    ".xarray.core.indexing.py@@BasicIndexer.__init__": "def __init__(self, key):\n    if not isinstance(key, tuple):\n        raise TypeError(f'key must be a tuple: {key!r}')\n    new_key = []\n    for k in key:\n        if isinstance(k, integer_types):\n            k = int(k)\n        elif isinstance(k, slice):\n            k = as_integer_slice(k)\n        else:\n            raise TypeError(f'unexpected indexer type for {type(self).__name__}: {k!r}')\n        new_key.append(k)\n    super().__init__(new_key)",
    ".xarray.core.indexing.py@@ExplicitIndexer.__init__": "def __init__(self, key):\n    if type(self) is ExplicitIndexer:\n        raise TypeError('cannot instantiate base ExplicitIndexer objects')\n    self._key = tuple(key)",
    ".xarray.core.indexing.py@@as_indexable": "def as_indexable(array):\n    if isinstance(array, ExplicitlyIndexed):\n        return array\n    if isinstance(array, np.ndarray):\n        return NumpyIndexingAdapter(array)\n    if isinstance(array, pd.Index):\n        return PandasIndexAdapter(array)\n    if isinstance(array, dask_array_type):\n        return DaskIndexingAdapter(array)\n    if hasattr(array, '__array_function__'):\n        return NdArrayLikeIndexingAdapter(array)\n    raise TypeError('Invalid array type: {}'.format(type(array)))",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__getitem__": "def __getitem__(self, indexer) -> Union[NumpyIndexingAdapter, np.ndarray, np.datetime64, np.timedelta64]:\n    key = indexer.tuple\n    if isinstance(key, tuple) and len(key) == 1:\n        key, = key\n    if getattr(key, 'ndim', 0) > 1:\n        return NumpyIndexingAdapter(self.array.values)[indexer]\n    result = self.array[key]\n    if isinstance(result, pd.Index):\n        result = PandasIndexAdapter(result, dtype=self.dtype)\n    else:\n        if result is pd.NaT:\n            result = np.datetime64('NaT', 'ns')\n        elif isinstance(result, timedelta):\n            result = np.timedelta64(getattr(result, 'value', result), 'ns')\n        elif isinstance(result, pd.Timestamp):\n            result = np.asarray(result.to_datetime64())\n        elif self.dtype != object:\n            result = np.asarray(result, dtype=self.dtype)\n        result = utils.to_0d_array(result)\n    return result",
    ".xarray.core.indexing.py@@ExplicitIndexer.tuple": "def tuple(self):\n    return self._key",
    ".xarray.core.utils.py@@to_0d_array": "def to_0d_array(value: Any) -> np.ndarray:\n    if np.isscalar(value) or (isinstance(value, np.ndarray) and value.ndim == 0):\n        return np.array(value)\n    else:\n        return to_0d_object_array(value)",
    ".xarray.core.utils.py@@to_0d_object_array": "def to_0d_object_array(value: Any) -> np.ndarray:\n    result = np.empty((), dtype=object)\n    result[()] = value\n    return result",
    ".xarray.core.variable.py@@IndexVariable._finalize_indexing_result": "def _finalize_indexing_result(self, dims, data):\n    if getattr(data, 'ndim', 0) != 1:\n        return Variable(dims, data, self._attrs, self._encoding)\n    else:\n        return type(self)(dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@_possibly_convert_objects": "def _possibly_convert_objects(values):\n    return np.asarray(pd.Series(values.ravel())).reshape(values.shape)",
    ".xarray.core.indexing.py@@as_integer_slice": "def as_integer_slice(value):\n    start = as_integer_or_none(value.start)\n    stop = as_integer_or_none(value.stop)\n    step = as_integer_or_none(value.step)\n    return slice(start, stop, step)",
    ".xarray.core.indexing.py@@as_integer_or_none": "def as_integer_or_none(value):\n    return None if value is None else operator.index(value)",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter.__init__": "def __init__(self, array):\n    if not isinstance(array, np.ndarray):\n        raise TypeError('NumpyIndexingAdapter only wraps np.ndarray. Trying to wrap {}'.format(type(array)))\n    self.array = array",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter.__getitem__": "def __getitem__(self, key):\n    array, key = self._indexing_array_and_key(key)\n    return array[key]",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter._indexing_array_and_key": "def _indexing_array_and_key(self, key):\n    if isinstance(key, OuterIndexer):\n        array = self.array\n        key = _outer_to_numpy_indexer(key, self.array.shape)\n    elif isinstance(key, VectorizedIndexer):\n        array = nputils.NumpyVIndexAdapter(self.array)\n        key = key.tuple\n    elif isinstance(key, BasicIndexer):\n        array = self.array\n        key = key.tuple + (Ellipsis,)\n    else:\n        raise TypeError('unexpected key type: {}'.format(type(key)))\n    return (array, key)",
    ".xarray.core.variable.py@@Variable._finalize_indexing_result": "def _finalize_indexing_result(self: VariableType, dims, data) -> VariableType:\n    return type(self)(dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> Dict[Hashable, Any]:\n    if self._attrs is None:\n        self._attrs = {}\n    return self._attrs",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self):\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.core.dataset.py@@Dataset._overwrite_indexes": "def _overwrite_indexes(self, indexes: Mapping[Any, pd.Index]) -> 'Dataset':\n    if not indexes:\n        return self\n    variables = self._variables.copy()\n    new_indexes = dict(self.indexes)\n    for name, idx in indexes.items():\n        variables[name] = IndexVariable(name, idx)\n        new_indexes[name] = idx\n    obj = self._replace(variables, indexes=new_indexes)\n    dim_names: Dict[Hashable, str] = {}\n    for dim, idx in indexes.items():\n        if not isinstance(idx, pd.MultiIndex) and idx.name != dim:\n            dim_names[dim] = idx.name\n    if dim_names:\n        obj = obj.rename(dim_names)\n    return obj",
    ".xarray.core.dataarray.py@@DataArray.name": "def name(self) -> Optional[Hashable]:\n    return self._name",
    ".xarray.core.common.py@@DataWithCoords.squeeze": "def squeeze(self, dim: Union[Hashable, Iterable[Hashable], None]=None, drop: bool=False, axis: Union[int, Iterable[int], None]=None):\n    dims = get_squeeze_dims(self, dim, axis)\n    return self.isel(drop=drop, **{d: 0 for d in dims})",
    ".xarray.core.common.py@@get_squeeze_dims": "def get_squeeze_dims(xarray_obj, dim: Union[Hashable, Iterable[Hashable], None]=None, axis: Union[int, Iterable[int], None]=None) -> List[Hashable]:\n    if dim is not None and axis is not None:\n        raise ValueError('cannot use both parameters `axis` and `dim`')\n    if dim is None and axis is None:\n        return [d for d, s in xarray_obj.sizes.items() if s == 1]\n    if isinstance(dim, Iterable) and (not isinstance(dim, str)):\n        dim = list(dim)\n    elif dim is not None:\n        dim = [dim]\n    else:\n        assert axis is not None\n        if isinstance(axis, int):\n            axis = [axis]\n        axis = list(axis)\n        if any((not isinstance(a, int) for a in axis)):\n            raise TypeError('parameter `axis` must be int or iterable of int.')\n        alldims = list(xarray_obj.sizes.keys())\n        dim = [alldims[a] for a in axis]\n    if any((xarray_obj.sizes[k] > 1 for k in dim)):\n        raise ValueError('cannot select a dimension to squeeze out which has length greater than one')\n    return dim",
    ".xarray.core.common.py@@AbstractArray.sizes": "def sizes(self: Any) -> Mapping[Hashable, int]:\n    return Frozen(dict(zip(self.dims, self.shape)))",
    ".xarray.core.indexes.py@@default_indexes": "def default_indexes(coords: Mapping[Any, Variable], dims: Iterable) -> Dict[Hashable, pd.Index]:\n    return {key: coords[key].to_index() for key in dims if key in coords}",
    ".xarray.core.variable.py@@IndexVariable.name": "def name(self):\n    return self.dims[0]",
    ".xarray.core.variable.py@@Variable._validate_indexers": "def _validate_indexers(self, key):\n    for dim, k in zip(self.dims, key):\n        if isinstance(k, BASIC_INDEXING_TYPES):\n            pass\n        else:\n            if not isinstance(k, Variable):\n                k = np.asarray(k)\n                if k.ndim > 1:\n                    raise IndexError('Unlabeled multi-dimensional array cannot be used for indexing: {}'.format(k))\n            if k.dtype.kind == 'b':\n                if self.shape[self.get_axis_num(dim)] != len(k):\n                    raise IndexError('Boolean array size {:d} is used to index array with shape {:s}.'.format(len(k), str(self.shape)))\n                if k.ndim > 1:\n                    raise IndexError('{}-dimensional boolean indexing is not supported. '.format(k.ndim))\n                if getattr(k, 'dims', (dim,)) != (dim,):\n                    raise IndexError('Boolean indexer should be unlabeled or on the same dimension to the indexed array. Indexer is on {:s} but the target dimension is {:s}.'.format(str(k.dims), dim))",
    ".xarray.core.common.py@@AbstractArray.get_axis_num": "def get_axis_num(self, dim: Union[Hashable, Iterable[Hashable]]) -> Union[int, Tuple[int, ...]]:\n    if isinstance(dim, Iterable) and (not isinstance(dim, str)):\n        return tuple((self._get_axis_num(d) for d in dim))\n    else:\n        return self._get_axis_num(dim)",
    ".xarray.core.common.py@@AbstractArray._get_axis_num": "def _get_axis_num(self: Any, dim: Hashable) -> int:\n    try:\n        return self.dims.index(dim)\n    except ValueError:\n        raise ValueError(f'{dim!r} not found in array dimensions {self.dims!r}')",
    ".xarray.core.variable.py@@Variable._broadcast_indexes_outer": "def _broadcast_indexes_outer(self, key):\n    dims = tuple((k.dims[0] if isinstance(k, Variable) else dim for k, dim in zip(key, self.dims) if not isinstance(k, integer_types)))\n    new_key = []\n    for k in key:\n        if isinstance(k, Variable):\n            k = k.data\n        if not isinstance(k, BASIC_INDEXING_TYPES):\n            k = np.asarray(k)\n            if k.size == 0:\n                k = k.astype(int)\n            elif k.dtype.kind == 'b':\n                k, = np.nonzero(k)\n        new_key.append(k)\n    return (dims, OuterIndexer(tuple(new_key)), None)",
    ".xarray.core.indexing.py@@OuterIndexer.__init__": "def __init__(self, key):\n    if not isinstance(key, tuple):\n        raise TypeError(f'key must be a tuple: {key!r}')\n    new_key = []\n    for k in key:\n        if isinstance(k, integer_types):\n            k = int(k)\n        elif isinstance(k, slice):\n            k = as_integer_slice(k)\n        elif isinstance(k, np.ndarray):\n            if not np.issubdtype(k.dtype, np.integer):\n                raise TypeError(f'invalid indexer array, does not have integer dtype: {k!r}')\n            if k.ndim != 1:\n                raise TypeError(f'invalid indexer array for {type(self).__name__}; must have exactly 1 dimension: {k!r}')\n            k = np.asarray(k, dtype=np.int64)\n        else:\n            raise TypeError(f'unexpected indexer type for {type(self).__name__}: {k!r}')\n        new_key.append(k)\n    super().__init__(new_key)",
    ".xarray.core.indexing.py@@_outer_to_numpy_indexer": "def _outer_to_numpy_indexer(key, shape):\n    if len([k for k in key.tuple if not isinstance(k, slice)]) <= 1:\n        return key.tuple\n    else:\n        return _outer_to_vectorized_indexer(key, shape).tuple",
    ".xarray.core.dataset.py@@Dataset._replace": "def _replace(self, variables: Dict[Hashable, Variable]=None, coord_names: Set[Hashable]=None, dims: Dict[Any, int]=None, attrs: Union[Dict[Hashable, Any], None, Default]=_default, indexes: Union[Dict[Any, pd.Index], None, Default]=_default, encoding: Union[dict, None, Default]=_default, inplace: bool=False) -> 'Dataset':\n    if inplace:\n        if variables is not None:\n            self._variables = variables\n        if coord_names is not None:\n            self._coord_names = coord_names\n        if dims is not None:\n            self._dims = dims\n        if attrs is not _default:\n            self._attrs = attrs\n        if indexes is not _default:\n            self._indexes = indexes\n        if encoding is not _default:\n            self._encoding = encoding\n        obj = self\n    else:\n        if variables is None:\n            variables = self._variables.copy()\n        if coord_names is None:\n            coord_names = self._coord_names.copy()\n        if dims is None:\n            dims = self._dims.copy()\n        if attrs is _default:\n            attrs = copy.copy(self._attrs)\n        if indexes is _default:\n            indexes = copy.copy(self._indexes)\n        if encoding is _default:\n            encoding = copy.copy(self._encoding)\n        obj = self._construct_direct(variables, coord_names, dims, attrs, indexes, encoding)\n    return obj",
    ".xarray.core.dataset.py@@Dataset.rename": "def rename(self, name_dict: Mapping[Hashable, Hashable]=None, inplace: bool=None, **names: Hashable) -> 'Dataset':\n    _check_inplace(inplace)\n    name_dict = either_dict_or_kwargs(name_dict, names, 'rename')\n    for k in name_dict.keys():\n        if k not in self and k not in self.dims:\n            raise ValueError('cannot rename %r because it is not a variable or dimension in this dataset' % k)\n    variables, coord_names, dims, indexes = self._rename_all(name_dict=name_dict, dims_dict=name_dict)\n    assert_unique_multiindex_level_names(variables)\n    return self._replace(variables, coord_names, dims=dims, indexes=indexes)",
    ".xarray.core.utils.py@@_check_inplace": "def _check_inplace(inplace: Optional[bool]) -> None:\n    if inplace is not None:\n        raise TypeError(\"The `inplace` argument has been removed from xarray. You can achieve an identical effect with python's standard assignment.\")",
    ".xarray.core.dataset.py@@Dataset.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self._variables",
    ".xarray.core.dataset.py@@Dataset._rename_all": "def _rename_all(self, name_dict, dims_dict):\n    variables, coord_names = self._rename_vars(name_dict, dims_dict)\n    dims = self._rename_dims(dims_dict)\n    indexes = self._rename_indexes(name_dict, dims.keys())\n    return (variables, coord_names, dims, indexes)",
    ".xarray.core.dataset.py@@Dataset._rename_vars": "def _rename_vars(self, name_dict, dims_dict):\n    variables = {}\n    coord_names = set()\n    for k, v in self.variables.items():\n        var = v.copy(deep=False)\n        var.dims = tuple((dims_dict.get(dim, dim) for dim in v.dims))\n        name = name_dict.get(k, k)\n        if name in variables:\n            raise ValueError(f'the new name {name!r} conflicts')\n        variables[name] = var\n        if k in self._coord_names:\n            coord_names.add(name)\n    return (variables, coord_names)",
    ".xarray.core.variable.py@@IndexVariable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data.copy(deep=deep)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.copy": "def copy(self, deep: bool=True) -> 'PandasIndexAdapter':\n    array = self.array.copy(deep=True) if deep else self.array\n    return PandasIndexAdapter(array, self._dtype)",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data\n        if isinstance(data, indexing.MemoryCachedArray):\n            data = indexing.MemoryCachedArray(data.array)\n        if deep:\n            if hasattr(data, '__array_function__') or isinstance(data, dask_array_type):\n                data = data.copy()\n            elif not isinstance(data, PandasIndexAdapter):\n                data = np.array(data)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return self._replace(data=data)",
    ".xarray.core.variable.py@@Variable._replace": "def _replace(self, dims=_default, data=_default, attrs=_default, encoding=_default) -> 'Variable':\n    if dims is _default:\n        dims = copy.copy(self._dims)\n    if data is _default:\n        data = copy.copy(self.data)\n    if attrs is _default:\n        attrs = copy.copy(self._attrs)\n    if encoding is _default:\n        encoding = copy.copy(self._encoding)\n    return type(self)(dims, data, attrs, encoding, fastpath=True)",
    ".xarray.core.dataset.py@@Dataset._rename_dims": "def _rename_dims(self, name_dict):\n    return {name_dict.get(k, k): v for k, v in self.dims.items()}",
    ".xarray.core.utils.py@@SortedKeysDict.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.dataset.py@@Dataset._rename_indexes": "def _rename_indexes(self, name_dict, dims_set):\n    if self._indexes is None:\n        return None\n    indexes = {}\n    for k, v in self.indexes.items():\n        new_name = name_dict.get(k, k)\n        if new_name not in dims_set:\n            continue\n        if isinstance(v, pd.MultiIndex):\n            new_names = [name_dict.get(k, k) for k in v.names]\n            index = v.rename(names=new_names)\n        else:\n            index = v.rename(new_name)\n        indexes[new_name] = index\n    return indexes",
    ".xarray.core.variable.py@@assert_unique_multiindex_level_names": "def assert_unique_multiindex_level_names(variables):\n    level_names = defaultdict(list)\n    all_level_names = set()\n    for var_name, var in variables.items():\n        if isinstance(var._data, PandasIndexAdapter):\n            idx_level_names = var.to_index_variable().level_names\n            if idx_level_names is not None:\n                for n in idx_level_names:\n                    level_names[n].append(f'{n!r} ({var_name})')\n            if idx_level_names:\n                all_level_names.update(idx_level_names)\n    for k, v in level_names.items():\n        if k in variables:\n            v.append('(%s)' % k)\n    duplicate_names = [v for v in level_names.values() if len(v) > 1]\n    if duplicate_names:\n        conflict_str = '\\n'.join((', '.join(v) for v in duplicate_names))\n        raise ValueError('conflicting MultiIndex level name(s):\\n%s' % conflict_str)\n    for k, v in variables.items():\n        for d in v.dims:\n            if d in all_level_names:\n                raise ValueError('conflicting level / dimension names. {} already exists as a level name.'.format(d))"
}
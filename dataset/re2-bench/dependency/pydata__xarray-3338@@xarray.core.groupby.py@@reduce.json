{
    ".xarray.core.options.py@@_get_keep_attrs": "def _get_keep_attrs(default):\n    global_choice = OPTIONS['keep_attrs']\n    if global_choice == 'default':\n        return default\n    elif global_choice in [True, False]:\n        return global_choice\n    else:\n        raise ValueError(\"The global option keep_attrs must be one of True, False or 'default'.\")",
    ".xarray.core.groupby.py@@GroupBy.dims": "def dims(self):\n    if self._dims is None:\n        self._dims = self._obj.isel(**{self._group_dim: self._group_indices[0]}).dims\n    return self._dims",
    ".xarray.core.dataset.py@@Dataset.isel": "def isel(self, indexers: Mapping[Hashable, Any]=None, drop: bool=False, **indexers_kwargs: Any) -> 'Dataset':\n    indexers = either_dict_or_kwargs(indexers, indexers_kwargs, 'isel')\n    indexers_list = list(self._validate_indexers(indexers))\n    variables = OrderedDict()\n    indexes = OrderedDict()\n    for name, var in self.variables.items():\n        var_indexers = {k: v for k, v in indexers_list if k in var.dims}\n        if drop and name in var_indexers:\n            continue\n        if name in self.indexes:\n            new_var, new_index = isel_variable_and_index(name, var, self.indexes[name], var_indexers)\n            if new_index is not None:\n                indexes[name] = new_index\n        elif var_indexers:\n            new_var = var.isel(indexers=var_indexers)\n        else:\n            new_var = var.copy(deep=False)\n        variables[name] = new_var\n    coord_names = self._coord_names & variables.keys()\n    selected = self._replace_with_new_dims(variables, coord_names, indexes)\n    coord_vars, new_indexes = selected._get_indexers_coords_and_indexes(indexers)\n    variables.update(coord_vars)\n    indexes.update(new_indexes)\n    coord_names = self._coord_names & variables.keys() | coord_vars.keys()\n    return self._replace_with_new_dims(variables, coord_names, indexes=indexes)",
    ".xarray.core.utils.py@@either_dict_or_kwargs": "def either_dict_or_kwargs(pos_kwargs: Optional[Mapping[Hashable, T]], kw_kwargs: Mapping[str, T], func_name: str) -> Mapping[Hashable, T]:\n    if pos_kwargs is not None:\n        if not is_dict_like(pos_kwargs):\n            raise ValueError('the first argument to .%s must be a dictionary' % func_name)\n        if kw_kwargs:\n            raise ValueError('cannot specify both keyword and positional arguments to .%s' % func_name)\n        return pos_kwargs\n    else:\n        return cast(Mapping[Hashable, T], kw_kwargs)",
    ".xarray.core.dataset.py@@Dataset._validate_indexers": "def _validate_indexers(self, indexers: Mapping[Hashable, Any]) -> Iterator[Tuple[Hashable, Union[int, slice, np.ndarray, Variable]]]:\n    from .dataarray import DataArray\n    invalid = indexers.keys() - self.dims.keys()\n    if invalid:\n        raise ValueError('dimensions %r do not exist' % invalid)\n    for k, v in indexers.items():\n        if isinstance(v, (int, slice, Variable)):\n            yield (k, v)\n        elif isinstance(v, DataArray):\n            yield (k, v.variable)\n        elif isinstance(v, tuple):\n            yield (k, as_variable(v))\n        elif isinstance(v, Dataset):\n            raise TypeError('cannot use a Dataset as an indexer')\n        elif isinstance(v, Sequence) and len(v) == 0:\n            yield (k, np.empty((0,), dtype='int64'))\n        else:\n            v = np.asarray(v)\n            if v.dtype.kind in 'US':\n                index = self.indexes[k]\n                if isinstance(index, pd.DatetimeIndex):\n                    v = v.astype('datetime64[ns]')\n                elif isinstance(index, xr.CFTimeIndex):\n                    v = _parse_array_of_cftime_strings(v, index.date_type)\n            if v.ndim > 1:\n                raise IndexError('Unlabeled multi-dimensional array cannot be used for indexing: {}'.format(k))\n            yield (k, v)",
    ".xarray.core.dataset.py@@Dataset.dims": "def dims(self) -> Mapping[Hashable, int]:\n    return Frozen(SortedKeysDict(self._dims))",
    ".xarray.core.utils.py@@SortedKeysDict.__init__": "def __init__(self, mapping: MutableMapping[K, V]=None):\n    self.mapping = {} if mapping is None else mapping",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.utils.py@@SortedKeysDict.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(sorted(self.mapping))",
    ".xarray.core.dataset.py@@Dataset.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen(self._variables)",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self):\n    return self._dims",
    ".xarray.core.dataset.py@@Dataset.indexes": "def indexes(self) -> Indexes:\n    if self._indexes is None:\n        self._indexes = default_indexes(self._variables, self._dims)\n    return Indexes(self._indexes)",
    ".xarray.core.indexes.py@@Indexes.__init__": "def __init__(self, indexes):\n    self._indexes = indexes",
    ".xarray.core.indexes.py@@Indexes.__contains__": "def __contains__(self, key):\n    return key in self._indexes",
    ".xarray.core.variable.py@@Variable.isel": "def isel(self: VariableType, indexers: Mapping[Hashable, Any]=None, **indexers_kwargs: Any) -> VariableType:\n    indexers = either_dict_or_kwargs(indexers, indexers_kwargs, 'isel')\n    invalid = indexers.keys() - set(self.dims)\n    if invalid:\n        raise ValueError('dimensions %r do not exist' % invalid)\n    key = tuple((indexers.get(dim, slice(None)) for dim in self.dims))\n    return self[key]",
    ".xarray.core.utils.py@@is_dict_like": "def is_dict_like(value: Any) -> bool:\n    return hasattr(value, 'keys') and hasattr(value, '__getitem__')",
    ".xarray.core.variable.py@@Variable.__getitem__": "def __getitem__(self: VariableType, key) -> VariableType:\n    dims, indexer, new_order = self._broadcast_indexes(key)\n    data = as_indexable(self._data)[indexer]\n    if new_order:\n        data = duck_array_ops.moveaxis(data, range(len(new_order)), new_order)\n    return self._finalize_indexing_result(dims, data)",
    ".xarray.core.variable.py@@Variable._broadcast_indexes": "def _broadcast_indexes(self, key):\n    key = self._item_key_to_tuple(key)\n    key = indexing.expanded_indexer(key, self.ndim)\n    key = tuple((k.data.item() if isinstance(k, Variable) and k.ndim == 0 else k for k in key))\n    key = tuple((k.item() if isinstance(k, np.ndarray) and k.ndim == 0 else k for k in key))\n    if all((isinstance(k, BASIC_INDEXING_TYPES) for k in key)):\n        return self._broadcast_indexes_basic(key)\n    self._validate_indexers(key)\n    if all((not isinstance(k, Variable) for k in key)):\n        return self._broadcast_indexes_outer(key)\n    dims = []\n    for k, d in zip(key, self.dims):\n        if isinstance(k, Variable):\n            if len(k.dims) > 1:\n                return self._broadcast_indexes_vectorized(key)\n            dims.append(k.dims[0])\n        elif not isinstance(k, integer_types):\n            dims.append(d)\n    if len(set(dims)) == len(dims):\n        return self._broadcast_indexes_outer(key)\n    return self._broadcast_indexes_vectorized(key)",
    ".xarray.core.variable.py@@Variable._item_key_to_tuple": "def _item_key_to_tuple(self, key):\n    if utils.is_dict_like(key):\n        return tuple((key.get(dim, slice(None)) for dim in self.dims))\n    else:\n        return key",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.indexing.py@@expanded_indexer": "def expanded_indexer(key, ndim):\n    if not isinstance(key, tuple):\n        key = (key,)\n    new_key = []\n    found_ellipsis = False\n    for k in key:\n        if k is Ellipsis:\n            if not found_ellipsis:\n                new_key.extend((ndim + 1 - len(key)) * [slice(None)])\n                found_ellipsis = True\n            else:\n                new_key.append(slice(None))\n        else:\n            new_key.append(k)\n    if len(new_key) > ndim:\n        raise IndexError('too many indices')\n    new_key.extend((ndim - len(new_key)) * [slice(None)])\n    return tuple(new_key)",
    ".xarray.core.variable.py@@Variable._broadcast_indexes_basic": "def _broadcast_indexes_basic(self, key):\n    dims = tuple((dim for k, dim in zip(key, self.dims) if not isinstance(k, integer_types)))\n    return (dims, BasicIndexer(key), None)",
    ".xarray.core.indexing.py@@BasicIndexer.__init__": "def __init__(self, key):\n    if not isinstance(key, tuple):\n        raise TypeError('key must be a tuple: {!r}'.format(key))\n    new_key = []\n    for k in key:\n        if isinstance(k, integer_types):\n            k = int(k)\n        elif isinstance(k, slice):\n            k = as_integer_slice(k)\n        else:\n            raise TypeError('unexpected indexer type for {}: {!r}'.format(type(self).__name__, k))\n        new_key.append(k)\n    super().__init__(new_key)",
    ".xarray.core.indexing.py@@as_integer_slice": "def as_integer_slice(value):\n    start = as_integer_or_none(value.start)\n    stop = as_integer_or_none(value.stop)\n    step = as_integer_or_none(value.step)\n    return slice(start, stop, step)",
    ".xarray.core.indexing.py@@as_integer_or_none": "def as_integer_or_none(value):\n    return None if value is None else operator.index(value)",
    ".xarray.core.indexing.py@@ExplicitIndexer.__init__": "def __init__(self, key):\n    if type(self) is ExplicitIndexer:\n        raise TypeError('cannot instantiate base ExplicitIndexer objects')\n    self._key = tuple(key)",
    ".xarray.core.indexing.py@@as_indexable": "def as_indexable(array):\n    if isinstance(array, ExplicitlyIndexed):\n        return array\n    if isinstance(array, np.ndarray):\n        return NumpyIndexingAdapter(array)\n    if isinstance(array, pd.Index):\n        return PandasIndexAdapter(array)\n    if isinstance(array, dask_array_type):\n        return DaskIndexingAdapter(array)\n    if hasattr(array, '__array_function__'):\n        return NdArrayLikeIndexingAdapter(array)\n    raise TypeError('Invalid array type: {}'.format(type(array)))",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter.__init__": "def __init__(self, array):\n    if not isinstance(array, np.ndarray):\n        raise TypeError('NumpyIndexingAdapter only wraps np.ndarray. Trying to wrap {}'.format(type(array)))\n    self.array = array",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter.__getitem__": "def __getitem__(self, key):\n    array, key = self._indexing_array_and_key(key)\n    return array[key]",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter._indexing_array_and_key": "def _indexing_array_and_key(self, key):\n    if isinstance(key, OuterIndexer):\n        array = self.array\n        key = _outer_to_numpy_indexer(key, self.array.shape)\n    elif isinstance(key, VectorizedIndexer):\n        array = nputils.NumpyVIndexAdapter(self.array)\n        key = key.tuple\n    elif isinstance(key, BasicIndexer):\n        array = self.array\n        key = key.tuple + (Ellipsis,)\n    else:\n        raise TypeError('unexpected key type: {}'.format(type(key)))\n    return (array, key)",
    ".xarray.core.indexing.py@@ExplicitIndexer.tuple": "def tuple(self):\n    return self._key",
    ".xarray.core.variable.py@@Variable._finalize_indexing_result": "def _finalize_indexing_result(self: VariableType, dims, data) -> VariableType:\n    return type(self)(dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, Variable):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    data = getattr(data, 'values', data)\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, '__array_function__'):\n            if IS_NEP18_ACTIVE:\n                return data\n            else:\n                raise TypeError('Got an NumPy-like array type providing the __array_function__ protocol but NEP18 is not enabled. Check that numpy >= v1.16 and that the environment variable \"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\" is set to \"1\"')\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == 'O':\n            data = _possibly_convert_objects(data)\n        elif data.dtype.kind == 'M':\n            data = np.asarray(data, 'datetime64[ns]')\n        elif data.dtype.kind == 'm':\n            data = np.asarray(data, 'timedelta64[ns]')\n    return _maybe_wrap_data(data)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims):\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError('dimensions %s must have the same length as the number of data dimensions, ndim=%s' % (dims, self.ndim))\n    return dims",
    ".xarray.core.indexes.py@@Indexes.__getitem__": "def __getitem__(self, key):\n    return self._indexes[key]",
    ".xarray.core.indexes.py@@isel_variable_and_index": "def isel_variable_and_index(name: Hashable, variable: Variable, index: pd.Index, indexers: Mapping[Hashable, Union[int, slice, np.ndarray, Variable]]) -> Tuple[Variable, Optional[pd.Index]]:\n    if not indexers:\n        return (variable.copy(deep=False), index)\n    if len(variable.dims) > 1:\n        raise NotImplementedError('indexing multi-dimensional variable with indexes is not supported yet')\n    new_variable = variable.isel(indexers)\n    if new_variable.dims != (name,):\n        return (new_variable, None)\n    dim, = variable.dims\n    indexer = indexers[dim]\n    if isinstance(indexer, Variable):\n        indexer = indexer.data\n    new_index = index[indexer]\n    return (new_variable, new_index)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.shape": "def shape(self) -> Tuple[int]:\n    return (len(self.array),)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__getitem__": "def __getitem__(self, indexer) -> Union[NumpyIndexingAdapter, np.ndarray, np.datetime64, np.timedelta64]:\n    key = indexer.tuple\n    if isinstance(key, tuple) and len(key) == 1:\n        key, = key\n    if getattr(key, 'ndim', 0) > 1:\n        return NumpyIndexingAdapter(self.array.values)[indexer]\n    result = self.array[key]\n    if isinstance(result, pd.Index):\n        result = PandasIndexAdapter(result, dtype=self.dtype)\n    else:\n        if result is pd.NaT:\n            result = np.datetime64('NaT', 'ns')\n        elif isinstance(result, timedelta):\n            result = np.timedelta64(getattr(result, 'value', result), 'ns')\n        elif isinstance(result, pd.Timestamp):\n            result = np.asarray(result.to_datetime64())\n        elif self.dtype != object:\n            result = np.asarray(result, dtype=self.dtype)\n        result = utils.to_0d_array(result)\n    return result",
    ".xarray.core.indexing.py@@PandasIndexAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.utils.py@@to_0d_array": "def to_0d_array(value: Any) -> np.ndarray:\n    if np.isscalar(value) or (isinstance(value, np.ndarray) and value.ndim == 0):\n        return np.array(value)\n    else:\n        return to_0d_object_array(value)",
    ".xarray.core.utils.py@@to_0d_object_array": "def to_0d_object_array(value: Any) -> np.ndarray:\n    result = np.empty((), dtype=object)\n    result[()] = value\n    return result",
    ".xarray.core.variable.py@@IndexVariable._finalize_indexing_result": "def _finalize_indexing_result(self, dims, data):\n    if getattr(data, 'ndim', 0) != 1:\n        return Variable(dims, data, self._attrs, self._encoding)\n    else:\n        return type(self)(dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@_possibly_convert_objects": "def _possibly_convert_objects(values):\n    return np.asarray(pd.Series(values.ravel())).reshape(values.shape)",
    ".xarray.core.dataset.py@@Dataset._replace_with_new_dims": "def _replace_with_new_dims(self, variables: 'OrderedDict[Any, Variable]', coord_names: set=None, attrs: Optional['OrderedDict']=__default, indexes: 'OrderedDict[Any, pd.Index]'=__default, inplace: bool=False) -> 'Dataset':\n    dims = calculate_dimensions(variables)\n    return self._replace(variables, coord_names, dims, attrs, indexes, inplace=inplace)",
    ".xarray.core.dataset.py@@calculate_dimensions": "def calculate_dimensions(variables: Mapping[Hashable, Variable]) -> 'Dict[Any, int]':\n    dims: Dict[Any, int] = {}\n    last_used = {}\n    scalar_vars = {k for k, v in variables.items() if not v.dims}\n    for k, var in variables.items():\n        for dim, size in zip(var.dims, var.shape):\n            if dim in scalar_vars:\n                raise ValueError('dimension %r already exists as a scalar variable' % dim)\n            if dim not in dims:\n                dims[dim] = size\n                last_used[dim] = k\n            elif dims[dim] != size:\n                raise ValueError('conflicting sizes for dimension %r: length %s on %r and length %s on %r' % (dim, size, k, dims[dim], last_used[dim]))\n    return dims",
    ".xarray.core.dataset.py@@Dataset._replace": "def _replace(self, variables: 'OrderedDict[Any, Variable]'=None, coord_names: Set[Hashable]=None, dims: Dict[Any, int]=None, attrs: 'Optional[OrderedDict]'=__default, indexes: 'Optional[OrderedDict[Any, pd.Index]]'=__default, encoding: Optional[dict]=__default, inplace: bool=False) -> 'Dataset':\n    if inplace:\n        if variables is not None:\n            self._variables = variables\n        if coord_names is not None:\n            self._coord_names = coord_names\n        if dims is not None:\n            self._dims = dims\n        if attrs is not self.__default:\n            self._attrs = attrs\n        if indexes is not self.__default:\n            self._indexes = indexes\n        if encoding is not self.__default:\n            self._encoding = encoding\n        obj = self\n    else:\n        if variables is None:\n            variables = self._variables.copy()\n        if coord_names is None:\n            coord_names = self._coord_names.copy()\n        if dims is None:\n            dims = self._dims.copy()\n        if attrs is self.__default:\n            attrs = copy.copy(self._attrs)\n        if indexes is self.__default:\n            indexes = copy.copy(self._indexes)\n        if encoding is self.__default:\n            encoding = copy.copy(self._encoding)\n        obj = self._construct_direct(variables, coord_names, dims, attrs, indexes, encoding)\n    return obj",
    ".xarray.core.dataset.py@@Dataset._construct_direct": "def _construct_direct(cls, variables, coord_names, dims=None, attrs=None, indexes=None, encoding=None, file_obj=None):\n    if dims is None:\n        dims = calculate_dimensions(variables)\n    obj = object.__new__(cls)\n    obj._variables = variables\n    obj._coord_names = coord_names\n    obj._dims = dims\n    obj._indexes = indexes\n    obj._attrs = attrs\n    obj._file_obj = file_obj\n    obj._encoding = encoding\n    obj._accessors = None\n    return obj",
    ".xarray.core.common.py@@AttrAccessMixin.__setattr__": "def __setattr__(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '%r object has no attribute %r' % (type(self).__name__, name):\n            raise\n        raise AttributeError(\"cannot set attribute %r on a %r object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\" % (name, type(self).__name__)) from e",
    ".xarray.core.dataset.py@@Dataset._get_indexers_coords_and_indexes": "def _get_indexers_coords_and_indexes(self, indexers):\n    from .dataarray import DataArray\n    coords_list = []\n    for k, v in indexers.items():\n        if isinstance(v, DataArray):\n            if v.dtype.kind == 'b':\n                if v.ndim != 1:\n                    raise ValueError('{:d}d-boolean array is used for indexing along dimension {!r}, but only 1d boolean arrays are supported.'.format(v.ndim, k))\n                v_coords = v[v.values.nonzero()[0]].coords\n            else:\n                v_coords = v.coords\n            coords_list.append(v_coords)\n    coords, indexes = merge_coordinates_without_align(coords_list)\n    assert_coordinate_consistent(self, coords)\n    attached_coords = OrderedDict(((k, v) for k, v in coords.items() if k not in self._variables))\n    attached_indexes = OrderedDict(((k, v) for k, v in indexes.items() if k not in self._variables))\n    return (attached_coords, attached_indexes)",
    ".xarray.core.merge.py@@merge_coordinates_without_align": "def merge_coordinates_without_align(objects: 'List[Coordinates]', prioritized: Mapping[Hashable, MergeElement]=None, exclude_dims: AbstractSet=frozenset()) -> Tuple['OrderedDict[Hashable, Variable]', 'OrderedDict[Hashable, pd.Index]']:\n    collected = collect_from_coordinates(objects)\n    if exclude_dims:\n        filtered = OrderedDict()\n        for name, elements in collected.items():\n            new_elements = [(variable, index) for variable, index in elements if exclude_dims.isdisjoint(variable.dims)]\n            if new_elements:\n                filtered[name] = new_elements\n    else:\n        filtered = collected\n    return merge_collected(filtered, prioritized)",
    ".xarray.core.merge.py@@collect_from_coordinates": "def collect_from_coordinates(list_of_coords: 'List[Coordinates]') -> 'OrderedDict[Hashable, List[MergeElement]]':\n    grouped = OrderedDict()\n    for coords in list_of_coords:\n        variables = coords.variables\n        indexes = coords.indexes\n        for name, variable in variables.items():\n            value = grouped.setdefault(name, [])\n            value.append((variable, indexes.get(name)))\n    return grouped",
    ".xarray.core.merge.py@@merge_collected": "def merge_collected(grouped: 'OrderedDict[Hashable, List[MergeElement]]', prioritized: Mapping[Hashable, MergeElement]=None, compat: str='minimal') -> Tuple['OrderedDict[Hashable, Variable]', 'OrderedDict[Hashable, pd.Index]']:\n    if prioritized is None:\n        prioritized = {}\n    _assert_compat_valid(compat)\n    merged_vars = OrderedDict()\n    merged_indexes = OrderedDict()\n    for name, elements_list in grouped.items():\n        if name in prioritized:\n            variable, index = prioritized[name]\n            merged_vars[name] = variable\n            if index is not None:\n                merged_indexes[name] = index\n        else:\n            indexed_elements = [(variable, index) for variable, index in elements_list if index is not None]\n            if indexed_elements:\n                variable, index = indexed_elements[0]\n                for _, other_index in indexed_elements[1:]:\n                    if not index.equals(other_index):\n                        raise MergeError('conflicting values for index %r on objects to be combined:\\nfirst value: %r\\nsecond value: %r' % (name, index, other_index))\n                if compat == 'identical':\n                    for other_variable, _ in indexed_elements[1:]:\n                        if not dict_equiv(variable.attrs, other_variable.attrs):\n                            raise MergeError('conflicting attribute values on combined variable %r:\\nfirst value: %r\\nsecond value: %r' % (name, variable.attrs, other_variable.attrs))\n                merged_vars[name] = variable\n                merged_indexes[name] = index\n            else:\n                variables = [variable for variable, _ in elements_list]\n                try:\n                    merged_vars[name] = unique_variable(name, variables, compat)\n                except MergeError:\n                    if compat != 'minimal':\n                        raise\n    return (merged_vars, merged_indexes)",
    ".xarray.core.merge.py@@_assert_compat_valid": "def _assert_compat_valid(compat):\n    if compat not in _VALID_COMPAT:\n        raise ValueError('compat=%r invalid: must be %s' % (compat, set(_VALID_COMPAT)))",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.coordinates.py@@assert_coordinate_consistent": "def assert_coordinate_consistent(obj: Union['DataArray', 'Dataset'], coords: Mapping[Hashable, Variable]) -> None:\n    for k in obj.dims:\n        if k in coords and k in obj.coords:\n            if not coords[k].equals(obj[k].variable):\n                raise IndexError('dimension coordinate {!r} conflicts between indexed and indexing objects:\\n{}\\nvs.\\n{}'.format(k, obj[k], coords[k]))",
    ".xarray.core.utils.py@@SortedKeysDict.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping"
}
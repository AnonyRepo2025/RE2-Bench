{
    ".sklearn.metrics.ranking.py@@_binary_clf_curve": "def _binary_clf_curve(y_true, y_score, pos_label=None, sample_weight=None):\n    y_type = type_of_target(y_true)\n    if not (y_type == 'binary' or (y_type == 'multiclass' and pos_label is not None)):\n        raise ValueError('{0} format is not supported'.format(y_type))\n    check_consistent_length(y_true, y_score, sample_weight)\n    y_true = column_or_1d(y_true)\n    y_score = column_or_1d(y_score)\n    assert_all_finite(y_true)\n    assert_all_finite(y_score)\n    if sample_weight is not None:\n        sample_weight = column_or_1d(sample_weight)\n    classes = np.unique(y_true)\n    if pos_label is None and (not (np.array_equal(classes, [0, 1]) or np.array_equal(classes, [-1, 1]) or np.array_equal(classes, [0]) or np.array_equal(classes, [-1]) or np.array_equal(classes, [1]))):\n        raise ValueError('Data is not binary and pos_label is not specified')\n    elif pos_label is None:\n        pos_label = 1.0\n    y_true = y_true == pos_label\n    desc_score_indices = np.argsort(y_score, kind='mergesort')[::-1]\n    y_score = y_score[desc_score_indices]\n    y_true = y_true[desc_score_indices]\n    if sample_weight is not None:\n        weight = sample_weight[desc_score_indices]\n    else:\n        weight = 1.0\n    distinct_value_indices = np.where(np.diff(y_score))[0]\n    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n    tps = stable_cumsum(y_true * weight)[threshold_idxs]\n    if sample_weight is not None:\n        fps = stable_cumsum((1 - y_true) * weight)[threshold_idxs]\n    else:\n        fps = 1 + threshold_idxs - tps\n    return (fps, tps, y_score[threshold_idxs])",
    ".sklearn.utils.multiclass.py@@type_of_target": "def type_of_target(y):\n    valid = (isinstance(y, (Sequence, spmatrix)) or hasattr(y, '__array__')) and (not isinstance(y, str))\n    if not valid:\n        raise ValueError('Expected array-like (array or non-string sequence), got %r' % y)\n    sparseseries = y.__class__.__name__ == 'SparseSeries'\n    if sparseseries:\n        raise ValueError(\"y cannot be class 'SparseSeries'.\")\n    if is_multilabel(y):\n        return 'multilabel-indicator'\n    try:\n        y = np.asarray(y)\n    except ValueError:\n        return 'unknown'\n    try:\n        if not hasattr(y[0], '__array__') and isinstance(y[0], Sequence) and (not isinstance(y[0], str)):\n            raise ValueError('You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.')\n    except IndexError:\n        pass\n    if y.ndim > 2 or (y.dtype == object and len(y) and (not isinstance(y.flat[0], str))):\n        return 'unknown'\n    if y.ndim == 2 and y.shape[1] == 0:\n        return 'unknown'\n    if y.ndim == 2 and y.shape[1] > 1:\n        suffix = '-multioutput'\n    else:\n        suffix = ''\n    if y.dtype.kind == 'f' and np.any(y != y.astype(int)):\n        _assert_all_finite(y)\n        return 'continuous' + suffix\n    if len(np.unique(y)) > 2 or (y.ndim >= 2 and len(y[0]) > 1):\n        return 'multiclass' + suffix\n    else:\n        return 'binary'",
    ".sklearn.utils.multiclass.py@@is_multilabel": "def is_multilabel(y):\n    if hasattr(y, '__array__'):\n        y = np.asarray(y)\n    if not (hasattr(y, 'shape') and y.ndim == 2 and (y.shape[1] > 1)):\n        return False\n    if issparse(y):\n        if isinstance(y, (dok_matrix, lil_matrix)):\n            y = y.tocsr()\n        return len(y.data) == 0 or (np.unique(y.data).size == 1 and (y.dtype.kind in 'biu' or _is_integral_float(np.unique(y.data))))\n    else:\n        labels = np.unique(y)\n        return len(labels) < 3 and (y.dtype.kind in 'biu' or _is_integral_float(labels))",
    ".sklearn.utils.validation.py@@check_consistent_length": "def check_consistent_length(*arrays):\n    lengths = [_num_samples(X) for X in arrays if X is not None]\n    uniques = np.unique(lengths)\n    if len(uniques) > 1:\n        raise ValueError('Found input variables with inconsistent numbers of samples: %r' % [int(l) for l in lengths])",
    ".sklearn.utils.validation.py@@_num_samples": "def _num_samples(x):\n    if hasattr(x, 'fit') and callable(x.fit):\n        raise TypeError('Expected sequence or array-like, got estimator %s' % x)\n    if not hasattr(x, '__len__') and (not hasattr(x, 'shape')):\n        if hasattr(x, '__array__'):\n            x = np.asarray(x)\n        else:\n            raise TypeError('Expected sequence or array-like, got %s' % type(x))\n    if hasattr(x, 'shape'):\n        if len(x.shape) == 0:\n            raise TypeError('Singleton array %r cannot be considered a valid collection.' % x)\n        if isinstance(x.shape[0], numbers.Integral):\n            return x.shape[0]\n        else:\n            return len(x)\n    else:\n        return len(x)",
    ".sklearn.utils.validation.py@@column_or_1d": "def column_or_1d(y, warn=False):\n    shape = np.shape(y)\n    if len(shape) == 1:\n        return np.ravel(y)\n    if len(shape) == 2 and shape[1] == 1:\n        if warn:\n            warnings.warn('A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().', DataConversionWarning, stacklevel=2)\n        return np.ravel(y)\n    raise ValueError('bad input shape {0}'.format(shape))",
    ".sklearn.utils.validation.py@@assert_all_finite": "def assert_all_finite(X, allow_nan=False):\n    _assert_all_finite(X.data if sp.issparse(X) else X, allow_nan)",
    ".sklearn.utils.validation.py@@_assert_all_finite": "def _assert_all_finite(X, allow_nan=False):\n    from .extmath import _safe_accumulator_op\n    if _get_config()['assume_finite']:\n        return\n    X = np.asanyarray(X)\n    is_float = X.dtype.kind in 'fc'\n    if is_float and np.isfinite(_safe_accumulator_op(np.sum, X)):\n        pass\n    elif is_float:\n        msg_err = 'Input contains {} or a value too large for {!r}.'\n        if allow_nan and np.isinf(X).any() or (not allow_nan and (not np.isfinite(X).all())):\n            type_err = 'infinity' if allow_nan else 'NaN, infinity'\n            raise ValueError(msg_err.format(type_err, X.dtype))\n    elif X.dtype == np.dtype('object') and (not allow_nan):\n        if _object_dtype_isnan(X).any():\n            raise ValueError('Input contains NaN')",
    ".sklearn._config.py@@get_config": "def get_config():\n    return _global_config.copy()",
    ".sklearn.utils.extmath.py@@_safe_accumulator_op": "def _safe_accumulator_op(op, x, *args, **kwargs):\n    if np.issubdtype(x.dtype, np.floating) and x.dtype.itemsize < 8:\n        result = op(x, *args, **kwargs, dtype=np.float64)\n    else:\n        result = op(x, *args, **kwargs)\n    return result",
    ".sklearn.utils.extmath.py@@stable_cumsum": "def stable_cumsum(arr, axis=None, rtol=1e-05, atol=1e-08):\n    out = np.cumsum(arr, axis=axis, dtype=np.float64)\n    expected = np.sum(arr, axis=axis, dtype=np.float64)\n    if not np.all(np.isclose(out.take(-1, axis=axis), expected, rtol=rtol, atol=atol, equal_nan=True)):\n        warnings.warn('cumsum was found to be unstable: its last element does not correspond to sum', RuntimeWarning)\n    return out"
}
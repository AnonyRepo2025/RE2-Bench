{
    ".sklearn.metrics.pairwise.py@@_euclidean_distances": "def _euclidean_distances(X, Y, X_norm_squared=None, Y_norm_squared=None, squared=False):\n    if X_norm_squared is not None:\n        if X_norm_squared.dtype == np.float32:\n            XX = None\n        else:\n            XX = X_norm_squared.reshape(-1, 1)\n    elif X.dtype == np.float32:\n        XX = None\n    else:\n        XX = row_norms(X, squared=True)[:, np.newaxis]\n    if Y is X:\n        YY = None if XX is None else XX.T\n    elif Y_norm_squared is not None:\n        if Y_norm_squared.dtype == np.float32:\n            YY = None\n        else:\n            YY = Y_norm_squared.reshape(1, -1)\n    elif Y.dtype == np.float32:\n        YY = None\n    else:\n        YY = row_norms(Y, squared=True)[np.newaxis, :]\n    if X.dtype == np.float32:\n        distances = _euclidean_distances_upcast(X, XX, Y, YY)\n    else:\n        distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)\n        distances += XX\n        distances += YY\n    np.maximum(distances, 0, out=distances)\n    if X is Y:\n        np.fill_diagonal(distances, 0)\n    return distances if squared else np.sqrt(distances, out=distances)",
    ".sklearn.utils.extmath.py@@row_norms": "def row_norms(X, squared=False):\n    if sparse.issparse(X):\n        if not isinstance(X, sparse.csr_matrix):\n            X = sparse.csr_matrix(X)\n        norms = csr_row_norms(X)\n    else:\n        norms = np.einsum('ij,ij->i', X, X)\n    if not squared:\n        np.sqrt(norms, norms)\n    return norms",
    ".sklearn.utils.extmath.py@@safe_sparse_dot": "def safe_sparse_dot(a, b, *, dense_output=False):\n    if a.ndim > 2 or b.ndim > 2:\n        if sparse.issparse(a):\n            b_ = np.rollaxis(b, -2)\n            b_2d = b_.reshape((b.shape[-2], -1))\n            ret = a @ b_2d\n            ret = ret.reshape(a.shape[0], *b_.shape[1:])\n        elif sparse.issparse(b):\n            a_2d = a.reshape(-1, a.shape[-1])\n            ret = a_2d @ b\n            ret = ret.reshape(*a.shape[:-1], b.shape[1])\n        else:\n            ret = np.dot(a, b)\n    else:\n        ret = a @ b\n    if sparse.issparse(a) and sparse.issparse(b) and dense_output and hasattr(ret, 'toarray'):\n        return ret.toarray()\n    return ret",
    ".sklearn.utils.extmath.py@@stable_cumsum": "def stable_cumsum(arr, axis=None, rtol=1e-05, atol=1e-08):\n    out = np.cumsum(arr, axis=axis, dtype=np.float64)\n    expected = np.sum(arr, axis=axis, dtype=np.float64)\n    if not np.all(np.isclose(out.take(-1, axis=axis), expected, rtol=rtol, atol=atol, equal_nan=True)):\n        warnings.warn('cumsum was found to be unstable: its last element does not correspond to sum', RuntimeWarning)\n    return out",
    ".sklearn.metrics.pairwise.py@@_euclidean_distances_upcast": "def _euclidean_distances_upcast(X, XX=None, Y=None, YY=None, batch_size=None):\n    n_samples_X = X.shape[0]\n    n_samples_Y = Y.shape[0]\n    n_features = X.shape[1]\n    distances = np.empty((n_samples_X, n_samples_Y), dtype=np.float32)\n    if batch_size is None:\n        x_density = X.nnz / np.prod(X.shape) if issparse(X) else 1\n        y_density = Y.nnz / np.prod(Y.shape) if issparse(Y) else 1\n        maxmem = max(((x_density * n_samples_X + y_density * n_samples_Y) * n_features + x_density * n_samples_X * y_density * n_samples_Y) / 10, 10 * 2 ** 17)\n        tmp = (x_density + y_density) * n_features\n        batch_size = (-tmp + np.sqrt(tmp ** 2 + 4 * maxmem)) / 2\n        batch_size = max(int(batch_size), 1)\n    x_batches = gen_batches(n_samples_X, batch_size)\n    for i, x_slice in enumerate(x_batches):\n        X_chunk = X[x_slice].astype(np.float64)\n        if XX is None:\n            XX_chunk = row_norms(X_chunk, squared=True)[:, np.newaxis]\n        else:\n            XX_chunk = XX[x_slice]\n        y_batches = gen_batches(n_samples_Y, batch_size)\n        for j, y_slice in enumerate(y_batches):\n            if X is Y and j < i:\n                d = distances[y_slice, x_slice].T\n            else:\n                Y_chunk = Y[y_slice].astype(np.float64)\n                if YY is None:\n                    YY_chunk = row_norms(Y_chunk, squared=True)[np.newaxis, :]\n                else:\n                    YY_chunk = YY[:, y_slice]\n                d = -2 * safe_sparse_dot(X_chunk, Y_chunk.T, dense_output=True)\n                d += XX_chunk\n                d += YY_chunk\n            distances[x_slice, y_slice] = d.astype(np.float32, copy=False)\n    return distances",
    ".sklearn.utils._param_validation.py@@wrapper": "def wrapper(*args, **kwargs):\n    func_sig = signature(func)\n    params = func_sig.bind(*args, **kwargs)\n    params.apply_defaults()\n    to_ignore = [p.name for p in func_sig.parameters.values() if p.kind in (p.VAR_POSITIONAL, p.VAR_KEYWORD)]\n    to_ignore += ['self', 'cls']\n    params = {k: v for k, v in params.arguments.items() if k not in to_ignore}\n    validate_parameter_constraints(parameter_constraints, params, caller_name=func.__qualname__)\n    try:\n        return func(*args, **kwargs)\n    except InvalidParameterError as e:\n        msg = re.sub('parameter of \\\\w+ must be', f'parameter of {func.__qualname__} must be', str(e))\n        raise InvalidParameterError(msg) from e",
    ".sklearn.utils._param_validation.py@@validate_parameter_constraints": "def validate_parameter_constraints(parameter_constraints, params, caller_name):\n    for param_name, param_val in params.items():\n        if param_name not in parameter_constraints:\n            continue\n        constraints = parameter_constraints[param_name]\n        if constraints == 'no_validation':\n            continue\n        constraints = [make_constraint(constraint) for constraint in constraints]\n        for constraint in constraints:\n            if constraint.is_satisfied_by(param_val):\n                break\n        else:\n            constraints = [constraint for constraint in constraints if not constraint.hidden]\n            if len(constraints) == 1:\n                constraints_str = f'{constraints[0]}'\n            else:\n                constraints_str = f'{', '.join([str(c) for c in constraints[:-1]])} or {constraints[-1]}'\n            raise InvalidParameterError(f'The {param_name!r} parameter of {caller_name} must be {constraints_str}. Got {param_val!r} instead.')",
    ".sklearn.utils._param_validation.py@@make_constraint": "def make_constraint(constraint):\n    if isinstance(constraint, str) and constraint == 'array-like':\n        return _ArrayLikes()\n    if isinstance(constraint, str) and constraint == 'sparse matrix':\n        return _SparseMatrices()\n    if isinstance(constraint, str) and constraint == 'random_state':\n        return _RandomStates()\n    if constraint is callable:\n        return _Callables()\n    if constraint is None:\n        return _NoneConstraint()\n    if isinstance(constraint, type):\n        return _InstancesOf(constraint)\n    if isinstance(constraint, (Interval, StrOptions, Options, HasMethods)):\n        return constraint\n    if isinstance(constraint, str) and constraint == 'boolean':\n        return _Booleans()\n    if isinstance(constraint, str) and constraint == 'verbose':\n        return _VerboseHelper()\n    if isinstance(constraint, str) and constraint == 'missing_values':\n        return _MissingValues()\n    if isinstance(constraint, str) and constraint == 'cv_object':\n        return _CVObjects()\n    if isinstance(constraint, Hidden):\n        constraint = make_constraint(constraint.constraint)\n        constraint.hidden = True\n        return constraint\n    raise ValueError(f'Unknown constraint type: {constraint}')",
    ".sklearn.utils._param_validation.py@@Interval.is_satisfied_by": "def is_satisfied_by(self, val):\n    if not isinstance(val, self.type):\n        return False\n    return val in self",
    ".sklearn.utils._param_validation.py@@Interval.__contains__": "def __contains__(self, val):\n    if np.isnan(val):\n        return False\n    left_cmp = operator.lt if self.closed in ('left', 'both') else operator.le\n    right_cmp = operator.gt if self.closed in ('right', 'both') else operator.ge\n    left = -np.inf if self.left is None else self.left\n    right = np.inf if self.right is None else self.right\n    if left_cmp(val, left):\n        return False\n    if right_cmp(val, right):\n        return False\n    return True",
    ".sklearn.utils.__init__.py@@gen_batches": "def gen_batches(n, batch_size, *, min_batch_size=0):\n    start = 0\n    for _ in range(int(n // batch_size)):\n        end = start + batch_size\n        if end + min_batch_size > n:\n            continue\n        yield slice(start, end)\n        start = end\n    if start < n:\n        yield slice(start, n)"
}
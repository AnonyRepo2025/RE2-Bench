{
    ".xarray.core.merge.py@@_assert_compat_valid": "def _assert_compat_valid(compat):\n    if compat not in _VALID_COMPAT:\n        raise ValueError(f'compat={compat!r} invalid: must be {set(_VALID_COMPAT)}')",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.merge.py@@coerce_pandas_values": "def coerce_pandas_values(objects: Iterable[CoercibleMapping]) -> list[DatasetLike]:\n    from .dataarray import DataArray\n    from .dataset import Dataset\n    out = []\n    for obj in objects:\n        if isinstance(obj, Dataset):\n            variables: DatasetLike = obj\n        else:\n            variables = {}\n            if isinstance(obj, PANDAS_TYPES):\n                obj = dict(obj.items())\n            for k, v in obj.items():\n                if isinstance(v, PANDAS_TYPES):\n                    v = DataArray(v)\n                variables[k] = v\n        out.append(variables)\n    return out",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.alignment.py@@deep_align": "def deep_align(objects: Iterable[Any], join: JoinOptions='inner', copy=True, indexes=None, exclude=frozenset(), raise_on_invalid=True, fill_value=dtypes.NA):\n    from .dataarray import DataArray\n    from .dataset import Dataset\n    if indexes is None:\n        indexes = {}\n\n    def is_alignable(obj):\n        return isinstance(obj, (DataArray, Dataset))\n    positions = []\n    keys = []\n    out = []\n    targets = []\n    no_key = object()\n    not_replaced = object()\n    for position, variables in enumerate(objects):\n        if is_alignable(variables):\n            positions.append(position)\n            keys.append(no_key)\n            targets.append(variables)\n            out.append(not_replaced)\n        elif is_dict_like(variables):\n            current_out = {}\n            for k, v in variables.items():\n                if is_alignable(v) and k not in indexes:\n                    positions.append(position)\n                    keys.append(k)\n                    targets.append(v)\n                    current_out[k] = not_replaced\n                else:\n                    current_out[k] = v\n            out.append(current_out)\n        elif raise_on_invalid:\n            raise ValueError('object to align is neither an xarray.Dataset, an xarray.DataArray nor a dictionary: {!r}'.format(variables))\n        else:\n            out.append(variables)\n    aligned = align(*targets, join=join, copy=copy, indexes=indexes, exclude=exclude, fill_value=fill_value)\n    for position, key, aligned_obj in zip(positions, keys, aligned):\n        if key is no_key:\n            out[position] = aligned_obj\n        else:\n            out[position][key] = aligned_obj\n    return out",
    ".xarray.core.alignment.py@@is_alignable": "def is_alignable(obj):\n    return isinstance(obj, (DataArray, Dataset))",
    ".xarray.core.utils.py@@is_dict_like": "def is_dict_like(value: Any) -> TypeGuard[Mapping]:\n    return hasattr(value, 'keys') and hasattr(value, '__getitem__')",
    ".xarray.core.alignment.py@@align": "def align(*objects: DataAlignable, join: JoinOptions='inner', copy: bool=True, indexes=None, exclude=frozenset(), fill_value=dtypes.NA) -> tuple[DataAlignable, ...]:\n    aligner = Aligner(objects, join=join, copy=copy, indexes=indexes, exclude_dims=exclude, fill_value=fill_value)\n    aligner.align()\n    return aligner.results",
    ".xarray.core.alignment.py@@Aligner.__init__": "def __init__(self, objects: Iterable[DataAlignable], join: str='inner', indexes: Mapping[Any, Any] | None=None, exclude_dims: Iterable=frozenset(), exclude_vars: Iterable[Hashable]=frozenset(), method: str | None=None, tolerance: int | float | Iterable[int | float] | None=None, copy: bool=True, fill_value: Any=dtypes.NA, sparse: bool=False):\n    self.objects = tuple(objects)\n    self.objects_matching_indexes = ()\n    if join not in ['inner', 'outer', 'override', 'exact', 'left', 'right']:\n        raise ValueError(f'invalid value for join: {join}')\n    self.join = join\n    self.copy = copy\n    self.fill_value = fill_value\n    self.sparse = sparse\n    if method is None and tolerance is None:\n        self.reindex_kwargs = {}\n    else:\n        self.reindex_kwargs = {'method': method, 'tolerance': tolerance}\n    if isinstance(exclude_dims, str):\n        exclude_dims = [exclude_dims]\n    self.exclude_dims = frozenset(exclude_dims)\n    self.exclude_vars = frozenset(exclude_vars)\n    if indexes is None:\n        indexes = {}\n    self.indexes, self.index_vars = self._normalize_indexes(indexes)\n    self.all_indexes = {}\n    self.all_index_vars = {}\n    self.unindexed_dim_sizes = {}\n    self.aligned_indexes = {}\n    self.aligned_index_vars = {}\n    self.reindex = {}\n    self.results = tuple()",
    ".xarray.core.alignment.py@@Aligner._normalize_indexes": "def _normalize_indexes(self, indexes: Mapping[Any, Any]) -> tuple[NormalizedIndexes, NormalizedIndexVars]:\n    if isinstance(indexes, Indexes):\n        xr_variables = dict(indexes.variables)\n    else:\n        xr_variables = {}\n    xr_indexes: dict[Hashable, Index] = {}\n    for k, idx in indexes.items():\n        if not isinstance(idx, Index):\n            if getattr(idx, 'dims', (k,)) != (k,):\n                raise ValueError(f\"Indexer has dimensions {idx.dims} that are different from that to be indexed along '{k}'\")\n            data = as_compatible_data(idx)\n            pd_idx = safe_cast_to_index(data)\n            pd_idx.name = k\n            if isinstance(pd_idx, pd.MultiIndex):\n                idx = PandasMultiIndex(pd_idx, k)\n            else:\n                idx = PandasIndex(pd_idx, k, coord_dtype=data.dtype)\n            xr_variables.update(idx.create_variables())\n        xr_indexes[k] = idx\n    normalized_indexes = {}\n    normalized_index_vars = {}\n    for idx, index_vars in Indexes(xr_indexes, xr_variables).group_by_index():\n        coord_names_and_dims = []\n        all_dims: set[Hashable] = set()\n        for name, var in index_vars.items():\n            dims = var.dims\n            coord_names_and_dims.append((name, dims))\n            all_dims.update(dims)\n        exclude_dims = all_dims & self.exclude_dims\n        if exclude_dims == all_dims:\n            continue\n        elif exclude_dims:\n            excl_dims_str = ', '.join((str(d) for d in exclude_dims))\n            incl_dims_str = ', '.join((str(d) for d in all_dims - exclude_dims))\n            raise ValueError(f'cannot exclude dimension(s) {excl_dims_str} from alignment because these are used by an index together with non-excluded dimensions {incl_dims_str}')\n        key = (tuple(coord_names_and_dims), type(idx))\n        normalized_indexes[key] = idx\n        normalized_index_vars[key] = index_vars\n    return (normalized_indexes, normalized_index_vars)",
    ".xarray.core.indexes.py@@Indexes.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen(self._variables)",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.indexes.py@@Indexes.__iter__": "def __iter__(self) -> Iterator[T_PandasOrXarrayIndex]:\n    return iter(self._indexes)",
    ".xarray.core.indexes.py@@Indexes.__getitem__": "def __getitem__(self, key) -> T_PandasOrXarrayIndex:\n    return self._indexes[key]",
    ".xarray.core.indexes.py@@Indexes.__init__": "def __init__(self, indexes: dict[Any, T_PandasOrXarrayIndex], variables: dict[Any, Variable]):\n    self._indexes = indexes\n    self._variables = variables\n    self._dims: Mapping[Hashable, int] | None = None\n    self.__coord_name_id: dict[Any, int] | None = None\n    self.__id_index: dict[int, T_PandasOrXarrayIndex] | None = None\n    self.__id_coord_names: dict[int, tuple[Hashable, ...]] | None = None",
    ".xarray.core.indexes.py@@Indexes.group_by_index": "def group_by_index(self) -> list[tuple[T_PandasOrXarrayIndex, dict[Hashable, Variable]]]:\n    index_coords = []\n    for i in self._id_index:\n        index = self._id_index[i]\n        coords = {k: self._variables[k] for k in self._id_coord_names[i]}\n        index_coords.append((index, coords))\n    return index_coords",
    ".xarray.core.indexes.py@@Indexes._id_index": "def _id_index(self) -> dict[int, T_PandasOrXarrayIndex]:\n    if self.__id_index is None:\n        self.__id_index = {id(idx): idx for idx in self.get_unique()}\n    return self.__id_index",
    ".xarray.core.indexes.py@@Indexes.get_unique": "def get_unique(self) -> list[T_PandasOrXarrayIndex]:\n    unique_indexes: list[T_PandasOrXarrayIndex] = []\n    seen: set[int] = set()\n    for index in self._indexes.values():\n        index_id = id(index)\n        if index_id not in seen:\n            unique_indexes.append(index)\n            seen.add(index_id)\n    return unique_indexes",
    ".xarray.core.indexes.py@@Indexes._id_coord_names": "def _id_coord_names(self) -> dict[int, tuple[Hashable, ...]]:\n    if self.__id_coord_names is None:\n        id_coord_names: Mapping[int, list[Hashable]] = defaultdict(list)\n        for k, v in self._coord_name_id.items():\n            id_coord_names[v].append(k)\n        self.__id_coord_names = {k: tuple(v) for k, v in id_coord_names.items()}\n    return self.__id_coord_names",
    ".xarray.core.indexes.py@@Indexes._coord_name_id": "def _coord_name_id(self) -> dict[Any, int]:\n    if self.__coord_name_id is None:\n        self.__coord_name_id = {k: id(idx) for k, idx in self._indexes.items()}\n    return self.__coord_name_id",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self) -> tuple[Hashable, ...]:\n    return self._dims",
    ".xarray.core.alignment.py@@Aligner.align": "def align(self) -> None:\n    if not self.indexes and len(self.objects) == 1:\n        obj, = self.objects\n        self.results = (obj.copy(deep=self.copy),)\n        return\n    self.find_matching_indexes()\n    self.find_matching_unindexed_dims()\n    self.assert_no_index_conflict()\n    self.align_indexes()\n    self.assert_unindexed_dim_sizes_equal()\n    if self.join == 'override':\n        self.override_indexes()\n    else:\n        self.reindex_all()",
    ".xarray.core.alignment.py@@Aligner.find_matching_indexes": "def find_matching_indexes(self) -> None:\n    all_indexes: dict[MatchingIndexKey, list[Index]]\n    all_index_vars: dict[MatchingIndexKey, list[dict[Hashable, Variable]]]\n    all_indexes_dim_sizes: dict[MatchingIndexKey, dict[Hashable, set]]\n    objects_matching_indexes: list[dict[MatchingIndexKey, Index]]\n    all_indexes = defaultdict(list)\n    all_index_vars = defaultdict(list)\n    all_indexes_dim_sizes = defaultdict(lambda: defaultdict(set))\n    objects_matching_indexes = []\n    for obj in self.objects:\n        obj_indexes, obj_index_vars = self._normalize_indexes(obj.xindexes)\n        objects_matching_indexes.append(obj_indexes)\n        for key, idx in obj_indexes.items():\n            all_indexes[key].append(idx)\n        for key, index_vars in obj_index_vars.items():\n            all_index_vars[key].append(index_vars)\n            for dim, size in calculate_dimensions(index_vars).items():\n                all_indexes_dim_sizes[key][dim].add(size)\n    self.objects_matching_indexes = tuple(objects_matching_indexes)\n    self.all_indexes = all_indexes\n    self.all_index_vars = all_index_vars\n    if self.join == 'override':\n        for dim_sizes in all_indexes_dim_sizes.values():\n            for dim, sizes in dim_sizes.items():\n                if len(sizes) > 1:\n                    raise ValueError(f\"cannot align objects with join='override' with matching indexes along dimension {dim!r} that don't have the same size\")",
    ".xarray.core.alignment.py@@Aligner.find_matching_unindexed_dims": "def find_matching_unindexed_dims(self) -> None:\n    unindexed_dim_sizes = defaultdict(set)\n    for obj in self.objects:\n        for dim in obj.dims:\n            if dim not in self.exclude_dims and dim not in obj.xindexes.dims:\n                unindexed_dim_sizes[dim].add(obj.sizes[dim])\n    self.unindexed_dim_sizes = unindexed_dim_sizes",
    ".xarray.core.alignment.py@@Aligner.assert_no_index_conflict": "def assert_no_index_conflict(self) -> None:\n    matching_keys = set(self.all_indexes) | set(self.indexes)\n    coord_count: dict[Hashable, int] = defaultdict(int)\n    dim_count: dict[Hashable, int] = defaultdict(int)\n    for coord_names_dims, _ in matching_keys:\n        dims_set: set[Hashable] = set()\n        for name, dims in coord_names_dims:\n            coord_count[name] += 1\n            dims_set.update(dims)\n        for dim in dims_set:\n            dim_count[dim] += 1\n    for count, msg in [(coord_count, 'coordinates'), (dim_count, 'dimensions')]:\n        dup = {k: v for k, v in count.items() if v > 1}\n        if dup:\n            items_msg = ', '.join((f'{k!r} ({v} conflicting indexes)' for k, v in dup.items()))\n            raise ValueError(f\"cannot re-index or align objects with conflicting indexes found for the following {msg}: {items_msg}\\nConflicting indexes may occur when\\n- they relate to different sets of coordinate and/or dimension names\\n- they don't have the same type\\n- they may be used to reindex data along common dimensions\")",
    ".xarray.core.alignment.py@@Aligner.align_indexes": "def align_indexes(self) -> None:\n    aligned_indexes = {}\n    aligned_index_vars = {}\n    reindex = {}\n    new_indexes = {}\n    new_index_vars = {}\n    for key, matching_indexes in self.all_indexes.items():\n        matching_index_vars = self.all_index_vars[key]\n        dims = {d for coord in matching_index_vars[0].values() for d in coord.dims}\n        index_cls = key[1]\n        if self.join == 'override':\n            joined_index = matching_indexes[0]\n            joined_index_vars = matching_index_vars[0]\n            need_reindex = False\n        elif key in self.indexes:\n            joined_index = self.indexes[key]\n            joined_index_vars = self.index_vars[key]\n            cmp_indexes = list(zip([joined_index] + matching_indexes, [joined_index_vars] + matching_index_vars))\n            need_reindex = self._need_reindex(dims, cmp_indexes)\n        else:\n            if len(matching_indexes) > 1:\n                need_reindex = self._need_reindex(dims, list(zip(matching_indexes, matching_index_vars)))\n            else:\n                need_reindex = False\n            if need_reindex:\n                if self.join == 'exact':\n                    raise ValueError(\"cannot align objects with join='exact' where index/labels/sizes are not equal along these coordinates (dimensions): \" + ', '.join((f'{name!r} {dims!r}' for name, dims in key[0])))\n                joiner = self._get_index_joiner(index_cls)\n                joined_index = joiner(matching_indexes)\n                if self.join == 'left':\n                    joined_index_vars = matching_index_vars[0]\n                elif self.join == 'right':\n                    joined_index_vars = matching_index_vars[-1]\n                else:\n                    joined_index_vars = joined_index.create_variables()\n            else:\n                joined_index = matching_indexes[0]\n                joined_index_vars = matching_index_vars[0]\n        reindex[key] = need_reindex\n        aligned_indexes[key] = joined_index\n        aligned_index_vars[key] = joined_index_vars\n        for name, var in joined_index_vars.items():\n            new_indexes[name] = joined_index\n            new_index_vars[name] = var\n    for key, idx in self.indexes.items():\n        if key not in aligned_indexes:\n            index_vars = self.index_vars[key]\n            reindex[key] = False\n            aligned_indexes[key] = idx\n            aligned_index_vars[key] = index_vars\n            for name, var in index_vars.items():\n                new_indexes[name] = idx\n                new_index_vars[name] = var\n    self.aligned_indexes = aligned_indexes\n    self.aligned_index_vars = aligned_index_vars\n    self.reindex = reindex\n    self.new_indexes = Indexes(new_indexes, new_index_vars)",
    ".xarray.core.alignment.py@@Aligner.assert_unindexed_dim_sizes_equal": "def assert_unindexed_dim_sizes_equal(self) -> None:\n    for dim, sizes in self.unindexed_dim_sizes.items():\n        index_size = self.new_indexes.dims.get(dim)\n        if index_size is not None:\n            sizes.add(index_size)\n            add_err_msg = f' (note: an index is found along that dimension with size={index_size!r})'\n        else:\n            add_err_msg = ''\n        if len(sizes) > 1:\n            raise ValueError(f'cannot reindex or align along dimension {dim!r} because of conflicting dimension sizes: {sizes!r}' + add_err_msg)",
    ".xarray.core.alignment.py@@Aligner.reindex_all": "def reindex_all(self) -> None:\n    self.results = tuple((self._reindex_one(obj, matching_indexes) for obj, matching_indexes in zip(self.objects, self.objects_matching_indexes)))",
    ".xarray.core.merge.py@@collect_variables_and_indexes": "def collect_variables_and_indexes(list_of_mappings: list[DatasetLike], indexes: Mapping[Any, Any] | None=None) -> dict[Hashable, list[MergeElement]]:\n    from .dataarray import DataArray\n    from .dataset import Dataset\n    if indexes is None:\n        indexes = {}\n    grouped: dict[Hashable, list[MergeElement]] = defaultdict(list)\n\n    def append(name, variable, index):\n        grouped[name].append((variable, index))\n\n    def append_all(variables, indexes):\n        for name, variable in variables.items():\n            append(name, variable, indexes.get(name))\n    for mapping in list_of_mappings:\n        if isinstance(mapping, Dataset):\n            append_all(mapping.variables, mapping._indexes)\n            continue\n        for name, variable in mapping.items():\n            if isinstance(variable, DataArray):\n                coords_ = variable._coords.copy()\n                indexes_ = dict(variable._indexes)\n                coords_.pop(name, None)\n                indexes_.pop(name, None)\n                append_all(coords_, indexes_)\n            variable = as_variable(variable, name=name)\n            if name in indexes:\n                append(name, variable, indexes[name])\n            elif variable.dims == (name,):\n                idx, idx_vars = create_default_index_implicit(variable)\n                append_all(idx_vars, {k: idx for k in idx_vars})\n            else:\n                append(name, variable, None)\n    return grouped",
    ".xarray.core.variable.py@@as_variable": "def as_variable(obj, name=None) -> Variable | IndexVariable:\n    from .dataarray import DataArray\n    if isinstance(obj, DataArray):\n        obj = obj.variable\n    if isinstance(obj, Variable):\n        obj = obj.copy(deep=False)\n    elif isinstance(obj, tuple):\n        if isinstance(obj[1], DataArray):\n            raise TypeError('Using a DataArray object to construct a variable is ambiguous, please extract the data using the .data property.')\n        try:\n            obj = Variable(*obj)\n        except (TypeError, ValueError) as error:\n            raise error.__class__('Could not convert tuple of form (dims, data[, attrs, encoding]): {} to Variable.'.format(obj))\n    elif utils.is_scalar(obj):\n        obj = Variable([], obj)\n    elif isinstance(obj, (pd.Index, IndexVariable)) and obj.name is not None:\n        obj = Variable(obj.name, obj)\n    elif isinstance(obj, (set, dict)):\n        raise TypeError(f'variable {name!r} has invalid type {type(obj)!r}')\n    elif name is not None:\n        data = as_compatible_data(obj)\n        if data.ndim != 1:\n            raise MissingDimensionsError(f'cannot set variable {name!r} with {data.ndim!r}-dimensional data without explicit dimension names. Pass a tuple of (dims, data) instead.')\n        obj = Variable(name, data, fastpath=True)\n    else:\n        raise TypeError(f'unable to convert object into a variable without an explicit list of dimensions: {obj!r}')\n    if name is not None and name in obj.dims:\n        if obj.ndim != 1:\n            raise MissingDimensionsError(f'{name!r} has more than 1-dimension and the same name as one of its dimensions {obj.dims!r}. xarray disallows such variables because they conflict with the coordinates used to label dimensions.')\n        obj = obj.to_index_variable()\n    return obj",
    ".xarray.core.variable.py@@IndexVariable.copy": "def copy(self, deep: bool=True, data: ArrayLike | None=None):\n    if data is None:\n        ndata = self._data.copy(deep=deep)\n    else:\n        ndata = as_compatible_data(data)\n        if self.shape != ndata.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(ndata.shape, self.shape))\n    attrs = copy.deepcopy(self._attrs) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding) if deep else copy.copy(self._encoding)\n    return self._replace(data=ndata, attrs=attrs, encoding=encoding)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.copy": "def copy(self, deep: bool=True) -> PandasIndexingAdapter:\n    array = self.array.copy(deep=True) if deep else self.array\n    return type(self)(array, self._dtype)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__init__": "def __init__(self, array: pd.Index, dtype: DTypeLike=None):\n    from .indexes import safe_cast_to_index\n    self.array = safe_cast_to_index(array)\n    if dtype is None:\n        self._dtype = get_valid_numpy_dtype(array)\n    else:\n        self._dtype = np.dtype(dtype)",
    ".xarray.core.indexes.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    from .dataarray import DataArray\n    from .variable import Variable\n    if isinstance(array, pd.Index):\n        index = array\n    elif isinstance(array, (DataArray, Variable)):\n        index = array._to_index()\n    elif isinstance(array, Index):\n        index = array.to_pandas_index()\n    elif isinstance(array, PandasIndexingAdapter):\n        index = array.array\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.indexes.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.core.variable.py@@Variable._replace": "def _replace(self: T_Variable, dims=_default, data=_default, attrs=_default, encoding=_default) -> T_Variable:\n    if dims is _default:\n        dims = copy.copy(self._dims)\n    if data is _default:\n        data = copy.copy(self.data)\n    if attrs is _default:\n        attrs = copy.copy(self._attrs)\n    if encoding is _default:\n        encoding = copy.copy(self._encoding)\n    return type(self)(dims, data, attrs, encoding, fastpath=True)",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError(f'{type(self).__name__} objects must be 1-dimensional')\n    if not isinstance(self._data, PandasIndexingAdapter):\n        self._data = PandasIndexingAdapter(self._data)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    from .dataarray import DataArray\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, (Variable, DataArray)):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _possibly_convert_datetime_or_timedelta_index(data)\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    if isinstance(data, (pd.Series, pd.Index, pd.DataFrame)):\n        data = data.values\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray) and (hasattr(data, '__array_function__') or hasattr(data, '__array_namespace__')):\n        return data\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray) and data.dtype.kind in 'OMm':\n        data = _possibly_convert_objects(data)\n    return _maybe_wrap_data(data)",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.shape": "def shape(self) -> tuple[int, ...]:\n    return (len(self.array),)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexingAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims: str | Iterable[Hashable]) -> tuple[Hashable, ...]:\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError(f'dimensions {dims} must have the same length as the number of data dimensions, ndim={self.ndim}')\n    return dims",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> dict[Any, Any]:\n    if self._attrs is None:\n        self._attrs = {}\n    return self._attrs",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self) -> dict[Any, Any]:\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.core.variable.py@@IndexVariable.to_index_variable": "def to_index_variable(self) -> IndexVariable:\n    return self.copy(deep=False)",
    ".xarray.core.indexes.py@@Indexes.__contains__": "def __contains__(self, key) -> bool:\n    return key in self._indexes",
    ".xarray.core.merge.py@@append": "def append(name, variable, index):\n    grouped[name].append((variable, index))",
    ".xarray.coding.cftimeindex.py@@CFTimeIndex.__new__": "def __new__(cls, data, name=None, **kwargs):\n    assert_all_valid_date_type(data)\n    if name is None and hasattr(data, 'name'):\n        name = data.name\n    result = object.__new__(cls)\n    result._data = np.array(data, dtype='O')\n    result.name = name\n    result._cache = {}\n    return result",
    ".xarray.coding.cftimeindex.py@@assert_all_valid_date_type": "def assert_all_valid_date_type(data):\n    if cftime is None:\n        raise ModuleNotFoundError(\"No module named 'cftime'\")\n    if len(data) > 0:\n        sample = data[0]\n        date_type = type(sample)\n        if not isinstance(sample, cftime.datetime):\n            raise TypeError('CFTimeIndex requires cftime.datetime objects. Got object of {}.'.format(date_type))\n        if not all((isinstance(value, date_type) for value in data)):\n            raise TypeError('CFTimeIndex requires using datetime objects of all the same type.  Got\\n{}.'.format(data))",
    ".xarray.core.merge.py@@_get_priority_vars_and_indexes": "def _get_priority_vars_and_indexes(objects: list[DatasetLike], priority_arg: int | None, compat: CompatOptions='equals') -> dict[Hashable, MergeElement]:\n    if priority_arg is None:\n        return {}\n    collected = collect_variables_and_indexes([objects[priority_arg]])\n    variables, indexes = merge_collected(collected, compat=compat)\n    grouped: dict[Hashable, MergeElement] = {}\n    for name, variable in variables.items():\n        grouped[name] = (variable, indexes.get(name))\n    return grouped",
    ".xarray.core.merge.py@@merge_collected": "def merge_collected(grouped: dict[Hashable, list[MergeElement]], prioritized: Mapping[Any, MergeElement] | None=None, compat: CompatOptions='minimal', combine_attrs: CombineAttrsOptions='override', equals: dict[Hashable, bool] | None=None) -> tuple[dict[Hashable, Variable], dict[Hashable, Index]]:\n    if prioritized is None:\n        prioritized = {}\n    if equals is None:\n        equals = {}\n    _assert_compat_valid(compat)\n    _assert_prioritized_valid(grouped, prioritized)\n    merged_vars: dict[Hashable, Variable] = {}\n    merged_indexes: dict[Hashable, Index] = {}\n    index_cmp_cache: dict[tuple[int, int], bool | None] = {}\n    for name, elements_list in grouped.items():\n        if name in prioritized:\n            variable, index = prioritized[name]\n            merged_vars[name] = variable\n            if index is not None:\n                merged_indexes[name] = index\n        else:\n            indexed_elements = [(variable, index) for variable, index in elements_list if index is not None]\n            if indexed_elements:\n                variable, index = indexed_elements[0]\n                for other_var, other_index in indexed_elements[1:]:\n                    if not indexes_equal(index, other_index, variable, other_var, index_cmp_cache):\n                        raise MergeError(f'conflicting values/indexes on objects to be combined fo coordinate {name!r}\\nfirst index: {index!r}\\nsecond index: {other_index!r}\\nfirst variable: {variable!r}\\nsecond variable: {other_var!r}\\n')\n                if compat == 'identical':\n                    for other_variable, _ in indexed_elements[1:]:\n                        if not dict_equiv(variable.attrs, other_variable.attrs):\n                            raise MergeError(f'conflicting attribute values on combined variable {name!r}:\\nfirst value: {variable.attrs!r}\\nsecond value: {other_variable.attrs!r}')\n                merged_vars[name] = variable\n                merged_vars[name].attrs = merge_attrs([var.attrs for var, _ in indexed_elements], combine_attrs=combine_attrs)\n                merged_indexes[name] = index\n            else:\n                variables = [variable for variable, _ in elements_list]\n                try:\n                    merged_vars[name] = unique_variable(name, variables, compat, equals.get(name, None))\n                except MergeError:\n                    if compat != 'minimal':\n                        raise\n                if name in merged_vars:\n                    merged_vars[name].attrs = merge_attrs([var.attrs for var in variables], combine_attrs=combine_attrs)\n    return (merged_vars, merged_indexes)",
    ".xarray.core.merge.py@@_assert_prioritized_valid": "def _assert_prioritized_valid(grouped: dict[Hashable, list[MergeElement]], prioritized: Mapping[Any, MergeElement]) -> None:\n    prioritized_names = set(prioritized)\n    grouped_by_index: dict[int, list[Hashable]] = defaultdict(list)\n    indexes: dict[int, Index] = {}\n    for name, elements_list in grouped.items():\n        for _, index in elements_list:\n            if index is not None:\n                grouped_by_index[id(index)].append(name)\n                indexes[id(index)] = index\n    for index_id, index_coord_names in grouped_by_index.items():\n        index_names = set(index_coord_names)\n        common_names = index_names & prioritized_names\n        if common_names and len(common_names) != len(index_names):\n            common_names_str = ', '.join((f'{k!r}' for k in common_names))\n            index_names_str = ', '.join((f'{k!r}' for k in index_coord_names))\n            raise ValueError(f'cannot set or update variable(s) {common_names_str}, which would corrupt the following index built from coordinates {index_names_str}:\\n{indexes[index_id]!r}')",
    ".xarray.core.merge.py@@unique_variable": "def unique_variable(name: Hashable, variables: list[Variable], compat: CompatOptions='broadcast_equals', equals: bool | None=None) -> Variable:\n    out = variables[0]\n    if len(variables) == 1 or compat == 'override':\n        return out\n    combine_method = None\n    if compat == 'minimal':\n        compat = 'broadcast_equals'\n    if compat == 'broadcast_equals':\n        dim_lengths = broadcast_dimension_size(variables)\n        out = out.set_dims(dim_lengths)\n    if compat == 'no_conflicts':\n        combine_method = 'fillna'\n    if equals is None:\n        for var in variables[1:]:\n            equals = getattr(out, compat)(var, equiv=lazy_array_equiv)\n            if equals is not True:\n                break\n        if equals is None:\n            out = out.compute()\n            for var in variables[1:]:\n                equals = getattr(out, compat)(var)\n                if not equals:\n                    break\n    if not equals:\n        raise MergeError(f\"conflicting values for variable {name!r} on objects to be combined. You can skip this check by specifying compat='override'.\")\n    if combine_method:\n        for var in variables[1:]:\n            out = getattr(out, combine_method)(var)\n    return out",
    ".xarray.core.merge.py@@merge_attrs": "def merge_attrs(variable_attrs, combine_attrs, context=None):\n    if not variable_attrs:\n        return None\n    if callable(combine_attrs):\n        return combine_attrs(variable_attrs, context=context)\n    elif combine_attrs == 'drop':\n        return {}\n    elif combine_attrs == 'override':\n        return dict(variable_attrs[0])\n    elif combine_attrs == 'no_conflicts':\n        result = dict(variable_attrs[0])\n        for attrs in variable_attrs[1:]:\n            try:\n                result = compat_dict_union(result, attrs)\n            except ValueError as e:\n                raise MergeError(f\"combine_attrs='no_conflicts', but some values are not the same. Merging {str(result)} with {str(attrs)}\") from e\n        return result\n    elif combine_attrs == 'drop_conflicts':\n        result = {}\n        dropped_keys = set()\n        for attrs in variable_attrs:\n            result.update({key: value for key, value in attrs.items() if key not in result and key not in dropped_keys})\n            result = {key: value for key, value in result.items() if key not in attrs or equivalent(attrs[key], value)}\n            dropped_keys |= {key for key in attrs if key not in result}\n        return result\n    elif combine_attrs == 'identical':\n        result = dict(variable_attrs[0])\n        for attrs in variable_attrs[1:]:\n            if not dict_equiv(result, attrs):\n                raise MergeError(f\"combine_attrs='identical', but attrs differ. First is {str(result)} , other is {str(attrs)}.\")\n        return result\n    else:\n        raise ValueError(f'Unrecognised value for combine_attrs={combine_attrs}')",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self: T_Variable, deep: bool=True, data: ArrayLike | None=None) -> T_Variable:\n    return self._copy(deep=deep, data=data)",
    ".xarray.core.variable.py@@Variable._copy": "def _copy(self: T_Variable, deep: bool=True, data: ArrayLike | None=None, memo: dict[int, Any] | None=None) -> T_Variable:\n    if data is None:\n        ndata = self._data\n        if isinstance(ndata, indexing.MemoryCachedArray):\n            ndata = indexing.MemoryCachedArray(ndata.array)\n        if deep:\n            ndata = copy.deepcopy(ndata, memo)\n    else:\n        ndata = as_compatible_data(data)\n        if self.shape != ndata.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(ndata.shape, self.shape))\n    attrs = copy.deepcopy(self._attrs, memo) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding, memo) if deep else copy.copy(self._encoding)\n    return self._replace(data=ndata, attrs=attrs, encoding=encoding)",
    ".xarray.core.utils.py@@is_scalar": "def is_scalar(value: Any, include_0d: bool=True) -> TypeGuard[Hashable]:\n    return _is_scalar(value, include_0d)",
    ".xarray.core.utils.py@@_is_scalar": "def _is_scalar(value, include_0d):\n    from .variable import NON_NUMPY_SUPPORTED_ARRAY_TYPES\n    if include_0d:\n        include_0d = getattr(value, 'ndim', None) == 0\n    return include_0d or isinstance(value, (str, bytes)) or (not (isinstance(value, (Iterable,) + NON_NUMPY_SUPPORTED_ARRAY_TYPES) or hasattr(value, '__array_function__') or hasattr(value, '__array_namespace__')))",
    ".xarray.core.variable.py@@_possibly_convert_datetime_or_timedelta_index": "def _possibly_convert_datetime_or_timedelta_index(data):\n    if isinstance(data, (pd.DatetimeIndex, pd.TimedeltaIndex)):\n        return _as_nanosecond_precision(data)\n    else:\n        return data",
    ".xarray.core.utils.py@@get_valid_numpy_dtype": "def get_valid_numpy_dtype(array: np.ndarray | pd.Index):\n    if isinstance(array, pd.PeriodIndex):\n        dtype = np.dtype('O')\n    elif hasattr(array, 'categories'):\n        dtype = array.categories.dtype\n    elif not is_valid_numpy_dtype(array.dtype):\n        dtype = np.dtype('O')\n    else:\n        dtype = array.dtype\n    return dtype",
    ".xarray.core.variable.py@@Variable.to_index_variable": "def to_index_variable(self) -> IndexVariable:\n    return IndexVariable(self._dims, self._data, self._attrs, encoding=self._encoding, fastpath=True)",
    ".xarray.core.indexes.py@@create_default_index_implicit": "def create_default_index_implicit(dim_variable: Variable, all_variables: Mapping | Iterable[Hashable] | None=None) -> tuple[PandasIndex, IndexVars]:\n    if all_variables is None:\n        all_variables = {}\n    if not isinstance(all_variables, Mapping):\n        all_variables = {k: None for k in all_variables}\n    name = dim_variable.dims[0]\n    array = getattr(dim_variable._data, 'array', None)\n    index: PandasIndex\n    if isinstance(array, pd.MultiIndex):\n        index = PandasMultiIndex(array, name)\n        index_vars = index.create_variables()\n        duplicate_names = [k for k in index_vars if k in all_variables and k != name]\n        if duplicate_names:\n            if len(duplicate_names) < len(index.index.names):\n                conflict = True\n            else:\n                duplicate_vars = [all_variables[k] for k in duplicate_names]\n                conflict = any((v is None or not dim_variable.equals(v) for v in duplicate_vars))\n            if conflict:\n                conflict_str = '\\n'.join(duplicate_names)\n                raise ValueError(f'conflicting MultiIndex level / variable name(s):\\n{conflict_str}')\n    else:\n        dim_var = {name: dim_variable}\n        index = PandasIndex.from_variables(dim_var, options={})\n        index_vars = index.create_variables(dim_var)\n    return (index, index_vars)",
    ".xarray.core.indexes.py@@PandasIndex.from_variables": "def from_variables(cls, variables: Mapping[Any, Variable], *, options: Mapping[str, Any]) -> PandasIndex:\n    if len(variables) != 1:\n        raise ValueError(f'PandasIndex only accepts one variable, found {len(variables)} variables')\n    name, var = next(iter(variables.items()))\n    if var.ndim != 1:\n        raise ValueError(f'PandasIndex only accepts a 1-dimensional variable, variable {name!r} has {var.ndim} dimensions')\n    dim = var.dims[0]\n    data = getattr(var._data, 'array', var.data)\n    if isinstance(var._data, PandasMultiIndexingAdapter):\n        level = var._data.level\n        if level is not None:\n            data = var._data.array.get_level_values(level)\n    obj = cls(data, dim, coord_dtype=var.dtype)\n    assert not isinstance(obj.index, pd.MultiIndex)\n    obj.index.name = name\n    return obj",
    ".xarray.core.variable.py@@Variable.data": "def data(self) -> Any:\n    if is_duck_array(self._data):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.utils.py@@is_duck_array": "def is_duck_array(value: Any) -> bool:\n    if isinstance(value, np.ndarray):\n        return True\n    return hasattr(value, 'ndim') and hasattr(value, 'shape') and hasattr(value, 'dtype') and (hasattr(value, '__array_function__') and hasattr(value, '__array_ufunc__') or hasattr(value, '__array_namespace__'))",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.variable.py@@Variable.values": "def values(self):\n    return _as_array_or_item(self._data)",
    ".xarray.core.variable.py@@_as_array_or_item": "def _as_array_or_item(data):\n    data = np.asarray(data)\n    if data.ndim == 0:\n        if data.dtype.kind == 'M':\n            data = np.datetime64(data, 'ns')\n        elif data.dtype.kind == 'm':\n            data = np.timedelta64(data, 'ns')\n    return data",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__array__": "def __array__(self, dtype: DTypeLike=None) -> np.ndarray:\n    if dtype is None:\n        dtype = self.dtype\n    array = self.array\n    if isinstance(array, pd.PeriodIndex):\n        with suppress(AttributeError):\n            array = array.astype('object')\n    return np.asarray(array.values, dtype=dtype)",
    ".xarray.core.variable.py@@Variable.dtype": "def dtype(self):\n    return self._data.dtype",
    ".xarray.core.indexes.py@@PandasIndex.__init__": "def __init__(self, array: Any, dim: Hashable, coord_dtype: Any=None):\n    index = safe_cast_to_index(array).copy()\n    if index.name is None:\n        index.name = dim\n    self.index = index\n    self.dim = dim\n    if coord_dtype is None:\n        coord_dtype = get_valid_numpy_dtype(index)\n    self.coord_dtype = coord_dtype",
    ".xarray.core.indexes.py@@PandasIndex.create_variables": "def create_variables(self, variables: Mapping[Any, Variable] | None=None) -> IndexVars:\n    from .variable import IndexVariable\n    name = self.index.name\n    attrs: Mapping[Hashable, Any] | None\n    encoding: Mapping[Hashable, Any] | None\n    if variables is not None and name in variables:\n        var = variables[name]\n        attrs = var.attrs\n        encoding = var.encoding\n    else:\n        attrs = None\n        encoding = None\n    data = PandasIndexingAdapter(self.index, dtype=self.coord_dtype)\n    var = IndexVariable(self.dim, data, attrs=attrs, encoding=encoding)\n    return {name: var}",
    ".xarray.core.merge.py@@append_all": "def append_all(variables, indexes):\n    for name, variable in variables.items():\n        append(name, variable, indexes.get(name))",
    ".xarray.core.utils.py@@is_valid_numpy_dtype": "def is_valid_numpy_dtype(dtype: Any) -> bool:\n    try:\n        np.dtype(dtype)\n    except (TypeError, ValueError):\n        return False\n    else:\n        return True",
    ".xarray.core.dataarray.py@@DataArray.xindexes": "def xindexes(self) -> Indexes:\n    return Indexes(self._indexes, {k: self._coords[k] for k in self._indexes})",
    ".xarray.core.variable.py@@calculate_dimensions": "def calculate_dimensions(variables: Mapping[Any, Variable]) -> dict[Hashable, int]:\n    dims: dict[Hashable, int] = {}\n    last_used = {}\n    scalar_vars = {k for k, v in variables.items() if not v.dims}\n    for k, var in variables.items():\n        for dim, size in zip(var.dims, var.shape):\n            if dim in scalar_vars:\n                raise ValueError(f'dimension {dim!r} already exists as a scalar variable')\n            if dim not in dims:\n                dims[dim] = size\n                last_used[dim] = k\n            elif dims[dim] != size:\n                raise ValueError(f'conflicting sizes for dimension {dim!r}: length {size} on {k!r} and length {dims[dim]} on {last_used!r}')\n    return dims",
    ".xarray.core.dataarray.py@@DataArray.dims": "def dims(self) -> tuple[Hashable, ...]:\n    return self.variable.dims",
    ".xarray.core.dataarray.py@@DataArray.variable": "def variable(self) -> Variable:\n    return self._variable",
    ".xarray.core.indexes.py@@Indexes.dims": "def dims(self) -> Mapping[Hashable, int]:\n    from .variable import calculate_dimensions\n    if self._dims is None:\n        self._dims = calculate_dimensions(self._variables)\n    return Frozen(self._dims)",
    ".xarray.core.alignment.py@@Aligner._reindex_one": "def _reindex_one(self, obj: DataAlignable, matching_indexes: dict[MatchingIndexKey, Index]) -> DataAlignable:\n    new_indexes, new_variables = self._get_indexes_and_vars(obj, matching_indexes)\n    dim_pos_indexers = self._get_dim_pos_indexers(matching_indexes)\n    new_obj = obj._reindex_callback(self, dim_pos_indexers, new_variables, new_indexes, self.fill_value, self.exclude_dims, self.exclude_vars)\n    new_obj.encoding = obj.encoding\n    return new_obj",
    ".xarray.core.alignment.py@@Aligner._get_indexes_and_vars": "def _get_indexes_and_vars(self, obj: DataAlignable, matching_indexes: dict[MatchingIndexKey, Index]) -> tuple[dict[Hashable, Index], dict[Hashable, Variable]]:\n    new_indexes = {}\n    new_variables = {}\n    for key, aligned_idx in self.aligned_indexes.items():\n        index_vars = self.aligned_index_vars[key]\n        obj_idx = matching_indexes.get(key)\n        if obj_idx is None:\n            index_vars_dims = {d for var in index_vars.values() for d in var.dims}\n            if index_vars_dims <= set(obj.dims):\n                obj_idx = aligned_idx\n        if obj_idx is not None:\n            for name, var in index_vars.items():\n                new_indexes[name] = aligned_idx\n                new_variables[name] = var.copy(deep=self.copy)\n    return (new_indexes, new_variables)",
    ".xarray.core.alignment.py@@Aligner._get_dim_pos_indexers": "def _get_dim_pos_indexers(self, matching_indexes: dict[MatchingIndexKey, Index]) -> dict[Hashable, Any]:\n    dim_pos_indexers = {}\n    for key, aligned_idx in self.aligned_indexes.items():\n        obj_idx = matching_indexes.get(key)\n        if obj_idx is not None:\n            if self.reindex[key]:\n                indexers = obj_idx.reindex_like(aligned_idx, **self.reindex_kwargs)\n                dim_pos_indexers.update(indexers)\n    return dim_pos_indexers",
    ".xarray.core.dataarray.py@@DataArray._reindex_callback": "def _reindex_callback(self: T_DataArray, aligner: alignment.Aligner, dim_pos_indexers: dict[Hashable, Any], variables: dict[Hashable, Variable], indexes: dict[Hashable, Index], fill_value: Any, exclude_dims: frozenset[Hashable], exclude_vars: frozenset[Hashable]) -> T_DataArray:\n    if isinstance(fill_value, dict):\n        fill_value = fill_value.copy()\n        sentinel = object()\n        value = fill_value.pop(self.name, sentinel)\n        if value is not sentinel:\n            fill_value[_THIS_ARRAY] = value\n    ds = self._to_temp_dataset()\n    reindexed = ds._reindex_callback(aligner, dim_pos_indexers, variables, indexes, fill_value, exclude_dims, exclude_vars)\n    return self._from_temp_dataset(reindexed)",
    ".xarray.core.dataarray.py@@DataArray._to_temp_dataset": "def _to_temp_dataset(self) -> Dataset:\n    return self._to_dataset_whole(name=_THIS_ARRAY, shallow_copy=False)",
    ".xarray.core.dataarray.py@@DataArray._to_dataset_whole": "def _to_dataset_whole(self, name: Hashable=None, shallow_copy: bool=True) -> Dataset:\n    if name is None:\n        name = self.name\n    if name is None:\n        raise ValueError('unable to convert unnamed DataArray to a Dataset without providing an explicit name')\n    if name in self.coords:\n        raise ValueError('cannot create a Dataset from a DataArray with the same name as one of its coordinates')\n    variables = self._coords.copy()\n    variables[name] = self.variable\n    if shallow_copy:\n        for k in variables:\n            variables[k] = variables[k].copy(deep=False)\n    indexes = self._indexes\n    coord_names = set(self._coords)\n    return Dataset._construct_direct(variables, coord_names, indexes=indexes)",
    ".xarray.core.dataarray.py@@DataArray.coords": "def coords(self) -> DataArrayCoordinates:\n    return DataArrayCoordinates(self)",
    ".xarray.core.coordinates.py@@DataArrayCoordinates.__init__": "def __init__(self, dataarray: T_DataArray) -> None:\n    self._data = dataarray",
    ".xarray.core.coordinates.py@@Coordinates.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._names",
    ".xarray.core.coordinates.py@@DataArrayCoordinates._names": "def _names(self) -> set[Hashable]:\n    return set(self._data._coords)",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((type(self), self._value))",
    ".xarray.core.dataset.py@@Dataset._construct_direct": "def _construct_direct(cls: type[T_Dataset], variables: dict[Any, Variable], coord_names: set[Hashable], dims: dict[Any, int] | None=None, attrs: dict | None=None, indexes: dict[Any, Index] | None=None, encoding: dict | None=None, close: Callable[[], None] | None=None) -> T_Dataset:\n    if dims is None:\n        dims = calculate_dimensions(variables)\n    if indexes is None:\n        indexes = {}\n    obj = object.__new__(cls)\n    obj._variables = variables\n    obj._coord_names = coord_names\n    obj._dims = dims\n    obj._indexes = indexes\n    obj._attrs = attrs\n    obj._close = close\n    obj._encoding = encoding\n    return obj",
    ".xarray.core.common.py@@AttrAccessMixin.__setattr__": "def __setattr__(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '{!r} object has no attribute {!r}'.format(type(self).__name__, name):\n            raise\n        raise AttributeError(f\"cannot set attribute {name!r} on a {type(self).__name__!r} object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\") from e",
    ".xarray.core.dataset.py@@Dataset._reindex_callback": "def _reindex_callback(self, aligner: alignment.Aligner, dim_pos_indexers: dict[Hashable, Any], variables: dict[Hashable, Variable], indexes: dict[Hashable, Index], fill_value: Any, exclude_dims: frozenset[Hashable], exclude_vars: frozenset[Hashable]) -> Dataset:\n    new_variables = variables.copy()\n    new_indexes = indexes.copy()\n    for name, new_var in new_variables.items():\n        var = self._variables.get(name)\n        if var is not None:\n            new_var.attrs = var.attrs\n            new_var.encoding = var.encoding\n    for name, idx in self._indexes.items():\n        var = self._variables[name]\n        if set(var.dims) <= exclude_dims:\n            new_indexes[name] = idx\n            new_variables[name] = var\n    if not dim_pos_indexers:\n        if set(new_indexes) - set(self._indexes):\n            reindexed = self._overwrite_indexes(new_indexes, new_variables)\n        else:\n            reindexed = self.copy(deep=aligner.copy)\n    else:\n        to_reindex = {k: v for k, v in self.variables.items() if k not in variables and k not in exclude_vars}\n        reindexed_vars = alignment.reindex_variables(to_reindex, dim_pos_indexers, copy=aligner.copy, fill_value=fill_value, sparse=aligner.sparse)\n        new_variables.update(reindexed_vars)\n        new_coord_names = self._coord_names | set(new_indexes)\n        reindexed = self._replace_with_new_dims(new_variables, new_coord_names, indexes=new_indexes)\n    return reindexed",
    ".xarray.core.dataset.py@@Dataset.copy": "def copy(self: T_Dataset, deep: bool=False, data: Mapping[Any, ArrayLike] | None=None) -> T_Dataset:\n    return self._copy(deep=deep, data=data)",
    ".xarray.core.dataset.py@@Dataset._copy": "def _copy(self: T_Dataset, deep: bool=False, data: Mapping[Any, ArrayLike] | None=None, memo: dict[int, Any] | None=None) -> T_Dataset:\n    if data is None:\n        data = {}\n    elif not utils.is_dict_like(data):\n        raise ValueError('Data must be dict-like')\n    if data:\n        var_keys = set(self.data_vars.keys())\n        data_keys = set(data.keys())\n        keys_not_in_vars = data_keys - var_keys\n        if keys_not_in_vars:\n            raise ValueError('Data must only contain variables in original dataset. Extra variables: {}'.format(keys_not_in_vars))\n        keys_missing_from_data = var_keys - data_keys\n        if keys_missing_from_data:\n            raise ValueError('Data must contain all variables in original dataset. Data is missing {}'.format(keys_missing_from_data))\n    indexes, index_vars = self.xindexes.copy_indexes(deep=deep)\n    variables = {}\n    for k, v in self._variables.items():\n        if k in index_vars:\n            variables[k] = index_vars[k]\n        else:\n            variables[k] = v._copy(deep=deep, data=data.get(k), memo=memo)\n    attrs = copy.deepcopy(self._attrs, memo) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding, memo) if deep else copy.copy(self._encoding)\n    return self._replace(variables, indexes=indexes, attrs=attrs, encoding=encoding)",
    ".xarray.core.dataset.py@@Dataset.xindexes": "def xindexes(self) -> Indexes[Index]:\n    return Indexes(self._indexes, {k: self._variables[k] for k in self._indexes})",
    ".xarray.core.indexes.py@@Indexes.copy_indexes": "def copy_indexes(self, deep: bool=True, memo: dict[int, Any] | None=None) -> tuple[dict[Hashable, T_PandasOrXarrayIndex], dict[Hashable, Variable]]:\n    new_indexes = {}\n    new_index_vars = {}\n    for idx, coords in self.group_by_index():\n        if isinstance(idx, pd.Index):\n            convert_new_idx = True\n            dim = next(iter(coords.values())).dims[0]\n            if isinstance(idx, pd.MultiIndex):\n                idx = PandasMultiIndex(idx, dim)\n            else:\n                idx = PandasIndex(idx, dim)\n        else:\n            convert_new_idx = False\n        new_idx = idx._copy(deep=deep, memo=memo)\n        idx_vars = idx.create_variables(coords)\n        if convert_new_idx:\n            new_idx = cast(PandasIndex, new_idx).index\n        new_indexes.update({k: new_idx for k in coords})\n        new_index_vars.update(idx_vars)\n    return (new_indexes, new_index_vars)",
    ".xarray.core.indexes.py@@PandasIndex._copy": "def _copy(self: T_PandasIndex, deep: bool=True, memo: dict[int, Any] | None=None) -> T_PandasIndex:\n    if deep:\n        index = self.index.copy(deep=True)\n    else:\n        index = self.index\n    return self._replace(index)",
    ".xarray.core.indexes.py@@PandasIndex._replace": "def _replace(self, index, dim=None, coord_dtype=None):\n    if dim is None:\n        dim = self.dim\n    if coord_dtype is None:\n        coord_dtype = self.coord_dtype\n    return type(self)(index, dim, coord_dtype)",
    ".xarray.core.dataset.py@@Dataset._replace": "def _replace(self: T_Dataset, variables: dict[Hashable, Variable] | None=None, coord_names: set[Hashable] | None=None, dims: dict[Any, int] | None=None, attrs: dict[Hashable, Any] | None | Default=_default, indexes: dict[Hashable, Index] | None=None, encoding: dict | None | Default=_default, inplace: bool=False) -> T_Dataset:\n    if inplace:\n        if variables is not None:\n            self._variables = variables\n        if coord_names is not None:\n            self._coord_names = coord_names\n        if dims is not None:\n            self._dims = dims\n        if attrs is not _default:\n            self._attrs = attrs\n        if indexes is not None:\n            self._indexes = indexes\n        if encoding is not _default:\n            self._encoding = encoding\n        obj = self\n    else:\n        if variables is None:\n            variables = self._variables.copy()\n        if coord_names is None:\n            coord_names = self._coord_names.copy()\n        if dims is None:\n            dims = self._dims.copy()\n        if attrs is _default:\n            attrs = copy.copy(self._attrs)\n        if indexes is None:\n            indexes = self._indexes.copy()\n        if encoding is _default:\n            encoding = copy.copy(self._encoding)\n        obj = self._construct_direct(variables, coord_names, dims, attrs, indexes, encoding)\n    return obj",
    ".xarray.core.dataarray.py@@DataArray._from_temp_dataset": "def _from_temp_dataset(self: T_DataArray, dataset: Dataset, name: Hashable | None | Default=_default) -> T_DataArray:\n    variable = dataset._variables.pop(_THIS_ARRAY)\n    coords = dataset._variables\n    indexes = dataset._indexes\n    return self._replace(variable, coords, name, indexes=indexes)",
    ".xarray.core.dataarray.py@@DataArray._replace": "def _replace(self: T_DataArray, variable: Variable | None=None, coords=None, name: Hashable | None | Default=_default, indexes=None) -> T_DataArray:\n    if variable is None:\n        variable = self.variable\n    if coords is None:\n        coords = self._coords\n    if indexes is None:\n        indexes = self._indexes\n    if name is _default:\n        name = self.name\n    return type(self)(variable, coords, name=name, indexes=indexes, fastpath=True)",
    ".xarray.core.dataarray.py@@DataArray.name": "def name(self) -> Hashable | None:\n    return self._name",
    ".xarray.core.dataarray.py@@DataArray.__init__": "def __init__(self, data: Any=dtypes.NA, coords: Sequence[Sequence[Any] | pd.Index | DataArray] | Mapping[Any, Any] | None=None, dims: Hashable | Sequence[Hashable] | None=None, name: Hashable | None=None, attrs: Mapping | None=None, indexes: dict[Hashable, Index] | None=None, fastpath: bool=False) -> None:\n    if fastpath:\n        variable = data\n        assert dims is None\n        assert attrs is None\n        assert indexes is not None\n    else:\n        if indexes is not None:\n            raise ValueError('Providing explicit indexes is not supported yet')\n        if coords is None:\n            if isinstance(data, DataArray):\n                coords = data.coords\n            elif isinstance(data, pd.Series):\n                coords = [data.index]\n            elif isinstance(data, pd.DataFrame):\n                coords = [data.index, data.columns]\n            elif isinstance(data, (pd.Index, IndexVariable)):\n                coords = [data]\n        if dims is None:\n            dims = getattr(data, 'dims', getattr(coords, 'dims', None))\n        if name is None:\n            name = getattr(data, 'name', None)\n        if attrs is None and (not isinstance(data, PANDAS_TYPES)):\n            attrs = getattr(data, 'attrs', None)\n        data = _check_data_shape(data, coords, dims)\n        data = as_compatible_data(data)\n        coords, dims = _infer_coords_and_dims(data.shape, coords, dims)\n        variable = Variable(dims, data, attrs, fastpath=True)\n        indexes, coords = _create_indexes_from_coords(coords)\n    self._variable = variable\n    assert isinstance(coords, dict)\n    self._coords = coords\n    self._name = name\n    self._indexes = indexes\n    self._close = None",
    ".xarray.core.dataarray.py@@DataArray.encoding": "def encoding(self) -> dict[Any, Any]:\n    return self.variable.encoding",
    ".xarray.core.common.py@@AbstractArray.sizes": "def sizes(self: Any) -> Frozen[Hashable, int]:\n    return Frozen(dict(zip(self.dims, self.shape)))",
    ".xarray.core.dataarray.py@@DataArray.shape": "def shape(self) -> tuple[int, ...]:\n    return self.variable.shape",
    ".xarray.core.variable.py@@_possibly_convert_objects": "def _possibly_convert_objects(values):\n    as_series = pd.Series(values.ravel())\n    if as_series.dtype.kind in 'mM':\n        as_series = _as_nanosecond_precision(as_series)\n    return np.asarray(as_series).reshape(values.shape)"
}
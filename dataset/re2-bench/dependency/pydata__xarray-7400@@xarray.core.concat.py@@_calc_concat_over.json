{
    ".xarray.core.dataset.py@@Dataset.dims": "def dims(self) -> Frozen[Hashable, int]:\n    return Frozen(self._dims)",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.dataset.py@@Dataset.variables": "def variables(self) -> Frozen[Hashable, Variable]:\n    return Frozen(self._variables)",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self) -> tuple[Hashable, ...]:\n    return self._dims",
    ".xarray.core.dataset.py@@Dataset.coords": "def coords(self) -> DatasetCoordinates:\n    return DatasetCoordinates(self)",
    ".xarray.core.coordinates.py@@DatasetCoordinates.__init__": "def __init__(self, dataset: Dataset):\n    self._data = dataset",
    ".xarray.core.coordinates.py@@Coordinates.__iter__": "def __iter__(self) -> Iterator[Hashable]:\n    for k in self.variables:\n        if k in self._names:\n            yield k",
    ".xarray.core.coordinates.py@@DatasetCoordinates.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen({k: v for k, v in self._data.variables.items() if k in self._names})",
    ".xarray.core.coordinates.py@@DatasetCoordinates._names": "def _names(self) -> set[Hashable]:\n    return self._data._coord_names",
    ".xarray.core.variable.py@@Variable.broadcast_equals": "def broadcast_equals(self, other, equiv=duck_array_ops.array_equiv):\n    try:\n        self, other = broadcast_variables(self, other)\n    except (ValueError, AttributeError):\n        return False\n    return self.equals(other, equiv=equiv)",
    ".xarray.core.variable.py@@broadcast_variables": "def broadcast_variables(*variables: Variable) -> tuple[Variable, ...]:\n    dims_map = _unified_dims(variables)\n    dims_tuple = tuple(dims_map)\n    return tuple((var.set_dims(dims_map) if var.dims != dims_tuple else var for var in variables))",
    ".xarray.core.variable.py@@_unified_dims": "def _unified_dims(variables):\n    all_dims = {}\n    for var in variables:\n        var_dims = var.dims\n        if len(set(var_dims)) < len(var_dims):\n            raise ValueError(f'broadcasting cannot handle duplicate dimensions: {list(var_dims)!r}')\n        for d, s in zip(var_dims, var.shape):\n            if d not in all_dims:\n                all_dims[d] = s\n            elif all_dims[d] != s:\n                raise ValueError(f'operands cannot be broadcast together with mismatched lengths for dimension {d!r}: {(all_dims[d], s)}')\n    return all_dims",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.shape": "def shape(self) -> tuple[int, ...]:\n    return (len(self.array),)",
    ".xarray.core.variable.py@@IndexVariable.equals": "def equals(self, other, equiv=None):\n    if equiv is not None:\n        return super().equals(other, equiv)\n    other = getattr(other, 'variable', other)\n    try:\n        return self.dims == other.dims and self._data_equals(other)\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.variable.py@@Variable.equals": "def equals(self, other, equiv=duck_array_ops.array_equiv):\n    other = getattr(other, 'variable', other)\n    try:\n        return self.dims == other.dims and (self._data is other._data or equiv(self.data, other.data))\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.variable.py@@Variable.data": "def data(self) -> Any:\n    if is_duck_array(self._data):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.utils.py@@is_duck_array": "def is_duck_array(value: Any) -> bool:\n    if isinstance(value, np.ndarray):\n        return True\n    return hasattr(value, 'ndim') and hasattr(value, 'shape') and hasattr(value, 'dtype') and (hasattr(value, '__array_function__') and hasattr(value, '__array_ufunc__') or hasattr(value, '__array_namespace__'))",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.variable.py@@Variable.values": "def values(self):\n    return _as_array_or_item(self._data)",
    ".xarray.core.variable.py@@_as_array_or_item": "def _as_array_or_item(data):\n    data = np.asarray(data)\n    if data.ndim == 0:\n        if data.dtype.kind == 'M':\n            data = np.datetime64(data, 'ns')\n        elif data.dtype.kind == 'm':\n            data = np.timedelta64(data, 'ns')\n    return data",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__array__": "def __array__(self, dtype: DTypeLike=None) -> np.ndarray:\n    if dtype is None:\n        dtype = self.dtype\n    array = self.array\n    if isinstance(array, pd.PeriodIndex):\n        with suppress(AttributeError):\n            array = array.astype('object')\n    return np.asarray(array.values, dtype=dtype)",
    ".xarray.core.duck_array_ops.py@@lazy_array_equiv": "def lazy_array_equiv(arr1, arr2):\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask_available and is_duck_dask_array(arr1) and is_duck_dask_array(arr2):\n        from dask.base import tokenize\n        if tokenize(arr1) == tokenize(arr2):\n            return True\n        else:\n            return None\n    return None",
    ".xarray.core.duck_array_ops.py@@asarray": "def asarray(data, xp=np):\n    return data if is_duck_array(data) else xp.asarray(data)",
    ".xarray.core.pycompat.py@@is_duck_dask_array": "def is_duck_dask_array(x):\n    return is_duck_array(x) and is_dask_collection(x)",
    ".xarray.core.pycompat.py@@is_dask_collection": "def is_dask_collection(x):\n    if module_available('dask'):\n        from dask.base import is_dask_collection\n        return is_dask_collection(x)\n    return False",
    ".xarray.core.utils.py@@module_available": "def module_available(module: str) -> bool:\n    return importlib.util.find_spec(module) is not None",
    ".xarray.core.variable.py@@IndexVariable.load": "def load(self):\n    return self",
    ".xarray.core.variable.py@@Variable.compute": "def compute(self, **kwargs):\n    new = self.copy(deep=False)\n    return new.load(**kwargs)",
    ".xarray.core.variable.py@@IndexVariable.copy": "def copy(self, deep: bool=True, data: ArrayLike | None=None):\n    if data is None:\n        ndata = self._data.copy(deep=deep)\n    else:\n        ndata = as_compatible_data(data)\n        if self.shape != ndata.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(ndata.shape, self.shape))\n    attrs = copy.deepcopy(self._attrs) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding) if deep else copy.copy(self._encoding)\n    return self._replace(data=ndata, attrs=attrs, encoding=encoding)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.copy": "def copy(self, deep: bool=True) -> PandasIndexingAdapter:\n    array = self.array.copy(deep=True) if deep else self.array\n    return type(self)(array, self._dtype)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__init__": "def __init__(self, array: pd.Index, dtype: DTypeLike=None):\n    from xarray.core.indexes import safe_cast_to_index\n    self.array = safe_cast_to_index(array)\n    if dtype is None:\n        self._dtype = get_valid_numpy_dtype(array)\n    else:\n        self._dtype = np.dtype(dtype)",
    ".xarray.core.indexes.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    from xarray.core.dataarray import DataArray\n    from xarray.core.variable import Variable\n    if isinstance(array, pd.Index):\n        index = array\n    elif isinstance(array, (DataArray, Variable)):\n        index = array._to_index()\n    elif isinstance(array, Index):\n        index = array.to_pandas_index()\n    elif isinstance(array, PandasIndexingAdapter):\n        index = array.array\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.indexes.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from xarray.coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.core.variable.py@@Variable._replace": "def _replace(self: T_Variable, dims=_default, data=_default, attrs=_default, encoding=_default) -> T_Variable:\n    if dims is _default:\n        dims = copy.copy(self._dims)\n    if data is _default:\n        data = copy.copy(self.data)\n    if attrs is _default:\n        attrs = copy.copy(self._attrs)\n    if encoding is _default:\n        encoding = copy.copy(self._encoding)\n    return type(self)(dims, data, attrs, encoding, fastpath=True)",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError(f'{type(self).__name__} objects must be 1-dimensional')\n    if not isinstance(self._data, PandasIndexingAdapter):\n        self._data = PandasIndexingAdapter(self._data)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    from xarray.core.dataarray import DataArray\n    if isinstance(data, (Variable, DataArray)):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        data = _possibly_convert_datetime_or_timedelta_index(data)\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    if isinstance(data, (pd.Series, pd.Index, pd.DataFrame)):\n        data = data.values\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray) and (hasattr(data, '__array_function__') or hasattr(data, '__array_namespace__')):\n        return data\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray) and data.dtype.kind in 'OMm':\n        data = _possibly_convert_objects(data)\n    return _maybe_wrap_data(data)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexingAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims: str | Iterable[Hashable]) -> tuple[Hashable, ...]:\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError(f'dimensions {dims} must have the same length as the number of data dimensions, ndim={self.ndim}')\n    return dims",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> dict[Any, Any]:\n    if self._attrs is None:\n        self._attrs = {}\n    return self._attrs",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self) -> dict[Any, Any]:\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.core.duck_array_ops.py@@array_equiv": "def array_equiv(arr1, arr2):\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    lazy_equiv = lazy_array_equiv(arr1, arr2)\n    if lazy_equiv is None:\n        with warnings.catch_warnings():\n            warnings.filterwarnings('ignore', \"In the future, 'NAT == x'\")\n            flag_array = (arr1 == arr2) | isnull(arr1) & isnull(arr2)\n            return bool(flag_array.all())\n    else:\n        return lazy_equiv",
    ".xarray.core.duck_array_ops.py@@isnull": "def isnull(data):\n    data = asarray(data)\n    scalar_type = data.dtype.type\n    if issubclass(scalar_type, (np.datetime64, np.timedelta64)):\n        return isnat(data)\n    elif issubclass(scalar_type, np.inexact):\n        xp = get_array_namespace(data)\n        return xp.isnan(data)\n    elif issubclass(scalar_type, (np.bool_, np.integer, np.character, np.void)):\n        return zeros_like(data, dtype=bool)\n    elif isinstance(data, np.ndarray):\n        return pandas_isnull(data)\n    else:\n        return data != data",
    ".xarray.core.dataset.py@@Dataset.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self._variables",
    ".xarray.core.dataset.py@@Dataset.data_vars": "def data_vars(self) -> DataVariables:\n    return DataVariables(self)",
    ".xarray.core.dataset.py@@DataVariables.__init__": "def __init__(self, dataset: Dataset):\n    self._dataset = dataset",
    ".xarray.core.dataset.py@@DataVariables.__iter__": "def __iter__(self) -> Iterator[Hashable]:\n    return (key for key in self._dataset._variables if key not in self._dataset._coord_names)",
    ".xarray.core.variable.py@@Variable.load": "def load(self, **kwargs):\n    if is_duck_dask_array(self._data):\n        self._data = as_compatible_data(self._data.compute(**kwargs))\n    elif not is_duck_array(self._data):\n        self._data = np.asarray(self._data)\n    return self",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self: T_Variable, deep: bool=True, data: ArrayLike | None=None) -> T_Variable:\n    return self._copy(deep=deep, data=data)",
    ".xarray.core.variable.py@@Variable._copy": "def _copy(self: T_Variable, deep: bool=True, data: ArrayLike | None=None, memo: dict[int, Any] | None=None) -> T_Variable:\n    if data is None:\n        ndata = self._data\n        if isinstance(ndata, indexing.MemoryCachedArray):\n            ndata = indexing.MemoryCachedArray(ndata.array)\n        if deep:\n            ndata = copy.deepcopy(ndata, memo)\n    else:\n        ndata = as_compatible_data(data)\n        if self.shape != ndata.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(ndata.shape, self.shape))\n    attrs = copy.deepcopy(self._attrs, memo) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding, memo) if deep else copy.copy(self._encoding)\n    return self._replace(data=ndata, attrs=attrs, encoding=encoding)",
    ".xarray.core.duck_array_ops.py@@get_array_namespace": "def get_array_namespace(x):\n    if hasattr(x, '__array_namespace__'):\n        return x.__array_namespace__()\n    else:\n        return np",
    ".xarray.core.variable.py@@IndexVariable._data_equals": "def _data_equals(self, other):\n    return self._to_index().equals(other._to_index())",
    ".xarray.core.variable.py@@IndexVariable._to_index": "def _to_index(self) -> pd.Index:\n    assert self.ndim == 1\n    index = self._data.array\n    if isinstance(index, pd.MultiIndex):\n        valid_level_names = [name or f'{self.dims[0]}_level_{i}' for i, name in enumerate(index.names)]\n        index = index.set_names(valid_level_names)\n    else:\n        index = index.set_names(self.name)\n    return index",
    ".xarray.core.variable.py@@IndexVariable.name": "def name(self) -> Hashable:\n    return self.dims[0]",
    ".xarray.core.dataset.py@@DataVariables.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._dataset._variables and key not in self._dataset._coord_names",
    ".xarray.core.coordinates.py@@Coordinates.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._names",
    ".xarray.coding.cftimeindex.py@@CFTimeIndex.__new__": "def __new__(cls, data, name=None, **kwargs):\n    assert_all_valid_date_type(data)\n    if name is None and hasattr(data, 'name'):\n        name = data.name\n    result = object.__new__(cls)\n    result._data = np.array(data, dtype='O')\n    result.name = name\n    result._cache = {}\n    return result",
    ".xarray.coding.cftimeindex.py@@assert_all_valid_date_type": "def assert_all_valid_date_type(data):\n    if cftime is None:\n        raise ModuleNotFoundError(\"No module named 'cftime'\")\n    if len(data) > 0:\n        sample = data[0]\n        date_type = type(sample)\n        if not isinstance(sample, cftime.datetime):\n            raise TypeError('CFTimeIndex requires cftime.datetime objects. Got object of {}.'.format(date_type))\n        if not all((isinstance(value, date_type) for value in data)):\n            raise TypeError('CFTimeIndex requires using datetime objects of all the same type.  Got\\n{}.'.format(data))",
    ".xarray.core.variable.py@@Variable.identical": "def identical(self, other, equiv=duck_array_ops.array_equiv):\n    try:\n        return utils.dict_equiv(self.attrs, other.attrs) and self.equals(other, equiv=equiv)\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.utils.py@@dict_equiv": "def dict_equiv(first: Mapping[K, V], second: Mapping[K, V], compat: Callable[[V, V], bool]=equivalent) -> bool:\n    for k in first:\n        if k not in second or not compat(first[k], second[k]):\n            return False\n    return all((k in first for k in second))",
    ".xarray.core.dataset.py@@Dataset.set_coords": "def set_coords(self: T_Dataset, names: Hashable | Iterable[Hashable]) -> T_Dataset:\n    if isinstance(names, str) or not isinstance(names, Iterable):\n        names = [names]\n    else:\n        names = list(names)\n    self._assert_all_in_dataset(names)\n    obj = self.copy()\n    obj._coord_names.update(names)\n    return obj",
    ".xarray.core.dataset.py@@Dataset._assert_all_in_dataset": "def _assert_all_in_dataset(self, names: Iterable[Hashable], virtual_okay: bool=False) -> None:\n    bad_names = set(names) - set(self._variables)\n    if virtual_okay:\n        bad_names -= self.virtual_variables\n    if bad_names:\n        raise ValueError('One or more of the specified variables cannot be found in this dataset')",
    ".xarray.core.dataset.py@@Dataset.copy": "def copy(self: T_Dataset, deep: bool=False, data: Mapping[Any, ArrayLike] | None=None) -> T_Dataset:\n    return self._copy(deep=deep, data=data)",
    ".xarray.core.dataset.py@@Dataset._copy": "def _copy(self: T_Dataset, deep: bool=False, data: Mapping[Any, ArrayLike] | None=None, memo: dict[int, Any] | None=None) -> T_Dataset:\n    if data is None:\n        data = {}\n    elif not utils.is_dict_like(data):\n        raise ValueError('Data must be dict-like')\n    if data:\n        var_keys = set(self.data_vars.keys())\n        data_keys = set(data.keys())\n        keys_not_in_vars = data_keys - var_keys\n        if keys_not_in_vars:\n            raise ValueError('Data must only contain variables in original dataset. Extra variables: {}'.format(keys_not_in_vars))\n        keys_missing_from_data = var_keys - data_keys\n        if keys_missing_from_data:\n            raise ValueError('Data must contain all variables in original dataset. Data is missing {}'.format(keys_missing_from_data))\n    indexes, index_vars = self.xindexes.copy_indexes(deep=deep)\n    variables = {}\n    for k, v in self._variables.items():\n        if k in index_vars:\n            variables[k] = index_vars[k]\n        else:\n            variables[k] = v._copy(deep=deep, data=data.get(k), memo=memo)\n    attrs = copy.deepcopy(self._attrs, memo) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding, memo) if deep else copy.copy(self._encoding)\n    return self._replace(variables, indexes=indexes, attrs=attrs, encoding=encoding)",
    ".xarray.core.dataset.py@@Dataset.xindexes": "def xindexes(self) -> Indexes[Index]:\n    return Indexes(self._indexes, {k: self._variables[k] for k in self._indexes})",
    ".xarray.core.indexes.py@@Indexes.__init__": "def __init__(self, indexes: dict[Any, T_PandasOrXarrayIndex], variables: dict[Any, Variable]):\n    self._indexes = indexes\n    self._variables = variables\n    self._dims: Mapping[Hashable, int] | None = None\n    self.__coord_name_id: dict[Any, int] | None = None\n    self.__id_index: dict[int, T_PandasOrXarrayIndex] | None = None\n    self.__id_coord_names: dict[int, tuple[Hashable, ...]] | None = None",
    ".xarray.core.indexes.py@@Indexes.copy_indexes": "def copy_indexes(self, deep: bool=True, memo: dict[int, Any] | None=None) -> tuple[dict[Hashable, T_PandasOrXarrayIndex], dict[Hashable, Variable]]:\n    new_indexes = {}\n    new_index_vars = {}\n    for idx, coords in self.group_by_index():\n        if isinstance(idx, pd.Index):\n            convert_new_idx = True\n            dim = next(iter(coords.values())).dims[0]\n            if isinstance(idx, pd.MultiIndex):\n                idx = PandasMultiIndex(idx, dim)\n            else:\n                idx = PandasIndex(idx, dim)\n        else:\n            convert_new_idx = False\n        new_idx = idx._copy(deep=deep, memo=memo)\n        idx_vars = idx.create_variables(coords)\n        if convert_new_idx:\n            new_idx = cast(PandasIndex, new_idx).index\n        new_indexes.update({k: new_idx for k in coords})\n        new_index_vars.update(idx_vars)\n    return (new_indexes, new_index_vars)",
    ".xarray.core.indexes.py@@Indexes.group_by_index": "def group_by_index(self) -> list[tuple[T_PandasOrXarrayIndex, dict[Hashable, Variable]]]:\n    index_coords = []\n    for i in self._id_index:\n        index = self._id_index[i]\n        coords = {k: self._variables[k] for k in self._id_coord_names[i]}\n        index_coords.append((index, coords))\n    return index_coords",
    ".xarray.core.indexes.py@@Indexes._id_index": "def _id_index(self) -> dict[int, T_PandasOrXarrayIndex]:\n    if self.__id_index is None:\n        self.__id_index = {id(idx): idx for idx in self.get_unique()}\n    return self.__id_index",
    ".xarray.core.indexes.py@@Indexes.get_unique": "def get_unique(self) -> list[T_PandasOrXarrayIndex]:\n    unique_indexes: list[T_PandasOrXarrayIndex] = []\n    seen: set[int] = set()\n    for index in self._indexes.values():\n        index_id = id(index)\n        if index_id not in seen:\n            unique_indexes.append(index)\n            seen.add(index_id)\n    return unique_indexes",
    ".xarray.core.dataset.py@@Dataset._replace": "def _replace(self: T_Dataset, variables: dict[Hashable, Variable] | None=None, coord_names: set[Hashable] | None=None, dims: dict[Any, int] | None=None, attrs: dict[Hashable, Any] | None | Default=_default, indexes: dict[Hashable, Index] | None=None, encoding: dict | None | Default=_default, inplace: bool=False) -> T_Dataset:\n    if inplace:\n        if variables is not None:\n            self._variables = variables\n        if coord_names is not None:\n            self._coord_names = coord_names\n        if dims is not None:\n            self._dims = dims\n        if attrs is not _default:\n            self._attrs = attrs\n        if indexes is not None:\n            self._indexes = indexes\n        if encoding is not _default:\n            self._encoding = encoding\n        obj = self\n    else:\n        if variables is None:\n            variables = self._variables.copy()\n        if coord_names is None:\n            coord_names = self._coord_names.copy()\n        if dims is None:\n            dims = self._dims.copy()\n        if attrs is _default:\n            attrs = copy.copy(self._attrs)\n        if indexes is None:\n            indexes = self._indexes.copy()\n        if encoding is _default:\n            encoding = copy.copy(self._encoding)\n        obj = self._construct_direct(variables, coord_names, dims, attrs, indexes, encoding)\n    return obj",
    ".xarray.core.dataset.py@@Dataset._construct_direct": "def _construct_direct(cls: type[T_Dataset], variables: dict[Any, Variable], coord_names: set[Hashable], dims: dict[Any, int] | None=None, attrs: dict | None=None, indexes: dict[Any, Index] | None=None, encoding: dict | None=None, close: Callable[[], None] | None=None) -> T_Dataset:\n    if dims is None:\n        dims = calculate_dimensions(variables)\n    if indexes is None:\n        indexes = {}\n    obj = object.__new__(cls)\n    obj._variables = variables\n    obj._coord_names = coord_names\n    obj._dims = dims\n    obj._indexes = indexes\n    obj._attrs = attrs\n    obj._close = close\n    obj._encoding = encoding\n    return obj",
    ".xarray.core.common.py@@AttrAccessMixin.__setattr__": "def __setattr__(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '{!r} object has no attribute {!r}'.format(type(self).__name__, name):\n            raise\n        raise AttributeError(f\"cannot set attribute {name!r} on a {type(self).__name__!r} object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\") from e",
    ".xarray.core.variable.py@@_possibly_convert_objects": "def _possibly_convert_objects(values):\n    as_series = pd.Series(values.ravel())\n    if as_series.dtype.kind in 'mM':\n        as_series = _as_nanosecond_precision(as_series)\n    return np.asarray(as_series).reshape(values.shape)",
    ".xarray.core.variable.py@@_as_nanosecond_precision": "def _as_nanosecond_precision(data):\n    dtype = data.dtype\n    non_ns_datetime64 = dtype.kind == 'M' and isinstance(dtype, np.dtype) and (dtype != np.dtype('datetime64[ns]'))\n    non_ns_datetime_tz_dtype = isinstance(dtype, pd.DatetimeTZDtype) and dtype.unit != 'ns'\n    if non_ns_datetime64 or non_ns_datetime_tz_dtype:\n        utils.emit_user_level_warning(NON_NANOSECOND_WARNING.format(case='datetime'))\n        if isinstance(dtype, pd.DatetimeTZDtype):\n            nanosecond_precision_dtype = pd.DatetimeTZDtype('ns', dtype.tz)\n        else:\n            nanosecond_precision_dtype = 'datetime64[ns]'\n        return data.astype(nanosecond_precision_dtype)\n    elif dtype.kind == 'm' and dtype != np.dtype('timedelta64[ns]'):\n        utils.emit_user_level_warning(NON_NANOSECOND_WARNING.format(case='timedelta'))\n        return data.astype('timedelta64[ns]')\n    else:\n        return data",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((type(self), self._value))",
    ".xarray.core.indexes.py@@Indexes._id_coord_names": "def _id_coord_names(self) -> dict[int, tuple[Hashable, ...]]:\n    if self.__id_coord_names is None:\n        id_coord_names: Mapping[int, list[Hashable]] = defaultdict(list)\n        for k, v in self._coord_name_id.items():\n            id_coord_names[v].append(k)\n        self.__id_coord_names = {k: tuple(v) for k, v in id_coord_names.items()}\n    return self.__id_coord_names",
    ".xarray.core.indexes.py@@Indexes._coord_name_id": "def _coord_name_id(self) -> dict[Any, int]:\n    if self.__coord_name_id is None:\n        self.__coord_name_id = {k: id(idx) for k, idx in self._indexes.items()}\n    return self.__coord_name_id",
    ".xarray.core.indexes.py@@PandasIndex._copy": "def _copy(self: T_PandasIndex, deep: bool=True, memo: dict[int, Any] | None=None) -> T_PandasIndex:\n    if deep:\n        index = self.index.copy(deep=True)\n    else:\n        index = self.index\n    return self._replace(index)",
    ".xarray.core.indexes.py@@PandasIndex._replace": "def _replace(self, index, dim=None, coord_dtype=None):\n    if dim is None:\n        dim = self.dim\n    if coord_dtype is None:\n        coord_dtype = self.coord_dtype\n    return type(self)(index, dim, coord_dtype)",
    ".xarray.core.indexes.py@@PandasIndex.__init__": "def __init__(self, array: Any, dim: Hashable, coord_dtype: Any=None):\n    index = safe_cast_to_index(array).copy()\n    if index.name is None:\n        index.name = dim\n    self.index = index\n    self.dim = dim\n    if coord_dtype is None:\n        coord_dtype = get_valid_numpy_dtype(index)\n    self.coord_dtype = coord_dtype",
    ".xarray.core.indexes.py@@PandasIndex.create_variables": "def create_variables(self, variables: Mapping[Any, Variable] | None=None) -> IndexVars:\n    from xarray.core.variable import IndexVariable\n    name = self.index.name\n    attrs: Mapping[Hashable, Any] | None\n    encoding: Mapping[Hashable, Any] | None\n    if variables is not None and name in variables:\n        var = variables[name]\n        attrs = var.attrs\n        encoding = var.encoding\n    else:\n        attrs = None\n        encoding = None\n    data = PandasIndexingAdapter(self.index, dtype=self.coord_dtype)\n    var = IndexVariable(self.dim, data, attrs=attrs, encoding=encoding)\n    return {name: var}",
    ".xarray.core.variable.py@@_possibly_convert_datetime_or_timedelta_index": "def _possibly_convert_datetime_or_timedelta_index(data):\n    if isinstance(data, (pd.DatetimeIndex, pd.TimedeltaIndex)):\n        return _as_nanosecond_precision(data)\n    else:\n        return data"
}
{
    ".xarray.core.dataset.py@@Dataset.dims": "def dims(self) -> Mapping[Hashable, int]:\n    return Frozen(SortedKeysDict(self._dims))",
    ".xarray.core.utils.py@@SortedKeysDict.__init__": "def __init__(self, mapping: MutableMapping[K, V]=None):\n    self.mapping = {} if mapping is None else mapping",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.utils.py@@SortedKeysDict.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.dataset.py@@Dataset.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen(self._variables)",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self):\n    return self._dims",
    ".xarray.core.utils.py@@SortedKeysDict.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.dataset.py@@Dataset.data_vars": "def data_vars(self) -> DataVariables:\n    return DataVariables(self)",
    ".xarray.core.dataset.py@@DataVariables.__init__": "def __init__(self, dataset: 'Dataset'):\n    self._dataset = dataset",
    ".xarray.core.dataset.py@@DataVariables.__iter__": "def __iter__(self) -> Iterator[Hashable]:\n    return (key for key in self._dataset._variables if key not in self._dataset._coord_names)",
    ".xarray.core.utils.py@@SortedKeysDict.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(sorted(self.mapping))",
    ".xarray.core.dataset.py@@Dataset.coords": "def coords(self) -> DatasetCoordinates:\n    return DatasetCoordinates(self)",
    ".xarray.core.coordinates.py@@DatasetCoordinates.__init__": "def __init__(self, dataset: 'Dataset'):\n    self._data = dataset",
    ".xarray.core.coordinates.py@@AbstractCoordinates.__iter__": "def __iter__(self) -> Iterator['Hashable']:\n    for k in self.variables:\n        if k in self._names:\n            yield k",
    ".xarray.core.coordinates.py@@DatasetCoordinates.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen(OrderedDict(((k, v) for k, v in self._data.variables.items() if k in self._names)))",
    ".xarray.core.coordinates.py@@DatasetCoordinates._names": "def _names(self) -> Set[Hashable]:\n    return self._data._coord_names",
    ".xarray.core.variable.py@@IndexVariable.load": "def load(self):\n    return self",
    ".xarray.core.variable.py@@Variable.compute": "def compute(self, **kwargs):\n    new = self.copy(deep=False)\n    return new.load(**kwargs)",
    ".xarray.core.variable.py@@IndexVariable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data.copy(deep=deep)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.copy": "def copy(self, deep: bool=True) -> 'PandasIndexAdapter':\n    array = self.array.copy(deep=True) if deep else self.array\n    return PandasIndexAdapter(array, self._dtype)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__init__": "def __init__(self, array: Any, dtype: DTypeLike=None):\n    self.array = utils.safe_cast_to_index(array)\n    if dtype is None:\n        if isinstance(array, pd.PeriodIndex):\n            dtype = np.dtype('O')\n        elif hasattr(array, 'categories'):\n            dtype = array.categories.dtype\n        elif not utils.is_valid_numpy_dtype(array.dtype):\n            dtype = np.dtype('O')\n        else:\n            dtype = array.dtype\n    else:\n        dtype = np.dtype(dtype)\n    self._dtype = dtype",
    ".xarray.core.utils.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    if isinstance(array, pd.Index):\n        index = array\n    elif hasattr(array, 'to_index'):\n        index = array.to_index()\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.utils.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError('%s objects must be 1-dimensional' % type(self).__name__)\n    if not isinstance(self._data, PandasIndexAdapter):\n        self._data = PandasIndexAdapter(self._data)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, Variable):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    data = getattr(data, 'values', data)\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, '__array_function__'):\n            if IS_NEP18_ACTIVE:\n                return data\n            else:\n                raise TypeError('Got an NumPy-like array type providing the __array_function__ protocol but NEP18 is not enabled. Check that numpy >= v1.16 and that the environment variable \"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\" is set to \"1\"')\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == 'O':\n            data = _possibly_convert_objects(data)\n        elif data.dtype.kind == 'M':\n            data = np.asarray(data, 'datetime64[ns]')\n        elif data.dtype.kind == 'm':\n            data = np.asarray(data, 'timedelta64[ns]')\n    return _maybe_wrap_data(data)",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.shape": "def shape(self) -> Tuple[int]:\n    return (len(self.array),)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims):\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError('dimensions %s must have the same length as the number of data dimensions, ndim=%s' % (dims, self.ndim))\n    return dims",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.variable.py@@Variable.no_conflicts": "def no_conflicts(self, other):\n    return self.broadcast_equals(other, equiv=duck_array_ops.array_notnull_equiv)",
    ".xarray.core.variable.py@@Variable.broadcast_equals": "def broadcast_equals(self, other, equiv=duck_array_ops.array_equiv):\n    try:\n        self, other = broadcast_variables(self, other)\n    except (ValueError, AttributeError):\n        return False\n    return self.equals(other, equiv=equiv)",
    ".xarray.core.variable.py@@broadcast_variables": "def broadcast_variables(*variables):\n    dims_map = _unified_dims(variables)\n    dims_tuple = tuple(dims_map)\n    return tuple((var.set_dims(dims_map) if var.dims != dims_tuple else var for var in variables))",
    ".xarray.core.variable.py@@_unified_dims": "def _unified_dims(variables):\n    all_dims = OrderedDict()\n    for var in variables:\n        var_dims = var.dims\n        if len(set(var_dims)) < len(var_dims):\n            raise ValueError('broadcasting cannot handle duplicate dimensions: %r' % list(var_dims))\n        for d, s in zip(var_dims, var.shape):\n            if d not in all_dims:\n                all_dims[d] = s\n            elif all_dims[d] != s:\n                raise ValueError('operands cannot be broadcast together with mismatched lengths for dimension %r: %s' % (d, (all_dims[d], s)))\n    return all_dims",
    ".xarray.core.variable.py@@IndexVariable.equals": "def equals(self, other, equiv=None):\n    if equiv is not None:\n        return super().equals(other, equiv)\n    other = getattr(other, 'variable', other)\n    try:\n        return self.dims == other.dims and self._data_equals(other)\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.variable.py@@Variable.equals": "def equals(self, other, equiv=duck_array_ops.array_equiv):\n    other = getattr(other, 'variable', other)\n    try:\n        return self.dims == other.dims and (self._data is other._data or equiv(self.data, other.data))\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.variable.py@@Variable.data": "def data(self):\n    if hasattr(self._data, '__array_function__') or isinstance(self._data, dask_array_type):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.variable.py@@Variable.values": "def values(self):\n    return _as_array_or_item(self._data)",
    ".xarray.core.variable.py@@_as_array_or_item": "def _as_array_or_item(data):\n    data = np.asarray(data)\n    if data.ndim == 0:\n        if data.dtype.kind == 'M':\n            data = np.datetime64(data, 'ns')\n        elif data.dtype.kind == 'm':\n            data = np.timedelta64(data, 'ns')\n    return data",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__array__": "def __array__(self, dtype: DTypeLike=None) -> np.ndarray:\n    if dtype is None:\n        dtype = self.dtype\n    array = self.array\n    if isinstance(array, pd.PeriodIndex):\n        with suppress(AttributeError):\n            array = array.astype('object')\n    return np.asarray(array.values, dtype=dtype)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.duck_array_ops.py@@array_notnull_equiv": "def array_notnull_equiv(arr1, arr2):\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', \"In the future, 'NAT == x'\")\n        flag_array = (arr1 == arr2) | isnull(arr1) | isnull(arr2)\n        return bool(flag_array.all())",
    ".xarray.core.duck_array_ops.py@@asarray": "def asarray(data):\n    return data if isinstance(data, dask_array_type) or hasattr(data, '__array_function__') else np.asarray(data)",
    ".xarray.core.duck_array_ops.py@@isnull": "def isnull(data):\n    data = asarray(data)\n    scalar_type = data.dtype.type\n    if issubclass(scalar_type, (np.datetime64, np.timedelta64)):\n        return isnat(data)\n    elif issubclass(scalar_type, np.inexact):\n        return isnan(data)\n    elif issubclass(scalar_type, (np.bool_, np.integer, np.character, np.void)):\n        return zeros_like(data, dtype=bool)\n    elif isinstance(data, (np.ndarray, dask_array_type)):\n        return pandas_isnull(data)\n    else:\n        return data != data",
    ".xarray.core.duck_array_ops.py@@f": "def f(values, axis=None, skipna=None, **kwargs):\n    if kwargs.pop('out', None) is not None:\n        raise TypeError('`out` is not valid for {}'.format(name))\n    values = asarray(values)\n    if coerce_strings and values.dtype.kind in 'SU':\n        values = values.astype(object)\n    func = None\n    if skipna or (skipna is None and values.dtype.kind in 'cfO'):\n        nanname = 'nan' + name\n        func = getattr(nanops, nanname)\n    else:\n        func = _dask_or_eager_func(name)\n    try:\n        return func(values, axis=axis, **kwargs)\n    except AttributeError:\n        if isinstance(values, dask_array_type):\n            try:\n                return func(values, axis=axis, dtype=values.dtype, **kwargs)\n            except (AttributeError, TypeError):\n                msg = '%s is not yet implemented on dask arrays' % name\n        else:\n            msg = '%s is not available with skipna=False with the installed version of numpy; upgrade to numpy 1.12 or newer to use skipna=True or skipna=None' % name\n        raise NotImplementedError(msg)",
    ".xarray.coding.cftimeindex.py@@CFTimeIndex.__new__": "def __new__(cls, data, name=None):\n    assert_all_valid_date_type(data)\n    if name is None and hasattr(data, 'name'):\n        name = data.name\n    result = object.__new__(cls)\n    result._data = np.array(data, dtype='O')\n    result.name = name\n    return result",
    ".xarray.coding.cftimeindex.py@@assert_all_valid_date_type": "def assert_all_valid_date_type(data):\n    import cftime\n    if len(data) > 0:\n        sample = data[0]\n        date_type = type(sample)\n        if not isinstance(sample, cftime.datetime):\n            raise TypeError('CFTimeIndex requires cftime.datetime objects. Got object of {}.'.format(date_type))\n        if not all((isinstance(value, date_type) for value in data)):\n            raise TypeError('CFTimeIndex requires using datetime objects of all the same type.  Got\\n{}.'.format(data))",
    ".xarray.core.variable.py@@Variable.load": "def load(self, **kwargs):\n    if isinstance(self._data, dask_array_type):\n        self._data = as_compatible_data(self._data.compute(**kwargs))\n    elif not hasattr(self._data, '__array_function__'):\n        self._data = np.asarray(self._data)\n    return self",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data\n        if isinstance(data, indexing.MemoryCachedArray):\n            data = indexing.MemoryCachedArray(data.array)\n        if deep:\n            if hasattr(data, '__array_function__') or isinstance(data, dask_array_type):\n                data = data.copy()\n            elif not isinstance(data, PandasIndexAdapter):\n                data = np.array(data)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@IndexVariable._data_equals": "def _data_equals(self, other):\n    return self.to_index().equals(other.to_index())",
    ".xarray.core.variable.py@@IndexVariable.to_index": "def to_index(self):\n    assert self.ndim == 1\n    index = self._data.array\n    if isinstance(index, pd.MultiIndex):\n        valid_level_names = [name or '{}_level_{}'.format(self.dims[0], i) for i, name in enumerate(index.names)]\n        index = index.set_names(valid_level_names)\n    else:\n        index = index.set_names(self.name)\n    return index",
    ".xarray.core.variable.py@@IndexVariable.name": "def name(self):\n    return self.dims[0]",
    ".xarray.core.duck_array_ops.py@@array_equiv": "def array_equiv(arr1, arr2):\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', \"In the future, 'NAT == x'\")\n        flag_array = (arr1 == arr2) | isnull(arr1) & isnull(arr2)\n        return bool(flag_array.all())",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> 'OrderedDict[Any, Any]':\n    if self._attrs is None:\n        self._attrs = OrderedDict()\n    return self._attrs",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self):\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((ReprObject, self._value))",
    ".xarray.core.dataset.py@@DataVariables.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._dataset._variables and key not in self._dataset._coord_names",
    ".xarray.core.coordinates.py@@AbstractCoordinates.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._names",
    ".xarray.core.variable.py@@Variable.identical": "def identical(self, other):\n    try:\n        return utils.dict_equiv(self.attrs, other.attrs) and self.equals(other)\n    except (TypeError, AttributeError):\n        return False",
    ".xarray.core.utils.py@@dict_equiv": "def dict_equiv(first: Mapping[K, V], second: Mapping[K, V], compat: Callable[[V, V], bool]=equivalent) -> bool:\n    for k in first:\n        if k not in second or not compat(first[k], second[k]):\n            return False\n    for k in second:\n        if k not in first:\n            return False\n    return True",
    ".xarray.core.dataset.py@@Dataset.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self._variables",
    ".xarray.core.dataset.py@@Dataset.set_coords": "def set_coords(self, names: 'Union[Hashable, Iterable[Hashable]]', inplace: bool=None) -> 'Dataset':\n    _check_inplace(inplace)\n    if isinstance(names, str) or not isinstance(names, Iterable):\n        names = [names]\n    else:\n        names = list(names)\n    self._assert_all_in_dataset(names)\n    obj = self.copy()\n    obj._coord_names.update(names)\n    return obj",
    ".xarray.core.utils.py@@_check_inplace": "def _check_inplace(inplace: Optional[bool]) -> None:\n    if inplace is not None:\n        raise TypeError(\"The `inplace` argument has been removed from xarray. You can achieve an identical effect with python's standard assignment.\")",
    ".xarray.core.dataset.py@@Dataset._assert_all_in_dataset": "def _assert_all_in_dataset(self, names: Iterable[Hashable], virtual_okay: bool=False) -> None:\n    bad_names = set(names) - set(self._variables)\n    if virtual_okay:\n        bad_names -= self.virtual_variables\n    if bad_names:\n        raise ValueError('One or more of the specified variables cannot be found in this dataset')",
    ".xarray.core.dataset.py@@Dataset.copy": "def copy(self, deep: bool=False, data: Mapping=None) -> 'Dataset':\n    if data is None:\n        variables = OrderedDict(((k, v.copy(deep=deep)) for k, v in self._variables.items()))\n    elif not utils.is_dict_like(data):\n        raise ValueError('Data must be dict-like')\n    else:\n        var_keys = set(self.data_vars.keys())\n        data_keys = set(data.keys())\n        keys_not_in_vars = data_keys - var_keys\n        if keys_not_in_vars:\n            raise ValueError('Data must only contain variables in original dataset. Extra variables: {}'.format(keys_not_in_vars))\n        keys_missing_from_data = var_keys - data_keys\n        if keys_missing_from_data:\n            raise ValueError('Data must contain all variables in original dataset. Data is missing {}'.format(keys_missing_from_data))\n        variables = OrderedDict(((k, v.copy(deep=deep, data=data.get(k))) for k, v in self._variables.items()))\n    attrs = copy.deepcopy(self._attrs) if deep else copy.copy(self._attrs)\n    return self._replace(variables, attrs=attrs)",
    ".xarray.core.dataset.py@@Dataset._replace": "def _replace(self, variables: 'OrderedDict[Any, Variable]'=None, coord_names: Set[Hashable]=None, dims: Dict[Any, int]=None, attrs: 'Optional[OrderedDict]'=__default, indexes: 'Optional[OrderedDict[Any, pd.Index]]'=__default, encoding: Optional[dict]=__default, inplace: bool=False) -> 'Dataset':\n    if inplace:\n        if variables is not None:\n            self._variables = variables\n        if coord_names is not None:\n            self._coord_names = coord_names\n        if dims is not None:\n            self._dims = dims\n        if attrs is not self.__default:\n            self._attrs = attrs\n        if indexes is not self.__default:\n            self._indexes = indexes\n        if encoding is not self.__default:\n            self._encoding = encoding\n        obj = self\n    else:\n        if variables is None:\n            variables = self._variables.copy()\n        if coord_names is None:\n            coord_names = self._coord_names.copy()\n        if dims is None:\n            dims = self._dims.copy()\n        if attrs is self.__default:\n            attrs = copy.copy(self._attrs)\n        if indexes is self.__default:\n            indexes = copy.copy(self._indexes)\n        if encoding is self.__default:\n            encoding = copy.copy(self._encoding)\n        obj = self._construct_direct(variables, coord_names, dims, attrs, indexes, encoding)\n    return obj",
    ".xarray.core.dataset.py@@Dataset._construct_direct": "def _construct_direct(cls, variables, coord_names, dims, attrs=None, indexes=None, encoding=None, file_obj=None):\n    obj = object.__new__(cls)\n    obj._variables = variables\n    obj._coord_names = coord_names\n    obj._dims = dims\n    obj._indexes = indexes\n    obj._attrs = attrs\n    obj._file_obj = file_obj\n    obj._encoding = encoding\n    obj._accessors = None\n    return obj",
    ".xarray.core.common.py@@AttrAccessMixin._setattr_slots": "def _setattr_slots(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '%r object has no attribute %r' % (type(self).__name__, name):\n            raise\n        raise AttributeError(\"cannot set attribute %r on a %r object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\" % (name, type(self).__name__)) from e"
}
{
    ".xarray.core.coordinates.py@@DataArrayCoordinates.__init__": "def __init__(self, dataarray: DataArray):\n    self._data = dataarray",
    ".xarray.core.coordinates.py@@Coordinates.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._names",
    ".xarray.core.coordinates.py@@DataArrayCoordinates._names": "def _names(self) -> set[Hashable]:\n    return set(self._data._coords)",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((type(self), self._value))",
    ".xarray.core.dataset.py@@Dataset._construct_direct": "def _construct_direct(cls: type[T_Dataset], variables: dict[Any, Variable], coord_names: set[Hashable], dims: dict[Any, int] | None=None, attrs: dict | None=None, indexes: dict[Any, Index] | None=None, encoding: dict | None=None, close: Callable[[], None] | None=None) -> T_Dataset:\n    if dims is None:\n        dims = calculate_dimensions(variables)\n    if indexes is None:\n        indexes = {}\n    obj = object.__new__(cls)\n    obj._variables = variables\n    obj._coord_names = coord_names\n    obj._dims = dims\n    obj._indexes = indexes\n    obj._attrs = attrs\n    obj._close = close\n    obj._encoding = encoding\n    return obj",
    ".xarray.core.variable.py@@calculate_dimensions": "def calculate_dimensions(variables: Mapping[Any, Variable]) -> dict[Hashable, int]:\n    dims: dict[Hashable, int] = {}\n    last_used = {}\n    scalar_vars = {k for k, v in variables.items() if not v.dims}\n    for k, var in variables.items():\n        for dim, size in zip(var.dims, var.shape):\n            if dim in scalar_vars:\n                raise ValueError(f'dimension {dim!r} already exists as a scalar variable')\n            if dim not in dims:\n                dims[dim] = size\n                last_used[dim] = k\n            elif dims[dim] != size:\n                raise ValueError(f'conflicting sizes for dimension {dim!r}: length {size} on {k!r} and length {dims[dim]} on {last_used!r}')\n    return dims",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self) -> tuple[Hashable, ...]:\n    return self._dims",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.common.py@@AttrAccessMixin.__setattr__": "def __setattr__(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '{!r} object has no attribute {!r}'.format(type(self).__name__, name):\n            raise\n        raise AttributeError(f\"cannot set attribute {name!r} on a {type(self).__name__!r} object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\") from e",
    ".xarray.core.dataset.py@@Dataset.set_index": "def set_index(self, indexes: Mapping[Any, Hashable | Sequence[Hashable]] | None=None, append: bool=False, **indexes_kwargs: Hashable | Sequence[Hashable]) -> Dataset:\n    dim_coords = either_dict_or_kwargs(indexes, indexes_kwargs, 'set_index')\n    new_indexes: dict[Hashable, Index] = {}\n    new_variables: dict[Hashable, Variable] = {}\n    drop_indexes: set[Hashable] = set()\n    drop_variables: set[Hashable] = set()\n    replace_dims: dict[Hashable, Hashable] = {}\n    all_var_names: set[Hashable] = set()\n    for dim, _var_names in dim_coords.items():\n        if isinstance(_var_names, str) or not isinstance(_var_names, Sequence):\n            var_names = [_var_names]\n        else:\n            var_names = list(_var_names)\n        invalid_vars = set(var_names) - set(self._variables)\n        if invalid_vars:\n            raise ValueError(', '.join([str(v) for v in invalid_vars]) + ' variable(s) do not exist')\n        all_var_names.update(var_names)\n        drop_variables.update(var_names)\n        index_coord_names = self.xindexes.get_all_coords(dim, errors='ignore')\n        all_index_coord_names = set(index_coord_names)\n        for k in var_names:\n            all_index_coord_names.update(self.xindexes.get_all_coords(k, errors='ignore'))\n        drop_indexes.update(all_index_coord_names)\n        drop_variables.update(all_index_coord_names)\n        if len(var_names) == 1 and (not append or dim not in self._indexes):\n            var_name = var_names[0]\n            var = self._variables[var_name]\n            if var.dims != (dim,):\n                raise ValueError(f'dimension mismatch: try setting an index for dimension {dim!r} with variable {var_name!r} that has dimensions {var.dims}')\n            idx = PandasIndex.from_variables({dim: var}, options={})\n            idx_vars = idx.create_variables({var_name: var})\n            if dim in self._coord_names:\n                drop_variables.remove(dim)\n        else:\n            if append:\n                current_variables = {k: self._variables[k] for k in index_coord_names}\n            else:\n                current_variables = {}\n            idx, idx_vars = PandasMultiIndex.from_variables_maybe_expand(dim, current_variables, {k: self._variables[k] for k in var_names})\n            for n in idx.index.names:\n                replace_dims[n] = dim\n        new_indexes.update({k: idx for k in idx_vars})\n        new_variables.update(idx_vars)\n    for k in drop_variables:\n        if k not in new_variables and k not in all_var_names and (k in self._coord_names):\n            new_variables[k] = self._variables[k].to_base_variable()\n    indexes_: dict[Any, Index] = {k: v for k, v in self._indexes.items() if k not in drop_indexes}\n    indexes_.update(new_indexes)\n    variables = {k: v for k, v in self._variables.items() if k not in drop_variables}\n    variables.update(new_variables)\n    for k, v in variables.items():\n        if any((d in replace_dims for d in v.dims)):\n            new_dims = [replace_dims.get(d, d) for d in v.dims]\n            variables[k] = v._replace(dims=new_dims)\n    coord_names = self._coord_names - drop_variables | set(new_variables)\n    return self._replace_with_new_dims(variables, coord_names=coord_names, indexes=indexes_)",
    ".xarray.core.utils.py@@either_dict_or_kwargs": "def either_dict_or_kwargs(pos_kwargs: Mapping[Any, T] | None, kw_kwargs: Mapping[str, T], func_name: str) -> Mapping[Hashable, T]:\n    if pos_kwargs is None or pos_kwargs == {}:\n        return cast(Mapping[Hashable, T], kw_kwargs)\n    if not is_dict_like(pos_kwargs):\n        raise ValueError(f'the first argument to .{func_name} must be a dictionary')\n    if kw_kwargs:\n        raise ValueError(f'cannot specify both keyword and positional arguments to .{func_name}')\n    return pos_kwargs",
    ".xarray.core.dataset.py@@Dataset.xindexes": "def xindexes(self) -> Indexes[Index]:\n    return Indexes(self._indexes, {k: self._variables[k] for k in self._indexes})",
    ".xarray.core.indexes.py@@Indexes.__init__": "def __init__(self, indexes: dict[Any, T_PandasOrXarrayIndex], variables: dict[Any, Variable]):\n    self._indexes = indexes\n    self._variables = variables\n    self._dims: Mapping[Hashable, int] | None = None\n    self.__coord_name_id: dict[Any, int] | None = None\n    self.__id_index: dict[int, T_PandasOrXarrayIndex] | None = None\n    self.__id_coord_names: dict[int, tuple[Hashable, ...]] | None = None",
    ".xarray.core.indexes.py@@Indexes.get_all_coords": "def get_all_coords(self, key: Hashable, errors: ErrorOptions='raise') -> dict[Hashable, Variable]:\n    if errors not in ['raise', 'ignore']:\n        raise ValueError('errors must be either \"raise\" or \"ignore\"')\n    if key not in self._indexes:\n        if errors == 'raise':\n            raise ValueError(f'no index found for {key!r} coordinate')\n        else:\n            return {}\n    all_coord_names = self._id_coord_names[self._coord_name_id[key]]\n    return {k: self._variables[k] for k in all_coord_names}",
    ".xarray.core.indexes.py@@PandasMultiIndex.from_variables_maybe_expand": "def from_variables_maybe_expand(cls, dim: Hashable, current_variables: Mapping[Any, Variable], variables: Mapping[Any, Variable]) -> tuple[PandasMultiIndex, IndexVars]:\n    names: list[Hashable] = []\n    codes: list[list[int]] = []\n    levels: list[list[int]] = []\n    level_variables: dict[Any, Variable] = {}\n    _check_dim_compat({**current_variables, **variables})\n    if len(current_variables) > 1:\n        data = cast(PandasMultiIndexingAdapter, next(iter(current_variables.values()))._data)\n        current_index = data.array\n        names.extend(current_index.names)\n        codes.extend(current_index.codes)\n        levels.extend(current_index.levels)\n        for name in current_index.names:\n            level_variables[name] = current_variables[name]\n    elif len(current_variables) == 1:\n        var = next(iter(current_variables.values()))\n        new_var_name = f'{dim}_level_0'\n        names.append(new_var_name)\n        cat = pd.Categorical(var.values, ordered=True)\n        codes.append(cat.codes)\n        levels.append(cat.categories)\n        level_variables[new_var_name] = var\n    for name, var in variables.items():\n        names.append(name)\n        cat = pd.Categorical(var.values, ordered=True)\n        codes.append(cat.codes)\n        levels.append(cat.categories)\n        level_variables[name] = var\n    index = pd.MultiIndex(levels, codes, names=names)\n    level_coords_dtype = {k: var.dtype for k, var in level_variables.items()}\n    obj = cls(index, dim, level_coords_dtype=level_coords_dtype)\n    index_vars = obj.create_variables(level_variables)\n    return (obj, index_vars)",
    ".xarray.core.indexes.py@@_check_dim_compat": "def _check_dim_compat(variables: Mapping[Any, Variable], all_dims: str='equal'):\n    if any([var.ndim != 1 for var in variables.values()]):\n        raise ValueError('PandasMultiIndex only accepts 1-dimensional variables')\n    dims = {var.dims for var in variables.values()}\n    if all_dims == 'equal' and len(dims) > 1:\n        raise ValueError('unmatched dimensions for multi-index variables ' + ', '.join([f'{k!r} {v.dims}' for k, v in variables.items()]))\n    if all_dims == 'different' and len(dims) < len(variables):\n        raise ValueError('conflicting dimensions for multi-index product variables ' + ', '.join([f'{k!r} {v.dims}' for k, v in variables.items()]))",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.variable.py@@Variable.values": "def values(self):\n    return _as_array_or_item(self._data)",
    ".xarray.core.variable.py@@_as_array_or_item": "def _as_array_or_item(data):\n    data = np.asarray(data)\n    if data.ndim == 0:\n        if data.dtype.kind == 'M':\n            data = np.datetime64(data, 'ns')\n        elif data.dtype.kind == 'm':\n            data = np.timedelta64(data, 'ns')\n    return data",
    ".xarray.core.variable.py@@Variable.dtype": "def dtype(self):\n    return self._data.dtype",
    ".xarray.core.indexes.py@@PandasMultiIndex.__init__": "def __init__(self, array: Any, dim: Hashable, level_coords_dtype: Any=None):\n    super().__init__(array, dim)\n    names = []\n    for i, idx in enumerate(self.index.levels):\n        name = idx.name or f'{dim}_level_{i}'\n        if name == dim:\n            raise ValueError(f'conflicting multi-index level name {name!r} with dimension {dim!r}')\n        names.append(name)\n    self.index.names = names\n    if level_coords_dtype is None:\n        level_coords_dtype = {idx.name: get_valid_numpy_dtype(idx) for idx in self.index.levels}\n    self.level_coords_dtype = level_coords_dtype",
    ".xarray.core.indexes.py@@PandasIndex.__init__": "def __init__(self, array: Any, dim: Hashable, coord_dtype: Any=None):\n    index = utils.safe_cast_to_index(array).copy()\n    if index.name is None:\n        index.name = dim\n    self.index = index\n    self.dim = dim\n    if coord_dtype is None:\n        coord_dtype = get_valid_numpy_dtype(index)\n    self.coord_dtype = coord_dtype",
    ".xarray.core.utils.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    if isinstance(array, pd.Index):\n        index = array\n    elif hasattr(array, 'to_index'):\n        index = array.to_index()\n    elif hasattr(array, 'to_pandas_index'):\n        index = array.to_pandas_index()\n    elif hasattr(array, 'array') and isinstance(array.array, pd.Index):\n        index = array.array\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.utils.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.coding.cftimeindex.py@@CFTimeIndex.__new__": "def __new__(cls, data, name=None, **kwargs):\n    assert_all_valid_date_type(data)\n    if name is None and hasattr(data, 'name'):\n        name = data.name\n    result = object.__new__(cls)\n    result._data = np.array(data, dtype='O')\n    result.name = name\n    result._cache = {}\n    return result",
    ".xarray.coding.cftimeindex.py@@assert_all_valid_date_type": "def assert_all_valid_date_type(data):\n    if cftime is None:\n        raise ModuleNotFoundError(\"No module named 'cftime'\")\n    if len(data) > 0:\n        sample = data[0]\n        date_type = type(sample)\n        if not isinstance(sample, cftime.datetime):\n            raise TypeError('CFTimeIndex requires cftime.datetime objects. Got object of {}.'.format(date_type))\n        if not all((isinstance(value, date_type) for value in data)):\n            raise TypeError('CFTimeIndex requires using datetime objects of all the same type.  Got\\n{}.'.format(data))",
    ".xarray.core.utils.py@@get_valid_numpy_dtype": "def get_valid_numpy_dtype(array: np.ndarray | pd.Index):\n    if isinstance(array, pd.PeriodIndex):\n        dtype = np.dtype('O')\n    elif hasattr(array, 'categories'):\n        dtype = array.categories.dtype\n    elif not is_valid_numpy_dtype(array.dtype):\n        dtype = np.dtype('O')\n    else:\n        dtype = array.dtype\n    return dtype",
    ".xarray.core.utils.py@@is_valid_numpy_dtype": "def is_valid_numpy_dtype(dtype: Any) -> bool:\n    try:\n        np.dtype(dtype)\n    except (TypeError, ValueError):\n        return False\n    else:\n        return True",
    ".xarray.core.indexes.py@@PandasMultiIndex.create_variables": "def create_variables(self, variables: Mapping[Any, Variable] | None=None) -> IndexVars:\n    from .variable import IndexVariable\n    if variables is None:\n        variables = {}\n    index_vars: IndexVars = {}\n    for name in (self.dim,) + self.index.names:\n        if name == self.dim:\n            level = None\n            dtype = None\n        else:\n            level = name\n            dtype = self.level_coords_dtype[name]\n        var = variables.get(name, None)\n        if var is not None:\n            attrs = var.attrs\n            encoding = var.encoding\n        else:\n            attrs = {}\n            encoding = {}\n        data = PandasMultiIndexingAdapter(self.index, dtype=dtype, level=level)\n        index_vars[name] = IndexVariable(self.dim, data, attrs=attrs, encoding=encoding, fastpath=True)\n    return index_vars",
    ".xarray.core.indexing.py@@PandasMultiIndexingAdapter.__init__": "def __init__(self, array: pd.MultiIndex, dtype: DTypeLike=None, level: str | None=None):\n    super().__init__(array, dtype)\n    self.level = level",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__init__": "def __init__(self, array: pd.Index, dtype: DTypeLike=None):\n    self.array = safe_cast_to_index(array)\n    if dtype is None:\n        self._dtype = get_valid_numpy_dtype(array)\n    else:\n        self._dtype = np.dtype(dtype)",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError(f'{type(self).__name__} objects must be 1-dimensional')\n    if not isinstance(self._data, PandasIndexingAdapter):\n        self._data = PandasIndexingAdapter(self._data)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    from .dataarray import DataArray\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, (Variable, DataArray)):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    if isinstance(data, (pd.Series, pd.Index, pd.DataFrame)):\n        data = data.values\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray) and (hasattr(data, '__array_function__') or hasattr(data, '__array_namespace__')):\n        return data\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray) and data.dtype.kind in 'OMm':\n        data = _possibly_convert_objects(data)\n    return _maybe_wrap_data(data)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.shape": "def shape(self) -> tuple[int, ...]:\n    return (len(self.array),)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexingAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims: str | Iterable[Hashable]) -> tuple[Hashable, ...]:\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError(f'dimensions {dims} must have the same length as the number of data dimensions, ndim={self.ndim}')\n    return dims",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> dict[Hashable, Any]:\n    if self._attrs is None:\n        self._attrs = {}\n    return self._attrs",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self):\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.core.dataset.py@@Dataset._replace_with_new_dims": "def _replace_with_new_dims(self: T_Dataset, variables: dict[Hashable, Variable], coord_names: set | None=None, attrs: dict[Hashable, Any] | None | Default=_default, indexes: dict[Hashable, Index] | None=None, inplace: bool=False) -> T_Dataset:\n    dims = calculate_dimensions(variables)\n    return self._replace(variables, coord_names, dims, attrs, indexes, inplace=inplace)",
    ".xarray.core.dataset.py@@Dataset._replace": "def _replace(self: T_Dataset, variables: dict[Hashable, Variable]=None, coord_names: set[Hashable] | None=None, dims: dict[Any, int] | None=None, attrs: dict[Hashable, Any] | None | Default=_default, indexes: dict[Hashable, Index] | None=None, encoding: dict | None | Default=_default, inplace: bool=False) -> T_Dataset:\n    if inplace:\n        if variables is not None:\n            self._variables = variables\n        if coord_names is not None:\n            self._coord_names = coord_names\n        if dims is not None:\n            self._dims = dims\n        if attrs is not _default:\n            self._attrs = attrs\n        if indexes is not None:\n            self._indexes = indexes\n        if encoding is not _default:\n            self._encoding = encoding\n        obj = self\n    else:\n        if variables is None:\n            variables = self._variables.copy()\n        if coord_names is None:\n            coord_names = self._coord_names.copy()\n        if dims is None:\n            dims = self._dims.copy()\n        if attrs is _default:\n            attrs = copy.copy(self._attrs)\n        if indexes is None:\n            indexes = self._indexes.copy()\n        if encoding is _default:\n            encoding = copy.copy(self._encoding)\n        obj = self._construct_direct(variables, coord_names, dims, attrs, indexes, encoding)\n    return obj",
    ".xarray.core.indexes.py@@Indexes._id_coord_names": "def _id_coord_names(self) -> dict[int, tuple[Hashable, ...]]:\n    if self.__id_coord_names is None:\n        id_coord_names: Mapping[int, list[Hashable]] = defaultdict(list)\n        for k, v in self._coord_name_id.items():\n            id_coord_names[v].append(k)\n        self.__id_coord_names = {k: tuple(v) for k, v in id_coord_names.items()}\n    return self.__id_coord_names",
    ".xarray.core.indexes.py@@Indexes._coord_name_id": "def _coord_name_id(self) -> dict[Any, int]:\n    if self.__coord_name_id is None:\n        self.__coord_name_id = {k: id(idx) for k, idx in self._indexes.items()}\n    return self.__coord_name_id",
    ".xarray.core.indexing.py@@PandasMultiIndexingAdapter.__array__": "def __array__(self, dtype: DTypeLike=None) -> np.ndarray:\n    if self.level is not None:\n        return self.array.get_level_values(self.level).values\n    else:\n        return super().__array__(dtype)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__array__": "def __array__(self, dtype: DTypeLike=None) -> np.ndarray:\n    if dtype is None:\n        dtype = self.dtype\n    array = self.array\n    if isinstance(array, pd.PeriodIndex):\n        with suppress(AttributeError):\n            array = array.astype('object')\n    return np.asarray(array.values, dtype=dtype)",
    ".xarray.core.variable.py@@Variable._replace": "def _replace(self: T_Variable, dims=_default, data=_default, attrs=_default, encoding=_default) -> T_Variable:\n    if dims is _default:\n        dims = copy.copy(self._dims)\n    if data is _default:\n        data = copy.copy(self.data)\n    if attrs is _default:\n        attrs = copy.copy(self._attrs)\n    if encoding is _default:\n        encoding = copy.copy(self._encoding)\n    return type(self)(dims, data, attrs, encoding, fastpath=True)",
    ".xarray.core.variable.py@@Variable.data": "def data(self) -> Any:\n    if is_duck_array(self._data):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.utils.py@@is_duck_array": "def is_duck_array(value: Any) -> bool:\n    if isinstance(value, np.ndarray):\n        return True\n    return hasattr(value, 'ndim') and hasattr(value, 'shape') and hasattr(value, 'dtype') and (hasattr(value, '__array_function__') and hasattr(value, '__array_ufunc__') or hasattr(value, '__array_namespace__'))"
}
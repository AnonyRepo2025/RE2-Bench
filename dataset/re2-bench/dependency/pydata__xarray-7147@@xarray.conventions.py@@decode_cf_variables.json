{
    ".xarray.core.variable.py@@Variable.dims": "def dims(self) -> tuple[Hashable, ...]:\n    return self._dims",
    ".xarray.conventions.py@@_update_bounds_attributes": "def _update_bounds_attributes(variables):\n    for v in variables.values():\n        attrs = v.attrs\n        units = attrs.get('units')\n        has_date_units = isinstance(units, str) and 'since' in units\n        if has_date_units and 'bounds' in attrs:\n            if attrs['bounds'] in variables:\n                bounds_attrs = variables[attrs['bounds']].attrs\n                bounds_attrs.setdefault('units', attrs['units'])\n                if 'calendar' in attrs:\n                    bounds_attrs.setdefault('calendar', attrs['calendar'])",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> dict[Any, Any]:\n    if self._attrs is None:\n        self._attrs = {}\n    return self._attrs",
    ".xarray.core.variable.py@@Variable.dtype": "def dtype(self):\n    return self._data.dtype",
    ".xarray.conventions.py@@decode_cf_variable": "def decode_cf_variable(name, var, concat_characters=True, mask_and_scale=True, decode_times=True, decode_endianness=True, stack_char_dim=True, use_cftime=None, decode_timedelta=None):\n    var = as_variable(var)\n    if _contains_datetime_like_objects(var):\n        return var\n    original_dtype = var.dtype\n    if decode_timedelta is None:\n        decode_timedelta = decode_times\n    if concat_characters:\n        if stack_char_dim:\n            var = strings.CharacterArrayCoder().decode(var, name=name)\n        var = strings.EncodedStringCoder().decode(var)\n    if mask_and_scale:\n        for coder in [variables.UnsignedIntegerCoder(), variables.CFMaskCoder(), variables.CFScaleOffsetCoder()]:\n            var = coder.decode(var, name=name)\n    if decode_timedelta:\n        var = times.CFTimedeltaCoder().decode(var, name=name)\n    if decode_times:\n        var = times.CFDatetimeCoder(use_cftime=use_cftime).decode(var, name=name)\n    dimensions, data, attributes, encoding = variables.unpack_for_decoding(var)\n    if decode_endianness and (not data.dtype.isnative):\n        data = NativeEndiannessArray(data)\n        original_dtype = data.dtype\n    encoding.setdefault('dtype', original_dtype)\n    if 'dtype' in attributes and attributes['dtype'] == 'bool':\n        del attributes['dtype']\n        data = BoolTypeArray(data)\n    if not is_duck_dask_array(data):\n        data = indexing.LazilyIndexedArray(data)\n    return Variable(dimensions, data, attributes, encoding=encoding)",
    ".xarray.core.variable.py@@as_variable": "def as_variable(obj, name=None) -> Variable | IndexVariable:\n    from .dataarray import DataArray\n    if isinstance(obj, DataArray):\n        obj = obj.variable\n    if isinstance(obj, Variable):\n        obj = obj.copy(deep=False)\n    elif isinstance(obj, tuple):\n        if isinstance(obj[1], DataArray):\n            raise TypeError('Using a DataArray object to construct a variable is ambiguous, please extract the data using the .data property.')\n        try:\n            obj = Variable(*obj)\n        except (TypeError, ValueError) as error:\n            raise error.__class__('Could not convert tuple of form (dims, data[, attrs, encoding]): {} to Variable.'.format(obj))\n    elif utils.is_scalar(obj):\n        obj = Variable([], obj)\n    elif isinstance(obj, (pd.Index, IndexVariable)) and obj.name is not None:\n        obj = Variable(obj.name, obj)\n    elif isinstance(obj, (set, dict)):\n        raise TypeError(f'variable {name!r} has invalid type {type(obj)!r}')\n    elif name is not None:\n        data = as_compatible_data(obj)\n        if data.ndim != 1:\n            raise MissingDimensionsError(f'cannot set variable {name!r} with {data.ndim!r}-dimensional data without explicit dimension names. Pass a tuple of (dims, data) instead.')\n        obj = Variable(name, data, fastpath=True)\n    else:\n        raise TypeError(f'unable to convert object into a variable without an explicit list of dimensions: {obj!r}')\n    if name is not None and name in obj.dims:\n        if obj.ndim != 1:\n            raise MissingDimensionsError(f'{name!r} has more than 1-dimension and the same name as one of its dimensions {obj.dims!r}. xarray disallows such variables because they conflict with the coordinates used to label dimensions.')\n        obj = obj.to_index_variable()\n    return obj",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self: T_Variable, deep: bool=True, data: ArrayLike | None=None) -> T_Variable:\n    return self._copy(deep=deep, data=data)",
    ".xarray.core.variable.py@@Variable._copy": "def _copy(self: T_Variable, deep: bool=True, data: ArrayLike | None=None, memo: dict[int, Any] | None=None) -> T_Variable:\n    if data is None:\n        ndata = self._data\n        if isinstance(ndata, indexing.MemoryCachedArray):\n            ndata = indexing.MemoryCachedArray(ndata.array)\n        if deep:\n            ndata = copy.deepcopy(ndata, memo)\n    else:\n        ndata = as_compatible_data(data)\n        if self.shape != ndata.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(ndata.shape, self.shape))\n    attrs = copy.deepcopy(self._attrs, memo) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding, memo) if deep else copy.copy(self._encoding)\n    return self._replace(data=ndata, attrs=attrs, encoding=encoding)",
    ".xarray.core.variable.py@@Variable._replace": "def _replace(self: T_Variable, dims=_default, data=_default, attrs=_default, encoding=_default) -> T_Variable:\n    if dims is _default:\n        dims = copy.copy(self._dims)\n    if data is _default:\n        data = copy.copy(self.data)\n    if attrs is _default:\n        attrs = copy.copy(self._attrs)\n    if encoding is _default:\n        encoding = copy.copy(self._encoding)\n    return type(self)(dims, data, attrs, encoding, fastpath=True)",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    from .dataarray import DataArray\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, (Variable, DataArray)):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    if isinstance(data, (pd.Series, pd.Index, pd.DataFrame)):\n        data = data.values\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray) and (hasattr(data, '__array_function__') or hasattr(data, '__array_namespace__')):\n        return data\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray) and data.dtype.kind in 'OMm':\n        data = _possibly_convert_objects(data)\n    return _maybe_wrap_data(data)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexingAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims: str | Iterable[Hashable]) -> tuple[Hashable, ...]:\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError(f'dimensions {dims} must have the same length as the number of data dimensions, ndim={self.ndim}')\n    return dims",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.common.py@@_contains_datetime_like_objects": "def _contains_datetime_like_objects(var) -> bool:\n    return is_np_datetime_like(var.dtype) or contains_cftime_datetimes(var)",
    ".xarray.core.common.py@@is_np_datetime_like": "def is_np_datetime_like(dtype: DTypeLike) -> bool:\n    return np.issubdtype(dtype, np.datetime64) or np.issubdtype(dtype, np.timedelta64)",
    ".xarray.core.common.py@@contains_cftime_datetimes": "def contains_cftime_datetimes(var) -> bool:\n    if var.dtype == np.dtype('O') and var.size > 0:\n        return _contains_cftime_datetimes(var.data)\n    else:\n        return False",
    ".xarray.coding.strings.py@@EncodedStringCoder.__init__": "def __init__(self, allows_unicode=True):\n    self.allows_unicode = allows_unicode",
    ".xarray.coding.strings.py@@EncodedStringCoder.decode": "def decode(self, variable, name=None):\n    dims, data, attrs, encoding = unpack_for_decoding(variable)\n    if '_Encoding' in attrs:\n        string_encoding = pop_to(attrs, encoding, '_Encoding')\n        func = partial(decode_bytes_array, encoding=string_encoding)\n        data = lazy_elemwise_func(data, func, np.dtype(object))\n    return Variable(dims, data, attrs, encoding)",
    ".xarray.coding.variables.py@@unpack_for_decoding": "def unpack_for_decoding(var):\n    return (var.dims, var._data, var.attrs.copy(), var.encoding.copy())",
    ".xarray.core.variable.py@@Variable.encoding": "def encoding(self) -> dict[Any, Any]:\n    if self._encoding is None:\n        self._encoding = {}\n    return self._encoding",
    ".xarray.coding.variables.py@@UnsignedIntegerCoder.decode": "def decode(self, variable, name=None):\n    dims, data, attrs, encoding = unpack_for_decoding(variable)\n    if '_Unsigned' in attrs:\n        unsigned = pop_to(attrs, encoding, '_Unsigned')\n        if data.dtype.kind == 'i':\n            if unsigned == 'true':\n                unsigned_dtype = np.dtype(f'u{data.dtype.itemsize}')\n                transform = partial(np.asarray, dtype=unsigned_dtype)\n                data = lazy_elemwise_func(data, transform, unsigned_dtype)\n                if '_FillValue' in attrs:\n                    new_fill = unsigned_dtype.type(attrs['_FillValue'])\n                    attrs['_FillValue'] = new_fill\n        elif data.dtype.kind == 'u':\n            if unsigned == 'false':\n                signed_dtype = np.dtype(f'i{data.dtype.itemsize}')\n                transform = partial(np.asarray, dtype=signed_dtype)\n                data = lazy_elemwise_func(data, transform, signed_dtype)\n                if '_FillValue' in attrs:\n                    new_fill = signed_dtype.type(attrs['_FillValue'])\n                    attrs['_FillValue'] = new_fill\n        else:\n            warnings.warn(f'variable {name!r} has _Unsigned attribute but is not of integer type. Ignoring attribute.', SerializationWarning, stacklevel=3)\n    return Variable(dims, data, attrs, encoding)",
    ".xarray.coding.variables.py@@CFMaskCoder.decode": "def decode(self, variable, name=None):\n    dims, data, attrs, encoding = unpack_for_decoding(variable)\n    raw_fill_values = [pop_to(attrs, encoding, attr, name=name) for attr in ('missing_value', '_FillValue')]\n    if raw_fill_values:\n        encoded_fill_values = {fv for option in raw_fill_values for fv in np.ravel(option) if not pd.isnull(fv)}\n        if len(encoded_fill_values) > 1:\n            warnings.warn('variable {!r} has multiple fill values {}, decoding all values to NaN.'.format(name, encoded_fill_values), SerializationWarning, stacklevel=3)\n        dtype, decoded_fill_value = dtypes.maybe_promote(data.dtype)\n        if encoded_fill_values:\n            transform = partial(_apply_mask, encoded_fill_values=encoded_fill_values, decoded_fill_value=decoded_fill_value, dtype=dtype)\n            data = lazy_elemwise_func(data, transform, dtype)\n    return Variable(dims, data, attrs, encoding)",
    ".xarray.coding.variables.py@@pop_to": "def pop_to(source, dest, key, name=None):\n    value = source.pop(key, None)\n    if value is not None:\n        safe_setitem(dest, key, value, name=name)\n    return value",
    ".xarray.core.dtypes.py@@maybe_promote": "def maybe_promote(dtype):\n    if np.issubdtype(dtype, np.floating):\n        fill_value = np.nan\n    elif np.issubdtype(dtype, np.timedelta64):\n        fill_value = np.timedelta64('NaT')\n    elif np.issubdtype(dtype, np.integer):\n        dtype = np.float32 if dtype.itemsize <= 2 else np.float64\n        fill_value = np.nan\n    elif np.issubdtype(dtype, np.complexfloating):\n        fill_value = np.nan + np.nan * 1j\n    elif np.issubdtype(dtype, np.datetime64):\n        fill_value = np.datetime64('NaT')\n    else:\n        dtype = object\n        fill_value = np.nan\n    return (np.dtype(dtype), fill_value)",
    ".xarray.coding.variables.py@@CFScaleOffsetCoder.decode": "def decode(self, variable, name=None):\n    dims, data, attrs, encoding = unpack_for_decoding(variable)\n    if 'scale_factor' in attrs or 'add_offset' in attrs:\n        scale_factor = pop_to(attrs, encoding, 'scale_factor', name=name)\n        add_offset = pop_to(attrs, encoding, 'add_offset', name=name)\n        dtype = _choose_float_dtype(data.dtype, 'add_offset' in encoding)\n        if np.ndim(scale_factor) > 0:\n            scale_factor = np.asarray(scale_factor).item()\n        if np.ndim(add_offset) > 0:\n            add_offset = np.asarray(add_offset).item()\n        transform = partial(_scale_offset_decoding, scale_factor=scale_factor, add_offset=add_offset, dtype=dtype)\n        data = lazy_elemwise_func(data, transform, dtype)\n    return Variable(dims, data, attrs, encoding)",
    ".xarray.coding.times.py@@CFTimedeltaCoder.decode": "def decode(self, variable, name=None):\n    dims, data, attrs, encoding = unpack_for_decoding(variable)\n    units = attrs.get('units')\n    if isinstance(units, str) and units in TIME_UNITS:\n        units = pop_to(attrs, encoding, 'units')\n        transform = partial(decode_cf_timedelta, units=units)\n        dtype = np.dtype('timedelta64[ns]')\n        data = lazy_elemwise_func(data, transform, dtype=dtype)\n    return Variable(dims, data, attrs, encoding)",
    ".xarray.coding.times.py@@CFDatetimeCoder.__init__": "def __init__(self, use_cftime=None):\n    self.use_cftime = use_cftime",
    ".xarray.coding.times.py@@CFDatetimeCoder.decode": "def decode(self, variable, name=None):\n    dims, data, attrs, encoding = unpack_for_decoding(variable)\n    units = attrs.get('units')\n    if isinstance(units, str) and 'since' in units:\n        units = pop_to(attrs, encoding, 'units')\n        calendar = pop_to(attrs, encoding, 'calendar')\n        dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n        transform = partial(decode_cf_datetime, units=units, calendar=calendar, use_cftime=self.use_cftime)\n        data = lazy_elemwise_func(data, transform, dtype)\n    return Variable(dims, data, attrs, encoding)",
    ".xarray.core.pycompat.py@@is_duck_dask_array": "def is_duck_dask_array(x):\n    return is_duck_array(x) and is_dask_collection(x)",
    ".xarray.core.utils.py@@is_duck_array": "def is_duck_array(value: Any) -> bool:\n    if isinstance(value, np.ndarray):\n        return True\n    return hasattr(value, 'ndim') and hasattr(value, 'shape') and hasattr(value, 'dtype') and (hasattr(value, '__array_function__') and hasattr(value, '__array_ufunc__') or hasattr(value, '__array_namespace__'))",
    ".xarray.core.pycompat.py@@is_dask_collection": "def is_dask_collection(x):\n    if dsk.available:\n        from dask.base import is_dask_collection\n        return is_dask_collection(x)\n    else:\n        return False",
    ".xarray.core.indexing.py@@LazilyIndexedArray.__init__": "def __init__(self, array, key=None):\n    if isinstance(array, type(self)) and key is None:\n        key = array.key\n        array = array.array\n    if key is None:\n        key = BasicIndexer((slice(None),) * array.ndim)\n    self.array = as_indexable(array)\n    self.key = key",
    ".xarray.core.indexing.py@@BasicIndexer.__init__": "def __init__(self, key):\n    if not isinstance(key, tuple):\n        raise TypeError(f'key must be a tuple: {key!r}')\n    new_key = []\n    for k in key:\n        if isinstance(k, integer_types):\n            k = int(k)\n        elif isinstance(k, slice):\n            k = as_integer_slice(k)\n        else:\n            raise TypeError(f'unexpected indexer type for {type(self).__name__}: {k!r}')\n        new_key.append(k)\n    super().__init__(new_key)",
    ".xarray.core.indexing.py@@as_integer_slice": "def as_integer_slice(value):\n    start = as_integer_or_none(value.start)\n    stop = as_integer_or_none(value.stop)\n    step = as_integer_or_none(value.step)\n    return slice(start, stop, step)",
    ".xarray.core.indexing.py@@as_integer_or_none": "def as_integer_or_none(value):\n    return None if value is None else operator.index(value)",
    ".xarray.core.indexing.py@@ExplicitIndexer.__init__": "def __init__(self, key):\n    if type(self) is ExplicitIndexer:\n        raise TypeError('cannot instantiate base ExplicitIndexer objects')\n    self._key = tuple(key)",
    ".xarray.core.indexing.py@@as_indexable": "def as_indexable(array):\n    if isinstance(array, ExplicitlyIndexed):\n        return array\n    if isinstance(array, np.ndarray):\n        return NumpyIndexingAdapter(array)\n    if isinstance(array, pd.Index):\n        return PandasIndexingAdapter(array)\n    if is_duck_dask_array(array):\n        return DaskIndexingAdapter(array)\n    if hasattr(array, '__array_function__'):\n        return NdArrayLikeIndexingAdapter(array)\n    if hasattr(array, '__array_namespace__'):\n        return ArrayApiIndexingAdapter(array)\n    raise TypeError(f'Invalid array type: {type(array)}')",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter.__init__": "def __init__(self, array):\n    if not isinstance(array, np.ndarray):\n        raise TypeError('NumpyIndexingAdapter only wraps np.ndarray. Trying to wrap {}'.format(type(array)))\n    self.array = array",
    ".xarray.core.indexing.py@@LazilyIndexedArray.shape": "def shape(self) -> tuple[int, ...]:\n    shape = []\n    for size, k in zip(self.array.shape, self.key.tuple):\n        if isinstance(k, slice):\n            shape.append(len(range(*k.indices(size))))\n        elif isinstance(k, np.ndarray):\n            shape.append(k.size)\n    return tuple(shape)",
    ".xarray.core.utils.py@@NDArrayMixin.shape": "def shape(self: Any) -> tuple[int, ...]:\n    return self.array.shape",
    ".xarray.core.indexing.py@@ExplicitIndexer.tuple": "def tuple(self):\n    return self._key",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.dtype": "def dtype(self) -> np.dtype:\n    return self._dtype",
    ".xarray.core.variable.py@@IndexVariable.copy": "def copy(self, deep: bool=True, data: ArrayLike | None=None):\n    if data is None:\n        ndata = self._data.copy(deep=deep)\n    else:\n        ndata = as_compatible_data(data)\n        if self.shape != ndata.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(ndata.shape, self.shape))\n    attrs = copy.deepcopy(self._attrs) if deep else copy.copy(self._attrs)\n    encoding = copy.deepcopy(self._encoding) if deep else copy.copy(self._encoding)\n    return self._replace(data=ndata, attrs=attrs, encoding=encoding)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.copy": "def copy(self, deep: bool=True) -> PandasIndexingAdapter:\n    array = self.array.copy(deep=True) if deep else self.array\n    return type(self)(array, self._dtype)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__init__": "def __init__(self, array: pd.Index, dtype: DTypeLike=None):\n    self.array = safe_cast_to_index(array)\n    if dtype is None:\n        self._dtype = get_valid_numpy_dtype(array)\n    else:\n        self._dtype = np.dtype(dtype)",
    ".xarray.core.utils.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    if isinstance(array, pd.Index):\n        index = array\n    elif hasattr(array, 'to_index'):\n        index = array.to_index()\n    elif hasattr(array, 'to_pandas_index'):\n        index = array.to_pandas_index()\n    elif hasattr(array, 'array') and isinstance(array.array, pd.Index):\n        index = array.array\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.utils.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError(f'{type(self).__name__} objects must be 1-dimensional')\n    if not isinstance(self._data, PandasIndexingAdapter):\n        self._data = PandasIndexingAdapter(self._data)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.shape": "def shape(self) -> tuple[int, ...]:\n    return (len(self.array),)",
    ".xarray.coding.variables.py@@safe_setitem": "def safe_setitem(dest, key, value, name=None):\n    if key in dest:\n        var_str = f' on variable {name!r}' if name else ''\n        raise ValueError(\"failed to prevent overwriting existing key {} in attrs{}. This is probably an encoding field used by xarray to describe how a variable is serialized. To proceed, remove this key from the variable's attributes manually.\".format(key, var_str))\n    dest[key] = value",
    ".xarray.coding.times.py@@_decode_cf_datetime_dtype": "def _decode_cf_datetime_dtype(data, units, calendar, use_cftime):\n    values = indexing.ImplicitToExplicitIndexingAdapter(indexing.as_indexable(data))\n    example_value = np.concatenate([first_n_items(values, 1) or [0], last_item(values) or [0]])\n    try:\n        result = decode_cf_datetime(example_value, units, calendar, use_cftime)\n    except Exception:\n        calendar_msg = 'the default calendar' if calendar is None else f'calendar {calendar!r}'\n        msg = f'unable to decode time units {units!r} with {calendar_msg!r}. Try opening your dataset with decode_times=False or installing cftime if it is not installed.'\n        raise ValueError(msg)\n    else:\n        dtype = getattr(result, 'dtype', np.dtype('object'))\n    return dtype",
    ".xarray.core.indexing.py@@ImplicitToExplicitIndexingAdapter.__init__": "def __init__(self, array, indexer_cls=BasicIndexer):\n    self.array = as_indexable(array)\n    self.indexer_cls = indexer_cls",
    ".xarray.core.formatting.py@@first_n_items": "def first_n_items(array, n_desired):\n    if n_desired < 1:\n        raise ValueError('must request at least one item')\n    if array.size == 0:\n        return []\n    if n_desired < array.size:\n        indexer = _get_indexer_at_least_n_items(array.shape, n_desired, from_end=False)\n        array = array[indexer]\n    return np.asarray(array).flat[:n_desired]",
    ".xarray.core.utils.py@@NdimSizeLenMixin.size": "def size(self: Any) -> int:\n    return math.prod(self.shape)",
    ".xarray.core.indexing.py@@ImplicitToExplicitIndexingAdapter.__array__": "def __array__(self, dtype=None):\n    return np.asarray(self.array, dtype=dtype)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__array__": "def __array__(self, dtype: DTypeLike=None) -> np.ndarray:\n    if dtype is None:\n        dtype = self.dtype\n    array = self.array\n    if isinstance(array, pd.PeriodIndex):\n        with suppress(AttributeError):\n            array = array.astype('object')\n    return np.asarray(array.values, dtype=dtype)",
    ".xarray.core.formatting.py@@last_item": "def last_item(array):\n    if array.size == 0:\n        return []\n    indexer = (slice(-1, None),) * array.ndim\n    return np.ravel(np.asarray(array[indexer])).tolist()",
    ".xarray.core.indexing.py@@ImplicitToExplicitIndexingAdapter.__getitem__": "def __getitem__(self, key):\n    key = expanded_indexer(key, self.ndim)\n    result = self.array[self.indexer_cls(key)]\n    if isinstance(result, ExplicitlyIndexed):\n        return type(self)(result, self.indexer_cls)\n    else:\n        return result",
    ".xarray.core.indexing.py@@expanded_indexer": "def expanded_indexer(key, ndim):\n    if not isinstance(key, tuple):\n        key = (key,)\n    new_key = []\n    found_ellipsis = False\n    for k in key:\n        if k is Ellipsis:\n            if not found_ellipsis:\n                new_key.extend((ndim + 1 - len(key)) * [slice(None)])\n                found_ellipsis = True\n            else:\n                new_key.append(slice(None))\n        else:\n            new_key.append(k)\n    if len(new_key) > ndim:\n        raise IndexError('too many indices')\n    new_key.extend((ndim - len(new_key)) * [slice(None)])\n    return tuple(new_key)",
    ".xarray.core.indexing.py@@PandasIndexingAdapter.__getitem__": "def __getitem__(self, indexer) -> PandasIndexingAdapter | NumpyIndexingAdapter | np.ndarray | np.datetime64 | np.timedelta64:\n    key = indexer.tuple\n    if isinstance(key, tuple) and len(key) == 1:\n        key, = key\n    if getattr(key, 'ndim', 0) > 1:\n        return NumpyIndexingAdapter(np.asarray(self))[indexer]\n    result = self.array[key]\n    if isinstance(result, pd.Index):\n        return type(self)(result, dtype=self.dtype)\n    else:\n        return self._convert_scalar(result)",
    ".xarray.coding.times.py@@decode_cf_datetime": "def decode_cf_datetime(num_dates, units, calendar=None, use_cftime=None):\n    num_dates = np.asarray(num_dates)\n    flat_num_dates = num_dates.ravel()\n    if calendar is None:\n        calendar = 'standard'\n    if use_cftime is None:\n        try:\n            dates = _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n        except (KeyError, OutOfBoundsDatetime, OutOfBoundsTimedelta, OverflowError):\n            dates = _decode_datetime_with_cftime(flat_num_dates.astype(float), units, calendar)\n            if dates[np.nanargmin(num_dates)].year < 1678 or dates[np.nanargmax(num_dates)].year >= 2262:\n                if _is_standard_calendar(calendar):\n                    warnings.warn('Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range', SerializationWarning, stacklevel=3)\n            elif _is_standard_calendar(calendar):\n                dates = cftime_to_nptime(dates)\n    elif use_cftime:\n        dates = _decode_datetime_with_cftime(flat_num_dates, units, calendar)\n    else:\n        dates = _decode_datetime_with_pandas(flat_num_dates, units, calendar)\n    return dates.reshape(num_dates.shape)",
    ".xarray.coding.times.py@@_decode_datetime_with_pandas": "def _decode_datetime_with_pandas(flat_num_dates, units, calendar):\n    if not _is_standard_calendar(calendar):\n        raise OutOfBoundsDatetime('Cannot decode times from a non-standard calendar, {!r}, using pandas.'.format(calendar))\n    delta, ref_date = _unpack_netcdf_time_units(units)\n    delta = _netcdf_to_numpy_timeunit(delta)\n    try:\n        ref_date = pd.Timestamp(ref_date)\n    except ValueError:\n        raise OutOfBoundsDatetime\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore', 'invalid value encountered', RuntimeWarning)\n        if flat_num_dates.size > 0:\n            pd.to_timedelta(flat_num_dates.min(), delta) + ref_date\n            pd.to_timedelta(flat_num_dates.max(), delta) + ref_date\n    if flat_num_dates.dtype.kind in 'iu':\n        flat_num_dates = flat_num_dates.astype(np.int64)\n    flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(np.int64)\n    return (pd.to_timedelta(flat_num_dates_ns_int, 'ns') + ref_date).values",
    ".xarray.coding.times.py@@_is_standard_calendar": "def _is_standard_calendar(calendar):\n    return calendar.lower() in _STANDARD_CALENDARS",
    ".xarray.coding.times.py@@_unpack_netcdf_time_units": "def _unpack_netcdf_time_units(units):\n    matches = re.match('(.+) since (.+)', units)\n    if not matches:\n        raise ValueError(f'invalid time units: {units}')\n    delta_units, ref_date = (s.strip() for s in matches.groups())\n    ref_date = _ensure_padded_year(ref_date)\n    return (delta_units, ref_date)",
    ".xarray.coding.times.py@@_ensure_padded_year": "def _ensure_padded_year(ref_date):\n    matches_year = re.match('.*\\\\d{4}.*', ref_date)\n    if matches_year:\n        return ref_date\n    matches_start_digits = re.match('(\\\\d+)(.*)', ref_date)\n    if not matches_start_digits:\n        raise ValueError(f'invalid reference date for time units: {ref_date}')\n    ref_year, everything_else = (s for s in matches_start_digits.groups())\n    ref_date_padded = f'{int(ref_year):04d}{everything_else}'\n    warning_msg = f'Ambiguous reference date string: {ref_date}. The first value is assumed to be the year hence will be padded with zeros to remove the ambiguity (the padded reference date string is: {ref_date_padded}). To remove this message, remove the ambiguity by padding your reference date strings with zeros.'\n    warnings.warn(warning_msg, SerializationWarning)\n    return ref_date_padded",
    ".xarray.coding.times.py@@_netcdf_to_numpy_timeunit": "def _netcdf_to_numpy_timeunit(units):\n    units = units.lower()\n    if not units.endswith('s'):\n        units = f'{units}s'\n    return {'nanoseconds': 'ns', 'microseconds': 'us', 'milliseconds': 'ms', 'seconds': 's', 'minutes': 'm', 'hours': 'h', 'days': 'D'}[units]",
    ".xarray.coding.variables.py@@lazy_elemwise_func": "def lazy_elemwise_func(array, func, dtype):\n    if is_duck_dask_array(array):\n        import dask.array as da\n        return da.map_blocks(func, array, dtype=dtype)\n    else:\n        return _ElementwiseFunctionArray(array, func, dtype)",
    ".xarray.coding.variables.py@@_ElementwiseFunctionArray.__init__": "def __init__(self, array, func, dtype):\n    assert not is_duck_dask_array(array)\n    self.array = indexing.as_indexable(array)\n    self.func = func\n    self._dtype = dtype",
    ".xarray.coding.variables.py@@_ElementwiseFunctionArray.dtype": "def dtype(self):\n    return np.dtype(self._dtype)",
    ".xarray.core.formatting.py@@_get_indexer_at_least_n_items": "def _get_indexer_at_least_n_items(shape, n_desired, from_end):\n    assert 0 < n_desired <= math.prod(shape)\n    cum_items = np.cumprod(shape[::-1])\n    n_steps = np.argmax(cum_items >= n_desired)\n    stop = math.ceil(float(n_desired) / np.r_[1, cum_items][n_steps])\n    indexer = (-1 if from_end else 0,) * (len(shape) - 1 - n_steps) + (slice(-stop, None) if from_end else slice(stop),) + (slice(None),) * n_steps\n    return indexer",
    ".xarray.coding.times.py@@_decode_datetime_with_cftime": "def _decode_datetime_with_cftime(num_dates, units, calendar):\n    if cftime is None:\n        raise ModuleNotFoundError(\"No module named 'cftime'\")\n    if num_dates.size > 0:\n        return np.asarray(cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True))\n    else:\n        return np.array([], dtype=object)",
    ".xarray.core.indexing.py@@DaskIndexingAdapter.__init__": "def __init__(self, array):\n    self.array = array",
    ".xarray.core.indexing.py@@DaskIndexingAdapter.__getitem__": "def __getitem__(self, key):\n    if not isinstance(key, VectorizedIndexer):\n        rewritten_indexer = False\n        new_indexer = []\n        for idim, k in enumerate(key.tuple):\n            if isinstance(k, Iterable) and duck_array_ops.array_equiv(k, np.arange(self.array.shape[idim])):\n                new_indexer.append(slice(None))\n                rewritten_indexer = True\n            else:\n                new_indexer.append(k)\n        if rewritten_indexer:\n            key = type(key)(tuple(new_indexer))\n    if isinstance(key, BasicIndexer):\n        return self.array[key.tuple]\n    elif isinstance(key, VectorizedIndexer):\n        return self.array.vindex[key.tuple]\n    else:\n        assert isinstance(key, OuterIndexer)\n        key = key.tuple\n        try:\n            return self.array[key]\n        except NotImplementedError:\n            value = self.array\n            for axis, subkey in reversed(list(enumerate(key))):\n                value = value[(slice(None),) * axis + (subkey,)]\n            return value",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter.__getitem__": "def __getitem__(self, key):\n    array, key = self._indexing_array_and_key(key)\n    return array[key]",
    ".xarray.core.indexing.py@@NumpyIndexingAdapter._indexing_array_and_key": "def _indexing_array_and_key(self, key):\n    if isinstance(key, OuterIndexer):\n        array = self.array\n        key = _outer_to_numpy_indexer(key, self.array.shape)\n    elif isinstance(key, VectorizedIndexer):\n        array = NumpyVIndexAdapter(self.array)\n        key = key.tuple\n    elif isinstance(key, BasicIndexer):\n        array = self.array\n        key = key.tuple + (Ellipsis,)\n    else:\n        raise TypeError(f'unexpected key type: {type(key)}')\n    return (array, key)",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.variable.py@@Variable.data": "def data(self) -> Any:\n    if is_duck_array(self._data):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.common.py@@_contains_cftime_datetimes": "def _contains_cftime_datetimes(array) -> bool:\n    if cftime is None:\n        return False\n    elif array.dtype == np.dtype('O') and array.size > 0:\n        sample = np.asarray(array).flat[0]\n        if is_duck_dask_array(sample):\n            sample = sample.compute()\n            if isinstance(sample, np.ndarray):\n                sample = sample.item()\n        return isinstance(sample, cftime.datetime)\n    else:\n        return False",
    ".xarray.core.variable.py@@_possibly_convert_objects": "def _possibly_convert_objects(values):\n    return np.asarray(pd.Series(values.ravel())).reshape(values.shape)",
    ".xarray.core.indexing.py@@ExplicitlyIndexedNDArrayMixin.__array__": "def __array__(self, dtype=None):\n    key = BasicIndexer((slice(None),) * self.ndim)\n    return np.asarray(self[key], dtype=dtype)",
    ".xarray.core.utils.py@@NDArrayMixin.dtype": "def dtype(self: Any) -> np.dtype:\n    return self.array.dtype",
    ".xarray.core.indexing.py@@LazilyIndexedArray.__array__": "def __array__(self, dtype=None):\n    array = as_indexable(self.array)\n    return np.asarray(array[self.key], dtype=None)",
    ".xarray.backends.netCDF4_.py@@NetCDF4ArrayWrapper.__getitem__": "def __getitem__(self, key):\n    return indexing.explicit_indexing_adapter(key, self.shape, indexing.IndexingSupport.OUTER, self._getitem)",
    ".xarray.core.indexing.py@@explicit_indexing_adapter": "def explicit_indexing_adapter(key: ExplicitIndexer, shape: tuple[int, ...], indexing_support: IndexingSupport, raw_indexing_method: Callable) -> Any:\n    raw_key, numpy_indices = decompose_indexer(key, shape, indexing_support)\n    result = raw_indexing_method(raw_key.tuple)\n    if numpy_indices.tuple:\n        result = NumpyIndexingAdapter(np.asarray(result))[numpy_indices]\n    return result",
    ".xarray.core.indexing.py@@decompose_indexer": "def decompose_indexer(indexer: ExplicitIndexer, shape: tuple[int, ...], indexing_support: IndexingSupport) -> tuple[ExplicitIndexer, ExplicitIndexer]:\n    if isinstance(indexer, VectorizedIndexer):\n        return _decompose_vectorized_indexer(indexer, shape, indexing_support)\n    if isinstance(indexer, (BasicIndexer, OuterIndexer)):\n        return _decompose_outer_indexer(indexer, shape, indexing_support)\n    raise TypeError(f'unexpected key type: {indexer}')",
    ".xarray.core.indexing.py@@_decompose_outer_indexer": "def _decompose_outer_indexer(indexer: BasicIndexer | OuterIndexer, shape: tuple[int, ...], indexing_support: IndexingSupport) -> tuple[ExplicitIndexer, ExplicitIndexer]:\n    if indexing_support == IndexingSupport.VECTORIZED:\n        return (indexer, BasicIndexer(()))\n    assert isinstance(indexer, (OuterIndexer, BasicIndexer))\n    backend_indexer: list[Any] = []\n    np_indexer = []\n    pos_indexer: list[np.ndarray | int | np.number] = []\n    for k, s in zip(indexer.tuple, shape):\n        if isinstance(k, np.ndarray):\n            pos_indexer.append(np.where(k < 0, k + s, k))\n        elif isinstance(k, integer_types) and k < 0:\n            pos_indexer.append(k + s)\n        else:\n            pos_indexer.append(k)\n    indexer_elems = pos_indexer\n    if indexing_support is IndexingSupport.OUTER_1VECTOR:\n        gains = [(np.max(k) - np.min(k) + 1.0) / len(np.unique(k)) if isinstance(k, np.ndarray) else 0 for k in indexer_elems]\n        array_index = np.argmax(np.array(gains)) if len(gains) > 0 else None\n        for i, (k, s) in enumerate(zip(indexer_elems, shape)):\n            if isinstance(k, np.ndarray) and i != array_index:\n                backend_indexer.append(slice(np.min(k), np.max(k) + 1))\n                np_indexer.append(k - np.min(k))\n            elif isinstance(k, np.ndarray):\n                pkey, ekey = np.unique(k, return_inverse=True)\n                backend_indexer.append(pkey)\n                np_indexer.append(ekey)\n            elif isinstance(k, integer_types):\n                backend_indexer.append(k)\n            else:\n                bk_slice, np_slice = _decompose_slice(k, s)\n                backend_indexer.append(bk_slice)\n                np_indexer.append(np_slice)\n        return (OuterIndexer(tuple(backend_indexer)), OuterIndexer(tuple(np_indexer)))\n    if indexing_support == IndexingSupport.OUTER:\n        for k, s in zip(indexer_elems, shape):\n            if isinstance(k, slice):\n                bk_slice, np_slice = _decompose_slice(k, s)\n                backend_indexer.append(bk_slice)\n                np_indexer.append(np_slice)\n            elif isinstance(k, integer_types):\n                backend_indexer.append(k)\n            elif isinstance(k, np.ndarray) and (np.diff(k) >= 0).all():\n                backend_indexer.append(k)\n                np_indexer.append(slice(None))\n            else:\n                oind, vind = np.unique(k, return_inverse=True)\n                backend_indexer.append(oind)\n                np_indexer.append(vind.reshape(*k.shape))\n        return (OuterIndexer(tuple(backend_indexer)), OuterIndexer(tuple(np_indexer)))\n    assert indexing_support == IndexingSupport.BASIC\n    for k, s in zip(indexer_elems, shape):\n        if isinstance(k, np.ndarray):\n            backend_indexer.append(slice(np.min(k), np.max(k) + 1))\n            np_indexer.append(k - np.min(k))\n        elif isinstance(k, integer_types):\n            backend_indexer.append(k)\n        else:\n            bk_slice, np_slice = _decompose_slice(k, s)\n            backend_indexer.append(bk_slice)\n            np_indexer.append(np_slice)\n    return (BasicIndexer(tuple(backend_indexer)), OuterIndexer(tuple(np_indexer)))",
    ".xarray.core.indexing.py@@_decompose_slice": "def _decompose_slice(key, size):\n    start, stop, step = key.indices(size)\n    if step > 0:\n        return (key, slice(None))\n    else:\n        stop = start + int((stop - start - 1) / step) * step + 1\n        start, stop = (stop + 1, start + 1)\n        return (slice(start, stop, -step), slice(None, None, -1))",
    ".xarray.core.indexing.py@@OuterIndexer.__init__": "def __init__(self, key):\n    if not isinstance(key, tuple):\n        raise TypeError(f'key must be a tuple: {key!r}')\n    new_key = []\n    for k in key:\n        if isinstance(k, integer_types):\n            k = int(k)\n        elif isinstance(k, slice):\n            k = as_integer_slice(k)\n        elif isinstance(k, np.ndarray):\n            if not np.issubdtype(k.dtype, np.integer):\n                raise TypeError(f'invalid indexer array, does not have integer dtype: {k!r}')\n            if k.ndim != 1:\n                raise TypeError(f'invalid indexer array for {type(self).__name__}; must have exactly 1 dimension: {k!r}')\n            k = np.asarray(k, dtype=np.int64)\n        else:\n            raise TypeError(f'unexpected indexer type for {type(self).__name__}: {k!r}')\n        new_key.append(k)\n    super().__init__(new_key)",
    ".xarray.backends.netCDF4_.py@@NetCDF4ArrayWrapper._getitem": "def _getitem(self, key):\n    if self.datastore.is_remote:\n        getitem = functools.partial(robust_getitem, catch=RuntimeError)\n    else:\n        getitem = operator.getitem\n    try:\n        with self.datastore.lock:\n            original_array = self.get_array(needs_lock=False)\n            array = getitem(original_array, key)\n    except IndexError:\n        msg = 'The indexing operation you are attempting to perform is not valid on netCDF4.Variable object. Try loading your data into memory first by calling .load().'\n        raise IndexError(msg)\n    return array",
    ".xarray.backends.locks.py@@CombinedLock.__enter__": "def __enter__(self):\n    for lock in self.locks:\n        lock.__enter__()",
    ".xarray.backends.netCDF4_.py@@NetCDF4ArrayWrapper.get_array": "def get_array(self, needs_lock=True):\n    ds = self.datastore._acquire(needs_lock)\n    variable = ds.variables[self.variable_name]\n    variable.set_auto_maskandscale(False)\n    with suppress(AttributeError):\n        variable.set_auto_chartostring(False)\n    return variable",
    ".xarray.backends.netCDF4_.py@@NetCDF4DataStore._acquire": "def _acquire(self, needs_lock=True):\n    with self._manager.acquire_context(needs_lock) as root:\n        ds = _nc4_require_group(root, self._group, self._mode)\n    return ds",
    ".xarray.backends.file_manager.py@@CachingFileManager.acquire_context": "def acquire_context(self, needs_lock=True):\n    file, cached = self._acquire_with_cache_info(needs_lock)\n    try:\n        yield file\n    except Exception:\n        if not cached:\n            self.close(needs_lock)\n        raise",
    ".xarray.backends.file_manager.py@@CachingFileManager._acquire_with_cache_info": "def _acquire_with_cache_info(self, needs_lock=True):\n    with self._optional_lock(needs_lock):\n        try:\n            file = self._cache[self._key]\n        except KeyError:\n            kwargs = self._kwargs\n            if self._mode is not _DEFAULT_MODE:\n                kwargs = kwargs.copy()\n                kwargs['mode'] = self._mode\n            file = self._opener(*self._args, **kwargs)\n            if self._mode == 'w':\n                self._mode = 'a'\n            self._cache[self._key] = file\n            return (file, False)\n        else:\n            return (file, True)",
    ".xarray.backends.file_manager.py@@CachingFileManager._optional_lock": "def _optional_lock(self, needs_lock):\n    if needs_lock:\n        with self._lock:\n            yield\n    else:\n        yield",
    ".xarray.backends.lru_cache.py@@LRUCache.__getitem__": "def __getitem__(self, key: K) -> V:\n    with self._lock:\n        value = self._cache[key]\n        self._cache.move_to_end(key)\n        return value",
    ".xarray.backends.file_manager.py@@_HashedSequence.__hash__": "def __hash__(self):\n    return self.hashvalue",
    ".xarray.backends.netCDF4_.py@@_nc4_require_group": "def _nc4_require_group(ds, group, mode, create_group=_netcdf4_create_group):\n    if group in {None, '', '/'}:\n        return ds\n    else:\n        if not isinstance(group, str):\n            raise ValueError('group must be a string or None')\n        path = group.strip('/').split('/')\n        for key in path:\n            try:\n                ds = ds.groups[key]\n            except KeyError as e:\n                if mode != 'r':\n                    ds = create_group(ds, key)\n                else:\n                    raise OSError(f'group not found: {key}', e)\n        return ds",
    ".xarray.backends.locks.py@@CombinedLock.__exit__": "def __exit__(self, *args):\n    for lock in self.locks:\n        lock.__exit__(*args)",
    ".xarray.core.indexing.py@@_outer_to_numpy_indexer": "def _outer_to_numpy_indexer(key, shape):\n    if len([k for k in key.tuple if not isinstance(k, slice)]) <= 1:\n        return key.tuple\n    else:\n        return _outer_to_vectorized_indexer(key, shape).tuple",
    ".xarray.core.indexing.py@@LazilyIndexedArray.__getitem__": "def __getitem__(self, indexer):\n    if isinstance(indexer, VectorizedIndexer):\n        array = LazilyVectorizedIndexedArray(self.array, self.key)\n        return array[indexer]\n    return type(self)(self.array, self._updated_key(indexer))",
    ".xarray.core.indexing.py@@LazilyIndexedArray._updated_key": "def _updated_key(self, new_key):\n    iter_new_key = iter(expanded_indexer(new_key.tuple, self.ndim))\n    full_key = []\n    for size, k in zip(self.array.shape, self.key.tuple):\n        if isinstance(k, integer_types):\n            full_key.append(k)\n        else:\n            full_key.append(_index_indexer_1d(k, next(iter_new_key), size))\n    full_key = tuple(full_key)\n    if all((isinstance(k, integer_types + (slice,)) for k in full_key)):\n        return BasicIndexer(full_key)\n    return OuterIndexer(full_key)",
    ".xarray.core.indexing.py@@_index_indexer_1d": "def _index_indexer_1d(old_indexer, applied_indexer, size):\n    assert isinstance(applied_indexer, integer_types + (slice, np.ndarray))\n    if isinstance(applied_indexer, slice) and applied_indexer == slice(None):\n        return old_indexer\n    if isinstance(old_indexer, slice):\n        if isinstance(applied_indexer, slice):\n            indexer = slice_slice(old_indexer, applied_indexer, size)\n        else:\n            indexer = _expand_slice(old_indexer, size)[applied_indexer]\n    else:\n        indexer = old_indexer[applied_indexer]\n    return indexer",
    ".xarray.core.indexing.py@@slice_slice": "def slice_slice(old_slice, applied_slice, size):\n    old_slice = _normalize_slice(old_slice, size)\n    size_after_old_slice = len(range(old_slice.start, old_slice.stop, old_slice.step))\n    if size_after_old_slice == 0:\n        return slice(0)\n    applied_slice = _normalize_slice(applied_slice, size_after_old_slice)\n    start = old_slice.start + applied_slice.start * old_slice.step\n    if start < 0:\n        return slice(0)\n    stop = old_slice.start + applied_slice.stop * old_slice.step\n    if stop < 0:\n        stop = None\n    step = old_slice.step * applied_slice.step\n    return slice(start, stop, step)",
    ".xarray.core.indexing.py@@_normalize_slice": "def _normalize_slice(sl, size):\n    return slice(*sl.indices(size))",
    ".xarray.conventions.py@@BoolTypeArray.__init__": "def __init__(self, array):\n    self.array = indexing.as_indexable(array)",
    ".xarray.conventions.py@@BoolTypeArray.dtype": "def dtype(self):\n    return np.dtype('bool')",
    ".xarray.coding.variables.py@@_choose_float_dtype": "def _choose_float_dtype(dtype, has_offset):\n    if dtype.itemsize <= 4 and np.issubdtype(dtype, np.floating):\n        return np.float32\n    if dtype.itemsize <= 2 and np.issubdtype(dtype, np.integer):\n        if not has_offset:\n            return np.float32\n    return np.float64",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((type(self), self._value))",
    ".xarray.conventions.py@@NativeEndiannessArray.__init__": "def __init__(self, array):\n    self.array = indexing.as_indexable(array)",
    ".xarray.conventions.py@@NativeEndiannessArray.dtype": "def dtype(self):\n    return np.dtype(self.array.dtype.kind + str(self.array.dtype.itemsize))",
    ".xarray.core.variable.py@@Variable.values": "def values(self):\n    return _as_array_or_item(self._data)",
    ".xarray.core.variable.py@@_as_array_or_item": "def _as_array_or_item(data):\n    data = np.asarray(data)\n    if data.ndim == 0:\n        if data.dtype.kind == 'M':\n            data = np.datetime64(data, 'ns')\n        elif data.dtype.kind == 'm':\n            data = np.timedelta64(data, 'ns')\n    return data"
}
{
    ".sklearn.utils.validation.py@@check_random_state": "def check_random_state(seed):\n    if seed is None or seed is np.random:\n        return np.random.mtrand._rand\n    if isinstance(seed, numbers.Integral):\n        return np.random.RandomState(seed)\n    if isinstance(seed, np.random.RandomState):\n        return seed\n    raise ValueError('%r cannot be used to seed a numpy.random.RandomState instance' % seed)",
    ".sklearn.datasets.samples_generator.py@@_generate_hypercube": "def _generate_hypercube(samples, dimensions, rng):\n    if dimensions > 30:\n        return np.hstack([rng.randint(2, size=(samples, dimensions - 30)), _generate_hypercube(samples, 30, rng)])\n    out = sample_without_replacement(2 ** dimensions, samples, random_state=rng).astype(dtype='>u4', copy=False)\n    out = np.unpackbits(out.view('>u1')).reshape((-1, 32))[:, -dimensions:]\n    return out",
    ".sklearn.utils.__init__.py@@shuffle": "def shuffle(*arrays, **options):\n    options['replace'] = False\n    return resample(*arrays, **options)",
    ".sklearn.utils.__init__.py@@resample": "def resample(*arrays, **options):\n    random_state = check_random_state(options.pop('random_state', None))\n    replace = options.pop('replace', True)\n    max_n_samples = options.pop('n_samples', None)\n    stratify = options.pop('stratify', None)\n    if options:\n        raise ValueError('Unexpected kw arguments: %r' % options.keys())\n    if len(arrays) == 0:\n        return None\n    first = arrays[0]\n    n_samples = first.shape[0] if hasattr(first, 'shape') else len(first)\n    if max_n_samples is None:\n        max_n_samples = n_samples\n    elif max_n_samples > n_samples and (not replace):\n        raise ValueError('Cannot sample %d out of arrays with dim %d when replace is False' % (max_n_samples, n_samples))\n    check_consistent_length(*arrays)\n    if stratify is None:\n        if replace:\n            indices = random_state.randint(0, n_samples, size=(max_n_samples,))\n        else:\n            indices = np.arange(n_samples)\n            random_state.shuffle(indices)\n            indices = indices[:max_n_samples]\n    else:\n        y = check_array(stratify, ensure_2d=False, dtype=None)\n        if y.ndim == 2:\n            y = np.array([' '.join(row.astype('str')) for row in y])\n        classes, y_indices = np.unique(y, return_inverse=True)\n        n_classes = classes.shape[0]\n        class_counts = np.bincount(y_indices)\n        class_indices = np.split(np.argsort(y_indices, kind='mergesort'), np.cumsum(class_counts)[:-1])\n        n_i = _approximate_mode(class_counts, max_n_samples, random_state)\n        indices = []\n        for i in range(n_classes):\n            indices_i = random_state.choice(class_indices[i], n_i[i], replace=replace)\n            indices.extend(indices_i)\n        indices = random_state.permutation(indices)\n    arrays = [a.tocsr() if issparse(a) else a for a in arrays]\n    resampled_arrays = [safe_indexing(a, indices) for a in arrays]\n    if len(resampled_arrays) == 1:\n        return resampled_arrays[0]\n    else:\n        return resampled_arrays",
    ".sklearn.utils.validation.py@@check_consistent_length": "def check_consistent_length(*arrays):\n    lengths = [_num_samples(X) for X in arrays if X is not None]\n    uniques = np.unique(lengths)\n    if len(uniques) > 1:\n        raise ValueError('Found input variables with inconsistent numbers of samples: %r' % [int(l) for l in lengths])",
    ".sklearn.utils.validation.py@@_num_samples": "def _num_samples(x):\n    message = 'Expected sequence or array-like, got %s' % type(x)\n    if hasattr(x, 'fit') and callable(x.fit):\n        raise TypeError(message)\n    if not hasattr(x, '__len__') and (not hasattr(x, 'shape')):\n        if hasattr(x, '__array__'):\n            x = np.asarray(x)\n        else:\n            raise TypeError(message)\n    if hasattr(x, 'shape') and x.shape is not None:\n        if len(x.shape) == 0:\n            raise TypeError('Singleton array %r cannot be considered a valid collection.' % x)\n        if isinstance(x.shape[0], numbers.Integral):\n            return x.shape[0]\n    try:\n        return len(x)\n    except TypeError:\n        raise TypeError(message)",
    ".sklearn.utils.__init__.py@@safe_indexing": "def safe_indexing(X, indices, axis=0):\n    if axis == 0:\n        return _safe_indexing_row(X, indices)\n    elif axis == 1:\n        return _safe_indexing_column(X, indices)\n    else:\n        raise ValueError(\"'axis' should be either 0 (to index rows) or 1 (to index  column). Got {} instead.\".format(axis))",
    ".sklearn.utils.__init__.py@@_safe_indexing_row": "def _safe_indexing_row(X, indices):\n    if hasattr(X, 'iloc'):\n        indices = np.asarray(indices)\n        indices = indices if indices.flags.writeable else indices.copy()\n        try:\n            return X.iloc[indices]\n        except ValueError:\n            warnings.warn('Copying input dataframe for slicing.', DataConversionWarning)\n            return X.copy().iloc[indices]\n    elif hasattr(X, 'shape'):\n        if hasattr(X, 'take') and (hasattr(indices, 'dtype') and indices.dtype.kind == 'i'):\n            return X.take(indices, axis=0)\n        else:\n            return _array_indexing(X, indices, axis=0)\n    else:\n        return [X[idx] for idx in indices]"
}
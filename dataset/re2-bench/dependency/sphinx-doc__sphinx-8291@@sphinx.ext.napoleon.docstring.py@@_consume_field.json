{
    ".sphinx.ext.napoleon.iterators.py@@peek_iter.__next__": "def __next__(self, n: int=None) -> Any:\n    return self.next(n)",
    ".sphinx.ext.napoleon.iterators.py@@peek_iter.next": "def next(self, n: int=None) -> Any:\n    self._fillcache(n)\n    if not n:\n        if self._cache[0] == self.sentinel:\n            raise StopIteration\n        if n is None:\n            result = self._cache.popleft()\n        else:\n            result = []\n    else:\n        if self._cache[n - 1] == self.sentinel:\n            raise StopIteration\n        result = [self._cache.popleft() for i in range(n)]\n    return result",
    ".sphinx.ext.napoleon.iterators.py@@modify_iter._fillcache": "def _fillcache(self, n: Optional[int]) -> None:\n    if not n:\n        n = 1\n    try:\n        while len(self._cache) < n:\n            self._cache.append(self.modifier(next(self._iterable)))\n    except StopIteration:\n        while len(self._cache) < n:\n            self._cache.append(self.sentinel)",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._partition_field_on_colon": "def _partition_field_on_colon(self, line: str) -> Tuple[str, str, str]:\n    before_colon = []\n    after_colon = []\n    colon = ''\n    found_colon = False\n    for i, source in enumerate(_xref_or_code_regex.split(line)):\n        if found_colon:\n            after_colon.append(source)\n        else:\n            m = _single_colon_regex.search(source)\n            if i % 2 == 0 and m:\n                found_colon = True\n                colon = source[m.start():m.end()]\n                before_colon.append(source[:m.start()])\n                after_colon.append(source[m.end():])\n            else:\n                before_colon.append(source)\n    return (''.join(before_colon).strip(), colon, ''.join(after_colon).strip())",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._escape_args_and_kwargs": "def _escape_args_and_kwargs(self, name: str) -> str:\n    if name.endswith('_') and getattr(self._config, 'strip_signature_backslash', False):\n        name = name[:-1] + '\\\\_'\n    if name[:2] == '**':\n        return '\\\\*\\\\*' + name[2:]\n    elif name[:1] == '*':\n        return '\\\\*' + name[1:]\n    else:\n        return name",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._get_indent": "def _get_indent(self, line: str) -> int:\n    for i, s in enumerate(line):\n        if not s.isspace():\n            return i\n    return len(line)",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._consume_indented_block": "def _consume_indented_block(self, indent: int=1) -> List[str]:\n    lines = []\n    line = self._line_iter.peek()\n    while not self._is_section_break() and (not line or self._is_indented(line, indent)):\n        lines.append(next(self._line_iter))\n        line = self._line_iter.peek()\n    return lines",
    ".sphinx.ext.napoleon.iterators.py@@peek_iter.peek": "def peek(self, n: Optional[int]=None) -> Any:\n    self._fillcache(n)\n    if n is None:\n        result = self._cache[0]\n    else:\n        result = [self._cache[i] for i in range(n)]\n    return result",
    ".sphinx.ext.napoleon.iterators.py@@peek_iter.has_next": "def has_next(self) -> bool:\n    return self.peek() != self.sentinel",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._is_indented": "def _is_indented(self, line: str, indent: int=1) -> bool:\n    for i, s in enumerate(line):\n        if i >= indent:\n            return True\n        elif not s.isspace():\n            return False\n    return False",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._dedent": "def _dedent(self, lines: List[str], full: bool=False) -> List[str]:\n    if full:\n        return [line.lstrip() for line in lines]\n    else:\n        min_indent = self._get_min_indent(lines)\n        return [line[min_indent:] for line in lines]",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._get_min_indent": "def _get_min_indent(self, lines: List[str]) -> int:\n    min_indent = None\n    for line in lines:\n        if line:\n            indent = self._get_indent(line)\n            if min_indent is None:\n                min_indent = indent\n            elif indent < min_indent:\n                min_indent = indent\n    return min_indent or 0",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring.__init__": "def __init__(self, docstring: Union[str, List[str]], config: SphinxConfig=None, app: Sphinx=None, what: str='', name: str='', obj: Any=None, options: Any=None) -> None:\n    self._config = config\n    self._app = app\n    if not self._config:\n        from sphinx.ext.napoleon import Config\n        self._config = self._app.config if self._app else Config()\n    if not what:\n        if inspect.isclass(obj):\n            what = 'class'\n        elif inspect.ismodule(obj):\n            what = 'module'\n        elif callable(obj):\n            what = 'function'\n        else:\n            what = 'object'\n    self._what = what\n    self._name = name\n    self._obj = obj\n    self._opt = options\n    if isinstance(docstring, str):\n        lines = docstring.splitlines()\n    else:\n        lines = docstring\n    self._line_iter = modify_iter(lines, modifier=lambda s: s.rstrip())\n    self._parsed_lines = []\n    self._is_in_section = False\n    self._section_indent = 0\n    if not hasattr(self, '_directive_sections'):\n        self._directive_sections = []\n    if not hasattr(self, '_sections'):\n        self._sections = {'args': self._parse_parameters_section, 'arguments': self._parse_parameters_section, 'attention': partial(self._parse_admonition, 'attention'), 'attributes': self._parse_attributes_section, 'caution': partial(self._parse_admonition, 'caution'), 'danger': partial(self._parse_admonition, 'danger'), 'error': partial(self._parse_admonition, 'error'), 'example': self._parse_examples_section, 'examples': self._parse_examples_section, 'hint': partial(self._parse_admonition, 'hint'), 'important': partial(self._parse_admonition, 'important'), 'keyword args': self._parse_keyword_arguments_section, 'keyword arguments': self._parse_keyword_arguments_section, 'methods': self._parse_methods_section, 'note': partial(self._parse_admonition, 'note'), 'notes': self._parse_notes_section, 'other parameters': self._parse_other_parameters_section, 'parameters': self._parse_parameters_section, 'return': self._parse_returns_section, 'returns': self._parse_returns_section, 'raise': self._parse_raises_section, 'raises': self._parse_raises_section, 'references': self._parse_references_section, 'see also': self._parse_see_also_section, 'tip': partial(self._parse_admonition, 'tip'), 'todo': partial(self._parse_admonition, 'todo'), 'warning': partial(self._parse_admonition, 'warning'), 'warnings': partial(self._parse_admonition, 'warning'), 'warn': self._parse_warns_section, 'warns': self._parse_warns_section, 'yield': self._parse_yields_section, 'yields': self._parse_yields_section}\n    self._load_custom_sections()\n    self._parse()",
    ".sphinx.ext.napoleon.iterators.py@@modify_iter.__init__": "def __init__(self, *args: Any, **kwargs: Any) -> None:\n    if 'modifier' in kwargs:\n        self.modifier = kwargs['modifier']\n    elif len(args) > 2:\n        self.modifier = args[2]\n        args = args[:2]\n    else:\n        self.modifier = lambda x: x\n    if not callable(self.modifier):\n        raise TypeError('modify_iter(o, modifier): modifier must be callable')\n    super().__init__(*args)",
    ".sphinx.ext.napoleon.iterators.py@@peek_iter.__init__": "def __init__(self, *args: Any) -> None:\n    self._iterable = iter(*args)\n    self._cache = collections.deque()\n    if len(args) == 2:\n        self.sentinel = args[1]\n    else:\n        self.sentinel = object()",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._load_custom_sections": "def _load_custom_sections(self) -> None:\n    if self._config.napoleon_custom_sections is not None:\n        for entry in self._config.napoleon_custom_sections:\n            if isinstance(entry, str):\n                self._sections[entry.lower()] = self._parse_custom_generic_section\n            else:\n                self._sections[entry[0].lower()] = self._sections.get(entry[1].lower(), self._parse_custom_generic_section)",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._parse": "def _parse(self) -> None:\n    self._parsed_lines = self._consume_empty()\n    if self._name and self._what in ('attribute', 'data', 'property'):\n        res = []\n        try:\n            res = self._parse_attribute_docstring()\n        except StopIteration:\n            pass\n        self._parsed_lines.extend(res)\n        return\n    while self._line_iter.has_next():\n        if self._is_section_header():\n            try:\n                section = self._consume_section_header()\n                self._is_in_section = True\n                self._section_indent = self._get_current_indent()\n                if _directive_regex.match(section):\n                    lines = [section] + self._consume_to_next_section()\n                else:\n                    lines = self._sections[section.lower()](section)\n            finally:\n                self._is_in_section = False\n                self._section_indent = 0\n        elif not self._parsed_lines:\n            lines = self._consume_contiguous() + self._consume_empty()\n        else:\n            lines = self._consume_to_next_section()\n        self._parsed_lines.extend(lines)",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._consume_empty": "def _consume_empty(self) -> List[str]:\n    lines = []\n    line = self._line_iter.peek()\n    while self._line_iter.has_next() and (not line):\n        lines.append(next(self._line_iter))\n        line = self._line_iter.peek()\n    return lines",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._consume_contiguous": "def _consume_contiguous(self) -> List[str]:\n    lines = []\n    while self._line_iter.has_next() and self._line_iter.peek() and (not self._is_section_header()):\n        lines.append(next(self._line_iter))\n    return lines",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring.lines": "def lines(self) -> List[str]:\n    return self._parsed_lines",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._consume_to_next_section": "def _consume_to_next_section(self) -> List[str]:\n    self._consume_empty()\n    lines = []\n    while not self._is_section_break():\n        lines.append(next(self._line_iter))\n    return lines + self._consume_empty()",
    ".sphinx.ext.napoleon.docstring.py@@GoogleDocstring._lookup_annotation": "def _lookup_annotation(self, _name: str) -> str:\n    if self._config.napoleon_attr_annotations:\n        if self._what in ('module', 'class', 'exception') and self._obj:\n            if not hasattr(self, '_annotations'):\n                localns = getattr(self._config, 'autodoc_type_aliases', {})\n                localns.update(getattr(self._config, 'napoleon_type_aliases', {}) or {})\n                self._annotations = get_type_hints(self._obj, None, localns)\n            if _name in self._annotations:\n                return stringify_annotation(self._annotations[_name])\n    return ''",
    ".sphinx.ext.napoleon.docstring.py@@_convert_numpy_type_spec": "def _convert_numpy_type_spec(_type: str, location: str=None, translations: dict={}) -> str:\n\n    def convert_obj(obj, translations, default_translation):\n        translation = translations.get(obj, obj)\n        if translation in _SINGLETONS and default_translation == ':class:`%s`':\n            default_translation = ':obj:`%s`'\n        elif translation == '...' and default_translation == ':class:`%s`':\n            default_translation = ':obj:`%s <Ellipsis>`'\n        if _xref_regex.match(translation) is None:\n            translation = default_translation % translation\n        return translation\n    tokens = _tokenize_type_spec(_type)\n    combined_tokens = _recombine_set_tokens(tokens)\n    types = [(token, _token_type(token, location)) for token in combined_tokens]\n    converters = {'literal': lambda x: '``%s``' % x, 'obj': lambda x: convert_obj(x, translations, ':class:`%s`'), 'control': lambda x: '*%s*' % x, 'delimiter': lambda x: x, 'reference': lambda x: x}\n    converted = ''.join((converters.get(type_)(token) for token, type_ in types))\n    return converted",
    ".sphinx.ext.napoleon.docstring.py@@_tokenize_type_spec": "def _tokenize_type_spec(spec: str) -> List[str]:\n\n    def postprocess(item):\n        if _default_regex.match(item):\n            default = item[:7]\n            other = item[8:]\n            return [default, ' ', other]\n        else:\n            return [item]\n    tokens = list((item for raw_token in _token_regex.split(spec) for item in postprocess(raw_token) if item))\n    return tokens",
    ".sphinx.ext.napoleon.docstring.py@@postprocess": "def postprocess(item):\n    if _default_regex.match(item):\n        default = item[:7]\n        other = item[8:]\n        return [default, ' ', other]\n    else:\n        return [item]",
    ".sphinx.ext.napoleon.docstring.py@@_recombine_set_tokens": "def _recombine_set_tokens(tokens: List[str]) -> List[str]:\n    token_queue = collections.deque(tokens)\n    keywords = ('optional', 'default')\n\n    def takewhile_set(tokens):\n        open_braces = 0\n        previous_token = None\n        while True:\n            try:\n                token = tokens.popleft()\n            except IndexError:\n                break\n            if token == ', ':\n                previous_token = token\n                continue\n            if not token.strip():\n                continue\n            if token in keywords:\n                tokens.appendleft(token)\n                if previous_token is not None:\n                    tokens.appendleft(previous_token)\n                break\n            if previous_token is not None:\n                yield previous_token\n                previous_token = None\n            if token == '{':\n                open_braces += 1\n            elif token == '}':\n                open_braces -= 1\n            yield token\n            if open_braces == 0:\n                break\n\n    def combine_set(tokens):\n        while True:\n            try:\n                token = tokens.popleft()\n            except IndexError:\n                break\n            if token == '{':\n                tokens.appendleft('{')\n                yield ''.join(takewhile_set(tokens))\n            else:\n                yield token\n    return list(combine_set(token_queue))",
    ".sphinx.ext.napoleon.docstring.py@@combine_set": "def combine_set(tokens):\n    while True:\n        try:\n            token = tokens.popleft()\n        except IndexError:\n            break\n        if token == '{':\n            tokens.appendleft('{')\n            yield ''.join(takewhile_set(tokens))\n        else:\n            yield token",
    ".sphinx.ext.napoleon.docstring.py@@_token_type": "def _token_type(token: str, location: str=None) -> str:\n\n    def is_numeric(token):\n        try:\n            complex(token)\n        except ValueError:\n            return False\n        else:\n            return True\n    if token.startswith(' ') or token.endswith(' '):\n        type_ = 'delimiter'\n    elif is_numeric(token) or (token.startswith('{') and token.endswith('}')) or (token.startswith('\"') and token.endswith('\"')) or (token.startswith(\"'\") and token.endswith(\"'\")):\n        type_ = 'literal'\n    elif token.startswith('{'):\n        logger.warning(__('invalid value set (missing closing brace): %s'), token, location=location)\n        type_ = 'literal'\n    elif token.endswith('}'):\n        logger.warning(__('invalid value set (missing opening brace): %s'), token, location=location)\n        type_ = 'literal'\n    elif token.startswith(\"'\") or token.startswith('\"'):\n        logger.warning(__('malformed string literal (missing closing quote): %s'), token, location=location)\n        type_ = 'literal'\n    elif token.endswith(\"'\") or token.endswith('\"'):\n        logger.warning(__('malformed string literal (missing opening quote): %s'), token, location=location)\n        type_ = 'literal'\n    elif token in ('optional', 'default'):\n        type_ = 'control'\n    elif _xref_regex.match(token):\n        type_ = 'reference'\n    else:\n        type_ = 'obj'\n    return type_",
    ".sphinx.ext.napoleon.docstring.py@@is_numeric": "def is_numeric(token):\n    try:\n        complex(token)\n    except ValueError:\n        return False\n    else:\n        return True",
    ".sphinx.ext.napoleon.docstring.py@@convert_obj": "def convert_obj(obj, translations, default_translation):\n    translation = translations.get(obj, obj)\n    if translation in _SINGLETONS and default_translation == ':class:`%s`':\n        default_translation = ':obj:`%s`'\n    elif translation == '...' and default_translation == ':class:`%s`':\n        default_translation = ':obj:`%s <Ellipsis>`'\n    if _xref_regex.match(translation) is None:\n        translation = default_translation % translation\n    return translation",
    ".sphinx.ext.napoleon.docstring.py@@takewhile_set": "def takewhile_set(tokens):\n    open_braces = 0\n    previous_token = None\n    while True:\n        try:\n            token = tokens.popleft()\n        except IndexError:\n            break\n        if token == ', ':\n            previous_token = token\n            continue\n        if not token.strip():\n            continue\n        if token in keywords:\n            tokens.appendleft(token)\n            if previous_token is not None:\n                tokens.appendleft(previous_token)\n            break\n        if previous_token is not None:\n            yield previous_token\n            previous_token = None\n        if token == '{':\n            open_braces += 1\n        elif token == '}':\n            open_braces -= 1\n        yield token\n        if open_braces == 0:\n            break",
    ".sphinx.util.typing.py@@get_type_hints": "def get_type_hints(obj: Any, globalns: Dict=None, localns: Dict=None) -> Dict[str, Any]:\n    from sphinx.util.inspect import safe_getattr\n    try:\n        return typing.get_type_hints(obj, globalns, localns)\n    except NameError:\n        return safe_getattr(obj, '__annotations__', {})\n    except TypeError:\n        return {}\n    except KeyError:\n        return {}\n    except AttributeError:\n        return {}",
    ".sphinx.util.typing.py@@stringify": "def stringify(annotation: Any) -> str:\n    from sphinx.util import inspect\n    if isinstance(annotation, str):\n        if annotation.startswith(\"'\") and annotation.endswith(\"'\"):\n            return annotation[1:-1]\n        else:\n            return annotation\n    elif isinstance(annotation, TypeVar):\n        return annotation.__name__\n    elif inspect.isNewType(annotation):\n        return annotation.__name__\n    elif not annotation:\n        return repr(annotation)\n    elif annotation is NoneType:\n        return 'None'\n    elif getattr(annotation, '__module__', None) == 'builtins' and hasattr(annotation, '__qualname__'):\n        return annotation.__qualname__\n    elif annotation is Ellipsis:\n        return '...'\n    if sys.version_info >= (3, 7):\n        return _stringify_py37(annotation)\n    else:\n        return _stringify_py36(annotation)",
    ".sphinx.util.inspect.py@@isNewType": "def isNewType(obj: Any) -> bool:\n    __module__ = safe_getattr(obj, '__module__', None)\n    __qualname__ = safe_getattr(obj, '__qualname__', None)\n    if __module__ == 'typing' and __qualname__ == 'NewType.<locals>.new_type':\n        return True\n    else:\n        return False",
    ".sphinx.util.inspect.py@@safe_getattr": "def safe_getattr(obj: Any, name: str, *defargs: Any) -> Any:\n    try:\n        return getattr(obj, name, *defargs)\n    except Exception as exc:\n        try:\n            return obj.__dict__[name]\n        except Exception:\n            pass\n        if defargs:\n            return defargs[0]\n        raise AttributeError(name) from exc"
}
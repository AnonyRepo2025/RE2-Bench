{
    ".xarray.core.utils.py@@SortedKeysDict.__init__": "def __init__(self, mapping: MutableMapping[K, V]=None):\n    self.mapping = {} if mapping is None else mapping",
    ".xarray.core.utils.py@@Frozen.__init__": "def __init__(self, mapping: Mapping[K, V]):\n    self.mapping = mapping",
    ".xarray.core.utils.py@@Frozen.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(self.mapping)",
    ".xarray.core.utils.py@@SortedKeysDict.__iter__": "def __iter__(self) -> Iterator[K]:\n    return iter(sorted(self.mapping))",
    ".xarray.core.utils.py@@Frozen.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.utils.py@@SortedKeysDict.__contains__": "def __contains__(self, key: object) -> bool:\n    return key in self.mapping",
    ".xarray.core.dataset.py@@_assert_empty": "def _assert_empty(args: tuple, msg: str='%s') -> None:\n    if args:\n        raise ValueError(msg % args)",
    ".xarray.core.utils.py@@ReprObject.__hash__": "def __hash__(self) -> int:\n    return hash((ReprObject, self._value))",
    ".xarray.core.utils.py@@Frozen.__getitem__": "def __getitem__(self, key: K) -> V:\n    return self.mapping[key]",
    ".xarray.core.variable.py@@Variable.dims": "def dims(self):\n    return self._dims",
    ".xarray.core.coordinates.py@@DatasetCoordinates.__init__": "def __init__(self, dataset: 'Dataset'):\n    self._data = dataset",
    ".xarray.core.coordinates.py@@AbstractCoordinates.__contains__": "def __contains__(self, key: Hashable) -> bool:\n    return key in self._names",
    ".xarray.core.coordinates.py@@DatasetCoordinates._names": "def _names(self) -> Set[Hashable]:\n    return self._data._coord_names",
    ".xarray.core.utils.py@@NdimSizeLenMixin.ndim": "def ndim(self: Any) -> int:\n    return len(self.shape)",
    ".xarray.core.variable.py@@Variable.shape": "def shape(self):\n    return self._data.shape",
    ".xarray.core.variable.py@@Variable.quantile": "def quantile(self, q, dim=None, interpolation='linear', keep_attrs=None):\n    if isinstance(self.data, dask_array_type):\n        raise TypeError('quantile does not work for arrays stored as dask arrays. Load the data via .compute() or .load() prior to calling this method.')\n    q = np.asarray(q, dtype=np.float64)\n    new_dims = list(self.dims)\n    if dim is not None:\n        axis = self.get_axis_num(dim)\n        if utils.is_scalar(dim):\n            new_dims.remove(dim)\n        else:\n            for d in dim:\n                new_dims.remove(d)\n    else:\n        axis = None\n        new_dims = []\n    if q.ndim != 0:\n        new_dims = ['quantile'] + new_dims\n    qs = np.nanpercentile(self.data, q * 100.0, axis=axis, interpolation=interpolation)\n    if keep_attrs is None:\n        keep_attrs = _get_keep_attrs(default=False)\n    attrs = self._attrs if keep_attrs else None\n    return Variable(new_dims, qs, attrs)",
    ".xarray.core.variable.py@@Variable.data": "def data(self):\n    if hasattr(self._data, '__array_function__') or isinstance(self._data, dask_array_type):\n        return self._data\n    else:\n        return self.values",
    ".xarray.core.variable.py@@Variable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    self._data = as_compatible_data(data, fastpath=fastpath)\n    self._dims = self._parse_dimensions(dims)\n    self._attrs = None\n    self._encoding = None\n    if attrs is not None:\n        self.attrs = attrs\n    if encoding is not None:\n        self.encoding = encoding",
    ".xarray.core.variable.py@@as_compatible_data": "def as_compatible_data(data, fastpath=False):\n    if fastpath and getattr(data, 'ndim', 0) > 0:\n        return _maybe_wrap_data(data)\n    if isinstance(data, Variable):\n        return data.data\n    if isinstance(data, NON_NUMPY_SUPPORTED_ARRAY_TYPES):\n        return _maybe_wrap_data(data)\n    if isinstance(data, tuple):\n        data = utils.to_0d_object_array(data)\n    if isinstance(data, pd.Timestamp):\n        data = np.datetime64(data.value, 'ns')\n    if isinstance(data, timedelta):\n        data = np.timedelta64(getattr(data, 'value', data), 'ns')\n    data = getattr(data, 'values', data)\n    if isinstance(data, np.ma.MaskedArray):\n        mask = np.ma.getmaskarray(data)\n        if mask.any():\n            dtype, fill_value = dtypes.maybe_promote(data.dtype)\n            data = np.asarray(data, dtype=dtype)\n            data[mask] = fill_value\n        else:\n            data = np.asarray(data)\n    if not isinstance(data, np.ndarray):\n        if hasattr(data, '__array_function__'):\n            if IS_NEP18_ACTIVE:\n                return data\n            else:\n                raise TypeError('Got an NumPy-like array type providing the __array_function__ protocol but NEP18 is not enabled. Check that numpy >= v1.16 and that the environment variable \"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\" is set to \"1\"')\n    data = np.asarray(data)\n    if isinstance(data, np.ndarray):\n        if data.dtype.kind == 'O':\n            data = _possibly_convert_objects(data)\n        elif data.dtype.kind == 'M':\n            data = np.asarray(data, 'datetime64[ns]')\n        elif data.dtype.kind == 'm':\n            data = np.asarray(data, 'timedelta64[ns]')\n    return _maybe_wrap_data(data)",
    ".xarray.core.variable.py@@_maybe_wrap_data": "def _maybe_wrap_data(data):\n    if isinstance(data, pd.Index):\n        return PandasIndexAdapter(data)\n    return data",
    ".xarray.core.variable.py@@Variable._parse_dimensions": "def _parse_dimensions(self, dims):\n    if isinstance(dims, str):\n        dims = (dims,)\n    dims = tuple(dims)\n    if len(dims) != self.ndim:\n        raise ValueError('dimensions %s must have the same length as the number of data dimensions, ndim=%s' % (dims, self.ndim))\n    return dims",
    ".xarray.core.variable.py@@Variable.attrs": "def attrs(self) -> 'OrderedDict[Any, Any]':\n    if self._attrs is None:\n        self._attrs = OrderedDict()\n    return self._attrs",
    ".xarray.core.coordinates.py@@AbstractCoordinates.__iter__": "def __iter__(self) -> Iterator['Hashable']:\n    for k in self.variables:\n        if k in self._names:\n            yield k",
    ".xarray.core.coordinates.py@@DatasetCoordinates.variables": "def variables(self) -> Mapping[Hashable, Variable]:\n    return Frozen(OrderedDict(((k, v) for k, v in self._data.variables.items() if k in self._names)))",
    ".xarray.core.indexes.py@@default_indexes": "def default_indexes(coords: Mapping[Any, Variable], dims: Iterable) -> 'OrderedDict[Any, pd.Index]':\n    return OrderedDict(((key, coords[key].to_index()) for key in dims if key in coords))",
    ".xarray.core.common.py@@AttrAccessMixin._setattr_slots": "def _setattr_slots(self, name: str, value: Any) -> None:\n    try:\n        object.__setattr__(self, name, value)\n    except AttributeError as e:\n        if str(e) != '%r object has no attribute %r' % (type(self).__name__, name):\n            raise\n        raise AttributeError(\"cannot set attribute %r on a %r object. Use __setitem__ styleassignment (e.g., `ds['name'] = ...`) instead of assigning variables.\" % (name, type(self).__name__)) from e",
    ".xarray.core.indexes.py@@Indexes.__init__": "def __init__(self, indexes):\n    self._indexes = indexes",
    ".xarray.core.indexes.py@@Indexes.__iter__": "def __iter__(self):\n    return iter(self._indexes)",
    ".xarray.core.dataset.py@@Dataset.attrs": "def attrs(self) -> 'OrderedDict[Any, Any]':\n    if self._attrs is None:\n        self._attrs = OrderedDict()\n    return self._attrs",
    ".xarray.core.dataset.py@@calculate_dimensions": "def calculate_dimensions(variables: Mapping[Hashable, Variable]) -> 'Dict[Any, int]':\n    dims = {}\n    last_used = {}\n    scalar_vars = {k for k, v in variables.items() if not v.dims}\n    for k, var in variables.items():\n        for dim, size in zip(var.dims, var.shape):\n            if dim in scalar_vars:\n                raise ValueError('dimension %r already exists as a scalar variable' % dim)\n            if dim not in dims:\n                dims[dim] = size\n                last_used[dim] = k\n            elif dims[dim] != size:\n                raise ValueError('conflicting sizes for dimension %r: length %s on %r and length %s on %r' % (dim, size, k, dims[dim], last_used[dim]))\n    return dims",
    ".xarray.core.coordinates.py@@AbstractCoordinates.__setitem__": "def __setitem__(self, key: Hashable, value: Any) -> None:\n    self.update({key: value})",
    ".xarray.core.coordinates.py@@AbstractCoordinates.update": "def update(self, other: Mapping[Hashable, Any]) -> None:\n    other_vars = getattr(other, 'variables', other)\n    coords = merge_coords([self.variables, other_vars], priority_arg=1, indexes=self.indexes)\n    self._update_coords(coords)",
    ".xarray.core.coordinates.py@@AbstractCoordinates.indexes": "def indexes(self) -> Indexes:\n    return self._data.indexes",
    ".xarray.core.merge.py@@merge_coords": "def merge_coords(objs, compat='minimal', join='outer', priority_arg=None, indexes=None, fill_value=dtypes.NA):\n    _assert_compat_valid(compat)\n    coerced = coerce_pandas_values(objs)\n    aligned = deep_align(coerced, join=join, copy=False, indexes=indexes, fill_value=fill_value)\n    expanded = expand_variable_dicts(aligned)\n    priority_vars = _get_priority_vars(aligned, priority_arg, compat=compat)\n    variables = merge_variables(expanded, priority_vars, compat=compat)\n    assert_unique_multiindex_level_names(variables)\n    return variables",
    ".xarray.core.merge.py@@_assert_compat_valid": "def _assert_compat_valid(compat):\n    if compat not in _VALID_COMPAT:\n        raise ValueError('compat=%r invalid: must be %s' % (compat, set(_VALID_COMPAT)))",
    ".xarray.core.merge.py@@coerce_pandas_values": "def coerce_pandas_values(objects: Iterable['DatasetLike']) -> List['DatasetLike']:\n    from .dataarray import DataArray\n    from .dataset import Dataset\n    out = []\n    for obj in objects:\n        if isinstance(obj, Dataset):\n            variables = obj\n        else:\n            variables = OrderedDict()\n            if isinstance(obj, PANDAS_TYPES):\n                obj = OrderedDict(obj.iteritems())\n            for k, v in obj.items():\n                if isinstance(v, PANDAS_TYPES):\n                    v = DataArray(v)\n                variables[k] = v\n        out.append(variables)\n    return out",
    ".xarray.core.alignment.py@@deep_align": "def deep_align(objects, join='inner', copy=True, indexes=None, exclude=frozenset(), raise_on_invalid=True, fill_value=dtypes.NA):\n    from .dataarray import DataArray\n    from .dataset import Dataset\n    if indexes is None:\n        indexes = {}\n\n    def is_alignable(obj):\n        return isinstance(obj, (DataArray, Dataset))\n    positions = []\n    keys = []\n    out = []\n    targets = []\n    no_key = object()\n    not_replaced = object()\n    for n, variables in enumerate(objects):\n        if is_alignable(variables):\n            positions.append(n)\n            keys.append(no_key)\n            targets.append(variables)\n            out.append(not_replaced)\n        elif is_dict_like(variables):\n            for k, v in variables.items():\n                if is_alignable(v) and k not in indexes:\n                    positions.append(n)\n                    keys.append(k)\n                    targets.append(v)\n            out.append(OrderedDict(variables))\n        elif raise_on_invalid:\n            raise ValueError('object to align is neither an xarray.Dataset, an xarray.DataArray nor a dictionary: %r' % variables)\n        else:\n            out.append(variables)\n    aligned = align(*targets, join=join, copy=copy, indexes=indexes, exclude=exclude, fill_value=fill_value)\n    for position, key, aligned_obj in zip(positions, keys, aligned):\n        if key is no_key:\n            out[position] = aligned_obj\n        else:\n            out[position][key] = aligned_obj\n    assert all((arg is not not_replaced for arg in out))\n    return out",
    ".xarray.core.alignment.py@@is_alignable": "def is_alignable(obj):\n    return isinstance(obj, (DataArray, Dataset))",
    ".xarray.core.utils.py@@is_dict_like": "def is_dict_like(value: Any) -> bool:\n    return hasattr(value, 'keys') and hasattr(value, '__getitem__')",
    ".xarray.core.alignment.py@@align": "def align(*objects, join='inner', copy=True, indexes=None, exclude=frozenset(), fill_value=dtypes.NA):\n    if indexes is None:\n        indexes = {}\n    if not indexes and len(objects) == 1:\n        obj, = objects\n        return (obj.copy(deep=copy),)\n    all_indexes = defaultdict(list)\n    unlabeled_dim_sizes = defaultdict(set)\n    for obj in objects:\n        for dim in obj.dims:\n            if dim not in exclude:\n                try:\n                    index = obj.indexes[dim]\n                except KeyError:\n                    unlabeled_dim_sizes[dim].add(obj.sizes[dim])\n                else:\n                    all_indexes[dim].append(index)\n    if join == 'override':\n        objects = _override_indexes(list(objects), all_indexes, exclude)\n    joiner = _get_joiner(join)\n    joined_indexes = {}\n    for dim, matching_indexes in all_indexes.items():\n        if dim in indexes:\n            index = utils.safe_cast_to_index(indexes[dim])\n            if any((not index.equals(other) for other in matching_indexes)) or dim in unlabeled_dim_sizes:\n                joined_indexes[dim] = index\n        elif any((not matching_indexes[0].equals(other) for other in matching_indexes[1:])) or dim in unlabeled_dim_sizes:\n            if join == 'exact':\n                raise ValueError('indexes along dimension {!r} are not equal'.format(dim))\n            index = joiner(matching_indexes)\n            joined_indexes[dim] = index\n        else:\n            index = matching_indexes[0]\n        if dim in unlabeled_dim_sizes:\n            unlabeled_sizes = unlabeled_dim_sizes[dim]\n            labeled_size = index.size\n            if len(unlabeled_sizes | {labeled_size}) > 1:\n                raise ValueError('arguments without labels along dimension %r cannot be aligned because they have different dimension size(s) %r than the size of the aligned dimension labels: %r' % (dim, unlabeled_sizes, labeled_size))\n    for dim in unlabeled_dim_sizes:\n        if dim not in all_indexes:\n            sizes = unlabeled_dim_sizes[dim]\n            if len(sizes) > 1:\n                raise ValueError('arguments without labels along dimension %r cannot be aligned because they have different dimension sizes: %r' % (dim, sizes))\n    result = []\n    for obj in objects:\n        valid_indexers = {k: v for k, v in joined_indexes.items() if k in obj.dims}\n        if not valid_indexers:\n            new_obj = obj.copy(deep=copy)\n        else:\n            new_obj = obj.reindex(copy=copy, fill_value=fill_value, **valid_indexers)\n        new_obj.encoding = obj.encoding\n        result.append(new_obj)\n    return tuple(result)",
    ".xarray.core.indexes.py@@Indexes.__len__": "def __len__(self):\n    return len(self._indexes)",
    ".xarray.core.alignment.py@@_get_joiner": "def _get_joiner(join):\n    if join == 'outer':\n        return functools.partial(functools.reduce, operator.or_)\n    elif join == 'inner':\n        return functools.partial(functools.reduce, operator.and_)\n    elif join == 'left':\n        return operator.itemgetter(0)\n    elif join == 'right':\n        return operator.itemgetter(-1)\n    elif join == 'exact':\n        return None\n    elif join == 'override':\n        return operator.itemgetter(0)\n    else:\n        raise ValueError('invalid value for join: %s' % join)",
    ".xarray.core.merge.py@@expand_variable_dicts": "def expand_variable_dicts(list_of_variable_dicts: 'List[Union[Dataset, OrderedDict]]') -> 'List[Mapping[Any, Variable]]':\n    from .dataarray import DataArray\n    from .dataset import Dataset\n    var_dicts = []\n    for variables in list_of_variable_dicts:\n        if isinstance(variables, Dataset):\n            var_dicts.append(variables.variables)\n            continue\n        sanitized_vars = OrderedDict()\n        for name, var in variables.items():\n            if isinstance(var, DataArray):\n                coords = var._coords.copy()\n                coords.pop(name, None)\n                var_dicts.append(coords)\n            var = as_variable(var, name=name)\n            sanitized_vars[name] = var\n        var_dicts.append(sanitized_vars)\n    return var_dicts",
    ".xarray.core.variable.py@@as_variable": "def as_variable(obj, name=None) -> 'Union[Variable, IndexVariable]':\n    from .dataarray import DataArray\n    if isinstance(obj, DataArray):\n        obj = obj.variable\n    if isinstance(obj, Variable):\n        obj = obj.copy(deep=False)\n    elif isinstance(obj, tuple):\n        try:\n            obj = Variable(*obj)\n        except (TypeError, ValueError) as error:\n            raise error.__class__('Could not convert tuple of form (dims, data[, attrs, encoding]): {} to Variable.'.format(obj))\n    elif utils.is_scalar(obj):\n        obj = Variable([], obj)\n    elif isinstance(obj, (pd.Index, IndexVariable)) and obj.name is not None:\n        obj = Variable(obj.name, obj)\n    elif isinstance(obj, (set, dict)):\n        raise TypeError('variable %r has invalid type %r' % (name, type(obj)))\n    elif name is not None:\n        data = as_compatible_data(obj)\n        if data.ndim != 1:\n            raise MissingDimensionsError('cannot set variable %r with %r-dimensional data without explicit dimension names. Pass a tuple of (dims, data) instead.' % (name, data.ndim))\n        obj = Variable(name, data, fastpath=True)\n    else:\n        raise TypeError('unable to convert object into a variable without an explicit list of dimensions: %r' % obj)\n    if name is not None and name in obj.dims:\n        if obj.ndim != 1:\n            raise MissingDimensionsError('%r has more than 1-dimension and the same name as one of its dimensions %r. xarray disallows such variables because they conflict with the coordinates used to label dimensions.' % (name, obj.dims))\n        obj = obj.to_index_variable()\n    return obj",
    ".xarray.core.utils.py@@is_scalar": "def is_scalar(value: Any, include_0d: bool=True) -> bool:\n    from .variable import NON_NUMPY_SUPPORTED_ARRAY_TYPES\n    if include_0d:\n        include_0d = getattr(value, 'ndim', None) == 0\n    return include_0d or isinstance(value, (str, bytes)) or (not (isinstance(value, (Iterable,) + NON_NUMPY_SUPPORTED_ARRAY_TYPES) or hasattr(value, '__array_function__')))",
    ".xarray.core.merge.py@@_get_priority_vars": "def _get_priority_vars(objects, priority_arg, compat='equals'):\n    if priority_arg is None:\n        priority_vars = {}\n    else:\n        expanded = expand_variable_dicts([objects[priority_arg]])\n        priority_vars = merge_variables(expanded, compat=compat)\n    return priority_vars",
    ".xarray.core.merge.py@@merge_variables": "def merge_variables(list_of_variables_dicts: List[Mapping[Any, Variable]], priority_vars: Mapping[Any, Variable]=None, compat: str='minimal') -> 'OrderedDict[Any, Variable]':\n    if priority_vars is None:\n        priority_vars = {}\n    _assert_compat_valid(compat)\n    dim_compat = min(compat, 'equals', key=_VALID_COMPAT.get)\n    lookup = OrderedDefaultDict(list)\n    for variables in list_of_variables_dicts:\n        for name, var in variables.items():\n            lookup[name].append(var)\n    merged = OrderedDict()\n    for name, var_list in lookup.items():\n        if name in priority_vars:\n            merged[name] = priority_vars[name]\n        else:\n            dim_variables = [var for var in var_list if (name,) == var.dims]\n            if dim_variables:\n                merged[name] = unique_variable(name, dim_variables, dim_compat)\n            else:\n                try:\n                    merged[name] = unique_variable(name, var_list, compat)\n                except MergeError:\n                    if compat != 'minimal':\n                        raise\n    return merged",
    ".xarray.core.merge.py@@OrderedDefaultDict.__init__": "def __init__(self, default_factory):\n    self.default_factory = default_factory\n    super().__init__()",
    ".xarray.core.merge.py@@OrderedDefaultDict.__missing__": "def __missing__(self, key):\n    self[key] = default = self.default_factory()\n    return default",
    ".xarray.core.merge.py@@unique_variable": "def unique_variable(name, variables, compat='broadcast_equals'):\n    out = variables[0]\n    if len(variables) > 1:\n        combine_method = None\n        if compat == 'minimal':\n            compat = 'broadcast_equals'\n        if compat == 'broadcast_equals':\n            dim_lengths = broadcast_dimension_size(variables)\n            out = out.set_dims(dim_lengths)\n        if compat == 'no_conflicts':\n            combine_method = 'fillna'\n        for var in variables[1:]:\n            if not getattr(out, compat)(var):\n                raise MergeError('conflicting values for variable %r on objects to be combined:\\nfirst value: %r\\nsecond value: %r' % (name, out, var))\n            if combine_method:\n                out = getattr(out, combine_method)(var)\n                out.attrs = var.attrs\n    return out",
    ".xarray.core.variable.py@@assert_unique_multiindex_level_names": "def assert_unique_multiindex_level_names(variables):\n    level_names = defaultdict(list)\n    all_level_names = set()\n    for var_name, var in variables.items():\n        if isinstance(var._data, PandasIndexAdapter):\n            idx_level_names = var.to_index_variable().level_names\n            if idx_level_names is not None:\n                for n in idx_level_names:\n                    level_names[n].append('%r (%s)' % (n, var_name))\n            if idx_level_names:\n                all_level_names.update(idx_level_names)\n    for k, v in level_names.items():\n        if k in variables:\n            v.append('(%s)' % k)\n    duplicate_names = [v for v in level_names.values() if len(v) > 1]\n    if duplicate_names:\n        conflict_str = '\\n'.join([', '.join(v) for v in duplicate_names])\n        raise ValueError('conflicting MultiIndex level name(s):\\n%s' % conflict_str)\n    for k, v in variables.items():\n        for d in v.dims:\n            if d in all_level_names:\n                raise ValueError('conflicting level / dimension names. {} already exists as a level name.'.format(d))",
    ".xarray.core.coordinates.py@@DatasetCoordinates._update_coords": "def _update_coords(self, coords: Mapping[Hashable, Any]) -> None:\n    from .dataset import calculate_dimensions\n    variables = self._data._variables.copy()\n    variables.update(coords)\n    dims = calculate_dimensions(variables)\n    new_coord_names = set(coords)\n    for dim, size in dims.items():\n        if dim in variables:\n            new_coord_names.add(dim)\n    self._data._variables = variables\n    self._data._coord_names.update(new_coord_names)\n    self._data._dims = dims\n    self._data._indexes = None",
    ".xarray.core.common.py@@AbstractArray.get_axis_num": "def get_axis_num(self, dim: Union[Hashable, Iterable[Hashable]]) -> Union[int, Tuple[int, ...]]:\n    if isinstance(dim, Iterable) and (not isinstance(dim, str)):\n        return tuple((self._get_axis_num(d) for d in dim))\n    else:\n        return self._get_axis_num(dim)",
    ".xarray.core.common.py@@AbstractArray._get_axis_num": "def _get_axis_num(self: Any, dim: Hashable) -> int:\n    try:\n        return self.dims.index(dim)\n    except ValueError:\n        raise ValueError('%r not found in array dimensions %r' % (dim, self.dims))",
    ".xarray.core.variable.py@@Variable.copy": "def copy(self, deep=True, data=None):\n    if data is None:\n        data = self._data\n        if isinstance(data, indexing.MemoryCachedArray):\n            data = indexing.MemoryCachedArray(data.array)\n        if deep:\n            if hasattr(data, '__array_function__') or isinstance(data, dask_array_type):\n                data = data.copy()\n            elif not isinstance(data, PandasIndexAdapter):\n                data = np.array(data)\n    else:\n        data = as_compatible_data(data)\n        if self.shape != data.shape:\n            raise ValueError('Data shape {} must match shape of object {}'.format(data.shape, self.shape))\n    return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@Variable.to_index_variable": "def to_index_variable(self):\n    return IndexVariable(self.dims, self._data, self._attrs, encoding=self._encoding, fastpath=True)",
    ".xarray.core.variable.py@@IndexVariable.__init__": "def __init__(self, dims, data, attrs=None, encoding=None, fastpath=False):\n    super().__init__(dims, data, attrs, encoding, fastpath)\n    if self.ndim != 1:\n        raise ValueError('%s objects must be 1-dimensional' % type(self).__name__)\n    if not isinstance(self._data, PandasIndexAdapter):\n        self._data = PandasIndexAdapter(self._data)",
    ".xarray.core.indexing.py@@PandasIndexAdapter.__init__": "def __init__(self, array: Any, dtype: DTypeLike=None):\n    self.array = utils.safe_cast_to_index(array)\n    if dtype is None:\n        if isinstance(array, pd.PeriodIndex):\n            dtype = np.dtype('O')\n        elif hasattr(array, 'categories'):\n            dtype = array.categories.dtype\n        elif not utils.is_valid_numpy_dtype(array.dtype):\n            dtype = np.dtype('O')\n        else:\n            dtype = array.dtype\n    else:\n        dtype = np.dtype(dtype)\n    self._dtype = dtype",
    ".xarray.core.utils.py@@safe_cast_to_index": "def safe_cast_to_index(array: Any) -> pd.Index:\n    if isinstance(array, pd.Index):\n        index = array\n    elif hasattr(array, 'to_index'):\n        index = array.to_index()\n    else:\n        kwargs = {}\n        if hasattr(array, 'dtype') and array.dtype.kind == 'O':\n            kwargs['dtype'] = object\n        index = pd.Index(np.asarray(array), **kwargs)\n    return _maybe_cast_to_cftimeindex(index)",
    ".xarray.core.utils.py@@_maybe_cast_to_cftimeindex": "def _maybe_cast_to_cftimeindex(index: pd.Index) -> pd.Index:\n    from ..coding.cftimeindex import CFTimeIndex\n    if len(index) > 0 and index.dtype == 'O':\n        try:\n            return CFTimeIndex(index)\n        except (ImportError, TypeError):\n            return index\n    else:\n        return index",
    ".xarray.core.utils.py@@is_valid_numpy_dtype": "def is_valid_numpy_dtype(dtype: Any) -> bool:\n    try:\n        np.dtype(dtype)\n    except (TypeError, ValueError):\n        return False\n    else:\n        return True",
    ".xarray.core.variable.py@@IndexVariable.to_index_variable": "def to_index_variable(self):\n    return self",
    ".xarray.core.variable.py@@IndexVariable.level_names": "def level_names(self):\n    index = self.to_index()\n    if isinstance(index, pd.MultiIndex):\n        return index.names\n    else:\n        return None",
    ".xarray.core.variable.py@@IndexVariable.to_index": "def to_index(self):\n    assert self.ndim == 1\n    index = self._data.array\n    if isinstance(index, pd.MultiIndex):\n        valid_level_names = [name or '{}_level_{}'.format(self.dims[0], i) for i, name in enumerate(index.names)]\n        index = index.set_names(valid_level_names)\n    else:\n        index = index.set_names(self.name)\n    return index",
    ".xarray.core.indexing.py@@PandasIndexAdapter.shape": "def shape(self) -> Tuple[int]:\n    return (len(self.array),)",
    ".xarray.core.variable.py@@IndexVariable.name": "def name(self):\n    return self.dims[0]"
}
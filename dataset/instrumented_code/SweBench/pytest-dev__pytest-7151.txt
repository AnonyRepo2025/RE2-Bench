diff --git a/src/_pytest/debugging.py b/src/_pytest/debugging.py
index 9155d7e..aba89b8 100644
--- a/src/_pytest/debugging.py
+++ b/src/_pytest/debugging.py
@@ -1,3 +1,196 @@
+import inspect
+def recursive_object_seralizer(obj, visited):
+    seralized_dict = {}
+    keys = list(obj.__dict__)
+    for k in keys:
+        if id(obj.__dict__[k]) in visited:
+            seralized_dict[k] = "<RECURSIVE {}>".format(obj.__dict__[k])
+            continue
+        if isinstance(obj.__dict__[k], (float, int, str, bool, type(None))):
+            seralized_dict[k] = obj.__dict__[k]
+        elif isinstance(obj.__dict__[k], tuple):
+            ## handle tuple
+            seralized_dict[k] = recursive_tuple_seralizer(obj.__dict__[k], visited)
+        elif isinstance(obj.__dict__[k], set):
+            ## handle set
+            seralized_dict[k] = recursive_set_seralizer(obj.__dict__[k], visited)
+        elif isinstance(obj.__dict__[k], list):
+            ## handle list
+            seralized_dict[k] = recursive_list_seralizer(obj.__dict__[k], visited)
+        elif hasattr(obj.__dict__[k], '__dict__'):
+            ## handle object
+            visited.append(id(obj.__dict__[k]))
+            seralized_dict[k] = recursive_object_seralizer(obj.__dict__[k], visited)
+        elif isinstance(obj.__dict__[k], dict):
+            visited.append(id(obj.__dict__[k]))
+            seralized_dict[k] = recursive_dict_seralizer(obj.__dict__[k], visited)
+        elif callable(obj.__dict__[k]):
+            ## handle function
+            if hasattr(obj.__dict__[k], '__name__'):
+                seralized_dict[k] = "<function {}>".format(obj.__dict__[k].__name__)
+        else:
+            seralized_dict[k] = str(obj.__dict__[k])
+    return seralized_dict
+
+def recursive_dict_seralizer(dictionary, visited):
+    seralized_dict = {}
+    keys = list(dictionary)
+    for k in keys:
+        if id(dictionary[k]) in visited:
+            seralized_dict[k] = "<RECURSIVE {}>".format(dictionary[k])
+            continue
+        # if isinstance(dictionary[k], (float, int, str, bool, type(None))):
+        #     pass
+        # else:
+        #     visited.append(id(dictionary[k]))
+        if isinstance(dictionary[k], (float, int, str, bool, type(None))):
+            seralized_dict[k] = dictionary[k]
+        elif isinstance(dictionary[k], list):
+            seralized_dict[k] = recursive_list_seralizer(dictionary[k], visited)
+        elif isinstance(dictionary[k], tuple):
+            seralized_dict[k] = recursive_tuple_seralizer(dictionary[k], visited)
+        elif isinstance(dictionary[k], set):
+            seralized_dict[k] = recursive_set_seralizer(dictionary[k], visited)        
+        elif hasattr(dictionary[k], '__dict__'):
+            visited.append(id(dictionary[k]))
+            seralized_dict[k] = recursive_object_seralizer(dictionary[k], visited)
+        elif callable(dictionary[k]):
+            if hasattr(dictionary[k], '__name__'):
+                seralized_dict[k] = "<function {}>".format(dictionary[k].__name__)
+        elif isinstance(dictionary[k], dict):
+            visited.append(id(dictionary[k]))
+            seralized_dict[k] = recursive_dict_seralizer(dictionary[k], visited)
+        else:
+            seralized_dict[k] =str(dictionary[k])
+    return seralized_dict   
+
+def recursive_set_seralizer(set_data, visited):
+    new_set = set()
+    for s in set_data:
+        if id(s) in visited:
+            continue 
+        if isinstance(s, (float, int, str, bool, type(None))):
+            new_set.add(s)
+        elif isinstance(s, tuple):
+            new_set.add(recursive_tuple_seralizer(s, visited))
+        elif isinstance(s, list):
+            new_set.add(recursive_list_seralizer(s, visited))
+        elif isinstance(s, set):
+            new_set.add(recursive_set_seralizer(s,visited))
+        elif isinstance(s, dict):
+            visited.append(id(s))
+            new_set.add(recursive_dict_seralizer(s, visited))
+        elif hasattr(s, '__dict__'):
+            visited.append(id(s))
+            new_set.add(str(recursive_object_seralizer(s, visited)))
+        elif callable(s):
+            if hasattr(s, '__name__'):
+                new_set.add("<function {}>".format(s.__name__))
+        else:
+            new_set.add(str(s))
+    return new_set
+    
+
+def recursive_tuple_seralizer(tup, visited):
+    new_tup = ()
+    for t in tup:
+        if id(t) in visited:
+           continue
+        if isinstance(t, (float, int, str, bool, type(None))):
+            new_tup = (*new_tup, t)
+        elif isinstance(t, tuple):
+            new_tup = (*new_tup, recursive_tuple_seralizer(t, visited))
+        elif isinstance(t, list):
+            new_tup = (*new_tup, recursive_list_seralizer(t, visited))
+        elif isinstance(t, set):
+            new_tup = (*new_tup, recursive_set_seralizer(t, visited))
+        elif isinstance(t, dict):
+            visited.append(id(t))
+            new_tup = (*new_tup, recursive_dict_seralizer(t, visited))
+        elif hasattr(t, '__dict__'):
+            visited.append(id(t))
+            new_tup = (*new_tup, recursive_object_seralizer(t, visited))
+        elif callable(t):
+            if hasattr(t, '__name__'):
+                new_tup = (*new_tup, "<function {}>".format(t.__name__))
+        else:
+            new_tup = (*new_tup, str(t))
+    return new_tup
+
+def recursive_list_seralizer(li, visited):
+    new_list = []
+    for l in li:
+        if id(l) in visited:
+            continue
+        if isinstance(l, (float, int, str, bool, type(None))):
+            new_list.append(l)
+        elif isinstance(l, tuple):
+            new_list.append(recursive_tuple_seralizer(l, visited))
+        elif isinstance(l, list):
+            new_list.append(recursive_list_seralizer(l, visited))
+        elif isinstance(l, set):
+            new_list.append(recursive_set_seralizer(l, visited))
+        elif hasattr(l, '__dict__'):
+            visited.append(id(l))
+            new_list.append(recursive_object_seralizer(l, visited))
+        elif isinstance(l, dict):
+            visited.append(id(l))
+            new_list.append(recursive_dict_seralizer(l, visited))
+        elif callable(l):
+            if hasattr(l, '__name__'):
+                new_list.append("<function {}>".format(l.__name__))
+        else:
+            new_list.append(str(l))       
+
+def inspect_code(func):
+    def wrapper(*args, **kwargs):
+        visited = []
+        filename = "/home/changshu/CODEMIND/scripts/swebench/swebench_playground/obj/pytest-dev__pytest-7151/src/_pytest/debugging.py"
+        para_dict = {"name": func.__name__}
+        args_names = inspect.getfullargspec(func).args
+        if len(args) > 0 and hasattr(args[0], '__dict__') and args_names[0] == 'self':
+            ## 'self'
+            self_args = args[0]
+            para_dict['self'] = recursive_object_seralizer(self_args, [id(self_args)])
+        else:
+            para_dict['self'] = {}
+        if len(args) > 0 :
+            if args_names[0] == 'self':
+                other_args = {}
+                for m,n in zip(args_names[1:], args[1:]):
+                    other_args[m] = n
+            else:
+                other_args = {}
+                for m,n in zip(args_names, args):
+                    other_args[m] = n
+            para_dict['args'] = recursive_dict_seralizer(other_args, [id(other_args)])
+        else:
+            para_dict['args'] = {}
+        if kwargs:
+            para_dict['kwargs'] = recursive_dict_seralizer(kwargs, [id(kwargs)])
+        else:
+            para_dict['kwargs'] = {}
+            
+        result = func(*args, **kwargs)
+        ## seralize the return value
+        if isinstance(result, tuple):
+            ret = recursive_tuple_seralizer(result, [])
+        elif isinstance(result, (float, int, str)):
+            ret = result
+        elif isinstance(result, list):
+            ret = recursive_list_seralizer(result, [])
+        elif isinstance(result, dict):
+            ret = recursive_dict_seralizer(result, [])
+        elif hasattr(result, '__dict__'):
+            ret = recursive_object_seralizer(result, [])
+        elif callable(result):
+            ret = "<function {}>".format(result.__name__)
+        else:
+            ret = str(result)
+        para_dict["return"] = ret
+        print("@[DATA]@", filename,"[SEP]", para_dict, "[/SEP]")
+        return result
+    return wrapper
 """ interactive debugging with PDB, the Python Debugger. """
 import argparse
 import functools
@@ -272,11 +465,15 @@ class PdbInvoke:
 class PdbTrace:
     @hookimpl(hookwrapper=True)
     def pytest_pyfunc_call(self, pyfuncitem):
-        _test_pytest_function(pyfuncitem)
+        wrap_pytest_function_for_tracing(pyfuncitem)
         yield
 
 
-def _test_pytest_function(pyfuncitem):
+def wrap_pytest_function_for_tracing(pyfuncitem):
+    """Changes the python function object of the given Function item by a wrapper which actually
+    enters pdb before calling the python function itself, effectively leaving the user
+    in the pdb prompt in the first statement of the function.
+    """
     _pdb = pytestPDB._init_pdb("runcall")
     testfunction = pyfuncitem.obj
 
@@ -291,6 +488,14 @@ def _test_pytest_function(pyfuncitem):
     pyfuncitem.obj = wrapper
 
 
+@inspect_code
+def maybe_wrap_pytest_function_for_tracing(pyfuncitem):
+    """Wrap the given pytestfunct item for tracing support if --trace was given in
+    the command line"""
+    if pyfuncitem.config.getvalue("trace"):
+        wrap_pytest_function_for_tracing(pyfuncitem)
+
+
 def _enter_pdb(node, excinfo, rep):
     # XXX we re-use the TerminalReporter's terminalwriter
     # because this seems to avoid some encoding related troubles
diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py
index e461248..fc3d1a5 100644
--- a/src/_pytest/unittest.py
+++ b/src/_pytest/unittest.py
@@ -1,5 +1,4 @@
 """ discovery and running of std-library "unittest" style tests. """
-import functools
 import sys
 import traceback
 
@@ -114,15 +113,17 @@ class TestCaseFunction(Function):
     _testcase = None
 
     def setup(self):
-        self._needs_explicit_tearDown = False
+        # a bound method to be called during teardown() if set (see 'runtest()')
+        self._explicit_tearDown = None
         self._testcase = self.parent.obj(self.name)
         self._obj = getattr(self._testcase, self.name)
         if hasattr(self, "_request"):
             self._request._fillfixtures()
 
     def teardown(self):
-        if self._needs_explicit_tearDown:
-            self._testcase.tearDown()
+        if self._explicit_tearDown is not None:
+            self._explicit_tearDown()
+            self._explicit_tearDown = None
         self._testcase = None
         self._obj = None
 
@@ -205,40 +206,31 @@ class TestCaseFunction(Function):
         return bool(expecting_failure_class or expecting_failure_method)
 
     def runtest(self):
-        # TODO: move testcase reporter into separate class, this shouldnt be on item
-        import unittest
+        from _pytest.debugging import maybe_wrap_pytest_function_for_tracing
 
-        testMethod = getattr(self._testcase, self._testcase._testMethodName)
-
-        class _GetOutOf_testPartExecutor(KeyboardInterrupt):
-            """Helper exception to get out of unittests's testPartExecutor (see TestCase.run)."""
-
-        @functools.wraps(testMethod)
-        def wrapped_testMethod(*args, **kwargs):
-            """Wrap the original method to call into pytest's machinery, so other pytest
-            features can have a chance to kick in (notably --pdb)"""
-            try:
-                self.ihook.pytest_pyfunc_call(pyfuncitem=self)
-            except unittest.SkipTest:
-                raise
-            except Exception as exc:
-                expecting_failure = self._expecting_failure(testMethod)
-                if expecting_failure:
-                    raise
-                self._needs_explicit_tearDown = True
-                raise _GetOutOf_testPartExecutor(exc)
+        maybe_wrap_pytest_function_for_tracing(self)
 
         # let the unittest framework handle async functions
         if is_async_function(self.obj):
             self._testcase(self)
         else:
-            setattr(self._testcase, self._testcase._testMethodName, wrapped_testMethod)
+            # when --pdb is given, we want to postpone calling tearDown() otherwise
+            # when entering the pdb prompt, tearDown() would have probably cleaned up
+            # instance variables, which makes it difficult to debug
+            # arguably we could always postpone tearDown(), but this changes the moment where the
+            # TestCase instance interacts with the results object, so better to only do it
+            # when absolutely needed
+            if self.config.getoption("usepdb"):
+                self._explicit_tearDown = self._testcase.tearDown
+                setattr(self._testcase, "tearDown", lambda *args: None)
+
+            # we need to update the actual bound method with self.obj, because
+            # wrap_pytest_function_for_tracing replaces self.obj by a wrapper
+            setattr(self._testcase, self.name, self.obj)
             try:
                 self._testcase(result=self)
-            except _GetOutOf_testPartExecutor as exc:
-                raise exc.args[0] from exc.args[0]
             finally:
-                delattr(self._testcase, self._testcase._testMethodName)
+                delattr(self._testcase, self.name)
 
     def _prunetraceback(self, excinfo):
         Function._prunetraceback(self, excinfo)
diff --git a/testing/test_unittest.py b/testing/test_unittest.py
index a026dc3..83f1b6b 100644
--- a/testing/test_unittest.py
+++ b/testing/test_unittest.py
@@ -537,28 +537,24 @@ class TestTrialUnittest:
         )
         result.stdout.fnmatch_lines(
             [
-                "test_trial_error.py::TC::test_four SKIPPED",
+                "test_trial_error.py::TC::test_four FAILED",
                 "test_trial_error.py::TC::test_four ERROR",
                 "test_trial_error.py::TC::test_one FAILED",
                 "test_trial_error.py::TC::test_three FAILED",
-                "test_trial_error.py::TC::test_two SKIPPED",
-                "test_trial_error.py::TC::test_two ERROR",
+                "test_trial_error.py::TC::test_two FAILED",
                 "*ERRORS*",
                 "*_ ERROR at teardown of TC.test_four _*",
-                "NOTE: Incompatible Exception Representation, displaying natively:",
-                "*DelayedCalls*",
-                "*_ ERROR at teardown of TC.test_two _*",
-                "NOTE: Incompatible Exception Representation, displaying natively:",
                 "*DelayedCalls*",
                 "*= FAILURES =*",
-                # "*_ TC.test_four _*",
-                # "*NameError*crash*",
+                "*_ TC.test_four _*",
+                "*NameError*crash*",
                 "*_ TC.test_one _*",
                 "*NameError*crash*",
                 "*_ TC.test_three _*",
-                "NOTE: Incompatible Exception Representation, displaying natively:",
                 "*DelayedCalls*",
-                "*= 2 failed, 2 skipped, 2 errors in *",
+                "*_ TC.test_two _*",
+                "*NameError*crash*",
+                "*= 4 failed, 1 error in *",
             ]
         )
 
@@ -876,6 +872,37 @@ def test_no_teardown_if_setupclass_failed(testdir):
     reprec.assertoutcome(passed=1, failed=1)
 
 
+def test_cleanup_functions(testdir):
+    """Ensure functions added with addCleanup are always called after each test ends (#6947)"""
+    testdir.makepyfile(
+        """
+        import unittest
+
+        cleanups = []
+
+        class Test(unittest.TestCase):
+
+            def test_func_1(self):
+                self.addCleanup(cleanups.append, "test_func_1")
+
+            def test_func_2(self):
+                self.addCleanup(cleanups.append, "test_func_2")
+                assert 0
+
+            def test_func_3_check_cleanups(self):
+                assert cleanups == ["test_func_1", "test_func_2"]
+    """
+    )
+    result = testdir.runpytest("-v")
+    result.stdout.fnmatch_lines(
+        [
+            "*::test_func_1 PASSED *",
+            "*::test_func_2 FAILED *",
+            "*::test_func_3_check_cleanups PASSED *",
+        ]
+    )
+
+
 def test_issue333_result_clearing(testdir):
     testdir.makeconftest(
         """
@@ -1131,6 +1158,41 @@ def test_trace(testdir, monkeypatch):
     assert result.ret == 0
 
 
+def test_pdb_teardown_called(testdir, monkeypatch):
+    """Ensure tearDown() is always called when --pdb is given in the command-line.
+
+    We delay the normal tearDown() calls when --pdb is given, so this ensures we are calling
+    tearDown() eventually to avoid memory leaks when using --pdb.
+    """
+    teardowns = []
+    monkeypatch.setattr(
+        pytest, "test_pdb_teardown_called_teardowns", teardowns, raising=False
+    )
+
+    testdir.makepyfile(
+        """
+        import unittest
+        import pytest
+
+        class MyTestCase(unittest.TestCase):
+
+            def tearDown(self):
+                pytest.test_pdb_teardown_called_teardowns.append(self.id())
+
+            def test_1(self):
+                pass
+            def test_2(self):
+                pass
+    """
+    )
+    result = testdir.runpytest_inprocess("--pdb")
+    result.stdout.fnmatch_lines("* 2 passed in *")
+    assert teardowns == [
+        "test_pdb_teardown_called.MyTestCase.test_1",
+        "test_pdb_teardown_called.MyTestCase.test_2",
+    ]
+
+
 def test_async_support(testdir):
     pytest.importorskip("unittest.async_case")
 

diff --git a/sklearn/ensemble/tests/test_weight_boosting.py b/sklearn/ensemble/tests/test_weight_boosting.py
index 435d2ef..adeaf1d 100755
--- a/sklearn/ensemble/tests/test_weight_boosting.py
+++ b/sklearn/ensemble/tests/test_weight_boosting.py
@@ -471,7 +471,6 @@ def test_sparse_regression():
 def test_sample_weight_adaboost_regressor():
     """
     AdaBoostRegressor should work without sample_weights in the base estimator
-
     The random weighted sampling is done internally in the _boost method in
     AdaBoostRegressor.
     """
@@ -486,3 +485,27 @@ def test_sample_weight_adaboost_regressor():
     boost = AdaBoostRegressor(DummyEstimator(), n_estimators=3)
     boost.fit(X, y_regr)
     assert_equal(len(boost.estimator_weights_), len(boost.estimator_errors_))
+
+
+def test_multidimensional_X():
+    """
+    Check that the AdaBoost estimators can work with n-dimensional
+    data matrix
+    """
+
+    from sklearn.dummy import DummyClassifier, DummyRegressor
+
+    rng = np.random.RandomState(0)
+
+    X = rng.randn(50, 3, 3)
+    yc = rng.choice([0, 1], 50)
+    yr = rng.randn(50)
+
+    boost = AdaBoostClassifier(DummyClassifier(strategy='most_frequent'))
+    boost.fit(X, yc)
+    boost.predict(X)
+    boost.predict_proba(X)
+
+    boost = AdaBoostRegressor(DummyRegressor())
+    boost.fit(X, yr)
+    boost.predict(X)
diff --git a/sklearn/ensemble/weight_boosting.py b/sklearn/ensemble/weight_boosting.py
index f82a0d8..e42cd3b 100644
--- a/sklearn/ensemble/weight_boosting.py
+++ b/sklearn/ensemble/weight_boosting.py
@@ -1,3 +1,196 @@
+import inspect
+def recursive_object_seralizer(obj, visited):
+    seralized_dict = {}
+    keys = list(obj.__dict__)
+    for k in keys:
+        if id(obj.__dict__[k]) in visited:
+            seralized_dict[k] = "<RECURSIVE {}>".format(obj.__dict__[k])
+            continue
+        if isinstance(obj.__dict__[k], (float, int, str, bool, type(None))):
+            seralized_dict[k] = obj.__dict__[k]
+        elif isinstance(obj.__dict__[k], tuple):
+            ## handle tuple
+            seralized_dict[k] = recursive_tuple_seralizer(obj.__dict__[k], visited)
+        elif isinstance(obj.__dict__[k], set):
+            ## handle set
+            seralized_dict[k] = recursive_set_seralizer(obj.__dict__[k], visited)
+        elif isinstance(obj.__dict__[k], list):
+            ## handle list
+            seralized_dict[k] = recursive_list_seralizer(obj.__dict__[k], visited)
+        elif hasattr(obj.__dict__[k], '__dict__'):
+            ## handle object
+            visited.append(id(obj.__dict__[k]))
+            seralized_dict[k] = recursive_object_seralizer(obj.__dict__[k], visited)
+        elif isinstance(obj.__dict__[k], dict):
+            visited.append(id(obj.__dict__[k]))
+            seralized_dict[k] = recursive_dict_seralizer(obj.__dict__[k], visited)
+        elif callable(obj.__dict__[k]):
+            ## handle function
+            if hasattr(obj.__dict__[k], '__name__'):
+                seralized_dict[k] = "<function {}>".format(obj.__dict__[k].__name__)
+        else:
+            seralized_dict[k] = str(obj.__dict__[k])
+    return seralized_dict
+
+def recursive_dict_seralizer(dictionary, visited):
+    seralized_dict = {}
+    keys = list(dictionary)
+    for k in keys:
+        if id(dictionary[k]) in visited:
+            seralized_dict[k] = "<RECURSIVE {}>".format(dictionary[k])
+            continue
+        # if isinstance(dictionary[k], (float, int, str, bool, type(None))):
+        #     pass
+        # else:
+        #     visited.append(id(dictionary[k]))
+        if isinstance(dictionary[k], (float, int, str, bool, type(None))):
+            seralized_dict[k] = dictionary[k]
+        elif isinstance(dictionary[k], list):
+            seralized_dict[k] = recursive_list_seralizer(dictionary[k], visited)
+        elif isinstance(dictionary[k], tuple):
+            seralized_dict[k] = recursive_tuple_seralizer(dictionary[k], visited)
+        elif isinstance(dictionary[k], set):
+            seralized_dict[k] = recursive_set_seralizer(dictionary[k], visited)        
+        elif hasattr(dictionary[k], '__dict__'):
+            visited.append(id(dictionary[k]))
+            seralized_dict[k] = recursive_object_seralizer(dictionary[k], visited)
+        elif callable(dictionary[k]):
+            if hasattr(dictionary[k], '__name__'):
+                seralized_dict[k] = "<function {}>".format(dictionary[k].__name__)
+        elif isinstance(dictionary[k], dict):
+            visited.append(id(dictionary[k]))
+            seralized_dict[k] = recursive_dict_seralizer(dictionary[k], visited)
+        else:
+            seralized_dict[k] =str(dictionary[k])
+    return seralized_dict   
+
+def recursive_set_seralizer(set_data, visited):
+    new_set = set()
+    for s in set_data:
+        if id(s) in visited:
+            continue 
+        if isinstance(s, (float, int, str, bool, type(None))):
+            new_set.add(s)
+        elif isinstance(s, tuple):
+            new_set.add(recursive_tuple_seralizer(s, visited))
+        elif isinstance(s, list):
+            new_set.add(recursive_list_seralizer(s, visited))
+        elif isinstance(s, set):
+            new_set.add(recursive_set_seralizer(s,visited))
+        elif isinstance(s, dict):
+            visited.append(id(s))
+            new_set.add(recursive_dict_seralizer(s, visited))
+        elif hasattr(s, '__dict__'):
+            visited.append(id(s))
+            new_set.add(str(recursive_object_seralizer(s, visited)))
+        elif callable(s):
+            if hasattr(s, '__name__'):
+                new_set.add("<function {}>".format(s.__name__))
+        else:
+            new_set.add(str(s))
+    return new_set
+    
+
+def recursive_tuple_seralizer(tup, visited):
+    new_tup = ()
+    for t in tup:
+        if id(t) in visited:
+           continue
+        if isinstance(t, (float, int, str, bool, type(None))):
+            new_tup = (*new_tup, t)
+        elif isinstance(t, tuple):
+            new_tup = (*new_tup, recursive_tuple_seralizer(t, visited))
+        elif isinstance(t, list):
+            new_tup = (*new_tup, recursive_list_seralizer(t, visited))
+        elif isinstance(t, set):
+            new_tup = (*new_tup, recursive_set_seralizer(t, visited))
+        elif isinstance(t, dict):
+            visited.append(id(t))
+            new_tup = (*new_tup, recursive_dict_seralizer(t, visited))
+        elif hasattr(t, '__dict__'):
+            visited.append(id(t))
+            new_tup = (*new_tup, recursive_object_seralizer(t, visited))
+        elif callable(t):
+            if hasattr(t, '__name__'):
+                new_tup = (*new_tup, "<function {}>".format(t.__name__))
+        else:
+            new_tup = (*new_tup, str(t))
+    return new_tup
+
+def recursive_list_seralizer(li, visited):
+    new_list = []
+    for l in li:
+        if id(l) in visited:
+            continue
+        if isinstance(l, (float, int, str, bool, type(None))):
+            new_list.append(l)
+        elif isinstance(l, tuple):
+            new_list.append(recursive_tuple_seralizer(l, visited))
+        elif isinstance(l, list):
+            new_list.append(recursive_list_seralizer(l, visited))
+        elif isinstance(l, set):
+            new_list.append(recursive_set_seralizer(l, visited))
+        elif hasattr(l, '__dict__'):
+            visited.append(id(l))
+            new_list.append(recursive_object_seralizer(l, visited))
+        elif isinstance(l, dict):
+            visited.append(id(l))
+            new_list.append(recursive_dict_seralizer(l, visited))
+        elif callable(l):
+            if hasattr(l, '__name__'):
+                new_list.append("<function {}>".format(l.__name__))
+        else:
+            new_list.append(str(l))       
+
+def inspect_code(func):
+    def wrapper(*args, **kwargs):
+        visited = []
+        filename = "/home/changshu/CODEMIND/scripts/swebench/swebench_playground/obj/scikit-learn__scikit-learn-13174/sklearn/ensemble/weight_boosting.py"
+        para_dict = {"name": func.__name__}
+        args_names = inspect.getfullargspec(func).args
+        if len(args) > 0 and hasattr(args[0], '__dict__') and args_names[0] == 'self':
+            ## 'self'
+            self_args = args[0]
+            para_dict['self'] = recursive_object_seralizer(self_args, [id(self_args)])
+        else:
+            para_dict['self'] = {}
+        if len(args) > 0 :
+            if args_names[0] == 'self':
+                other_args = {}
+                for m,n in zip(args_names[1:], args[1:]):
+                    other_args[m] = n
+            else:
+                other_args = {}
+                for m,n in zip(args_names, args):
+                    other_args[m] = n
+            para_dict['args'] = recursive_dict_seralizer(other_args, [id(other_args)])
+        else:
+            para_dict['args'] = {}
+        if kwargs:
+            para_dict['kwargs'] = recursive_dict_seralizer(kwargs, [id(kwargs)])
+        else:
+            para_dict['kwargs'] = {}
+            
+        result = func(*args, **kwargs)
+        ## seralize the return value
+        if isinstance(result, tuple):
+            ret = recursive_tuple_seralizer(result, [])
+        elif isinstance(result, (float, int, str)):
+            ret = result
+        elif isinstance(result, list):
+            ret = recursive_list_seralizer(result, [])
+        elif isinstance(result, dict):
+            ret = recursive_dict_seralizer(result, [])
+        elif hasattr(result, '__dict__'):
+            ret = recursive_object_seralizer(result, [])
+        elif callable(result):
+            ret = "<function {}>".format(result.__name__)
+        else:
+            ret = str(result)
+        para_dict["return"] = ret
+        print("@[DATA]@", filename,"[SEP]", para_dict, "[/SEP]")
+        return result
+    return wrapper
 """Weight Boosting
 
 This module contains weight boosting estimators for both classification and
@@ -30,16 +223,15 @@ import numpy as np
 from scipy.special import xlogy
 
 from .base import BaseEnsemble
-from ..base import ClassifierMixin, RegressorMixin, is_regressor, is_classifier
+from ..base import ClassifierMixin, RegressorMixin, is_classifier, is_regressor
 
-from .forest import BaseForest
 from ..tree import DecisionTreeClassifier, DecisionTreeRegressor
-from ..tree.tree import BaseDecisionTree
-from ..tree._tree import DTYPE
-from ..utils import check_array, check_X_y, check_random_state
+from ..utils import check_array, check_random_state, check_X_y, safe_indexing
 from ..utils.extmath import stable_cumsum
 from ..metrics import accuracy_score, r2_score
-from sklearn.utils.validation import has_fit_parameter, check_is_fitted
+from ..utils.validation import check_is_fitted
+from ..utils.validation import has_fit_parameter
+from ..utils.validation import _num_samples
 
 __all__ = [
     'AdaBoostClassifier',
@@ -70,6 +262,28 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
         self.learning_rate = learning_rate
         self.random_state = random_state
 
+    @inspect_code
+    def _validate_data(self, X, y=None):
+
+        # Accept or convert to these sparse matrix formats so we can
+        # use safe_indexing
+        accept_sparse = ['csr', 'csc']
+        if y is None:
+            ret = check_array(X,
+                              accept_sparse=accept_sparse,
+                              ensure_2d=False,
+                              allow_nd=True,
+                              dtype=None)
+        else:
+            ret = check_X_y(X, y,
+                            accept_sparse=accept_sparse,
+                            ensure_2d=False,
+                            allow_nd=True,
+                            dtype=None,
+                            y_numeric=is_regressor(self))
+        return ret
+
+    @inspect_code
     def fit(self, X, y, sample_weight=None):
         """Build a boosted classifier/regressor from the training set (X, y).
 
@@ -77,9 +291,7 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. COO, DOK, and LIL are converted to CSR. The dtype is
-            forced to DTYPE from tree._tree if the base classifier of this
-            ensemble weighted boosting classifier is a tree or forest.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         y : array-like of shape = [n_samples]
             The target values (class labels in classification, real numbers in
@@ -97,22 +309,12 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
         if self.learning_rate <= 0:
             raise ValueError("learning_rate must be greater than zero")
 
-        if (self.base_estimator is None or
-                isinstance(self.base_estimator, (BaseDecisionTree,
-                                                 BaseForest))):
-            dtype = DTYPE
-            accept_sparse = 'csc'
-        else:
-            dtype = None
-            accept_sparse = ['csr', 'csc']
-
-        X, y = check_X_y(X, y, accept_sparse=accept_sparse, dtype=dtype,
-                         y_numeric=is_regressor(self))
+        X, y = self._validate_data(X, y)
 
         if sample_weight is None:
             # Initialize weights to 1 / n_samples
-            sample_weight = np.empty(X.shape[0], dtype=np.float64)
-            sample_weight[:] = 1. / X.shape[0]
+            sample_weight = np.empty(_num_samples(X), dtype=np.float64)
+            sample_weight[:] = 1. / _num_samples(X)
         else:
             sample_weight = check_array(sample_weight, ensure_2d=False)
             # Normalize existing weights
@@ -205,6 +407,7 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
         """
         pass
 
+    @inspect_code
     def staged_score(self, X, y, sample_weight=None):
         """Return staged scores for X, y.
 
@@ -216,7 +419,7 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         y : array-like, shape = [n_samples]
             Labels for X.
@@ -228,6 +431,8 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
         -------
         z : float
         """
+        X = self._validate_data(X)
+
         for y_pred in self.staged_predict(X):
             if is_classifier(self):
                 yield accuracy_score(y, y_pred, sample_weight=sample_weight)
@@ -259,18 +464,6 @@ class BaseWeightBoosting(BaseEnsemble, metaclass=ABCMeta):
                 "since base_estimator does not have a "
                 "feature_importances_ attribute")
 
-    def _validate_X_predict(self, X):
-        """Ensure that X is in the proper format"""
-        if (self.base_estimator is None or
-                isinstance(self.base_estimator,
-                           (BaseDecisionTree, BaseForest))):
-            X = check_array(X, accept_sparse='csr', dtype=DTYPE)
-
-        else:
-            X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])
-
-        return X
-
 
 def _samme_proba(estimator, n_classes, X):
     """Calculate algorithm 4, step 2, equation c) of Zhu et al [1].
@@ -391,7 +584,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         y : array-like of shape = [n_samples]
             The target values (class labels).
@@ -429,6 +622,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             raise ValueError("%s doesn't support sample_weight."
                              % self.base_estimator_.__class__.__name__)
 
+    @inspect_code
     def _boost(self, iboost, X, y, sample_weight, random_state):
         """Implement a single boost.
 
@@ -442,8 +636,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             The index of the current boost iteration.
 
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
-            The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            The training input samples.
 
         y : array-like of shape = [n_samples]
             The target values (class labels).
@@ -591,13 +784,15 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
         y : array of shape = [n_samples]
             The predicted classes.
         """
+        X = self._validate_data(X)
+
         pred = self.decision_function(X)
 
         if self.n_classes_ == 2:
@@ -618,13 +813,16 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         Parameters
         ----------
         X : array-like of shape = [n_samples, n_features]
-            The input samples.
+            The input samples. Sparse matrix can be CSC, CSR, COO,
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
         y : generator of array, shape = [n_samples]
             The predicted classes.
         """
+        X = self._validate_data(X)
+
         n_classes = self.n_classes_
         classes = self.classes_
 
@@ -644,7 +842,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
@@ -657,7 +855,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             class in ``classes_``, respectively.
         """
         check_is_fitted(self, "n_classes_")
-        X = self._validate_X_predict(X)
+        X = self._validate_data(X)
 
         n_classes = self.n_classes_
         classes = self.classes_[:, np.newaxis]
@@ -687,7 +885,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
@@ -700,7 +898,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             class in ``classes_``, respectively.
         """
         check_is_fitted(self, "n_classes_")
-        X = self._validate_X_predict(X)
+        X = self._validate_data(X)
 
         n_classes = self.n_classes_
         classes = self.classes_[:, np.newaxis]
@@ -741,7 +939,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
@@ -750,12 +948,12 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             outputs is the same of that of the `classes_` attribute.
         """
         check_is_fitted(self, "n_classes_")
+        X = self._validate_data(X)
 
         n_classes = self.n_classes_
-        X = self._validate_X_predict(X)
 
         if n_classes == 1:
-            return np.ones((X.shape[0], 1))
+            return np.ones((_num_samples(X), 1))
 
         if self.algorithm == 'SAMME.R':
             # The weights are all 1. for SAMME.R
@@ -790,7 +988,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
@@ -798,7 +996,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             The class probabilities of the input samples. The order of
             outputs is the same of that of the `classes_` attribute.
         """
-        X = self._validate_X_predict(X)
+        X = self._validate_data(X)
 
         n_classes = self.n_classes_
         proba = None
@@ -837,7 +1035,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
@@ -845,6 +1043,7 @@ class AdaBoostClassifier(BaseWeightBoosting, ClassifierMixin):
             The class probabilities of the input samples. The order of
             outputs is the same of that of the `classes_` attribute.
         """
+        X = self._validate_data(X)
         return np.log(self.predict_proba(X))
 
 
@@ -937,7 +1136,7 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         y : array-like of shape = [n_samples]
             The target values (real numbers).
@@ -975,8 +1174,7 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
             The index of the current boost iteration.
 
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
-            The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            The training input samples.
 
         y : array-like of shape = [n_samples]
             The target values (class labels in classification, real numbers in
@@ -1008,14 +1206,16 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
         # For NumPy >= 1.7.0 use np.random.choice
         cdf = stable_cumsum(sample_weight)
         cdf /= cdf[-1]
-        uniform_samples = random_state.random_sample(X.shape[0])
+        uniform_samples = random_state.random_sample(_num_samples(X))
         bootstrap_idx = cdf.searchsorted(uniform_samples, side='right')
         # searchsorted returns a scalar
         bootstrap_idx = np.array(bootstrap_idx, copy=False)
 
         # Fit on the bootstrapped sample and obtain a prediction
         # for all samples in the training set
-        estimator.fit(X[bootstrap_idx], y[bootstrap_idx])
+        X_ = safe_indexing(X, bootstrap_idx)
+        y_ = safe_indexing(y, bootstrap_idx)
+        estimator.fit(X_, y_)
         y_predict = estimator.predict(X)
 
         error_vect = np.abs(y_predict - y)
@@ -1067,10 +1267,10 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
         median_or_above = weight_cdf >= 0.5 * weight_cdf[:, -1][:, np.newaxis]
         median_idx = median_or_above.argmax(axis=1)
 
-        median_estimators = sorted_idx[np.arange(X.shape[0]), median_idx]
+        median_estimators = sorted_idx[np.arange(_num_samples(X)), median_idx]
 
         # Return median predictions
-        return predictions[np.arange(X.shape[0]), median_estimators]
+        return predictions[np.arange(_num_samples(X)), median_estimators]
 
     def predict(self, X):
         """Predict regression value for X.
@@ -1082,7 +1282,7 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
             The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            DOK, or LIL. COO, DOK, and LIL are converted to CSR.
 
         Returns
         -------
@@ -1090,7 +1290,7 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
             The predicted regression values.
         """
         check_is_fitted(self, "estimator_weights_")
-        X = self._validate_X_predict(X)
+        X = self._validate_data(X)
 
         return self._get_median_predict(X, len(self.estimators_))
 
@@ -1107,8 +1307,7 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
         Parameters
         ----------
         X : {array-like, sparse matrix} of shape = [n_samples, n_features]
-            The training input samples. Sparse matrix can be CSC, CSR, COO,
-            DOK, or LIL. DOK and LIL are converted to CSR.
+            The training input samples.
 
         Returns
         -------
@@ -1116,7 +1315,7 @@ class AdaBoostRegressor(BaseWeightBoosting, RegressorMixin):
             The predicted regression values.
         """
         check_is_fitted(self, "estimator_weights_")
-        X = self._validate_X_predict(X)
+        X = self._validate_data(X)
 
         for i, _ in enumerate(self.estimators_, 1):
             yield self._get_median_predict(X, limit=i)

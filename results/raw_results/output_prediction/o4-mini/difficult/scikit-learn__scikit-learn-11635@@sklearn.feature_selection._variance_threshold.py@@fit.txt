[THOUGHT]
We have a 3×5 CSR matrix X with
 row0 entries at cols 1–4: [1,2,3,4]
 row1 at cols 1–4: [2,2,3,5]
 row2 at cols 0–3: [1,1,2,4]
All other entries are zero.  Expanding to dense form:

col0: [0,0,1]  
col1: [1,2,1]  
col2: [2,2,2]  
col3: [3,3,4]  
col4: [4,5,0]

mean_variance_axis on a sparse matrix treats missing entries as zeros, so for each column j (n=3):

 sum_j = ∑values,  sum_sq_j = ∑values²,  
 mean = sum_j/3,  
 var = (sum_sq_j/3) – mean².

Compute per column:

col0: sum=1, sum_sq=1 → mean=1/3 ≈0.3333, var=1/3 –(1/3)² =0.3333–0.1111=0.2222  
col1: sum=4, sum_sq=6 → mean=4/3≈1.3333, var=2 –1.7778=0.2222  
col2: sum=6, sum_sq=12→ mean=2, var=4 –4 =0.0  
col3: sum=10,sum_sq=34→ mean=10/3≈3.3333, var=11.3333–11.1111=0.2222  
col4: sum=9, sum_sq=41 → mean=3, var=13.6667–9 =4.6667

Thus variances_ = [0.22222222, 0.22222222, 0.0, 0.22222222, 4.66666667].

Since threshold=0.4≠0, no peak-to-peak adjustment.  
We check if all variances ≤0.4: column 4 has var≈4.67>0.4, so at least one feature exceeds threshold and no error is raised.  
fit returns self with threshold unchanged and variances_ set as above.
[/THOUGHT]

[OUTPUT]
{
    "threshold": 0.4,
    "variances_": [0.2222222222222222, 0.2222222222222222, 0.0, 0.2222222222222222, 4.666666666666667]
}
[/OUTPUT]
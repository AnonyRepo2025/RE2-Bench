[THOUGHT]
The function `confusion_matrix` computes the confusion matrix to evaluate classification accuracy. Given the inputs:
- `y_true`: 40 zeros, 50 ones, 4 twos (total 94 samples)
- `y_pred`: 20 zeros, 20 ones, 10 zeros, 40 ones, 4 twos (total 94 samples)

Steps:
1. **Check targets**: Both `y_true` and `y_pred` are multiclass (3 classes: 0,1,2). They are converted to 1D arrays.
2. **Labels**: Since `labels=None`, `unique_labels` returns sorted unique labels: `[0, 1, 2]`.
3. **Sample weight**: `None`, so an array of 94 ones is used.
4. **Mapping**: Labels are mapped to indices: `0→0`, `1→1`, `2→2`.
5. **Filtering**: All labels are valid (indices < 3), so no samples are removed.
6. **Build matrix**: 
   - Row 0 (true class 0): 20 predicted as 0, 20 as 1, 0 as 2 → `[20, 20, 0]`
   - Row 1 (true class 1): 10 predicted as 0, 40 as 1, 0 as 2 → `[10, 40, 0]`
   - Row 2 (true class 2): 0 predicted as 0, 0 as 1, 4 as 2 → `[0, 0, 4]`
7. **Normalization**: `normalize=None`, so no change.
8. **Output**: The 3x3 confusion matrix as a list of lists.

The output is:
```
[
  [20, 20, 0],
  [10, 40, 0],
  [0, 0, 4]
]
```
[/THOUGHT]

[OUTPUT]
{
    "output": [[20, 20, 0], [10, 40, 0], [0, 0, 4]]
}
[/OUTPUT]
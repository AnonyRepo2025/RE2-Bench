
[INPUT]
```
{
    "self": {
        "input": "content",
        "encoding": "utf-8",
        "decode_error": "strict",
        "strip_accents": null,
        "preprocessor": null,
        "tokenizer": null,
        "analyzer": "word",
        "lowercase": true,
        "token_pattern": "(?u)\\b\\w\\w+\\b",
        "stop_words": null,
        "max_df": 1.0,
        "min_df": 1,
        "max_features": null,
        "ngram_range": [
            1,
            1
        ],
        "vocabulary": null,
        "binary": false,
        "dtype": {
            "__repr__": "<class 'numpy.float64'>",
            "__hash__": null,
            "__str__": "<class 'numpy.float64'>",
            "__lt__": null,
            "__le__": null,
            "__eq__": null,
            "__ne__": null,
            "__gt__": null,
            "__ge__": null,
            "__add__": null,
            "__radd__": null,
            "__sub__": null,
            "__rsub__": null,
            "__mul__": null,
            "__rmul__": null,
            "__mod__": null,
            "__rmod__": null,
            "__divmod__": null,
            "__rdivmod__": null,
            "__pow__": null,
            "__rpow__": null,
            "__neg__": null,
            "__pos__": null,
            "__abs__": null,
            "__bool__": null,
            "__int__": null,
            "__float__": null,
            "__floordiv__": null,
            "__rfloordiv__": null,
            "__truediv__": null,
            "__rtruediv__": null,
            "__new__": null,
            "as_integer_ratio": null,
            "__doc__": "A floating point number, represented as a double-precision floating-point number."
        },
        "_tfidf": {
            "norm": "l2",
            "use_idf": true,
            "smooth_idf": true,
            "sublinear_tf": false,
            "_idf_diag": {
                "_shape": [
                    11,
                    11
                ],
                "maxprint": 50,
                "indices": "[ 8  5  4  0  8  4  1  0  8  4  2 10  9  8  6]",
                "indptr": "[ 0  4  8 11 15]",
                "data": "[0.40077572 0.39693414 0.22714593 0.79386827 0.21902046 0.24826657\n 0.37083387 0.86768427 0.37754337 0.21397863 0.90092961 0.35827234\n 0.86321753 0.18086988 0.30623932]"
            }
        },
        "fixed_vocabulary_": true,
        "_stop_words_id": null,
        "stop_words_": null,
        "vocabulary_": {
            "the": 9,
            "pizza": 6,
            "beer": 1,
            "copyright": 2,
            "burger": 0,
            "coke": 3,
            "salad": 7,
            "celeri": 4,
            "sparkling": 10,
            "water": 8,
            "tomato": 5
        }
    },
    "args": {
        "raw_documents": [
            "the pizza is delicious",
            "the burger is not as good as the pizza",
            "the coke is a popular drink",
            "the salad is a healthy choice",
            "the celeri is a vegetable",
            "the sparkling water is refreshing",
            "the tomato is a fruit"
        ]
    },
    "kwargs": {}
}
```
[/INPUT]
[/EXAMPLE]
[PYTHON]
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.externals import joblib

# Load the csv file
df = pd.read_csv("data.csv")

# Select independent and dependent variable
X = df[["A", "B", "C", "D"]]
y = df["E"]

# Split the dataset into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Feature scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test= sc.transform(X_test)

# Instantiate the model
classifier = RandomForestClassifier(n_estimators=100, random_state=0)

# Fit the model
classifier.fit(X_train, y_train)

# Make pickle file of our model
joblib.dump(classifier, "model.pkl")
[/PYTHON]

Functions called during the execution:
[PYTHON]
.pandas.read_csv

def read_csv(filepath_or_buffer, sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None):
    from pandas.core.frame import DataFrame
    from pandas.io.parsers import read_csv
    return read_csv(filepath_or_buffer, sep=sep, delimiter=delimiter, header=header, names=names, index_col=index_col, usecols=usecols, squeeze=squeeze, prefix=prefix, mangle_dupe_cols=mangle_dupe_cols, dtype=dtype, engine=engine, converters=converters, true_values=true_values, false_values=false_values, skipinitialspace=skipinitialspace, skiprows=skiprows, skipfooter=skipfooter, nrows=nrows, na_values=na_values, keep_default_na=keep_default_na, na_filter=na_filter, verbose=verbose, skip_blank_lines=skip_blank_lines, parse_dates=parse_dates, infer_datetime_format=infer_datetime_format, keep_date_col=keep_date_col, date_parser=date_parser, dayfirst=dayfirst, iterator=iterator, chunksize=ch
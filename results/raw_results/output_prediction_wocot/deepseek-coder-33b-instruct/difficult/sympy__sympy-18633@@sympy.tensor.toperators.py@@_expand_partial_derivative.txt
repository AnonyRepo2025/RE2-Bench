
[OUTPUT]
```
{
    "_indices": null,
    "_free": null,
    "_dum": null
}
```
[/OUTPUT]
[/PYTHON]
[PYTHON]
from sympy import Symbol, Number, sympify
from sympy import MutableDenseNDimArray, S
from sympy.tensor.tensor import Tensor, TensExpr, TensAdd, TensMul, TensorIndex
from .array import derive_by_array, tensorcontraction

class PartialDerivative(TensExpr):

    def __new__(cls, expr, *variables):
        if isinstance(expr, PartialDerivative):
            variables = expr.variables + variables
            expr = expr.expr
        args, indices, free, dum = cls._contract_indices_for_derivative(S(expr), variables)
        obj = TensExpr.__new__(cls, *args)
        obj._indices = indices
        obj._free = free
        obj._dum = dum
        return obj

    @classmethod
    def _contract_indices_for_derivative(cls, expr, variables):
        variables_opposite_valence = []
        for i in variables:
            if isinstance(i, Tensor):
                i_free_indices = i.get_free_indices()
                variables_opposite_valence.append(i.xreplace({k: -k for k in i_free_indices}))
            elif isinstance(i, Symbol):
                variables_opposite_valence.append(i)
        args, indices, free, dum = TensMul._tensMul_contract_indices([expr] + variables_opposite_valence, replace_indices=True)
        for i in range(1, len(args)):
            args_i = args[i]
            if isinstance(args_i, Tensor):
                i_indices = args[i].get_free_indices()
                args[i] = args[i].xreplace({k: -k for k in i_indices})
        return (args, indices, free, dum)

    def _expand_partial_derivative(self):
        args, indices, free, dum = self._contract_indices_for_derivative(self.expr, self.variables)
        obj = self.func(*args)
        obj._indices = indices
        obj._free = free
        obj._dum = dum
        result = obj
        if not args[0].free_symbols:
            return S.Zero
        elif isinstance(obj.expr, TensAdd):
            result = obj.expr.func(*[self.func(a, *obj.variables)._expand_partial_derivative() for a in result.expr.args])
        elif isinstance(obj.expr, TensMul):
            if len(obj.variables) == 1:
                terms = []
                mulargs = list(obj.expr.args)
                for ind in range(len(mulargs)):
                    if not isinstance(sympify(mulargs[ind]), Number):
                        d = self.func(mulargs[ind], *obj.variables)._expand_partial_derivative()
                        terms.append(TensMul(*mulargs[:ind] + [d] + mulargs[ind + 1:]))
                result = TensAdd.fromiter(terms)
            else:
                result = obj.expr
                for v in obj.variables:
                    result = self.func(result, v)._expand_partial_derivative()
        return result

    @property
    def expr(self):
        return self.args[0]

    @property
    def variables(self):
        return self.args[1:]
[/PYTHON]

Functions called during the execution:
[PYTHON]
.sympy.core.basic.Basic.args

def args(self):
    return self._args

.sympy.tensor.tensor.TensMul._tensMul_contract_indices

def _tensMul_contract_indices(args, replace_indices=True):
    replacements = [{} for _ in args]
    args_indices = [get_indices(arg) for arg in args]
    indices, free, free_names, dummy_data = TensMul._indices_to_free_dum(args_indices)
    cdt = defaultdict(int)

    def dummy_name_gen(tensor_index_type):
        nd = str(cdt[tensor_index_type])
        cdt[tensor_index_type] += 1
        return tensor_index_type.dummy_name + '_' + nd
    if replace_indices:
        for old_index, pos1cov, pos1contra, pos2cov, pos2contra in dummy_data:
            index_type = old_index.tensor_index_type
            while True:
                dummy_name = dummy_name_gen(index_type)
                if dummy_name not in free_names:
                    break
            dummy = TensorIndex(dummy_name, index_type, True)
            replacements[pos1cov][old_index] = dummy
            replacements[pos1contra][-old_index] = -dummy
            indices[pos2cov] = dummy
            indices[pos2contra] = -dummy
        args = [arg._replace_indices(repl) if isinstance(arg, TensExpr) else arg for arg, repl in zip(args, replacements)]
    dum = TensMul._dummy_data_to_dum(dummy_data)
    return (args, indices, free, dum)

.sympy.tensor.tensor.get_indices

def get_indices(t):
    if not isinstance(t, TensExpr):
        return ()
    return t.get_indices()

.sympy.tensor.tensor.Tensor.get_indices

def get_indices(self):
    return list(self.args[1])

.sympy.core.containers.Tuple.__len__

def __len__(self):
    return len(self.args)

.sympy.core.containers.Tuple.__iter__

def __iter__(self):
    return iter(self.args)

.sympy.tensor.tensor.TensMul._indices_to_free_dum

def _indices_to_free_dum(args_indices):
    free2pos1 = {}
    free2pos2 = {}
    dummy_data = []
    indices = []
    pos2 = 0
    for pos1, arg_indices in enumerate(args_indices):
        for index_pos, index in enumerate(arg_indices):
            if not isinstance(index, TensorIndex):
                raise TypeError('expected TensorIndex')
            if -index in free2pos1:
                other_pos1 = free2pos1.pop(-index)
                other_pos2 = free2pos2.pop(-index)
                if index.is_up:
                    dummy_data.append((index, pos1, other_pos1, pos2, other_pos2))
                else:
                    dummy_data.append((-index, other_pos1, pos1, other_pos2, pos2))
                indices.append(index)
            elif index in free2pos1:
                raise ValueError('Repeated index: %s' % index)
            else:
                free2pos1[index] = pos1
                free2pos2[index] = pos2
                indices.append(index)
            pos2 += 1
    free = [(i, p) for i, p in free2pos2.items()]
    free_names = [i.name for i in free2pos2.keys()]
    dummy_data.sort(key=lambda x: x[3])
    return (indices, free, free_names, dummy_data)

.sympy.tensor.tensor.TensorIndex.__neg__

def __neg__(self):
    t1 = TensorIndex(self.name, self.tensor_index_type, not self.is_up)
    return t1

.sympy.tensor.
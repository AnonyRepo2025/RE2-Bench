
[OUTPUT]
```
{
    "n_iter": 300,
    "tol": 0.001,
    "alpha_1": 1e-06,
    "alpha_2": 1e-06,
    "lambda_1": 1e-06,
    "lambda_2": 1e-06,
    "alpha_init": null,
    "lambda_init": null,
    "compute_score": false,
    "fit_intercept": true,
    "normalize": false,
    "copy_X": true,
    "verbose": false,
    "X_offset_": [0.4572252094531982, 0.4629488372319979, 0.8572263978986534, 0.6037087978986534, 1.0],
    "X_scale_": [1.0, 1.0, 1.0, 1.0, 1.0],
    "scores_": [],
    "n_iter_": 300,
    "alpha_": 0.00010000000000000009,
    "lambda_": 0.9999999999999999,
    "coef_": [0.0, 0.0, 0.0, 0.0, 0.0],
    "sigma_": [[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]],
    "intercept_": 1.4999999999999998
}
```
[/OUTPUT]
[/EXAMPLE]
[EXAMPLE]
[PYTHON]
from math import log
import numpy as np
from scipy import linalg
from scipy.linalg import pinvh
from .base import LinearModel, _rescale_data
from ..base import RegressorMixin
from ..utils.extmath import fast_logdet
from ..utils import check_X_y

class BayesianRidge(LinearModel, RegressorMixin):

    def __init__(self, n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06, alpha_init=None, lambda_init=None, compute_score=False, fit_intercept=True, normalize=False, copy_X=True, verbose=False):
        self.n_iter = n_iter
        self.tol = tol
        self.alpha_1 = alpha_1
        self.alpha_2 = alpha_2
        self.lambda_1 = lambda_1
        self.lambda_2 = lambda_2
        self.alpha_init = alpha_init
        self.lambda_init = lambda_init
        self.compute_score = compute_score
        self.fit_intercept = fit_intercept
        self.normalize = normalize
        self.copy_X = copy_X
        self.verbose = verbose

    def fit(self, X, y, sample_weight=None):
        if self.n_iter < 1:
            raise ValueError('n_iter should be greater than or equal to 1. Got {}.'.format(self.n_iter))
        X, y = check_X_y(X, y, dtype=np.float64, y_numeric=True)
        X, y, X_offset_, y_offset_, X_scale_ = self._preprocess_data(X, y, self.fit_intercept, self.normalize, self.copy_X, sample_weight=sample_weight)
        if sample_weight is not None:
            X, y = _rescale_data(X, y, sample_weight)
        self.X_offset_ = X_offset_
        self.X_scale_ = X_scale_
        n_samples, n_features = X.shape
        eps = np.finfo(np.float64).eps
        alpha_ = self.alpha_init
        lambda_ = self.lambda_init
        if alpha_ is None:
            alpha_ = 1.0 / (np.var(y) + eps)
        if lambda_ is None:
            lambda_ = 1.0
        verbose = self.verbose
        lambda_1 = self.lambda_1
        lambda_2 = self.lambda_2
        alpha_1 = self.alpha_1
        alpha_2 = self.alpha_2
        self.scores_ = list()
        coef_old_ = None
        XT_y = np.dot(X.T, y)
        U, S, Vh = linalg.svd(X, full_matrices=False)
        eigen_vals_ = S ** 2
        for iter_ in range(self.n_iter):
            coef_, rmse_ = self._update_coef_(X, y, n_samples, n_features, XT_y, U, Vh, eigen_vals_, alpha_, lambda_)
            if self.compute_score:
                s = self._log_marginal_likelihood(n_samples, n_features, eigen_vals_, alpha_, lambda_, coef_, rmse_)
                self.scores_.append(s)
            gamma_ = np.sum(alpha_ * eigen_vals_ / (lambda_ + alpha_ * eigen_vals_))
            lambda_ = (gamma_ + 2 * lambda_1) / (np.sum(coef_ ** 2) + 2 * lambda_2)
            alpha_ = (n_samples - gamma_ + 2 * alpha_1) / (rmse_ + 2 * alpha_2)
            if iter_ != 0 and np.sum(np.abs(coef_old_ - coef_)) < self.tol:
                if verbose:
                    print('Convergence after ', str(iter_), ' iterations')
                break
            coef_old_ = np.copy(coef_)
        self.n_iter_ = iter_ + 1
        self.alpha_ = alpha_
        self.lambda_ = lambda_
        self.coef_, rmse_ = self._update_coef_(X, y, n_samples, n_features, XT_y, U, Vh, eigen_vals_, alpha_, lambda_)
        if self.compute_score:
            s = self._log_marginal_likelihood(n_samples, n_features, eigen_vals_, alpha_, lambda_, coef_, rmse_)
            self.scores_.append(s)
            self.scores_ = np.array(self.scores_)
        scaled_sigma_ = np.dot(Vh.T, Vh / (eigen_vals_ + lambda_ / alpha_)[:, np.newaxis])
        self.sigma_ = 1.0 / alpha_ * scaled_sigma_
        self._set_intercept(X_offset_, y_offset_, X_scale_)
        return self

    def predict(self, X, return_std=False):
        y_mean = self._decision_function(X)
        if return_std is False:
            return y_mean
        else:
            if self.normalize:
                X = (X - self.X_offset_) / self.X_scale_
            sigmas_squared_data = (np.dot(X, self.sigma_) * X).sum(axis=1)
            y_std = np.sqrt(sigmas_squared_data + 1.0 / self.alpha_)
            return (y_mean, y_std)

    def _update_coef_(self, X, y, n_
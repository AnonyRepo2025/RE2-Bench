```python
import numpy as np
from sklearn.metrics import precision_recall_fscore_support

y_true = np.array(['red', 'red', 'blue', 'red', 'greengreengreengreengreen', 'greengreengreengreengreen', 'blue', 'greengreengreengreengreen', 'red', 'greengreengreengreengreen', 'red', 'greengreengreengreengreen', 'greengreengreengreengreen', 'greengreengreengreengreen', 'greengreengreengreengreen', 'blue', 'red', 'red', 'greengreengreengreengreen', 'blue', 'red', 'greengreengreengreengreen', 'red', 'red', 'blue', 'greengreengreengreengreen', 'blue', 'red', 'greengreengreengreengreen', 'blue', 'greengreengreengreengreen', 'blue', 'greengreengreengreengreen', 'greengreengreengreengreen', 'blue', 'blue', 'blue', 'blue', 'red', 'blue', 'greengreengreengreengreen', 'red', 'blue', 'greengreengreengreengreen', 'blue', 'greengreengreengreengreen', 'greengreengreengreengreen', 'blue', 'blue', 'greengreengreengreengreen', 'greengreengreengreengreen', 'greengreengreengreengreen', 'greengreengreengreengreen', 'red', 'greengreengreengreengreen', 'greengreengreengreengreen', 'blue', 'blue', 'red', 'blue', 'greengreengreengreengreen', 'blue', 'red', 'red', 'blue', 'greengreengreengreengreen', 'greengreengreengreengreen', 'greengreengreengreengreen', 'greengreengreengreengreen', 'blue', 'red', 'blue', 'greengreengreengreengreen', 'red', 'red'])
y_pred = np.array(['red', 'red', 'greengreengreengreengreen', 'red', 'red', 'red', 'blue', 'greengreengreengreengreen', 'red', 'red', 'red', 'red', 'blue', 'red', 'red', 'blue', 'red', 'red', 'red', 'red', 'greengreengreengreengreen', 'red', 'red', 'red', 'blue', 'red', 'blue', 'red', 'greengreengreengreengreen', 'greengreengreengreengreen', 'red', 'blue', 'red', 'greengreengreengreengreen', 'blue', 'blue', 'blue', 'blue', 'red', 'blue', 'red', 'greengreengreengreengreen', 'blue', 'red', 'blue', 'blue', 'blue', 'blue', 'greengreengreengreengreen', 'red', 'red', 'red', 'blue', 'red', 'red', 'red', 'blue', 'blue', 'red', 'greengreengreengreengreen', 'red', 'blue', 'red', 'red', 'blue', 'red', 'red', 'red', 'red', 'blue', 'red', 'blue', 'red', 'red', 'red'])

labels = np.unique(np.concatenate((y_true, y_pred)))
target_names = [str(l) for l in labels]
name_width = max((len(cn) for cn in target_names))
width = max(name_width, 13, 2)
headers = ['precision', 'recall', 'f1-score', 'support']
head_fmt = u'{:>{width}s} ' + u' {:>9}' * len(headers)
report = head_fmt.format(u'', *headers, width=width)
report += u'\n\n'

p, r, f1, s = precision_recall_fscore_support(y_true, y_pred, labels=labels, average=None)
row_fmt = u'{:>{width}s} ' + u' {:>9.{digits}f}' * 3 + u' {:>9}\n'
rows = zip(target_names, p, r, f1, s)

avg_total = [np.average(p, weights=s), np.average(r, weights=s), np.average(f1, weights=s), np.sum(s)]

for row in rows:
    report += row_fmt.format(*row, width=width, digits=2)
report += u'\n'
report += row_fmt.format('avg / total', *avg_total, width=width, digits=2)

print(report)
```

[OUTPUT]
```
                       precision    recall  f1-score   support
                                                              
      blue       0.64      0.64      0.64        22
greengreengreengreengreen       0.56      0.48      0.52        27
         red       0.71      0.81      0.76        31

avg / total       0.64      0.65      0.64        80
```
[/OUTPUT]
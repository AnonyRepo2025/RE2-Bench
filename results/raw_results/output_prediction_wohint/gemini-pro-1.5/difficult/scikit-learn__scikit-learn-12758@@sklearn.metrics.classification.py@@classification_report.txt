```python
from sklearn.metrics import classification_report
import numpy as np

y_true = np.array(['red', 'red', 'blue', 'red', 'green', 'green', 'blue', 'green', 'red', 'green', 'red', 'green', 'green', 'green', 'green', 'blue', 'red', 'red', 'green', 'blue', 'red', 'green', 'red', 'red', 'blue', 'green', 'blue', 'red', 'green', 'blue', 'green', 'blue', 'green', 'green', 'blue', 'blue', 'blue', 'blue', 'red', 'blue', 'green', 'red', 'blue', 'green', 'blue', 'green', 'green', 'blue', 'blue', 'green', 'green', 'green', 'green', 'red', 'green', 'green', 'blue', 'blue', 'red', 'blue', 'green', 'blue', 'red', 'red', 'blue', 'green', 'green', 'green', 'green', 'blue', 'red', 'blue', 'green', 'red', 'red'])
y_pred = np.array(['red', 'red', 'green', 'red', 'red', 'red', 'blue', 'green', 'red', 'red', 'red', 'red', 'blue', 'red', 'red', 'blue', 'red', 'red', 'red', 'red', 'green', 'red', 'red', 'red', 'blue', 'red', 'blue', 'red', 'green', 'green', 'red', 'blue', 'red', 'green', 'blue', 'blue', 'blue', 'blue', 'red', 'blue', 'red', 'green', 'blue', 'blue', 'blue', 'blue', 'green', 'red', 'red', 'red', 'blue', 'red', 'red', 'red', 'blue', 'blue', 'red', 'green', 'red', 'blue', 'red', 'red', 'blue', 'red', 'blue', 'red', 'red', 'red', 'red', 'blue', 'red', 'blue', 'red', 'red', 'red'])

report = classification_report(y_true, y_pred)
print(report)
```

[THOUGHT]
The `classification_report` function calculates precision, recall, F1-score, and support for each class, as well as averaged scores (micro, macro, weighted).  The input consists of true labels (`y_true`) and predicted labels (`y_pred`). The function will first determine the unique labels present in the input. Then, it will compute the metrics for each label and the averages. The output is a formatted string.
[/THOUGHT]

[OUTPUT]
```
              precision    recall  f1-score   support

        blue       0.64      0.64      0.64        22
       green       0.50      0.41      0.45        27
         red       0.61      0.78      0.68        23

    accuracy                           0.59        72
   macro avg       0.58      0.61      0.59        72
weighted avg       0.58      0.59      0.58        72
```
[/OUTPUT]
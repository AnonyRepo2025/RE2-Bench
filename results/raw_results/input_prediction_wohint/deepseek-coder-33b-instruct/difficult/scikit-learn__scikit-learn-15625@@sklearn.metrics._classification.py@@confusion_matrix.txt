1. The confusion matrix is a 2x2 matrix, where the rows represent the true labels and the columns represent the predicted labels.
2. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier.
3. The confusion matrix is symmetric.
4. The sum of the elements in each row is the total number of instances in that class.
5. The sum of the elements in each column is the total number of instances that were predicted as that class.
6. The sum of all elements in the confusion matrix is the total number of instances.
[/THOUGHT]

[INPUT]
```
{
    "self": {
        "_check_targets": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "check_consistent_length": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "_num_samples": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "type_of_target": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "is_multilabel": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "unique_labels": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "_unique_multiclass": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        },
        "column_or_1d": {
            "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
            "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
        }
    },
    "args": {
        "y_true": [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],
        "y_pred": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
    },
    "kwargs": {
        "labels": [0, 1],
        "sample_weight": None,
        "normalize": None
    }
}
```
[/INPUT]
[/EXAMPLE]
[PYTHON]
import numpy as np
from scipy.sparse import coo_matrix
from scipy.sparse import csr_matrix
from ..preprocessing import LabelBinarizer
from ..preprocessing import LabelEncoder
from ..utils import assert_all_finite
from ..utils import check_array
from ..utils import check_consistent_length
from ..utils import column_or_1d
from ..utils.multiclass import unique_labels
from ..utils.multiclass import type_of_target
from ..utils.validation import _num_samples
from ..utils.sparsefuncs import count_nonzero
from ..exceptions import UndefinedMetricWarning

def confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None):
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
    if y_type not in ('binary', 'multiclass'):
        raise ValueError('%s is not supported' % y_type)
    if labels is None:
        labels = unique_labels(y_true, y_pred)
    else:
        labels = np.asarray(labels)
        if np.all([l not in y_true for l in labels]):
            raise ValueError('At least one label specified must be in y_true')
    if sample_weight is None:
        sample_weight = np.ones(y_true.shape[0], dtype=np.int64)
    else:
        sample_weight = np.asarray(sample_weight)
    check_consistent_length(y_true, y_pred, sample_weight)
    n_labels = labels.size
    label_to_ind = {y: x for x, y in enumerate(labels)}
    y_pred = np.array([label_to_ind.get(x, n_labels + 1) for x in y_pred])
    y_true = np.array([label_to_ind.get(x, n_labels + 1) for x in y_true])
    ind = np.logical_and(y_pred < n_labels, y_true < n_labels)
    y_pred = y_pred[ind]
    y_true = y_true[ind]
    sample_weight = sample_weight[ind]
    if sample_weight.dtype.kind in {'i', 'u', 'b'}:
        dtype = np.int64
    else:
        dtype = np.float64
    cm = coo_matrix((sample_weight, (y_true, y_pred)), shape=(n_labels, n_labels), dtype=dtype).toarray()
    with np.errstate(all='ignore'):
        if normalize == 'true':
            cm = cm / cm.sum(axis=1, keepdims=True)
        elif normalize == 'pred':
            cm = cm / cm.sum(axis=0, keepdims=True)
        elif normalize == 'all':
            cm = cm / cm.sum()
        cm = np.nan_to_num(cm)
    return cm
[/PYTHON]

Functions called during the execution:
[PYTHON]
.sklearn.metrics._classification._check_targets

def _check_targets(y_true, y_pred):
    check_consistent_length(y_true, y_pred)
    type_true = type_of_target(y_true)
    type_pred = type_of_target(y_pred)
    y_type = {type_true, type_pred}
    if y_type == {'binary', 'multiclass'}:
        y_type = {'multiclass'}
    if len(y_type) > 1:
        raise ValueError("Classification metrics can't handle a mix of {0} and {1} targets".format(type_true, type_pred))
    y_type = y_type.pop()
    if y_type not in ['binary', 'multiclass', 'multilabel-indicator']:
        raise ValueError('{0} is not supported'.format(y_type))
    if y_type in ['binary', 'multiclass']:
        y_true = column_or_1d(y_true)
        y_pred = column_or_1d(y_
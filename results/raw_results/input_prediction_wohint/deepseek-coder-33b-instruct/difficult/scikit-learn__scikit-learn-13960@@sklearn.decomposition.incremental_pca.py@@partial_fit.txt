1. The input of `partial_fit` is a 2D array X.
2. The `n_components` is 3, so the number of components in the PCA model is 3.
3. The `whiten` is False, so the data is not whitened.
4. The `copy` is True, so the input data is copied.
5. The `batch_size` is 18, so the batch size is 18.
6. The `components_` is a 3x3 matrix, so the components of the PCA model are 3x3.
7. The `n_samples_seen_` is 100, so the number of samples seen is 100.
8. The `mean_` is a 3-element array, so the mean of the PCA model is a 3-element array.
9. The `var_` is a 3-element array, so the variance of the PCA model is a 3-element array.
10. The `singular_values_` is a 3-element array, so the singular values of the PCA model are a 3-element array.
11. The `explained_variance_` is a 3-element array, so the explained variance of the PCA model is a 3-element array.
12. The `explained_variance_ratio_` is a 3-element array, so the explained variance ratio of the PCA model is a 3-element array.
13. The `noise_variance_` is 0.0, so the noise variance of the PCA model is 0.0.
14. The `batch_size_` is 18, so the batch size of the PCA model is 18.
15. The `n_components_` is 3, so the number of components in the PCA model is 3.
[/THOUGHT]

[INPUT]
```
{
    "X": "[[ 0.090962   -0.12025564 -0.02202145]\n [ 0.090962   -0.12025564 -0.02202145]\n [ 0.090962   -0.12025564 -0.02202145]]"
}
```
[/INPUT]
[/PYTHON]
[PYTHON]
import numpy as np
from scipy import linalg, sparse
from .base import _BasePCA
from ..utils import check_array, gen_batches
from ..utils.extmath import svd_flip, _incremental_mean_and_var

class IncrementalPCA(_BasePCA):

    def __init__(self, n_components=None, whiten=False, copy=True, batch_size=None):
        self.n_components = n_components
        self.whiten = whiten
        self.copy = copy
        self.batch_size = batch_size

    def fit(self, X, y=None):
        self.components_ = None
        self.n_samples_seen_ = 0
        self.mean_ = 0.0
        self.var_ = 0.0
        self.singular_values_ = None
        self.explained_variance_ = None
        self.explained_variance_ratio_ = None
        self.singular_values_ = None
        self.noise_variance_ = None
        X = check_array(X, accept_sparse=['csr', 'csc', 'lil'], copy=self.copy, dtype=[np.float64, np.float32])
        n_samples, n_features = X.shape
        if self.batch_size is None:
            self.batch_size_ = 5 * n_features
        else:
            self.batch_size_ = self.batch_size
        for batch in gen_batches(n_samples, self.batch_size_, min_batch_size=self.n_components or 0):
            X_batch = X[batch]
            if sparse.issparse(X_batch):
                X_batch = X_batch.toarray()
            self.partial_fit(X_batch, check_input=False)
        return self

    def partial_fit(self, X, y=None, check_input=True):
        if check_input:
            if sparse.issparse(X):
                raise TypeError('IncrementalPCA.partial_fit does not support sparse input. Either convert data to dense or use IncrementalPCA.fit to do so in batches.')
            X = check_array(X, copy=self.copy, dtype=[np.float64, np.float32])
        n_samples, n_features = X.shape
        if not hasattr(self, 'components_'):
            self.components_ = None
        if self.n_components is None:
            if self.components_ is None:
                self.n_components_ = min(n_samples, n_features)
            else:
                self.n_components_ = self.components_.shape[0]
        elif not 1 <= self.n_components <= n_features:
            raise ValueError('n_components=%r invalid for n_features=%d, need more rows than columns for IncrementalPCA processing' % (self.n_components, n_features))
        elif not self.n_components <= n_samples:
            raise ValueError('n_components=%r must be less or equal to the batch number of samples %d.' % (self.n_components, n_samples))
        else:
            self.n_components_ = self.n_components
        if self.components_ is not None and self.components_.shape[0] != self.n_components_:
            raise ValueError('Number of input features has changed from %i to %i between calls to partial_fit!' % (self.components_.shape[0], self.n_components_))
        if not hasattr(self, 'n_samples_seen_'):
            self.n_samples_seen_ = 0
            self.mean_ = 0.0
            self.var_ = 0.0
        col_mean, col_var, n_total_samples = _incremental_mean_and_var(X, last_mean=self.mean_, last_variance=self.var_, last_sample_count=np.repeat(self.n_samples_seen_, X.shape[1]))
        n_total_samples = n_total_samples[0]
        if self.n_samples_seen_ == 0:
            X -= col_mean
        else:
            col_batch_mean = np.mean(X, axis=0)
            X -= col_batch_mean
            mean_correction = np.sqrt(self.n_samples_seen_ * n_samples / n_total_samples) * (self.mean_ - col_batch_mean)
            X = np.vstack((self.singular_values_.reshape((-1, 1)) * self.components_, X, mean_correction))
        U, S, V = linalg.svd(X, full_matrices=False)
        U, V = svd_flip(U, V, u_based_decision=False)
        explained_variance = S ** 2 / (n_total_samples - 1)
        explained_variance_ratio = S ** 2 / np.sum(col_var * n_total_samples)
        self.n_samples_seen_ = n_total_samples
        self.components_ = V[:self.n_components_]
        self.singular_values_ = S[:self.n_components_]
        self.mean_ = col_mean
        self.var_ = col_var
        self.explained_variance_ = explained_variance[:self.n_components_]
        self.explained_variance_ratio_ = explained_variance_ratio[:self.n_components_]
        if self.n_components_ < n_features:
            self.noise_variance_ = explained_variance[self.n_components_:].mean()
        else:
            self.noise_variance_ = 0.0
        return self

    def transform(self, X):
        if sparse.issparse(X):
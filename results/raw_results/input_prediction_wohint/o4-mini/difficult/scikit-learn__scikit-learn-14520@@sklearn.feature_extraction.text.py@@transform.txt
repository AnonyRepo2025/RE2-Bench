[THOUGHT]
To get a 4×11 TF–IDF matrix you need exactly four documents whose combined vocabulary size is 11.  This is the canonical “sky/sun” example that appears in many scikit-learn tutorials:

    docs = [
      "The sky is blue",
      "The sun is bright",
      "The sun in the sky is bright",
      "We can see the shining sun, the bright sun"
    ]

CountVectorizer on these four lower‐cased, word‐tokenized documents produces exactly 11 distinct tokens:

    ['the','sky','is','blue','sun','bright','in','we','can','see','shining']

and TfidfVectorizer with smooth_idf=True, sublinear_tf=False and norm='l2' yields a 4×11 CSR with the nonzero indices and data shown.

Thus, the call was

    tfidf = TfidfVectorizer()
    tfidf.fit(corpus)          # builds vocabulary_ and idf_
    X = tfidf.transform(corpus)

with default copy='deprecated'.  Hence the input JSON is:
[INPUT]
{
  "self": {
    "input": "content",
    "encoding": "utf-8",
    "decode_error": "strict",
    "strip_accents": null,
    "lowercase": true,
    "preprocessor": null,
    "tokenizer": null,
    "analyzer": "word",
    "stop_words": null,
    "token_pattern": "(?u)\\\\b\\\\w\\\\w+\\\\b",
    "ngram_range": [1, 1],
    "max_df": 1.0,
    "min_df": 1,
    "max_features": null,
    "vocabulary_": {
      "the": 0,
      "sky": 1,
      "is": 2,
      "blue": 3,
      "sun": 4,
      "bright": 5,
      "in": 6,
      "we": 7,
      "can": 8,
      "see": 9,
      "shining": 10
    },
    "_tfidf": {
      "norm": "l2",
      "use_idf": true,
      "smooth_idf": true,
      "sublinear_tf": false,
      "idf_": [
        1.2231435513,
        1.5108256238,
        1.5108256238,
        1.9162907319,
        1.2231435513,
        1.9162907319,
        1.5108256238,
        1.9162907319,
        1.0,
        1.9162907319,
        1.9162907319
      ]
    }
  },
  "raw_documents": [
    "The sky is blue",
    "The sun is bright",
    "The sun in the sky is bright",
    "We can see the shining sun, the bright sun"
  ],
  "copy": "deprecated"
}
[/INPUT]